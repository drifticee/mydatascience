{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    " \n",
    " \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16828,
     "status": "ok",
     "timestamp": 1598155136621,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "4J-uM_NYZaui",
    "outputId": "edfdb337-fb39-4a12-94d8-400fea4f7313"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6394,
     "status": "ok",
     "timestamp": 1598155139625,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "9GCffZJIRF-O",
    "outputId": "b9d185b6-94e8-44e1-bd2c-70125bbd6f78"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('/content/drive/My Drive/cvision_1/train.csv')\n",
    "test = pd.read_csv('/content/drive/My Drive/cvision_1/test.csv')\n",
    "submission = pd.read_csv('/content/drive/My Drive/cvision_1/submission.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "      <th>letter</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>2044</td>\n",
       "      <td>6</td>\n",
       "      <td>V</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>2045</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>2046</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>2047</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2048</td>\n",
       "      <td>5</td>\n",
       "      <td>Z</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows × 787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  digit letter  0  1  2  3  4  5  6  ...  774  775  776  777  778  \\\n",
       "0        1      5      L  1  1  1  4  3  0  0  ...    2    1    0    1    2   \n",
       "1        2      0      B  0  4  0  0  4  1  1  ...    0    3    0    1    4   \n",
       "2        3      4      L  1  1  2  2  1  1  1  ...    3    3    3    0    2   \n",
       "3        4      9      D  1  2  0  2  0  4  0  ...    3    3    2    0    1   \n",
       "4        5      6      A  3  0  2  4  0  3  0  ...    4    4    3    2    1   \n",
       "...    ...    ...    ... .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...   \n",
       "2043  2044      6      V  2  4  3  4  2  4  4  ...    0    2    2    0    0   \n",
       "2044  2045      1      L  3  2  2  1  1  4  0  ...    2    3    4    2    1   \n",
       "2045  2046      9      A  4  0  4  0  2  4  4  ...    2    3    1    1    3   \n",
       "2046  2047      0      Z  2  3  3  0  3  0  4  ...    2    3    1    1    0   \n",
       "2047  2048      5      Z  4  2  2  1  3  0  0  ...    4    2    4    0    4   \n",
       "\n",
       "      779  780  781  782  783  \n",
       "0       4    4    4    3    4  \n",
       "1       1    4    2    1    2  \n",
       "2       0    3    0    2    2  \n",
       "3       4    0    0    1    1  \n",
       "4       3    4    3    1    2  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "2043    1    3    1    4    0  \n",
       "2044    2    3    4    1    1  \n",
       "2045    4    2    2    0    0  \n",
       "2046    4    1    4    3    1  \n",
       "2047    3    2    4    3    4  \n",
       "\n",
       "[2048 rows x 787 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#local 연결 전용\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('data/cvision/train.csv')\n",
    "test = pd.read_csv('data/cvision/test.csv')\n",
    "submission = pd.read_csv('data/cvision/submission.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5632,
     "status": "ok",
     "timestamp": 1598155139628,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "1zwkSGXiRF-S"
   },
   "outputs": [],
   "source": [
    "#X와 y 분리\n",
    "X = train.drop(['id','digit','letter'], axis=1).values\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "X = X/255.\n",
    "\n",
    "y = train['digit']\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5688,
     "status": "ok",
     "timestamp": 1598155140257,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "XrcmgXVBRF-V"
   },
   "outputs": [],
   "source": [
    "#train과 valid로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5350,
     "status": "ok",
     "timestamp": 1597982635917,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "gaxhVV6TRF-X",
    "outputId": "084bfeec-31ae-4b76-bad3-80c9c3797202",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#그림 시각화\n",
    "data = np.where(train_X >= 150/255., train_X, 0)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(train_X[i].reshape(28,28))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(data[i,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('number ' + str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec4UH2IrRF-c"
   },
   "outputs": [],
   "source": [
    "#숫자 있는 부분만 추출 (이걸로만 딥러닝해보니 성과 매우 안 좋음,\n",
    "#이 방식 적용할 거면 train, valid, test 모두 이런 형식으로 변형한 후 해야할 듯)\n",
    "\n",
    "#train_X = np.where(train_X >= 150/255., train_X, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1597801710042,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yqeCSgUDRF-f",
    "outputId": "deb594a8-d67a-48bc-e508-2a63e492992e"
   },
   "outputs": [],
   "source": [
    "#별 거 아님 kernel 예시\n",
    "from scipy.signal import correlate2d\n",
    "\n",
    "kernel = np.array(\n",
    "[\n",
    "    [0, -100, 0],\n",
    "    [0, 255, 0],\n",
    "    [0,-100,0]\n",
    "])\n",
    "plt.imshow(correlate2d(train_X[0].reshape(28,28), kernel, mode='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fd66eFzY4Mj3"
   },
   "outputs": [],
   "source": [
    "#model_4: 0.8284\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout, MaxPool2D,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.10, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=3, activation='relu', input_shape = train_X.shape[1:]))\n",
    "    model.add(Conv2D(32,kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(32,kernel_size=3, strides=2, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64,kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(64,kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(64,kernel_size=3, strides=2, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128,kernel_size=4, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRduAyEEAZ9F"
   },
   "outputs": [],
   "source": [
    "#model_5\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.10, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1597815169880,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "wDOUiuAiRF-p",
    "outputId": "7e701e81-6a8c-44d2-d13f-61ce1fd01abb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPbJftOsRF-s"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.975 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 571595,
     "status": "ok",
     "timestamp": 1597815744083,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "vJymm1W6RF-u",
    "outputId": "99976e7d-f05b-4bd4-ac9c-f63a9b111f30",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 120\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    "    #callbacks=[annealer],\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XF1MPFKyRF-w"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'/content/drive/My Drive/cvision_1/params_5.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'/content/drive/My Drive/cvision_1/model_5.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fjm7D-7jRF-z"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict(test_X)\n",
    "\n",
    "#submission 파일 생성\n",
    "for i in range(len(res)):\n",
    "    submission.digit[i] = int(res[i].argmax())\n",
    "submission.to_csv('/content/drive/My Drive/cvision_1/my_subm_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9V1sl_PZkAw"
   },
   "outputs": [],
   "source": [
    "#model_6\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.10, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2J4dDK7WcMjX"
   },
   "outputs": [],
   "source": [
    "#model_6\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.1, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1597828789914,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "bG2wRBFqSufq",
    "outputId": "f6766304-bc50-4e52-e751-289fafc95502"
   },
   "outputs": [],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q73HFCn7TfqS"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 690159,
     "status": "ok",
     "timestamp": 1597829479885,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "WjESPwIkTb3s",
    "outputId": "a89b9895-8416-4155-b03c-88500199cd8f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    "    #callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 688963,
     "status": "ok",
     "timestamp": 1597829480386,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "Ppp3z5-lXawC",
    "outputId": "29fc344b-1b47-4573-cc29-ed86cb5c3f91"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTtpmPijTjmk"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'/content/drive/My Drive/cvision_1/params_6.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'/content/drive/My Drive/cvision_1/model_6.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFSBLgQKTmM2"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('/content/drive/My Drive/cvision_1/my_subm_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qcD4AYCGQ9Np"
   },
   "outputs": [],
   "source": [
    "#model_8인데 데이터 부풀리기 x, 학습률 감소 x\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "'''\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.1, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "'''\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnWl2qzoURfw"
   },
   "outputs": [],
   "source": [
    "#model_8인데 데이터 부풀리기 x, 학습률 감소 x\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "'''\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.1, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "'''\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1597987417365,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "pO2aXT2wRIxn",
    "outputId": "844cd092-1f77-4b2f-ec82-a73fd3218df2"
   },
   "outputs": [],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 398869,
     "status": "error",
     "timestamp": 1597987815537,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "nS8BcL7CRNa7",
    "outputId": "5df7083b-3e1b-4666-b8bc-7dd13f53d38c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    "    #callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 604665,
     "status": "ok",
     "timestamp": 1597904733003,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "bseu0T8lRl3X",
    "outputId": "d803d7b7-14d2-42c9-8068-86e0d941c10c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2moYVE1jTLc"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'/content/drive/My Drive/cvision_1/params_9.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'/content/drive/My Drive/cvision_1/model_9.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12146,
     "status": "ok",
     "timestamp": 1597904941423,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "HDMU0LnTjiwo",
    "outputId": "7704ff38-1a02-49b2-80a3-f263ac8fcf35"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('/content/drive/My Drive/cvision_1/my_subm_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1598178326978,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "sTKcFoyikcjV"
   },
   "outputs": [],
   "source": [
    "#model_9-3 9-2에서 optimizer만 RMSprop로 바꿔봄\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), Adagrad(lr=0.01, epsilon=None, decay=0.0), adadelta, adam\n",
    "    model.compile(optimizer=RMSprop(lr=0.001, rho=0.95, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1598178327240,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "ySu34IFkkhNe",
    "outputId": "35e5e9cf-6ace-4666-d8f8-9a78010b08ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1130 (Conv2D)         (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1131 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_1132 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1133 (Conv2D)         (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_1134 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_1135 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1136 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_1137 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_1138 (Conv2D)         (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 133,648\n",
      "Trainable params: 133,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1598165198924,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "tPFielyJ5yMH"
   },
   "outputs": [],
   "source": [
    "'''#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** x)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19652,
     "status": "error",
     "timestamp": 1598178350080,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "cb892981-08ed-4ba9-af29-c492b265fb8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/230\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 2.3177 - accuracy: 0.1124 - val_loss: 2.3050 - val_accuracy: 0.1234\n",
      "Epoch 2/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.2986 - accuracy: 0.1224 - val_loss: 2.2818 - val_accuracy: 0.1364\n",
      "Epoch 3/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.2723 - accuracy: 0.1475 - val_loss: 2.2041 - val_accuracy: 0.2403\n",
      "Epoch 4/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.2194 - accuracy: 0.1698 - val_loss: 2.1775 - val_accuracy: 0.3084\n",
      "Epoch 5/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.1228 - accuracy: 0.2289 - val_loss: 1.9912 - val_accuracy: 0.3052\n",
      "Epoch 6/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.0449 - accuracy: 0.2600 - val_loss: 1.8695 - val_accuracy: 0.4383\n",
      "Epoch 7/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.0128 - accuracy: 0.2810 - val_loss: 1.8475 - val_accuracy: 0.4221\n",
      "Epoch 8/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.9614 - accuracy: 0.2945 - val_loss: 1.8433 - val_accuracy: 0.4156\n",
      "Epoch 9/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.9551 - accuracy: 0.2910 - val_loss: 1.9247 - val_accuracy: 0.4188\n",
      "Epoch 10/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.8949 - accuracy: 0.3296 - val_loss: 1.7544 - val_accuracy: 0.3766\n",
      "Epoch 11/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.8602 - accuracy: 0.3460 - val_loss: 1.5965 - val_accuracy: 0.4903\n",
      "Epoch 12/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.7710 - accuracy: 0.3700 - val_loss: 1.7271 - val_accuracy: 0.4481\n",
      "Epoch 13/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.7467 - accuracy: 0.3917 - val_loss: 1.8237 - val_accuracy: 0.3474\n",
      "Epoch 14/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.6872 - accuracy: 0.4227 - val_loss: 1.4903 - val_accuracy: 0.5325\n",
      "Epoch 15/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.6345 - accuracy: 0.4444 - val_loss: 1.5117 - val_accuracy: 0.5682\n",
      "Epoch 16/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.5943 - accuracy: 0.4496 - val_loss: 1.8145 - val_accuracy: 0.3766\n",
      "Epoch 17/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.5349 - accuracy: 0.4649 - val_loss: 1.5299 - val_accuracy: 0.5390\n",
      "Epoch 18/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.5205 - accuracy: 0.4778 - val_loss: 1.2588 - val_accuracy: 0.5974\n",
      "Epoch 19/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.4652 - accuracy: 0.5000 - val_loss: 1.2626 - val_accuracy: 0.6201\n",
      "Epoch 20/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.4198 - accuracy: 0.5105 - val_loss: 1.1165 - val_accuracy: 0.6656\n",
      "Epoch 21/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3907 - accuracy: 0.5181 - val_loss: 1.1452 - val_accuracy: 0.6234\n",
      "Epoch 22/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3534 - accuracy: 0.5322 - val_loss: 1.0149 - val_accuracy: 0.6916\n",
      "Epoch 23/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3238 - accuracy: 0.5632 - val_loss: 1.0673 - val_accuracy: 0.6948\n",
      "Epoch 24/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3346 - accuracy: 0.5404 - val_loss: 0.8865 - val_accuracy: 0.7143\n",
      "Epoch 25/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2577 - accuracy: 0.5761 - val_loss: 1.0915 - val_accuracy: 0.6558\n",
      "Epoch 26/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2388 - accuracy: 0.5714 - val_loss: 0.9715 - val_accuracy: 0.7013\n",
      "Epoch 27/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2483 - accuracy: 0.5755 - val_loss: 0.9189 - val_accuracy: 0.7110\n",
      "Epoch 28/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1921 - accuracy: 0.5925 - val_loss: 0.8702 - val_accuracy: 0.7403\n",
      "Epoch 29/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1864 - accuracy: 0.5954 - val_loss: 0.8952 - val_accuracy: 0.7175\n",
      "Epoch 30/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1314 - accuracy: 0.6241 - val_loss: 0.9693 - val_accuracy: 0.6948\n",
      "Epoch 31/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1450 - accuracy: 0.6025 - val_loss: 0.8525 - val_accuracy: 0.7240\n",
      "Epoch 32/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1039 - accuracy: 0.6183 - val_loss: 0.9708 - val_accuracy: 0.6721\n",
      "Epoch 33/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1173 - accuracy: 0.6189 - val_loss: 0.8858 - val_accuracy: 0.7175\n",
      "Epoch 34/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0926 - accuracy: 0.6235 - val_loss: 0.8311 - val_accuracy: 0.7305\n",
      "Epoch 35/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0195 - accuracy: 0.6399 - val_loss: 0.7765 - val_accuracy: 0.7760\n",
      "Epoch 36/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9932 - accuracy: 0.6710 - val_loss: 0.7761 - val_accuracy: 0.7695\n",
      "Epoch 37/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.0452 - accuracy: 0.6475 - val_loss: 0.7581 - val_accuracy: 0.7760\n",
      "Epoch 38/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.0113 - accuracy: 0.6458 - val_loss: 0.7927 - val_accuracy: 0.7468\n",
      "Epoch 39/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9987 - accuracy: 0.6669 - val_loss: 0.7346 - val_accuracy: 0.7630\n",
      "Epoch 40/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0015 - accuracy: 0.6622 - val_loss: 0.7314 - val_accuracy: 0.7727\n",
      "Epoch 41/230\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9653 - accuracy: 0.67 - 1s 11ms/step - loss: 0.9715 - accuracy: 0.6686 - val_loss: 0.6716 - val_accuracy: 0.7987\n",
      "Epoch 42/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9481 - accuracy: 0.6862 - val_loss: 0.7151 - val_accuracy: 0.7760\n",
      "Epoch 43/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9331 - accuracy: 0.6827 - val_loss: 0.8850 - val_accuracy: 0.6753\n",
      "Epoch 44/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9241 - accuracy: 0.6891 - val_loss: 0.6987 - val_accuracy: 0.7727\n",
      "Epoch 45/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8992 - accuracy: 0.6815 - val_loss: 0.6598 - val_accuracy: 0.7597\n",
      "Epoch 46/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8768 - accuracy: 0.7043 - val_loss: 0.8030 - val_accuracy: 0.7078\n",
      "Epoch 47/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9533 - accuracy: 0.6811 - val_loss: 0.6511 - val_accuracy: 0.7857\n",
      "Epoch 48/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8595 - accuracy: 0.6956 - val_loss: 0.5535 - val_accuracy: 0.8052\n",
      "Epoch 49/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9123 - accuracy: 0.6885 - val_loss: 0.6170 - val_accuracy: 0.8019\n",
      "Epoch 50/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.8473 - accuracy: 0.7143 - val_loss: 0.5661 - val_accuracy: 0.8019\n",
      "Epoch 51/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8663 - accuracy: 0.6967 - val_loss: 0.5684 - val_accuracy: 0.8247\n",
      "Epoch 52/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8399 - accuracy: 0.7149 - val_loss: 0.6037 - val_accuracy: 0.8214\n",
      "Epoch 53/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8163 - accuracy: 0.7160 - val_loss: 0.6094 - val_accuracy: 0.7987\n",
      "Epoch 54/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8425 - accuracy: 0.7049 - val_loss: 0.5611 - val_accuracy: 0.7955\n",
      "Epoch 55/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8168 - accuracy: 0.7090 - val_loss: 0.6181 - val_accuracy: 0.7857\n",
      "Epoch 56/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7773 - accuracy: 0.7313 - val_loss: 0.6119 - val_accuracy: 0.7955\n",
      "Epoch 57/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.8248 - accuracy: 0.7242 - val_loss: 0.6019 - val_accuracy: 0.8149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7739 - accuracy: 0.7348 - val_loss: 0.6018 - val_accuracy: 0.7922\n",
      "Epoch 59/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7909 - accuracy: 0.7336 - val_loss: 0.6387 - val_accuracy: 0.7695\n",
      "Epoch 60/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7693 - accuracy: 0.7459 - val_loss: 0.6013 - val_accuracy: 0.8052\n",
      "Epoch 61/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7673 - accuracy: 0.7365 - val_loss: 0.5130 - val_accuracy: 0.8344\n",
      "Epoch 62/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7447 - accuracy: 0.7518 - val_loss: 0.6460 - val_accuracy: 0.8084\n",
      "Epoch 63/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7523 - accuracy: 0.7518 - val_loss: 0.5000 - val_accuracy: 0.8409\n",
      "Epoch 64/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7247 - accuracy: 0.7506 - val_loss: 0.6095 - val_accuracy: 0.7955\n",
      "Epoch 65/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7170 - accuracy: 0.7518 - val_loss: 0.5885 - val_accuracy: 0.7955\n",
      "Epoch 66/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7369 - accuracy: 0.7512 - val_loss: 0.6119 - val_accuracy: 0.7695\n",
      "Epoch 67/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7083 - accuracy: 0.7594 - val_loss: 0.4885 - val_accuracy: 0.8344\n",
      "Epoch 68/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7254 - accuracy: 0.7523 - val_loss: 0.4787 - val_accuracy: 0.8377\n",
      "Epoch 69/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7286 - accuracy: 0.7576 - val_loss: 0.5186 - val_accuracy: 0.8377\n",
      "Epoch 70/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6793 - accuracy: 0.7646 - val_loss: 0.5703 - val_accuracy: 0.8149\n",
      "Epoch 71/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6988 - accuracy: 0.7605 - val_loss: 0.5299 - val_accuracy: 0.8149\n",
      "Epoch 72/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6631 - accuracy: 0.7758 - val_loss: 0.6274 - val_accuracy: 0.7825\n",
      "Epoch 73/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6650 - accuracy: 0.7641 - val_loss: 0.5105 - val_accuracy: 0.8247\n",
      "Epoch 74/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6457 - accuracy: 0.7769 - val_loss: 0.5771 - val_accuracy: 0.7987\n",
      "Epoch 75/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6977 - accuracy: 0.7594 - val_loss: 0.4793 - val_accuracy: 0.8279\n",
      "Epoch 76/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6522 - accuracy: 0.7763 - val_loss: 0.5858 - val_accuracy: 0.8149\n",
      "Epoch 77/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6635 - accuracy: 0.7641 - val_loss: 0.5228 - val_accuracy: 0.8117\n",
      "Epoch 78/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6658 - accuracy: 0.7799 - val_loss: 0.5041 - val_accuracy: 0.8442\n",
      "Epoch 79/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6588 - accuracy: 0.7875 - val_loss: 0.6038 - val_accuracy: 0.8019\n",
      "Epoch 80/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6423 - accuracy: 0.7810 - val_loss: 0.4605 - val_accuracy: 0.8506\n",
      "Epoch 81/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6312 - accuracy: 0.7828 - val_loss: 0.4990 - val_accuracy: 0.8506\n",
      "Epoch 82/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6483 - accuracy: 0.7769 - val_loss: 0.4782 - val_accuracy: 0.8474\n",
      "Epoch 83/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6581 - accuracy: 0.7676 - val_loss: 0.5275 - val_accuracy: 0.8312\n",
      "Epoch 84/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6654 - accuracy: 0.7746 - val_loss: 0.4795 - val_accuracy: 0.8377\n",
      "Epoch 85/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6280 - accuracy: 0.7922 - val_loss: 0.4741 - val_accuracy: 0.8571\n",
      "Epoch 86/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5763 - accuracy: 0.7992 - val_loss: 0.4233 - val_accuracy: 0.8669\n",
      "Epoch 87/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5899 - accuracy: 0.7992 - val_loss: 0.4360 - val_accuracy: 0.8734\n",
      "Epoch 88/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6025 - accuracy: 0.8050 - val_loss: 0.4724 - val_accuracy: 0.8377\n",
      "Epoch 89/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6041 - accuracy: 0.7998 - val_loss: 0.4556 - val_accuracy: 0.8506\n",
      "Epoch 90/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5971 - accuracy: 0.7992 - val_loss: 0.5826 - val_accuracy: 0.7955\n",
      "Epoch 91/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5931 - accuracy: 0.7945 - val_loss: 0.5675 - val_accuracy: 0.8247\n",
      "Epoch 92/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5908 - accuracy: 0.7875 - val_loss: 0.4997 - val_accuracy: 0.8442\n",
      "Epoch 93/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6145 - accuracy: 0.7922 - val_loss: 0.5062 - val_accuracy: 0.8149\n",
      "Epoch 94/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5989 - accuracy: 0.7951 - val_loss: 0.4525 - val_accuracy: 0.8506\n",
      "Epoch 95/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5821 - accuracy: 0.7998 - val_loss: 0.4634 - val_accuracy: 0.8474\n",
      "Epoch 96/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5883 - accuracy: 0.7986 - val_loss: 0.4475 - val_accuracy: 0.8279\n",
      "Epoch 97/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5777 - accuracy: 0.8056 - val_loss: 0.4844 - val_accuracy: 0.8312\n",
      "Epoch 98/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5971 - accuracy: 0.7927 - val_loss: 0.4933 - val_accuracy: 0.8312\n",
      "Epoch 99/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5654 - accuracy: 0.8074 - val_loss: 0.4268 - val_accuracy: 0.8604\n",
      "Epoch 100/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5543 - accuracy: 0.8056 - val_loss: 0.4702 - val_accuracy: 0.8279\n",
      "Epoch 101/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5759 - accuracy: 0.8050 - val_loss: 0.4207 - val_accuracy: 0.8539\n",
      "Epoch 102/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5605 - accuracy: 0.8033 - val_loss: 0.4433 - val_accuracy: 0.8539\n",
      "Epoch 103/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5445 - accuracy: 0.8203 - val_loss: 0.4404 - val_accuracy: 0.8442\n",
      "Epoch 104/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5624 - accuracy: 0.8103 - val_loss: 0.4165 - val_accuracy: 0.8604\n",
      "Epoch 105/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5452 - accuracy: 0.8144 - val_loss: 0.4152 - val_accuracy: 0.8604\n",
      "Epoch 106/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5701 - accuracy: 0.8074 - val_loss: 0.4217 - val_accuracy: 0.8636\n",
      "Epoch 107/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5230 - accuracy: 0.8296 - val_loss: 0.6655 - val_accuracy: 0.7922\n",
      "Epoch 108/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5247 - accuracy: 0.8208 - val_loss: 0.4336 - val_accuracy: 0.8571\n",
      "Epoch 109/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5333 - accuracy: 0.8185 - val_loss: 0.4924 - val_accuracy: 0.8279\n",
      "Epoch 110/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5110 - accuracy: 0.8273 - val_loss: 0.4556 - val_accuracy: 0.8409\n",
      "Epoch 111/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5310 - accuracy: 0.8091 - val_loss: 0.4325 - val_accuracy: 0.8506\n",
      "Epoch 112/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5458 - accuracy: 0.8132 - val_loss: 0.4134 - val_accuracy: 0.8571\n",
      "Epoch 113/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5328 - accuracy: 0.8191 - val_loss: 0.4153 - val_accuracy: 0.8571\n",
      "Epoch 114/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5189 - accuracy: 0.8197 - val_loss: 0.4529 - val_accuracy: 0.8377\n",
      "Epoch 115/230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5223 - accuracy: 0.8232 - val_loss: 0.4189 - val_accuracy: 0.8571\n",
      "Epoch 116/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5050 - accuracy: 0.8232 - val_loss: 0.3767 - val_accuracy: 0.8766\n",
      "Epoch 117/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.4927 - accuracy: 0.8244 - val_loss: 0.3828 - val_accuracy: 0.8636\n",
      "Epoch 118/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4960 - accuracy: 0.8191 - val_loss: 0.4566 - val_accuracy: 0.8442\n",
      "Epoch 119/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4953 - accuracy: 0.8367 - val_loss: 0.4092 - val_accuracy: 0.8701\n",
      "Epoch 120/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5260 - accuracy: 0.8109 - val_loss: 0.5021 - val_accuracy: 0.8344\n",
      "Epoch 121/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5075 - accuracy: 0.8255 - val_loss: 0.3741 - val_accuracy: 0.8799\n",
      "Epoch 122/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4718 - accuracy: 0.8349 - val_loss: 0.4149 - val_accuracy: 0.8636\n",
      "Epoch 123/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4893 - accuracy: 0.8285 - val_loss: 0.3955 - val_accuracy: 0.8734\n",
      "Epoch 124/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4911 - accuracy: 0.8308 - val_loss: 0.4521 - val_accuracy: 0.8506\n",
      "Epoch 125/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5092 - accuracy: 0.8308 - val_loss: 0.4509 - val_accuracy: 0.8506\n",
      "Epoch 126/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4643 - accuracy: 0.8396 - val_loss: 0.4137 - val_accuracy: 0.8506\n",
      "Epoch 127/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4980 - accuracy: 0.8314 - val_loss: 0.3651 - val_accuracy: 0.8734\n",
      "Epoch 128/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5201 - accuracy: 0.8273 - val_loss: 0.4537 - val_accuracy: 0.8571\n",
      "Epoch 129/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5283 - accuracy: 0.8162 - val_loss: 0.4360 - val_accuracy: 0.8442\n",
      "Epoch 130/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4743 - accuracy: 0.8402 - val_loss: 0.3794 - val_accuracy: 0.8506\n",
      "Epoch 131/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4995 - accuracy: 0.8296 - val_loss: 0.3629 - val_accuracy: 0.8734\n",
      "Epoch 132/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4887 - accuracy: 0.8214 - val_loss: 0.3670 - val_accuracy: 0.8734\n",
      "Epoch 133/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4913 - accuracy: 0.8337 - val_loss: 0.4355 - val_accuracy: 0.8377\n",
      "Epoch 134/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4631 - accuracy: 0.8331 - val_loss: 0.4081 - val_accuracy: 0.8409\n",
      "Epoch 135/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4617 - accuracy: 0.8448 - val_loss: 0.4126 - val_accuracy: 0.8571\n",
      "Epoch 136/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4250 - accuracy: 0.8571 - val_loss: 0.4091 - val_accuracy: 0.8506\n",
      "Epoch 137/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4703 - accuracy: 0.8355 - val_loss: 0.4157 - val_accuracy: 0.8442\n",
      "Epoch 138/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4312 - accuracy: 0.8536 - val_loss: 0.6881 - val_accuracy: 0.7792\n",
      "Epoch 139/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4571 - accuracy: 0.8443 - val_loss: 0.4421 - val_accuracy: 0.8539\n",
      "Epoch 140/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4565 - accuracy: 0.8431 - val_loss: 0.3743 - val_accuracy: 0.8734\n",
      "Epoch 141/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4972 - accuracy: 0.8267 - val_loss: 0.4497 - val_accuracy: 0.8571\n",
      "Epoch 142/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4625 - accuracy: 0.8349 - val_loss: 0.4282 - val_accuracy: 0.8571\n",
      "Epoch 143/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4723 - accuracy: 0.8337 - val_loss: 0.4391 - val_accuracy: 0.8377\n",
      "Epoch 144/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4243 - accuracy: 0.8548 - val_loss: 0.4713 - val_accuracy: 0.8442\n",
      "Epoch 145/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4324 - accuracy: 0.8536 - val_loss: 0.4646 - val_accuracy: 0.8474\n",
      "Epoch 146/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4689 - accuracy: 0.8367 - val_loss: 0.4995 - val_accuracy: 0.8214\n",
      "Epoch 147/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4394 - accuracy: 0.8413 - val_loss: 0.4976 - val_accuracy: 0.8312\n",
      "Epoch 148/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4387 - accuracy: 0.8407 - val_loss: 0.5034 - val_accuracy: 0.8312\n",
      "Epoch 149/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4473 - accuracy: 0.8390 - val_loss: 0.4072 - val_accuracy: 0.8442\n",
      "Epoch 150/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4536 - accuracy: 0.8443 - val_loss: 0.5050 - val_accuracy: 0.8182\n",
      "Epoch 151/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4197 - accuracy: 0.8607 - val_loss: 0.4946 - val_accuracy: 0.8409\n",
      "Epoch 152/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4526 - accuracy: 0.8507 - val_loss: 0.4987 - val_accuracy: 0.8149\n",
      "Epoch 153/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4534 - accuracy: 0.8460 - val_loss: 0.4463 - val_accuracy: 0.8506\n",
      "Epoch 154/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3870 - accuracy: 0.8706 - val_loss: 0.4379 - val_accuracy: 0.8539\n",
      "Epoch 155/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3913 - accuracy: 0.8642 - val_loss: 0.4166 - val_accuracy: 0.8377\n",
      "Epoch 156/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4195 - accuracy: 0.8548 - val_loss: 0.4562 - val_accuracy: 0.8442\n",
      "Epoch 157/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4318 - accuracy: 0.8443 - val_loss: 0.4946 - val_accuracy: 0.8214\n",
      "Epoch 158/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4403 - accuracy: 0.8448 - val_loss: 0.4147 - val_accuracy: 0.8539\n",
      "Epoch 159/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4061 - accuracy: 0.8612 - val_loss: 0.4974 - val_accuracy: 0.8247\n",
      "Epoch 160/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4252 - accuracy: 0.8560 - val_loss: 0.4254 - val_accuracy: 0.8636\n",
      "Epoch 161/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4234 - accuracy: 0.8495 - val_loss: 0.4465 - val_accuracy: 0.8474\n",
      "Epoch 162/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4072 - accuracy: 0.8560 - val_loss: 0.4465 - val_accuracy: 0.8279\n",
      "Epoch 163/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.4340 - accuracy: 0.8583 - val_loss: 0.4420 - val_accuracy: 0.8474\n",
      "Epoch 164/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4064 - accuracy: 0.8560 - val_loss: 0.5297 - val_accuracy: 0.8279\n",
      "Epoch 165/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4226 - accuracy: 0.8648 - val_loss: 0.4863 - val_accuracy: 0.8442\n",
      "Epoch 166/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.4153 - accuracy: 0.8560 - val_loss: 0.5444 - val_accuracy: 0.8052\n",
      "Epoch 167/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4555 - accuracy: 0.8448 - val_loss: 0.4393 - val_accuracy: 0.8344\n",
      "Epoch 168/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4088 - accuracy: 0.8595 - val_loss: 0.4376 - val_accuracy: 0.8539\n",
      "Epoch 169/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4198 - accuracy: 0.8560 - val_loss: 0.3890 - val_accuracy: 0.8669\n",
      "Epoch 170/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3958 - accuracy: 0.8683 - val_loss: 0.4161 - val_accuracy: 0.8636\n",
      "Epoch 171/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4086 - accuracy: 0.8548 - val_loss: 0.4671 - val_accuracy: 0.8377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4291 - accuracy: 0.8560 - val_loss: 0.4311 - val_accuracy: 0.8474\n",
      "Epoch 173/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3975 - accuracy: 0.8576 - val_loss: 0.4103 - val_accuracy: 0.8636\n",
      "Epoch 174/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4285 - accuracy: 0.8402 - val_loss: 0.4310 - val_accuracy: 0.8377\n",
      "Epoch 175/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3950 - accuracy: 0.8636 - val_loss: 0.4220 - val_accuracy: 0.8474\n",
      "Epoch 176/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3994 - accuracy: 0.8648 - val_loss: 0.4846 - val_accuracy: 0.8474\n",
      "Epoch 177/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3839 - accuracy: 0.8694 - val_loss: 0.4736 - val_accuracy: 0.8442\n",
      "Epoch 178/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4061 - accuracy: 0.8519 - val_loss: 0.5389 - val_accuracy: 0.8247\n",
      "Epoch 179/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3863 - accuracy: 0.8612 - val_loss: 0.5457 - val_accuracy: 0.8214\n",
      "Epoch 180/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3981 - accuracy: 0.8583 - val_loss: 0.4691 - val_accuracy: 0.8344\n",
      "Epoch 181/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3810 - accuracy: 0.8694 - val_loss: 0.4457 - val_accuracy: 0.8279\n",
      "Epoch 182/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3850 - accuracy: 0.8677 - val_loss: 0.4385 - val_accuracy: 0.8571\n",
      "Epoch 183/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4253 - accuracy: 0.8554 - val_loss: 0.5025 - val_accuracy: 0.8214\n",
      "Epoch 184/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3706 - accuracy: 0.8665 - val_loss: 0.3846 - val_accuracy: 0.8701\n",
      "Epoch 185/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3790 - accuracy: 0.8741 - val_loss: 0.4790 - val_accuracy: 0.8344\n",
      "Epoch 186/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3681 - accuracy: 0.8794 - val_loss: 0.4729 - val_accuracy: 0.8474\n",
      "Epoch 187/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3876 - accuracy: 0.8542 - val_loss: 0.4467 - val_accuracy: 0.8344\n",
      "Epoch 188/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3742 - accuracy: 0.8800 - val_loss: 0.3792 - val_accuracy: 0.8474\n",
      "Epoch 189/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3827 - accuracy: 0.8648 - val_loss: 0.4290 - val_accuracy: 0.8539\n",
      "Epoch 190/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3916 - accuracy: 0.8683 - val_loss: 0.4215 - val_accuracy: 0.8799\n",
      "Epoch 191/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3487 - accuracy: 0.8882 - val_loss: 0.4928 - val_accuracy: 0.8506\n",
      "Epoch 192/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3745 - accuracy: 0.8724 - val_loss: 0.5175 - val_accuracy: 0.8474\n",
      "Epoch 193/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3748 - accuracy: 0.8718 - val_loss: 0.5581 - val_accuracy: 0.8312\n",
      "Epoch 194/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3782 - accuracy: 0.8735 - val_loss: 0.4059 - val_accuracy: 0.8669\n",
      "Epoch 195/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3545 - accuracy: 0.8712 - val_loss: 0.3541 - val_accuracy: 0.8734\n",
      "Epoch 196/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3611 - accuracy: 0.8724 - val_loss: 0.3838 - val_accuracy: 0.8734\n",
      "Epoch 197/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3749 - accuracy: 0.8712 - val_loss: 0.6359 - val_accuracy: 0.8084\n",
      "Epoch 198/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3695 - accuracy: 0.8724 - val_loss: 0.4578 - val_accuracy: 0.8442\n",
      "Epoch 199/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3629 - accuracy: 0.8724 - val_loss: 0.5002 - val_accuracy: 0.8442\n",
      "Epoch 200/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3633 - accuracy: 0.8706 - val_loss: 0.4444 - val_accuracy: 0.8571\n",
      "Epoch 201/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3782 - accuracy: 0.8659 - val_loss: 0.4254 - val_accuracy: 0.8571\n",
      "Epoch 202/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3767 - accuracy: 0.8741 - val_loss: 0.4837 - val_accuracy: 0.8604\n",
      "Epoch 203/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3518 - accuracy: 0.8788 - val_loss: 0.4573 - val_accuracy: 0.8734\n",
      "Epoch 204/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3766 - accuracy: 0.8706 - val_loss: 0.4982 - val_accuracy: 0.8247\n",
      "Epoch 205/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3636 - accuracy: 0.8765 - val_loss: 0.3941 - val_accuracy: 0.8701\n",
      "Epoch 206/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3497 - accuracy: 0.8811 - val_loss: 0.4522 - val_accuracy: 0.8506\n",
      "Epoch 207/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3548 - accuracy: 0.8811 - val_loss: 0.5362 - val_accuracy: 0.8312\n",
      "Epoch 208/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3487 - accuracy: 0.8770 - val_loss: 0.4145 - val_accuracy: 0.8539\n",
      "Epoch 209/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3634 - accuracy: 0.8677 - val_loss: 0.4408 - val_accuracy: 0.8539\n",
      "Epoch 210/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3459 - accuracy: 0.8770 - val_loss: 0.4904 - val_accuracy: 0.8506\n",
      "Epoch 211/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3691 - accuracy: 0.8765 - val_loss: 0.4206 - val_accuracy: 0.8669\n",
      "Epoch 212/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3908 - accuracy: 0.8653 - val_loss: 0.4671 - val_accuracy: 0.8539\n",
      "Epoch 213/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3358 - accuracy: 0.8905 - val_loss: 0.4185 - val_accuracy: 0.8571\n",
      "Epoch 214/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3511 - accuracy: 0.8776 - val_loss: 0.4852 - val_accuracy: 0.8279\n",
      "Epoch 215/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3556 - accuracy: 0.8847 - val_loss: 0.3874 - val_accuracy: 0.8539\n",
      "Epoch 216/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3498 - accuracy: 0.8829 - val_loss: 0.5400 - val_accuracy: 0.8084\n",
      "Epoch 217/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3556 - accuracy: 0.8642 - val_loss: 0.4585 - val_accuracy: 0.8442\n",
      "Epoch 218/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3088 - accuracy: 0.8882 - val_loss: 0.4359 - val_accuracy: 0.8571\n",
      "Epoch 219/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3340 - accuracy: 0.8800 - val_loss: 0.4459 - val_accuracy: 0.8377\n",
      "Epoch 220/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3729 - accuracy: 0.8747 - val_loss: 0.4500 - val_accuracy: 0.8539\n",
      "Epoch 221/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3403 - accuracy: 0.8794 - val_loss: 0.5028 - val_accuracy: 0.8474\n",
      "Epoch 222/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3498 - accuracy: 0.8788 - val_loss: 0.4942 - val_accuracy: 0.8312\n",
      "Epoch 223/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3498 - accuracy: 0.8776 - val_loss: 0.3842 - val_accuracy: 0.8604\n",
      "Epoch 224/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3797 - accuracy: 0.8712 - val_loss: 0.5189 - val_accuracy: 0.8247\n",
      "Epoch 225/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3441 - accuracy: 0.8841 - val_loss: 0.4179 - val_accuracy: 0.8377\n",
      "Epoch 226/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3360 - accuracy: 0.8829 - val_loss: 0.4308 - val_accuracy: 0.8442\n",
      "Epoch 227/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3666 - accuracy: 0.8712 - val_loss: 0.4503 - val_accuracy: 0.8247\n",
      "Epoch 228/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3213 - accuracy: 0.8870 - val_loss: 0.3917 - val_accuracy: 0.8506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3175 - accuracy: 0.8841 - val_loss: 0.4069 - val_accuracy: 0.8701\n",
      "Epoch 230/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3304 - accuracy: 0.8841 - val_loss: 0.4257 - val_accuracy: 0.8701\n",
      "CNN: Epochs=230, Train accuracy=0.89052, Validation accuracy=0.87987\n"
     ]
    }
   ],
   "source": [
    "epochs = 230\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1#, callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2603262,
     "status": "ok",
     "timestamp": 1598167802346,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "9bcd067b-5514-491c-8c63-db77d4fc6967"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#맥스풀링 마지막에만 하고 FC두번 거쳐서 하니 느리지만 꾸준히 정확도 증가 80에서 거의 멈춤 - 해결 방안?\n",
    "#epoch 180정도로 한 결과 = model_9\n",
    "#model_9는 0.89166, 0.87805\n",
    "#model_9-2를 eopch 230, relu 대신 leaky relu\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EQCvPGZks9v"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'data/cvision/params_9.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'data/cvision/model_9.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12146,
     "status": "ok",
     "timestamp": 1597904941423,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "Y-8nb5jokyny",
    "outputId": "7704ff38-1a02-49b2-80a3-f263ac8fcf35"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('data/cvision/my_subm_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1598178326978,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "sTKcFoyikcjV"
   },
   "outputs": [],
   "source": [
    "#model_9-4\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop, Adagrad\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.10, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    #층을 2,3,4,6,3장처럼 더 쌓아보기 (resnet처럼)\n",
    "    model.add(Conv2D(8, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    #model.add(Conv2D(8, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    #model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides=2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    #model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    #model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    #model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    #model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides=2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    #model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    #model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(52, kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), adadelta, adam\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1598178327240,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "ySu34IFkkhNe",
    "outputId": "35e5e9cf-6ace-4666-d8f8-9a78010b08ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1255 (Conv2D)         (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_689 (LeakyReLU)  (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1256 (Conv2D)         (None, 28, 28, 8)         584       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_690 (LeakyReLU)  (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1257 (Conv2D)         (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_691 (LeakyReLU)  (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1258 (Conv2D)         (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_692 (LeakyReLU)  (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1259 (Conv2D)         (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_693 (LeakyReLU)  (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1260 (Conv2D)         (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_694 (LeakyReLU)  (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1261 (Conv2D)         (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_695 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 52)                30004     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_696 (LeakyReLU)  (None, 52)                0         \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 52)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 10)                530       \n",
      "=================================================================\n",
      "Total params: 67,070\n",
      "Trainable params: 67,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19652,
     "status": "error",
     "timestamp": 1598178350080,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "cb892981-08ed-4ba9-af29-c492b265fb8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 5.7119 - accuracy: 0.0896 - val_loss: 2.3477 - val_accuracy: 0.1104\n",
      "Epoch 2/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.8001 - accuracy: 0.1002 - val_loss: 2.3041 - val_accuracy: 0.1266\n",
      "Epoch 3/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.3949 - accuracy: 0.1132 - val_loss: 2.3017 - val_accuracy: 0.1169\n",
      "Epoch 4/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.3463 - accuracy: 0.0983 - val_loss: 2.3023 - val_accuracy: 0.0942\n",
      "Epoch 5/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.3175 - accuracy: 0.1034 - val_loss: 2.3025 - val_accuracy: 0.0812\n",
      "Epoch 6/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.3060 - accuracy: 0.1002 - val_loss: 2.3025 - val_accuracy: 0.0812\n",
      "Epoch 7/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2997 - accuracy: 0.1140 - val_loss: 2.3026 - val_accuracy: 0.1006\n",
      "Epoch 8/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.3032 - accuracy: 0.0993 - val_loss: 2.3025 - val_accuracy: 0.0942\n",
      "Epoch 9/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.3017 - accuracy: 0.1132 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 10/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.3016 - accuracy: 0.1009 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 11/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.3005 - accuracy: 0.1148 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 12/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.3023 - accuracy: 0.1067 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 13/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.3023 - accuracy: 0.1197 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 14/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.3030 - accuracy: 0.1140 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 15/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.3023 - accuracy: 0.1067 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 16/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2984 - accuracy: 0.1140 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 17/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2994 - accuracy: 0.1173 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 18/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.3054 - accuracy: 0.1132 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 19/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 20/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.3010 - accuracy: 0.1246 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 21/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2970 - accuracy: 0.1178 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 22/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2987 - accuracy: 0.1148 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 23/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2992 - accuracy: 0.1034 - val_loss: 2.3026 - val_accuracy: 0.1006\n",
      "Epoch 24/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2985 - accuracy: 0.1276 - val_loss: 2.3026 - val_accuracy: 0.1006\n",
      "Epoch 25/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2972 - accuracy: 0.1238 - val_loss: 2.3026 - val_accuracy: 0.1006\n",
      "Epoch 26/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.3000 - accuracy: 0.1279 - val_loss: 2.3026 - val_accuracy: 0.1006\n",
      "Epoch 27/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2990 - accuracy: 0.1116 - val_loss: 2.3026 - val_accuracy: 0.1006\n",
      "Epoch 28/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.3010 - accuracy: 0.1116 - val_loss: 2.3027 - val_accuracy: 0.1006\n",
      "Epoch 29/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2979 - accuracy: 0.1133 - val_loss: 2.3027 - val_accuracy: 0.1006\n",
      "Epoch 30/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2979 - accuracy: 0.1156 - val_loss: 2.3027 - val_accuracy: 0.1006\n",
      "Epoch 31/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2995 - accuracy: 0.1205 - val_loss: 2.3027 - val_accuracy: 0.1006\n",
      "Epoch 32/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2995 - accuracy: 0.1246 - val_loss: 2.3027 - val_accuracy: 0.1006\n",
      "Epoch 33/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2954 - accuracy: 0.1246 - val_loss: 2.3027 - val_accuracy: 0.1006\n",
      "Epoch 34/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2978 - accuracy: 0.1148 - val_loss: 2.3025 - val_accuracy: 0.1006\n",
      "Epoch 35/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.3016 - accuracy: 0.1034 - val_loss: 2.3024 - val_accuracy: 0.1006\n",
      "Epoch 36/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2998 - accuracy: 0.1238 - val_loss: 2.3024 - val_accuracy: 0.1006\n",
      "Epoch 37/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2959 - accuracy: 0.1287 - val_loss: 2.3022 - val_accuracy: 0.1006\n",
      "Epoch 38/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2964 - accuracy: 0.1083 - val_loss: 2.3019 - val_accuracy: 0.1006\n",
      "Epoch 39/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2967 - accuracy: 0.1107 - val_loss: 2.3016 - val_accuracy: 0.0909\n",
      "Epoch 40/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2947 - accuracy: 0.1156 - val_loss: 2.3013 - val_accuracy: 0.0909\n",
      "Epoch 41/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2997 - accuracy: 0.1059 - val_loss: 2.3010 - val_accuracy: 0.0909\n",
      "Epoch 42/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2997 - accuracy: 0.1262 - val_loss: 2.3007 - val_accuracy: 0.0974\n",
      "Epoch 43/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2950 - accuracy: 0.1352 - val_loss: 2.3004 - val_accuracy: 0.0974\n",
      "Epoch 44/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2970 - accuracy: 0.1213 - val_loss: 2.3000 - val_accuracy: 0.0974\n",
      "Epoch 45/1500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 2.2943 - accuracy: 0.1139 - val_loss: 2.2996 - val_accuracy: 0.0974\n",
      "Epoch 46/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2990 - accuracy: 0.1156 - val_loss: 2.2993 - val_accuracy: 0.1006\n",
      "Epoch 47/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2966 - accuracy: 0.1204 - val_loss: 2.2991 - val_accuracy: 0.1039\n",
      "Epoch 48/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2942 - accuracy: 0.1132 - val_loss: 2.2990 - val_accuracy: 0.1039\n",
      "Epoch 49/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2870 - accuracy: 0.1303 - val_loss: 2.2987 - val_accuracy: 0.1039\n",
      "Epoch 50/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2957 - accuracy: 0.1099 - val_loss: 2.2984 - val_accuracy: 0.1039\n",
      "Epoch 51/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2969 - accuracy: 0.1262 - val_loss: 2.2982 - val_accuracy: 0.1071\n",
      "Epoch 52/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2905 - accuracy: 0.1250 - val_loss: 2.2981 - val_accuracy: 0.1071\n",
      "Epoch 53/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2828 - accuracy: 0.1376 - val_loss: 2.2973 - val_accuracy: 0.1071\n",
      "Epoch 54/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2904 - accuracy: 0.1205 - val_loss: 2.2968 - val_accuracy: 0.1071\n",
      "Epoch 55/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2915 - accuracy: 0.1311 - val_loss: 2.2962 - val_accuracy: 0.1071\n",
      "Epoch 56/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2903 - accuracy: 0.1152 - val_loss: 2.2958 - val_accuracy: 0.1136\n",
      "Epoch 57/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2927 - accuracy: 0.1164 - val_loss: 2.2957 - val_accuracy: 0.1136\n",
      "Epoch 58/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2884 - accuracy: 0.1230 - val_loss: 2.2960 - val_accuracy: 0.1104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2773 - accuracy: 0.1336 - val_loss: 2.2962 - val_accuracy: 0.1039\n",
      "Epoch 60/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2888 - accuracy: 0.1107 - val_loss: 2.2960 - val_accuracy: 0.1039\n",
      "Epoch 61/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2943 - accuracy: 0.1243 - val_loss: 2.2961 - val_accuracy: 0.1039\n",
      "Epoch 62/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2830 - accuracy: 0.1279 - val_loss: 2.2959 - val_accuracy: 0.1039\n",
      "Epoch 63/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2885 - accuracy: 0.1279 - val_loss: 2.2950 - val_accuracy: 0.1071\n",
      "Epoch 64/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2925 - accuracy: 0.1181 - val_loss: 2.2943 - val_accuracy: 0.1104\n",
      "Epoch 65/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2877 - accuracy: 0.1238 - val_loss: 2.2941 - val_accuracy: 0.1071\n",
      "Epoch 66/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2879 - accuracy: 0.1185 - val_loss: 2.2938 - val_accuracy: 0.1071\n",
      "Epoch 67/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.2848 - accuracy: 0.1156 - val_loss: 2.2938 - val_accuracy: 0.1071\n",
      "Epoch 68/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2777 - accuracy: 0.1276 - val_loss: 2.2932 - val_accuracy: 0.1039\n",
      "Epoch 69/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2776 - accuracy: 0.1198 - val_loss: 2.2918 - val_accuracy: 0.1104\n",
      "Epoch 70/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2727 - accuracy: 0.1319 - val_loss: 2.2904 - val_accuracy: 0.1201\n",
      "Epoch 71/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2703 - accuracy: 0.1238 - val_loss: 2.2884 - val_accuracy: 0.1169\n",
      "Epoch 72/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2799 - accuracy: 0.1327 - val_loss: 2.2862 - val_accuracy: 0.1169\n",
      "Epoch 73/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2770 - accuracy: 0.1197 - val_loss: 2.2861 - val_accuracy: 0.1136\n",
      "Epoch 74/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2708 - accuracy: 0.1409 - val_loss: 2.2853 - val_accuracy: 0.1266\n",
      "Epoch 75/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2629 - accuracy: 0.1354 - val_loss: 2.2846 - val_accuracy: 0.1266\n",
      "Epoch 76/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2796 - accuracy: 0.1221 - val_loss: 2.2848 - val_accuracy: 0.1266\n",
      "Epoch 77/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2761 - accuracy: 0.1270 - val_loss: 2.2852 - val_accuracy: 0.1234\n",
      "Epoch 78/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2676 - accuracy: 0.1368 - val_loss: 2.2838 - val_accuracy: 0.1494\n",
      "Epoch 79/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2823 - accuracy: 0.1246 - val_loss: 2.2817 - val_accuracy: 0.1429\n",
      "Epoch 80/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2685 - accuracy: 0.1441 - val_loss: 2.2814 - val_accuracy: 0.1429\n",
      "Epoch 81/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2687 - accuracy: 0.1432 - val_loss: 2.2818 - val_accuracy: 0.1429\n",
      "Epoch 82/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.2596 - accuracy: 0.1384 - val_loss: 2.2805 - val_accuracy: 0.1591\n",
      "Epoch 83/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2602 - accuracy: 0.1417 - val_loss: 2.2778 - val_accuracy: 0.1623\n",
      "Epoch 84/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2648 - accuracy: 0.1311 - val_loss: 2.2745 - val_accuracy: 0.1656\n",
      "Epoch 85/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2685 - accuracy: 0.1319 - val_loss: 2.2746 - val_accuracy: 0.1656\n",
      "Epoch 86/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2723 - accuracy: 0.1283 - val_loss: 2.2762 - val_accuracy: 0.1786\n",
      "Epoch 87/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2557 - accuracy: 0.1348 - val_loss: 2.2765 - val_accuracy: 0.1688\n",
      "Epoch 88/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2611 - accuracy: 0.1433 - val_loss: 2.2748 - val_accuracy: 0.1623\n",
      "Epoch 89/1500\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 2.2495 - accuracy: 0.1361 - val_loss: 2.2708 - val_accuracy: 0.1688\n",
      "Epoch 90/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2673 - accuracy: 0.1173 - val_loss: 2.2653 - val_accuracy: 0.1883\n",
      "Epoch 91/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2472 - accuracy: 0.1507 - val_loss: 2.2656 - val_accuracy: 0.1916\n",
      "Epoch 92/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2599 - accuracy: 0.1417 - val_loss: 2.2675 - val_accuracy: 0.1883\n",
      "Epoch 93/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2576 - accuracy: 0.1279 - val_loss: 2.2718 - val_accuracy: 0.1721\n",
      "Epoch 94/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2509 - accuracy: 0.1458 - val_loss: 2.2721 - val_accuracy: 0.1688\n",
      "Epoch 95/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2560 - accuracy: 0.1458 - val_loss: 2.2703 - val_accuracy: 0.1721\n",
      "Epoch 96/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2492 - accuracy: 0.1466 - val_loss: 2.2658 - val_accuracy: 0.1948\n",
      "Epoch 97/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2483 - accuracy: 0.1478 - val_loss: 2.2625 - val_accuracy: 0.2013\n",
      "Epoch 98/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2486 - accuracy: 0.1400 - val_loss: 2.2590 - val_accuracy: 0.2143\n",
      "Epoch 99/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2291 - accuracy: 0.1360 - val_loss: 2.2553 - val_accuracy: 0.2175\n",
      "Epoch 100/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2395 - accuracy: 0.1641 - val_loss: 2.2571 - val_accuracy: 0.2403\n",
      "Epoch 101/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2360 - accuracy: 0.1441 - val_loss: 2.2612 - val_accuracy: 0.2500\n",
      "Epoch 102/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2358 - accuracy: 0.1384 - val_loss: 2.2643 - val_accuracy: 0.2305\n",
      "Epoch 103/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2308 - accuracy: 0.1507 - val_loss: 2.2615 - val_accuracy: 0.2305\n",
      "Epoch 104/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2292 - accuracy: 0.1735 - val_loss: 2.2536 - val_accuracy: 0.2532\n",
      "Epoch 105/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2249 - accuracy: 0.1556 - val_loss: 2.2473 - val_accuracy: 0.2468\n",
      "Epoch 106/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.2151 - accuracy: 0.1735 - val_loss: 2.2520 - val_accuracy: 0.2403\n",
      "Epoch 107/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2207 - accuracy: 0.1726 - val_loss: 2.2571 - val_accuracy: 0.2468\n",
      "Epoch 108/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2120 - accuracy: 0.1555 - val_loss: 2.2549 - val_accuracy: 0.2565\n",
      "Epoch 109/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2250 - accuracy: 0.1576 - val_loss: 2.2553 - val_accuracy: 0.2825\n",
      "Epoch 110/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2208 - accuracy: 0.1645 - val_loss: 2.2530 - val_accuracy: 0.2825\n",
      "Epoch 111/1500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 2.2112 - accuracy: 0.1536 - val_loss: 2.2504 - val_accuracy: 0.2955\n",
      "Epoch 112/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.1971 - accuracy: 0.1881 - val_loss: 2.2402 - val_accuracy: 0.3182\n",
      "Epoch 113/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.1948 - accuracy: 0.1712 - val_loss: 2.2286 - val_accuracy: 0.3149\n",
      "Epoch 114/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2000 - accuracy: 0.1738 - val_loss: 2.2316 - val_accuracy: 0.3182\n",
      "Epoch 115/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2133 - accuracy: 0.1800 - val_loss: 2.2468 - val_accuracy: 0.2825\n",
      "Epoch 116/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1812 - accuracy: 0.1726 - val_loss: 2.2574 - val_accuracy: 0.2532\n",
      "Epoch 117/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.1794 - accuracy: 0.1873 - val_loss: 2.2430 - val_accuracy: 0.2825\n",
      "Epoch 118/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1876 - accuracy: 0.1840 - val_loss: 2.2271 - val_accuracy: 0.3117\n",
      "Epoch 119/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1853 - accuracy: 0.1710 - val_loss: 2.2314 - val_accuracy: 0.2955\n",
      "Epoch 120/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1723 - accuracy: 0.1971 - val_loss: 2.2336 - val_accuracy: 0.2857\n",
      "Epoch 121/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1810 - accuracy: 0.1832 - val_loss: 2.2170 - val_accuracy: 0.3214\n",
      "Epoch 122/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1788 - accuracy: 0.1767 - val_loss: 2.2119 - val_accuracy: 0.3084\n",
      "Epoch 123/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1759 - accuracy: 0.1829 - val_loss: 2.2176 - val_accuracy: 0.2922\n",
      "Epoch 124/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1747 - accuracy: 0.1783 - val_loss: 2.2247 - val_accuracy: 0.2727\n",
      "Epoch 125/1500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.1632 - accuracy: 0.1881 - val_loss: 2.2036 - val_accuracy: 0.3019\n",
      "Epoch 126/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.1449 - accuracy: 0.1979 - val_loss: 2.1696 - val_accuracy: 0.3052\n",
      "Epoch 127/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1512 - accuracy: 0.2005 - val_loss: 2.1813 - val_accuracy: 0.3279\n",
      "Epoch 128/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1353 - accuracy: 0.1906 - val_loss: 2.2012 - val_accuracy: 0.3409\n",
      "Epoch 129/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1448 - accuracy: 0.1855 - val_loss: 2.2150 - val_accuracy: 0.3214\n",
      "Epoch 130/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1513 - accuracy: 0.1946 - val_loss: 2.2201 - val_accuracy: 0.2760\n",
      "Epoch 131/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.1484 - accuracy: 0.1953 - val_loss: 2.1920 - val_accuracy: 0.2987\n",
      "Epoch 132/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.1236 - accuracy: 0.1992 - val_loss: 2.1728 - val_accuracy: 0.3052\n",
      "Epoch 133/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.1313 - accuracy: 0.2215 - val_loss: 2.1791 - val_accuracy: 0.3474\n",
      "Epoch 134/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.1420 - accuracy: 0.2052 - val_loss: 2.2180 - val_accuracy: 0.2532\n",
      "Epoch 135/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.1199 - accuracy: 0.2272 - val_loss: 2.1988 - val_accuracy: 0.2597\n",
      "Epoch 136/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.1331 - accuracy: 0.2070 - val_loss: 2.1507 - val_accuracy: 0.2955\n",
      "Epoch 137/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.1131 - accuracy: 0.1987 - val_loss: 2.1762 - val_accuracy: 0.2922\n",
      "Epoch 138/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.0986 - accuracy: 0.2199 - val_loss: 2.1783 - val_accuracy: 0.2955\n",
      "Epoch 139/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1192 - accuracy: 0.2052 - val_loss: 2.1814 - val_accuracy: 0.3052\n",
      "Epoch 140/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.0894 - accuracy: 0.2256 - val_loss: 2.1527 - val_accuracy: 0.3279\n",
      "Epoch 141/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.1099 - accuracy: 0.2148 - val_loss: 2.1428 - val_accuracy: 0.3312\n",
      "Epoch 142/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1115 - accuracy: 0.2199 - val_loss: 2.1901 - val_accuracy: 0.2922\n",
      "Epoch 143/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.0749 - accuracy: 0.2370 - val_loss: 2.1660 - val_accuracy: 0.3214\n",
      "Epoch 144/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.0823 - accuracy: 0.2370 - val_loss: 2.0902 - val_accuracy: 0.3506\n",
      "Epoch 145/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0881 - accuracy: 0.2215 - val_loss: 2.1130 - val_accuracy: 0.3409\n",
      "Epoch 146/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.0719 - accuracy: 0.2533 - val_loss: 2.1180 - val_accuracy: 0.3377\n",
      "Epoch 147/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.0899 - accuracy: 0.2253 - val_loss: 2.0920 - val_accuracy: 0.3701\n",
      "Epoch 148/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.0621 - accuracy: 0.2422 - val_loss: 2.0875 - val_accuracy: 0.3604\n",
      "Epoch 149/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.0519 - accuracy: 0.2415 - val_loss: 2.0950 - val_accuracy: 0.3669\n",
      "Epoch 150/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0666 - accuracy: 0.2394 - val_loss: 2.1293 - val_accuracy: 0.3409\n",
      "Epoch 151/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.0496 - accuracy: 0.2345 - val_loss: 2.0616 - val_accuracy: 0.4188\n",
      "Epoch 152/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.0805 - accuracy: 0.2524 - val_loss: 2.0986 - val_accuracy: 0.3409\n",
      "Epoch 153/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.0633 - accuracy: 0.2606 - val_loss: 2.1199 - val_accuracy: 0.3474\n",
      "Epoch 154/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.0259 - accuracy: 0.2539 - val_loss: 2.0227 - val_accuracy: 0.3734\n",
      "Epoch 155/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.0443 - accuracy: 0.2448 - val_loss: 2.0312 - val_accuracy: 0.3636\n",
      "Epoch 156/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.0136 - accuracy: 0.2663 - val_loss: 2.0370 - val_accuracy: 0.3799\n",
      "Epoch 157/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0495 - accuracy: 0.2467 - val_loss: 2.0200 - val_accuracy: 0.3766\n",
      "Epoch 158/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0563 - accuracy: 0.2842 - val_loss: 2.0158 - val_accuracy: 0.3929\n",
      "Epoch 159/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.0224 - accuracy: 0.2663 - val_loss: 2.0323 - val_accuracy: 0.3994\n",
      "Epoch 160/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.0340 - accuracy: 0.2598 - val_loss: 2.0577 - val_accuracy: 0.3604\n",
      "Epoch 161/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.0380 - accuracy: 0.2769 - val_loss: 1.9805 - val_accuracy: 0.3896\n",
      "Epoch 162/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0328 - accuracy: 0.2866 - val_loss: 1.9443 - val_accuracy: 0.3994\n",
      "Epoch 163/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.0420 - accuracy: 0.2647 - val_loss: 1.9900 - val_accuracy: 0.3734\n",
      "Epoch 164/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.0161 - accuracy: 0.2656 - val_loss: 1.9891 - val_accuracy: 0.3929\n",
      "Epoch 165/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0157 - accuracy: 0.2842 - val_loss: 1.9601 - val_accuracy: 0.4123\n",
      "Epoch 166/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0081 - accuracy: 0.2744 - val_loss: 1.9376 - val_accuracy: 0.4383\n",
      "Epoch 167/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.0128 - accuracy: 0.2899 - val_loss: 1.9661 - val_accuracy: 0.4286\n",
      "Epoch 168/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.0218 - accuracy: 0.2689 - val_loss: 1.9522 - val_accuracy: 0.4351\n",
      "Epoch 169/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.9703 - accuracy: 0.3021 - val_loss: 1.9312 - val_accuracy: 0.4253\n",
      "Epoch 170/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.9903 - accuracy: 0.2752 - val_loss: 1.9703 - val_accuracy: 0.4156\n",
      "Epoch 171/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.9994 - accuracy: 0.2780 - val_loss: 1.9661 - val_accuracy: 0.4091\n",
      "Epoch 172/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.9925 - accuracy: 0.2812 - val_loss: 1.8509 - val_accuracy: 0.4513\n",
      "Epoch 173/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 62ms/step - loss: 1.9462 - accuracy: 0.2972 - val_loss: 1.8583 - val_accuracy: 0.4610\n",
      "Epoch 174/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.9551 - accuracy: 0.2964 - val_loss: 1.9181 - val_accuracy: 0.4318\n",
      "Epoch 175/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.9699 - accuracy: 0.2989 - val_loss: 1.8356 - val_accuracy: 0.4708\n",
      "Epoch 176/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.9753 - accuracy: 0.2875 - val_loss: 1.8302 - val_accuracy: 0.4675\n",
      "Epoch 177/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.9712 - accuracy: 0.2842 - val_loss: 1.9271 - val_accuracy: 0.4578\n",
      "Epoch 178/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.9759 - accuracy: 0.3046 - val_loss: 1.8440 - val_accuracy: 0.4610\n",
      "Epoch 179/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.9708 - accuracy: 0.3086 - val_loss: 1.8320 - val_accuracy: 0.4545\n",
      "Epoch 180/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.9620 - accuracy: 0.2923 - val_loss: 1.9559 - val_accuracy: 0.4058\n",
      "Epoch 181/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.9599 - accuracy: 0.2975 - val_loss: 1.8207 - val_accuracy: 0.4838\n",
      "Epoch 182/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.9567 - accuracy: 0.2923 - val_loss: 1.8159 - val_accuracy: 0.4675\n",
      "Epoch 183/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.9669 - accuracy: 0.2826 - val_loss: 1.9316 - val_accuracy: 0.4253\n",
      "Epoch 184/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.9836 - accuracy: 0.2785 - val_loss: 1.8707 - val_accuracy: 0.4513\n",
      "Epoch 185/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.9626 - accuracy: 0.2826 - val_loss: 1.8011 - val_accuracy: 0.4773\n",
      "Epoch 186/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.9385 - accuracy: 0.3151 - val_loss: 1.8169 - val_accuracy: 0.4773\n",
      "Epoch 187/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.9575 - accuracy: 0.3014 - val_loss: 1.8315 - val_accuracy: 0.4675\n",
      "Epoch 188/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.9105 - accuracy: 0.3249 - val_loss: 1.8029 - val_accuracy: 0.4805\n",
      "Epoch 189/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.8975 - accuracy: 0.3331 - val_loss: 1.8582 - val_accuracy: 0.4578\n",
      "Epoch 190/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.9087 - accuracy: 0.3190 - val_loss: 1.7804 - val_accuracy: 0.4773\n",
      "Epoch 191/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.9242 - accuracy: 0.2915 - val_loss: 1.7296 - val_accuracy: 0.5032\n",
      "Epoch 192/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.9127 - accuracy: 0.3054 - val_loss: 1.8140 - val_accuracy: 0.4805\n",
      "Epoch 193/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.9014 - accuracy: 0.3062 - val_loss: 1.7923 - val_accuracy: 0.4773\n",
      "Epoch 194/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.8815 - accuracy: 0.3192 - val_loss: 1.7381 - val_accuracy: 0.4903\n",
      "Epoch 195/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.8917 - accuracy: 0.3314 - val_loss: 1.7234 - val_accuracy: 0.5032\n",
      "Epoch 196/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.8720 - accuracy: 0.3371 - val_loss: 1.6762 - val_accuracy: 0.5065\n",
      "Epoch 197/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.9655 - accuracy: 0.2972 - val_loss: 1.7969 - val_accuracy: 0.4675\n",
      "Epoch 198/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.9069 - accuracy: 0.3073 - val_loss: 1.8260 - val_accuracy: 0.4545\n",
      "Epoch 199/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.8818 - accuracy: 0.3242 - val_loss: 1.7585 - val_accuracy: 0.4773\n",
      "Epoch 200/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.8582 - accuracy: 0.3241 - val_loss: 1.7440 - val_accuracy: 0.5065\n",
      "Epoch 201/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.8590 - accuracy: 0.3288 - val_loss: 1.7028 - val_accuracy: 0.5032\n",
      "Epoch 202/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.8442 - accuracy: 0.3451 - val_loss: 1.6970 - val_accuracy: 0.4870\n",
      "Epoch 203/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.8392 - accuracy: 0.3485 - val_loss: 1.7365 - val_accuracy: 0.4870\n",
      "Epoch 204/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.8627 - accuracy: 0.3428 - val_loss: 1.7024 - val_accuracy: 0.4903\n",
      "Epoch 205/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.8537 - accuracy: 0.3274 - val_loss: 1.6738 - val_accuracy: 0.5130\n",
      "Epoch 206/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.8369 - accuracy: 0.3496 - val_loss: 1.6568 - val_accuracy: 0.5260\n",
      "Epoch 207/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.8415 - accuracy: 0.3535 - val_loss: 1.6628 - val_accuracy: 0.5097\n",
      "Epoch 208/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.8451 - accuracy: 0.3257 - val_loss: 1.6741 - val_accuracy: 0.5195\n",
      "Epoch 209/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.8392 - accuracy: 0.3632 - val_loss: 1.6564 - val_accuracy: 0.5032\n",
      "Epoch 210/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.8224 - accuracy: 0.3567 - val_loss: 1.6303 - val_accuracy: 0.5260\n",
      "Epoch 211/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.8078 - accuracy: 0.3559 - val_loss: 1.6282 - val_accuracy: 0.5325\n",
      "Epoch 212/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.8438 - accuracy: 0.3583 - val_loss: 1.7062 - val_accuracy: 0.4838\n",
      "Epoch 213/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.8347 - accuracy: 0.3639 - val_loss: 1.6583 - val_accuracy: 0.4870\n",
      "Epoch 214/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.8242 - accuracy: 0.3534 - val_loss: 1.6387 - val_accuracy: 0.5227\n",
      "Epoch 215/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.8382 - accuracy: 0.3404 - val_loss: 1.5752 - val_accuracy: 0.5422\n",
      "Epoch 216/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.8286 - accuracy: 0.3555 - val_loss: 1.5874 - val_accuracy: 0.5357\n",
      "Epoch 217/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.7816 - accuracy: 0.3616 - val_loss: 1.6559 - val_accuracy: 0.5422\n",
      "Epoch 218/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.8192 - accuracy: 0.3363 - val_loss: 1.6455 - val_accuracy: 0.4968\n",
      "Epoch 219/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.8298 - accuracy: 0.3282 - val_loss: 1.6144 - val_accuracy: 0.5325\n",
      "Epoch 220/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.8004 - accuracy: 0.3616 - val_loss: 1.5759 - val_accuracy: 0.5519\n",
      "Epoch 221/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.8068 - accuracy: 0.3548 - val_loss: 1.5645 - val_accuracy: 0.5487\n",
      "Epoch 222/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.7802 - accuracy: 0.3587 - val_loss: 1.6029 - val_accuracy: 0.5487\n",
      "Epoch 223/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.8055 - accuracy: 0.3632 - val_loss: 1.6127 - val_accuracy: 0.5390\n",
      "Epoch 224/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.7783 - accuracy: 0.3594 - val_loss: 1.5810 - val_accuracy: 0.5682\n",
      "Epoch 225/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.8035 - accuracy: 0.3713 - val_loss: 1.5489 - val_accuracy: 0.5682\n",
      "Epoch 226/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.7942 - accuracy: 0.3681 - val_loss: 1.5789 - val_accuracy: 0.5455\n",
      "Epoch 227/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.7568 - accuracy: 0.3965 - val_loss: 1.6081 - val_accuracy: 0.5487\n",
      "Epoch 228/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.7439 - accuracy: 0.3876 - val_loss: 1.5747 - val_accuracy: 0.5617\n",
      "Epoch 229/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.7783 - accuracy: 0.3827 - val_loss: 1.5389 - val_accuracy: 0.5422\n",
      "Epoch 230/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 85ms/step - loss: 1.7690 - accuracy: 0.3632 - val_loss: 1.5256 - val_accuracy: 0.5584\n",
      "Epoch 231/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.7903 - accuracy: 0.3713 - val_loss: 1.5661 - val_accuracy: 0.5455\n",
      "Epoch 232/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.7603 - accuracy: 0.3966 - val_loss: 1.5986 - val_accuracy: 0.5584\n",
      "Epoch 233/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.7351 - accuracy: 0.4023 - val_loss: 1.5288 - val_accuracy: 0.5812\n",
      "Epoch 234/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.7201 - accuracy: 0.3893 - val_loss: 1.4607 - val_accuracy: 0.5844\n",
      "Epoch 235/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.7339 - accuracy: 0.3852 - val_loss: 1.4679 - val_accuracy: 0.5877\n",
      "Epoch 236/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.7580 - accuracy: 0.3754 - val_loss: 1.5202 - val_accuracy: 0.5714\n",
      "Epoch 237/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.7259 - accuracy: 0.4015 - val_loss: 1.4972 - val_accuracy: 0.6071\n",
      "Epoch 238/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.7166 - accuracy: 0.3867 - val_loss: 1.4510 - val_accuracy: 0.5909\n",
      "Epoch 239/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.7084 - accuracy: 0.3917 - val_loss: 1.4390 - val_accuracy: 0.6071\n",
      "Epoch 240/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.7078 - accuracy: 0.4072 - val_loss: 1.4531 - val_accuracy: 0.6071\n",
      "Epoch 241/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.6778 - accuracy: 0.4308 - val_loss: 1.4549 - val_accuracy: 0.6169\n",
      "Epoch 242/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.6771 - accuracy: 0.3909 - val_loss: 1.4571 - val_accuracy: 0.5942\n",
      "Epoch 243/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.6830 - accuracy: 0.3991 - val_loss: 1.4634 - val_accuracy: 0.5942\n",
      "Epoch 244/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.6542 - accuracy: 0.4129 - val_loss: 1.4464 - val_accuracy: 0.5779\n",
      "Epoch 245/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.7248 - accuracy: 0.3893 - val_loss: 1.4540 - val_accuracy: 0.5909\n",
      "Epoch 246/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.7113 - accuracy: 0.3958 - val_loss: 1.4443 - val_accuracy: 0.6299\n",
      "Epoch 247/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.6783 - accuracy: 0.4292 - val_loss: 1.4530 - val_accuracy: 0.6266\n",
      "Epoch 248/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.6907 - accuracy: 0.4178 - val_loss: 1.4474 - val_accuracy: 0.6234\n",
      "Epoch 249/1500\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 1.6554 - accuracy: 0.4153 - val_loss: 1.4168 - val_accuracy: 0.6201\n",
      "Epoch 250/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.6838 - accuracy: 0.4199 - val_loss: 1.4012 - val_accuracy: 0.6234\n",
      "Epoch 251/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.6378 - accuracy: 0.4147 - val_loss: 1.4235 - val_accuracy: 0.6104\n",
      "Epoch 252/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.6750 - accuracy: 0.4145 - val_loss: 1.3991 - val_accuracy: 0.6136\n",
      "Epoch 253/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.6461 - accuracy: 0.4267 - val_loss: 1.4082 - val_accuracy: 0.6006\n",
      "Epoch 254/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.6475 - accuracy: 0.3901 - val_loss: 1.3849 - val_accuracy: 0.5942\n",
      "Epoch 255/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.6245 - accuracy: 0.4292 - val_loss: 1.3700 - val_accuracy: 0.5909\n",
      "Epoch 256/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.6384 - accuracy: 0.4259 - val_loss: 1.3863 - val_accuracy: 0.6039\n",
      "Epoch 257/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.6467 - accuracy: 0.4421 - val_loss: 1.3561 - val_accuracy: 0.5877\n",
      "Epoch 258/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.6491 - accuracy: 0.4178 - val_loss: 1.3694 - val_accuracy: 0.6039\n",
      "Epoch 259/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.6703 - accuracy: 0.4104 - val_loss: 1.3996 - val_accuracy: 0.6169\n",
      "Epoch 260/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.6204 - accuracy: 0.4368 - val_loss: 1.3753 - val_accuracy: 0.6169\n",
      "Epoch 261/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.6136 - accuracy: 0.4169 - val_loss: 1.3362 - val_accuracy: 0.6201\n",
      "Epoch 262/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.5870 - accuracy: 0.4446 - val_loss: 1.3116 - val_accuracy: 0.6201\n",
      "Epoch 263/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.5831 - accuracy: 0.4463 - val_loss: 1.3150 - val_accuracy: 0.6169\n",
      "Epoch 264/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.6120 - accuracy: 0.4479 - val_loss: 1.3136 - val_accuracy: 0.6201\n",
      "Epoch 265/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.5861 - accuracy: 0.4570 - val_loss: 1.3501 - val_accuracy: 0.6169\n",
      "Epoch 266/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.6172 - accuracy: 0.4357 - val_loss: 1.3826 - val_accuracy: 0.5942\n",
      "Epoch 267/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.5678 - accuracy: 0.4544 - val_loss: 1.3738 - val_accuracy: 0.6104\n",
      "Epoch 268/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.5601 - accuracy: 0.4332 - val_loss: 1.3161 - val_accuracy: 0.6266\n",
      "Epoch 269/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.5680 - accuracy: 0.4650 - val_loss: 1.2780 - val_accuracy: 0.6234\n",
      "Epoch 270/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.5569 - accuracy: 0.4552 - val_loss: 1.2843 - val_accuracy: 0.6331\n",
      "Epoch 271/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.5295 - accuracy: 0.4756 - val_loss: 1.2749 - val_accuracy: 0.6136\n",
      "Epoch 272/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.5680 - accuracy: 0.4463 - val_loss: 1.2940 - val_accuracy: 0.6234\n",
      "Epoch 273/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.5596 - accuracy: 0.4414 - val_loss: 1.3025 - val_accuracy: 0.6234\n",
      "Epoch 274/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.5480 - accuracy: 0.4389 - val_loss: 1.2916 - val_accuracy: 0.6234\n",
      "Epoch 275/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.5333 - accuracy: 0.4792 - val_loss: 1.3122 - val_accuracy: 0.6169\n",
      "Epoch 276/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.5241 - accuracy: 0.4658 - val_loss: 1.2848 - val_accuracy: 0.6331\n",
      "Epoch 277/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.5396 - accuracy: 0.4512 - val_loss: 1.2638 - val_accuracy: 0.6299\n",
      "Epoch 278/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.5223 - accuracy: 0.4511 - val_loss: 1.2577 - val_accuracy: 0.6299\n",
      "Epoch 279/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.5772 - accuracy: 0.4365 - val_loss: 1.2615 - val_accuracy: 0.6234\n",
      "Epoch 280/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.5415 - accuracy: 0.4609 - val_loss: 1.2686 - val_accuracy: 0.6461\n",
      "Epoch 281/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.5522 - accuracy: 0.4634 - val_loss: 1.2542 - val_accuracy: 0.6558\n",
      "Epoch 282/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.5667 - accuracy: 0.4544 - val_loss: 1.2392 - val_accuracy: 0.6591\n",
      "Epoch 283/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.5223 - accuracy: 0.4609 - val_loss: 1.2250 - val_accuracy: 0.6526\n",
      "Epoch 284/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.5637 - accuracy: 0.4505 - val_loss: 1.2082 - val_accuracy: 0.6494\n",
      "Epoch 285/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.5033 - accuracy: 0.4788 - val_loss: 1.2200 - val_accuracy: 0.6429\n",
      "Epoch 286/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.5076 - accuracy: 0.4625 - val_loss: 1.2267 - val_accuracy: 0.6201\n",
      "Epoch 287/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 56ms/step - loss: 1.5160 - accuracy: 0.4862 - val_loss: 1.2406 - val_accuracy: 0.6201\n",
      "Epoch 288/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.5097 - accuracy: 0.4764 - val_loss: 1.2444 - val_accuracy: 0.6234\n",
      "Epoch 289/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.4998 - accuracy: 0.4878 - val_loss: 1.2154 - val_accuracy: 0.6299\n",
      "Epoch 290/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.5434 - accuracy: 0.4682 - val_loss: 1.2245 - val_accuracy: 0.6494\n",
      "Epoch 291/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.5335 - accuracy: 0.4585 - val_loss: 1.2084 - val_accuracy: 0.6364\n",
      "Epoch 292/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.5359 - accuracy: 0.4520 - val_loss: 1.2436 - val_accuracy: 0.6266\n",
      "Epoch 293/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.5195 - accuracy: 0.4967 - val_loss: 1.2182 - val_accuracy: 0.6461\n",
      "Epoch 294/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.4572 - accuracy: 0.4788 - val_loss: 1.1778 - val_accuracy: 0.6591\n",
      "Epoch 295/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.4730 - accuracy: 0.4796 - val_loss: 1.1476 - val_accuracy: 0.6721\n",
      "Epoch 296/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4446 - accuracy: 0.4862 - val_loss: 1.1397 - val_accuracy: 0.6526\n",
      "Epoch 297/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.4549 - accuracy: 0.4927 - val_loss: 1.1598 - val_accuracy: 0.6331\n",
      "Epoch 298/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4720 - accuracy: 0.4845 - val_loss: 1.1546 - val_accuracy: 0.6558\n",
      "Epoch 299/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.4699 - accuracy: 0.4805 - val_loss: 1.1310 - val_accuracy: 0.6623\n",
      "Epoch 300/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4743 - accuracy: 0.4980 - val_loss: 1.1501 - val_accuracy: 0.6688\n",
      "Epoch 301/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.5033 - accuracy: 0.4935 - val_loss: 1.1871 - val_accuracy: 0.6396\n",
      "Epoch 302/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4912 - accuracy: 0.4715 - val_loss: 1.1779 - val_accuracy: 0.6591\n",
      "Epoch 303/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4667 - accuracy: 0.5117 - val_loss: 1.1629 - val_accuracy: 0.6688\n",
      "Epoch 304/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4157 - accuracy: 0.5065 - val_loss: 1.1245 - val_accuracy: 0.6656\n",
      "Epoch 305/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.4419 - accuracy: 0.5147 - val_loss: 1.1258 - val_accuracy: 0.6461\n",
      "Epoch 306/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3919 - accuracy: 0.4984 - val_loss: 1.1008 - val_accuracy: 0.6558\n",
      "Epoch 307/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.4403 - accuracy: 0.5111 - val_loss: 1.1010 - val_accuracy: 0.6656\n",
      "Epoch 308/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.4800 - accuracy: 0.4805 - val_loss: 1.1343 - val_accuracy: 0.6591\n",
      "Epoch 309/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4464 - accuracy: 0.4976 - val_loss: 1.1333 - val_accuracy: 0.6656\n",
      "Epoch 310/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.4381 - accuracy: 0.5016 - val_loss: 1.1094 - val_accuracy: 0.6623\n",
      "Epoch 311/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.4090 - accuracy: 0.4992 - val_loss: 1.1225 - val_accuracy: 0.6461\n",
      "Epoch 312/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.4103 - accuracy: 0.4984 - val_loss: 1.1151 - val_accuracy: 0.6558\n",
      "Epoch 313/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.3814 - accuracy: 0.5497 - val_loss: 1.1403 - val_accuracy: 0.6526\n",
      "Epoch 314/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.3944 - accuracy: 0.5155 - val_loss: 1.1333 - val_accuracy: 0.6429\n",
      "Epoch 315/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.4394 - accuracy: 0.5147 - val_loss: 1.0909 - val_accuracy: 0.6591\n",
      "Epoch 316/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.4175 - accuracy: 0.5179 - val_loss: 1.0850 - val_accuracy: 0.6656\n",
      "Epoch 317/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4242 - accuracy: 0.4886 - val_loss: 1.0695 - val_accuracy: 0.6786\n",
      "Epoch 318/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3753 - accuracy: 0.5212 - val_loss: 1.0589 - val_accuracy: 0.6786\n",
      "Epoch 319/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.3972 - accuracy: 0.5179 - val_loss: 1.0669 - val_accuracy: 0.6656\n",
      "Epoch 320/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4097 - accuracy: 0.5057 - val_loss: 1.0676 - val_accuracy: 0.6786\n",
      "Epoch 321/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4333 - accuracy: 0.5013 - val_loss: 1.1030 - val_accuracy: 0.6461\n",
      "Epoch 322/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3222 - accuracy: 0.5537 - val_loss: 1.0778 - val_accuracy: 0.6623\n",
      "Epoch 323/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3912 - accuracy: 0.5163 - val_loss: 1.0412 - val_accuracy: 0.6688\n",
      "Epoch 324/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3874 - accuracy: 0.5187 - val_loss: 1.0710 - val_accuracy: 0.6558\n",
      "Epoch 325/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.3642 - accuracy: 0.5366 - val_loss: 1.0677 - val_accuracy: 0.6623\n",
      "Epoch 326/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3340 - accuracy: 0.5309 - val_loss: 1.0439 - val_accuracy: 0.6753\n",
      "Epoch 327/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.3210 - accuracy: 0.5521 - val_loss: 1.0307 - val_accuracy: 0.6818\n",
      "Epoch 328/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3537 - accuracy: 0.5334 - val_loss: 1.0440 - val_accuracy: 0.6623\n",
      "Epoch 329/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3560 - accuracy: 0.5350 - val_loss: 1.0445 - val_accuracy: 0.6753\n",
      "Epoch 330/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.3671 - accuracy: 0.5371 - val_loss: 1.0427 - val_accuracy: 0.6623\n",
      "Epoch 331/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3243 - accuracy: 0.5480 - val_loss: 1.0839 - val_accuracy: 0.6721\n",
      "Epoch 332/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3445 - accuracy: 0.5480 - val_loss: 1.0423 - val_accuracy: 0.6623\n",
      "Epoch 333/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4027 - accuracy: 0.5098 - val_loss: 1.0667 - val_accuracy: 0.6656\n",
      "Epoch 334/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.3155 - accuracy: 0.5501 - val_loss: 1.0813 - val_accuracy: 0.6558\n",
      "Epoch 335/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.3113 - accuracy: 0.5505 - val_loss: 1.0321 - val_accuracy: 0.6786\n",
      "Epoch 336/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3022 - accuracy: 0.5521 - val_loss: 1.0268 - val_accuracy: 0.6753\n",
      "Epoch 337/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.2816 - accuracy: 0.5480 - val_loss: 1.0321 - val_accuracy: 0.6721\n",
      "Epoch 338/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.3889 - accuracy: 0.5326 - val_loss: 1.0332 - val_accuracy: 0.6721\n",
      "Epoch 339/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3346 - accuracy: 0.5334 - val_loss: 1.0137 - val_accuracy: 0.6786\n",
      "Epoch 340/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.3188 - accuracy: 0.5529 - val_loss: 1.0198 - val_accuracy: 0.6786\n",
      "Epoch 341/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.3053 - accuracy: 0.5594 - val_loss: 1.0169 - val_accuracy: 0.6786\n",
      "Epoch 342/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.3180 - accuracy: 0.5358 - val_loss: 0.9916 - val_accuracy: 0.6818\n",
      "Epoch 343/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.3512 - accuracy: 0.5342 - val_loss: 0.9804 - val_accuracy: 0.6818\n",
      "Epoch 344/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3941 - accuracy: 0.5171 - val_loss: 1.0240 - val_accuracy: 0.6623\n",
      "Epoch 345/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.3008 - accuracy: 0.5440 - val_loss: 1.0298 - val_accuracy: 0.6688\n",
      "Epoch 346/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.3297 - accuracy: 0.5534 - val_loss: 1.0321 - val_accuracy: 0.6656\n",
      "Epoch 347/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.3063 - accuracy: 0.5668 - val_loss: 1.0231 - val_accuracy: 0.6786\n",
      "Epoch 348/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3111 - accuracy: 0.5570 - val_loss: 0.9757 - val_accuracy: 0.6753\n",
      "Epoch 349/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.3146 - accuracy: 0.5562 - val_loss: 0.9623 - val_accuracy: 0.6753\n",
      "Epoch 350/1500\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 1.3141 - accuracy: 0.5358 - val_loss: 0.9839 - val_accuracy: 0.6786\n",
      "Epoch 351/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.3268 - accuracy: 0.5375 - val_loss: 1.0008 - val_accuracy: 0.6786\n",
      "Epoch 352/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.2988 - accuracy: 0.5562 - val_loss: 0.9764 - val_accuracy: 0.6688\n",
      "Epoch 353/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.3370 - accuracy: 0.5358 - val_loss: 0.9911 - val_accuracy: 0.6721\n",
      "Epoch 354/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.3065 - accuracy: 0.5440 - val_loss: 0.9990 - val_accuracy: 0.6721\n",
      "Epoch 355/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.2804 - accuracy: 0.5611 - val_loss: 1.0214 - val_accuracy: 0.6721\n",
      "Epoch 356/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.2773 - accuracy: 0.5612 - val_loss: 1.0049 - val_accuracy: 0.6623\n",
      "Epoch 357/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.2462 - accuracy: 0.5749 - val_loss: 0.9855 - val_accuracy: 0.6623\n",
      "Epoch 358/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.3288 - accuracy: 0.5480 - val_loss: 0.9472 - val_accuracy: 0.6818\n",
      "Epoch 359/1500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.2733 - accuracy: 0.5573 - val_loss: 0.9566 - val_accuracy: 0.6753\n",
      "Epoch 360/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.2904 - accuracy: 0.5586 - val_loss: 1.0094 - val_accuracy: 0.6623\n",
      "Epoch 361/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.3047 - accuracy: 0.5546 - val_loss: 1.0015 - val_accuracy: 0.6753\n",
      "Epoch 362/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.3073 - accuracy: 0.5703 - val_loss: 0.9880 - val_accuracy: 0.6753\n",
      "Epoch 363/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.2703 - accuracy: 0.5611 - val_loss: 1.0456 - val_accuracy: 0.6591\n",
      "Epoch 364/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.2664 - accuracy: 0.5668 - val_loss: 0.9590 - val_accuracy: 0.6883\n",
      "Epoch 365/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.2986 - accuracy: 0.5586 - val_loss: 0.9067 - val_accuracy: 0.6916\n",
      "Epoch 366/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.2372 - accuracy: 0.5822 - val_loss: 0.9417 - val_accuracy: 0.6753\n",
      "Epoch 367/1500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.2681 - accuracy: 0.5618 - val_loss: 0.9473 - val_accuracy: 0.6721\n",
      "Epoch 368/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.2554 - accuracy: 0.5765 - val_loss: 0.9467 - val_accuracy: 0.6818\n",
      "Epoch 369/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.2573 - accuracy: 0.5928 - val_loss: 0.9721 - val_accuracy: 0.6851\n",
      "Epoch 370/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.2244 - accuracy: 0.5814 - val_loss: 0.9543 - val_accuracy: 0.6883\n",
      "Epoch 371/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.2285 - accuracy: 0.5684 - val_loss: 0.9391 - val_accuracy: 0.6818\n",
      "Epoch 372/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.2097 - accuracy: 0.5918 - val_loss: 0.9245 - val_accuracy: 0.6948\n",
      "Epoch 373/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.2679 - accuracy: 0.5643 - val_loss: 0.9315 - val_accuracy: 0.6916\n",
      "Epoch 374/1500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.2067 - accuracy: 0.5911 - val_loss: 0.9425 - val_accuracy: 0.6883\n",
      "Epoch 375/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.2472 - accuracy: 0.5562 - val_loss: 0.9588 - val_accuracy: 0.6688\n",
      "Epoch 376/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.2658 - accuracy: 0.5741 - val_loss: 0.9764 - val_accuracy: 0.6721\n",
      "Epoch 377/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.2479 - accuracy: 0.5729 - val_loss: 0.9165 - val_accuracy: 0.6753\n",
      "Epoch 378/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.2091 - accuracy: 0.5855 - val_loss: 0.8946 - val_accuracy: 0.6981\n",
      "Epoch 379/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.2442 - accuracy: 0.5697 - val_loss: 0.9240 - val_accuracy: 0.6916\n",
      "Epoch 380/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.2523 - accuracy: 0.5775 - val_loss: 0.9563 - val_accuracy: 0.6753\n",
      "Epoch 381/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.1829 - accuracy: 0.6010 - val_loss: 0.9852 - val_accuracy: 0.6558\n",
      "Epoch 382/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.2286 - accuracy: 0.5904 - val_loss: 0.9651 - val_accuracy: 0.6591\n",
      "Epoch 383/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.2140 - accuracy: 0.5733 - val_loss: 0.9196 - val_accuracy: 0.6981\n",
      "Epoch 384/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.2366 - accuracy: 0.5833 - val_loss: 0.9235 - val_accuracy: 0.6883\n",
      "Epoch 385/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.2107 - accuracy: 0.5912 - val_loss: 0.9326 - val_accuracy: 0.6786\n",
      "Epoch 386/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.2253 - accuracy: 0.5888 - val_loss: 0.9466 - val_accuracy: 0.6688\n",
      "Epoch 387/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.2482 - accuracy: 0.5888 - val_loss: 0.9229 - val_accuracy: 0.6818\n",
      "Epoch 388/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.2185 - accuracy: 0.5928 - val_loss: 0.9268 - val_accuracy: 0.6721\n",
      "Epoch 389/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.2080 - accuracy: 0.5885 - val_loss: 0.9081 - val_accuracy: 0.6818\n",
      "Epoch 390/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.2197 - accuracy: 0.5831 - val_loss: 0.9076 - val_accuracy: 0.6948\n",
      "Epoch 391/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.2640 - accuracy: 0.5866 - val_loss: 0.9531 - val_accuracy: 0.6591\n",
      "Epoch 392/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.2269 - accuracy: 0.5814 - val_loss: 0.9481 - val_accuracy: 0.6753\n",
      "Epoch 393/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.2260 - accuracy: 0.5611 - val_loss: 0.8975 - val_accuracy: 0.6916\n",
      "Epoch 394/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.1753 - accuracy: 0.5928 - val_loss: 0.9193 - val_accuracy: 0.6883\n",
      "Epoch 395/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.2171 - accuracy: 0.5945 - val_loss: 0.9634 - val_accuracy: 0.6753\n",
      "Epoch 396/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.1978 - accuracy: 0.5977 - val_loss: 0.9883 - val_accuracy: 0.6558\n",
      "Epoch 397/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.2218 - accuracy: 0.5936 - val_loss: 0.9412 - val_accuracy: 0.6753\n",
      "Epoch 398/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.2298 - accuracy: 0.5839 - val_loss: 0.9186 - val_accuracy: 0.6883\n",
      "Epoch 399/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.1985 - accuracy: 0.5969 - val_loss: 0.9190 - val_accuracy: 0.6916\n",
      "Epoch 400/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.1717 - accuracy: 0.5993 - val_loss: 0.9192 - val_accuracy: 0.6851\n",
      "Epoch 401/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 67ms/step - loss: 1.1752 - accuracy: 0.5928 - val_loss: 0.9475 - val_accuracy: 0.6656\n",
      "Epoch 402/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.1743 - accuracy: 0.6034 - val_loss: 0.9196 - val_accuracy: 0.6753\n",
      "Epoch 403/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.2314 - accuracy: 0.5708 - val_loss: 0.8506 - val_accuracy: 0.7143\n",
      "Epoch 404/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1777 - accuracy: 0.6132 - val_loss: 0.8404 - val_accuracy: 0.7110\n",
      "Epoch 405/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1519 - accuracy: 0.6124 - val_loss: 0.9013 - val_accuracy: 0.6721\n",
      "Epoch 406/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1577 - accuracy: 0.6100 - val_loss: 0.9099 - val_accuracy: 0.6656\n",
      "Epoch 407/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.1941 - accuracy: 0.6083 - val_loss: 0.8777 - val_accuracy: 0.6786\n",
      "Epoch 408/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.1978 - accuracy: 0.5885 - val_loss: 0.8919 - val_accuracy: 0.6916\n",
      "Epoch 409/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.2075 - accuracy: 0.5945 - val_loss: 0.8904 - val_accuracy: 0.6981\n",
      "Epoch 410/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.2067 - accuracy: 0.6002 - val_loss: 0.9010 - val_accuracy: 0.6883\n",
      "Epoch 411/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1972 - accuracy: 0.5945 - val_loss: 0.9258 - val_accuracy: 0.6916\n",
      "Epoch 412/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1668 - accuracy: 0.6029 - val_loss: 0.9152 - val_accuracy: 0.6916\n",
      "Epoch 413/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1321 - accuracy: 0.6087 - val_loss: 0.8435 - val_accuracy: 0.7078\n",
      "Epoch 414/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1675 - accuracy: 0.6050 - val_loss: 0.8642 - val_accuracy: 0.6883\n",
      "Epoch 415/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1570 - accuracy: 0.6026 - val_loss: 0.9371 - val_accuracy: 0.6494\n",
      "Epoch 416/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1708 - accuracy: 0.5904 - val_loss: 0.8996 - val_accuracy: 0.6948\n",
      "Epoch 417/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.2097 - accuracy: 0.5806 - val_loss: 0.9265 - val_accuracy: 0.6753\n",
      "Epoch 418/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.1496 - accuracy: 0.6075 - val_loss: 0.9526 - val_accuracy: 0.6591\n",
      "Epoch 419/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.1730 - accuracy: 0.5985 - val_loss: 0.9017 - val_accuracy: 0.6818\n",
      "Epoch 420/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1812 - accuracy: 0.6083 - val_loss: 0.8712 - val_accuracy: 0.7045\n",
      "Epoch 421/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.1845 - accuracy: 0.5872 - val_loss: 0.8942 - val_accuracy: 0.6851\n",
      "Epoch 422/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.1651 - accuracy: 0.5936 - val_loss: 0.9203 - val_accuracy: 0.6818\n",
      "Epoch 423/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1826 - accuracy: 0.6010 - val_loss: 0.8597 - val_accuracy: 0.7208\n",
      "Epoch 424/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1799 - accuracy: 0.5953 - val_loss: 0.8671 - val_accuracy: 0.7045\n",
      "Epoch 425/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1274 - accuracy: 0.6091 - val_loss: 0.8748 - val_accuracy: 0.7013\n",
      "Epoch 426/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.1172 - accuracy: 0.6002 - val_loss: 0.8844 - val_accuracy: 0.6656\n",
      "Epoch 427/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.1213 - accuracy: 0.6091 - val_loss: 0.8772 - val_accuracy: 0.6851\n",
      "Epoch 428/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.1871 - accuracy: 0.5928 - val_loss: 0.8439 - val_accuracy: 0.7078\n",
      "Epoch 429/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.1633 - accuracy: 0.5896 - val_loss: 0.8480 - val_accuracy: 0.7110\n",
      "Epoch 430/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.1303 - accuracy: 0.6116 - val_loss: 0.9174 - val_accuracy: 0.6753\n",
      "Epoch 431/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.1730 - accuracy: 0.5920 - val_loss: 0.9224 - val_accuracy: 0.6688\n",
      "Epoch 432/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.1277 - accuracy: 0.6279 - val_loss: 0.8482 - val_accuracy: 0.7143\n",
      "Epoch 433/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1205 - accuracy: 0.6254 - val_loss: 0.8188 - val_accuracy: 0.7045\n",
      "Epoch 434/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1548 - accuracy: 0.5977 - val_loss: 0.8337 - val_accuracy: 0.6981\n",
      "Epoch 435/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1300 - accuracy: 0.6055 - val_loss: 0.8296 - val_accuracy: 0.6948\n",
      "Epoch 436/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.1154 - accuracy: 0.6205 - val_loss: 0.8030 - val_accuracy: 0.7240\n",
      "Epoch 437/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.1625 - accuracy: 0.5953 - val_loss: 0.8356 - val_accuracy: 0.6948\n",
      "Epoch 438/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.1047 - accuracy: 0.6148 - val_loss: 0.8489 - val_accuracy: 0.7143\n",
      "Epoch 439/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1345 - accuracy: 0.6035 - val_loss: 0.8916 - val_accuracy: 0.6851\n",
      "Epoch 440/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1081 - accuracy: 0.6254 - val_loss: 0.9495 - val_accuracy: 0.6494\n",
      "Epoch 441/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.1366 - accuracy: 0.5961 - val_loss: 0.8609 - val_accuracy: 0.7110\n",
      "Epoch 442/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1022 - accuracy: 0.6322 - val_loss: 0.7954 - val_accuracy: 0.7305\n",
      "Epoch 443/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1628 - accuracy: 0.6034 - val_loss: 0.8116 - val_accuracy: 0.7110\n",
      "Epoch 444/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1495 - accuracy: 0.6026 - val_loss: 0.8796 - val_accuracy: 0.6656\n",
      "Epoch 445/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1555 - accuracy: 0.6055 - val_loss: 0.8646 - val_accuracy: 0.6786\n",
      "Epoch 446/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0898 - accuracy: 0.6099 - val_loss: 0.8317 - val_accuracy: 0.7078\n",
      "Epoch 447/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.1153 - accuracy: 0.6262 - val_loss: 0.8431 - val_accuracy: 0.7143\n",
      "Epoch 448/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1112 - accuracy: 0.6191 - val_loss: 0.8892 - val_accuracy: 0.6916\n",
      "Epoch 449/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0872 - accuracy: 0.6426 - val_loss: 0.8948 - val_accuracy: 0.6916\n",
      "Epoch 450/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.1437 - accuracy: 0.6140 - val_loss: 0.8663 - val_accuracy: 0.7013\n",
      "Epoch 451/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0814 - accuracy: 0.6432 - val_loss: 0.8281 - val_accuracy: 0.7208\n",
      "Epoch 452/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0991 - accuracy: 0.6327 - val_loss: 0.7939 - val_accuracy: 0.7338\n",
      "Epoch 453/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.1218 - accuracy: 0.6185 - val_loss: 0.7999 - val_accuracy: 0.7338\n",
      "Epoch 454/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1342 - accuracy: 0.6250 - val_loss: 0.8771 - val_accuracy: 0.6948\n",
      "Epoch 455/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0765 - accuracy: 0.6213 - val_loss: 0.8439 - val_accuracy: 0.7045\n",
      "Epoch 456/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1018 - accuracy: 0.6393 - val_loss: 0.8388 - val_accuracy: 0.7175\n",
      "Epoch 457/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0636 - accuracy: 0.6376 - val_loss: 0.8392 - val_accuracy: 0.7110\n",
      "Epoch 458/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0860 - accuracy: 0.6336 - val_loss: 0.8230 - val_accuracy: 0.7208\n",
      "Epoch 459/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.1239 - accuracy: 0.6148 - val_loss: 0.8646 - val_accuracy: 0.7045\n",
      "Epoch 460/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1065 - accuracy: 0.6336 - val_loss: 0.8342 - val_accuracy: 0.7208\n",
      "Epoch 461/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.1077 - accuracy: 0.6270 - val_loss: 0.8134 - val_accuracy: 0.7305\n",
      "Epoch 462/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1244 - accuracy: 0.6113 - val_loss: 0.8186 - val_accuracy: 0.7143\n",
      "Epoch 463/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1220 - accuracy: 0.6296 - val_loss: 0.8301 - val_accuracy: 0.7175\n",
      "Epoch 464/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.1189 - accuracy: 0.6230 - val_loss: 0.8408 - val_accuracy: 0.7013\n",
      "Epoch 465/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.1144 - accuracy: 0.6360 - val_loss: 0.8451 - val_accuracy: 0.7045\n",
      "Epoch 466/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.0606 - accuracy: 0.6319 - val_loss: 0.8334 - val_accuracy: 0.7110\n",
      "Epoch 467/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0897 - accuracy: 0.6148 - val_loss: 0.8436 - val_accuracy: 0.7045\n",
      "Epoch 468/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.1466 - accuracy: 0.5920 - val_loss: 0.8294 - val_accuracy: 0.7045\n",
      "Epoch 469/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0899 - accuracy: 0.6148 - val_loss: 0.7999 - val_accuracy: 0.7273\n",
      "Epoch 470/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0712 - accuracy: 0.6189 - val_loss: 0.8677 - val_accuracy: 0.6948\n",
      "Epoch 471/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.1117 - accuracy: 0.6197 - val_loss: 0.8805 - val_accuracy: 0.6786\n",
      "Epoch 472/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.1038 - accuracy: 0.6283 - val_loss: 0.8522 - val_accuracy: 0.6948\n",
      "Epoch 473/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0942 - accuracy: 0.6279 - val_loss: 0.8568 - val_accuracy: 0.6981\n",
      "Epoch 474/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0864 - accuracy: 0.6221 - val_loss: 0.8560 - val_accuracy: 0.6851\n",
      "Epoch 475/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.0995 - accuracy: 0.6181 - val_loss: 0.8199 - val_accuracy: 0.7013\n",
      "Epoch 476/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0853 - accuracy: 0.6401 - val_loss: 0.8099 - val_accuracy: 0.7143\n",
      "Epoch 477/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0502 - accuracy: 0.6433 - val_loss: 0.8032 - val_accuracy: 0.7208\n",
      "Epoch 478/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0469 - accuracy: 0.6572 - val_loss: 0.7848 - val_accuracy: 0.7175\n",
      "Epoch 479/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.0249 - accuracy: 0.6596 - val_loss: 0.7909 - val_accuracy: 0.7013\n",
      "Epoch 480/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.0367 - accuracy: 0.6564 - val_loss: 0.8006 - val_accuracy: 0.7078\n",
      "Epoch 481/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0930 - accuracy: 0.6360 - val_loss: 0.8172 - val_accuracy: 0.7078\n",
      "Epoch 482/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0702 - accuracy: 0.6400 - val_loss: 0.8604 - val_accuracy: 0.6851\n",
      "Epoch 483/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0303 - accuracy: 0.6450 - val_loss: 0.8308 - val_accuracy: 0.6948\n",
      "Epoch 484/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0972 - accuracy: 0.6146 - val_loss: 0.8064 - val_accuracy: 0.7045\n",
      "Epoch 485/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0995 - accuracy: 0.6295 - val_loss: 0.8417 - val_accuracy: 0.6753\n",
      "Epoch 486/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0930 - accuracy: 0.6303 - val_loss: 0.8346 - val_accuracy: 0.6883\n",
      "Epoch 487/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0636 - accuracy: 0.6425 - val_loss: 0.8130 - val_accuracy: 0.7045\n",
      "Epoch 488/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.1199 - accuracy: 0.6319 - val_loss: 0.8624 - val_accuracy: 0.6753\n",
      "Epoch 489/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.0976 - accuracy: 0.6238 - val_loss: 0.8854 - val_accuracy: 0.6688\n",
      "Epoch 490/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0486 - accuracy: 0.6555 - val_loss: 0.8216 - val_accuracy: 0.7370\n",
      "Epoch 491/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0502 - accuracy: 0.6531 - val_loss: 0.8116 - val_accuracy: 0.7078\n",
      "Epoch 492/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0429 - accuracy: 0.6517 - val_loss: 0.8356 - val_accuracy: 0.6753\n",
      "Epoch 493/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0693 - accuracy: 0.6344 - val_loss: 0.8134 - val_accuracy: 0.7143\n",
      "Epoch 494/1500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.0546 - accuracy: 0.6556 - val_loss: 0.8166 - val_accuracy: 0.7013\n",
      "Epoch 495/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0330 - accuracy: 0.6458 - val_loss: 0.8166 - val_accuracy: 0.6883\n",
      "Epoch 496/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0821 - accuracy: 0.6384 - val_loss: 0.7815 - val_accuracy: 0.7143\n",
      "Epoch 497/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0981 - accuracy: 0.6213 - val_loss: 0.7546 - val_accuracy: 0.7500\n",
      "Epoch 498/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.0750 - accuracy: 0.6295 - val_loss: 0.8062 - val_accuracy: 0.7175\n",
      "Epoch 499/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0970 - accuracy: 0.6283 - val_loss: 0.8425 - val_accuracy: 0.7013\n",
      "Epoch 500/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0260 - accuracy: 0.6621 - val_loss: 0.7792 - val_accuracy: 0.7468\n",
      "Epoch 501/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0306 - accuracy: 0.6484 - val_loss: 0.7699 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0216 - accuracy: 0.6417 - val_loss: 0.8151 - val_accuracy: 0.7175\n",
      "Epoch 503/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0661 - accuracy: 0.6490 - val_loss: 0.8487 - val_accuracy: 0.7078\n",
      "Epoch 504/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.0269 - accuracy: 0.6539 - val_loss: 0.8264 - val_accuracy: 0.7143\n",
      "Epoch 505/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0515 - accuracy: 0.6367 - val_loss: 0.8207 - val_accuracy: 0.7175\n",
      "Epoch 506/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0569 - accuracy: 0.6341 - val_loss: 0.8355 - val_accuracy: 0.6883\n",
      "Epoch 507/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.0714 - accuracy: 0.6507 - val_loss: 0.8441 - val_accuracy: 0.7143\n",
      "Epoch 508/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0271 - accuracy: 0.6474 - val_loss: 0.8323 - val_accuracy: 0.7208\n",
      "Epoch 509/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0192 - accuracy: 0.6602 - val_loss: 0.8122 - val_accuracy: 0.7143\n",
      "Epoch 510/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0395 - accuracy: 0.6368 - val_loss: 0.7967 - val_accuracy: 0.7305\n",
      "Epoch 511/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0176 - accuracy: 0.6669 - val_loss: 0.7661 - val_accuracy: 0.7370\n",
      "Epoch 512/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9881 - accuracy: 0.6669 - val_loss: 0.7611 - val_accuracy: 0.7468\n",
      "Epoch 513/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0263 - accuracy: 0.6602 - val_loss: 0.7793 - val_accuracy: 0.7403\n",
      "Epoch 514/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0842 - accuracy: 0.6295 - val_loss: 0.8117 - val_accuracy: 0.7240\n",
      "Epoch 515/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0515 - accuracy: 0.6458 - val_loss: 0.7929 - val_accuracy: 0.7338\n",
      "Epoch 516/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.0452 - accuracy: 0.6474 - val_loss: 0.7942 - val_accuracy: 0.7532\n",
      "Epoch 517/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0465 - accuracy: 0.6352 - val_loss: 0.8551 - val_accuracy: 0.7078\n",
      "Epoch 518/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0563 - accuracy: 0.6409 - val_loss: 0.8285 - val_accuracy: 0.7143\n",
      "Epoch 519/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0019 - accuracy: 0.6543 - val_loss: 0.7768 - val_accuracy: 0.7370\n",
      "Epoch 520/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0342 - accuracy: 0.6539 - val_loss: 0.7675 - val_accuracy: 0.7370\n",
      "Epoch 521/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0288 - accuracy: 0.6352 - val_loss: 0.7894 - val_accuracy: 0.7143\n",
      "Epoch 522/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0292 - accuracy: 0.6523 - val_loss: 0.7915 - val_accuracy: 0.7175\n",
      "Epoch 523/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.0266 - accuracy: 0.6484 - val_loss: 0.7907 - val_accuracy: 0.7305\n",
      "Epoch 524/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0532 - accuracy: 0.6417 - val_loss: 0.7872 - val_accuracy: 0.7468\n",
      "Epoch 525/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.0421 - accuracy: 0.6596 - val_loss: 0.8085 - val_accuracy: 0.7143\n",
      "Epoch 526/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9969 - accuracy: 0.6800 - val_loss: 0.8002 - val_accuracy: 0.7240\n",
      "Epoch 527/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0155 - accuracy: 0.6595 - val_loss: 0.7831 - val_accuracy: 0.7175\n",
      "Epoch 528/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0313 - accuracy: 0.6564 - val_loss: 0.7906 - val_accuracy: 0.7175\n",
      "Epoch 529/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9962 - accuracy: 0.6680 - val_loss: 0.7937 - val_accuracy: 0.7338\n",
      "Epoch 530/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.0024 - accuracy: 0.6637 - val_loss: 0.7943 - val_accuracy: 0.7305\n",
      "Epoch 531/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0481 - accuracy: 0.6490 - val_loss: 0.7796 - val_accuracy: 0.7273\n",
      "Epoch 532/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9892 - accuracy: 0.6515 - val_loss: 0.7852 - val_accuracy: 0.7273\n",
      "Epoch 533/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9902 - accuracy: 0.6555 - val_loss: 0.8008 - val_accuracy: 0.7175\n",
      "Epoch 534/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.0030 - accuracy: 0.6490 - val_loss: 0.7881 - val_accuracy: 0.7175\n",
      "Epoch 535/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0134 - accuracy: 0.6572 - val_loss: 0.7796 - val_accuracy: 0.7370\n",
      "Epoch 536/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.9929 - accuracy: 0.6667 - val_loss: 0.7884 - val_accuracy: 0.7370\n",
      "Epoch 537/1500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.9775 - accuracy: 0.6743 - val_loss: 0.8021 - val_accuracy: 0.7208\n",
      "Epoch 538/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0116 - accuracy: 0.6564 - val_loss: 0.7950 - val_accuracy: 0.7143\n",
      "Epoch 539/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.9948 - accuracy: 0.6669 - val_loss: 0.7686 - val_accuracy: 0.7338\n",
      "Epoch 540/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9798 - accuracy: 0.6732 - val_loss: 0.7598 - val_accuracy: 0.7338\n",
      "Epoch 541/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.9688 - accuracy: 0.6710 - val_loss: 0.7956 - val_accuracy: 0.7110\n",
      "Epoch 542/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9875 - accuracy: 0.6792 - val_loss: 0.7887 - val_accuracy: 0.7305\n",
      "Epoch 543/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0063 - accuracy: 0.6547 - val_loss: 0.8179 - val_accuracy: 0.7240\n",
      "Epoch 544/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.0235 - accuracy: 0.6726 - val_loss: 0.8145 - val_accuracy: 0.7240\n",
      "Epoch 545/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.0361 - accuracy: 0.6539 - val_loss: 0.7997 - val_accuracy: 0.7338\n",
      "Epoch 546/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.0070 - accuracy: 0.6629 - val_loss: 0.7917 - val_accuracy: 0.7273\n",
      "Epoch 547/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.0303 - accuracy: 0.6637 - val_loss: 0.7899 - val_accuracy: 0.7370\n",
      "Epoch 548/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9770 - accuracy: 0.6647 - val_loss: 0.7787 - val_accuracy: 0.7403\n",
      "Epoch 549/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0069 - accuracy: 0.6596 - val_loss: 0.7978 - val_accuracy: 0.7110\n",
      "Epoch 550/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9976 - accuracy: 0.6678 - val_loss: 0.7683 - val_accuracy: 0.7370\n",
      "Epoch 551/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0093 - accuracy: 0.6612 - val_loss: 0.7573 - val_accuracy: 0.7500\n",
      "Epoch 552/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9969 - accuracy: 0.6694 - val_loss: 0.7823 - val_accuracy: 0.7305\n",
      "Epoch 553/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.9920 - accuracy: 0.6595 - val_loss: 0.8133 - val_accuracy: 0.7013\n",
      "Epoch 554/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0059 - accuracy: 0.6726 - val_loss: 0.7502 - val_accuracy: 0.7435\n",
      "Epoch 555/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.9549 - accuracy: 0.6790 - val_loss: 0.7519 - val_accuracy: 0.7468\n",
      "Epoch 556/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9454 - accuracy: 0.6857 - val_loss: 0.7542 - val_accuracy: 0.7468\n",
      "Epoch 557/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9701 - accuracy: 0.6797 - val_loss: 0.7465 - val_accuracy: 0.7435\n",
      "Epoch 558/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.0077 - accuracy: 0.6580 - val_loss: 0.7379 - val_accuracy: 0.7532\n",
      "Epoch 559/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9824 - accuracy: 0.6645 - val_loss: 0.7704 - val_accuracy: 0.7240\n",
      "Epoch 560/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0581 - accuracy: 0.6471 - val_loss: 0.7994 - val_accuracy: 0.7143\n",
      "Epoch 561/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9996 - accuracy: 0.6582 - val_loss: 0.8038 - val_accuracy: 0.7273\n",
      "Epoch 562/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9988 - accuracy: 0.6539 - val_loss: 0.7760 - val_accuracy: 0.7305\n",
      "Epoch 563/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.0005 - accuracy: 0.6615 - val_loss: 0.7737 - val_accuracy: 0.7273\n",
      "Epoch 564/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9489 - accuracy: 0.6824 - val_loss: 0.7478 - val_accuracy: 0.7435\n",
      "Epoch 565/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9762 - accuracy: 0.6686 - val_loss: 0.7549 - val_accuracy: 0.7370\n",
      "Epoch 566/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9715 - accuracy: 0.6588 - val_loss: 0.7455 - val_accuracy: 0.7305\n",
      "Epoch 567/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9977 - accuracy: 0.6547 - val_loss: 0.7559 - val_accuracy: 0.7305\n",
      "Epoch 568/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9783 - accuracy: 0.6547 - val_loss: 0.7483 - val_accuracy: 0.7370\n",
      "Epoch 569/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9750 - accuracy: 0.6725 - val_loss: 0.7739 - val_accuracy: 0.7273\n",
      "Epoch 570/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9608 - accuracy: 0.6726 - val_loss: 0.8047 - val_accuracy: 0.7273\n",
      "Epoch 571/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9846 - accuracy: 0.6615 - val_loss: 0.7643 - val_accuracy: 0.7403\n",
      "Epoch 572/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9655 - accuracy: 0.6694 - val_loss: 0.7391 - val_accuracy: 0.7532\n",
      "Epoch 573/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9528 - accuracy: 0.6718 - val_loss: 0.7394 - val_accuracy: 0.7532\n",
      "Epoch 574/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9372 - accuracy: 0.6881 - val_loss: 0.7331 - val_accuracy: 0.7468\n",
      "Epoch 575/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9398 - accuracy: 0.6621 - val_loss: 0.7415 - val_accuracy: 0.7435\n",
      "Epoch 576/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9701 - accuracy: 0.6816 - val_loss: 0.7739 - val_accuracy: 0.7208\n",
      "Epoch 577/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9660 - accuracy: 0.6767 - val_loss: 0.7803 - val_accuracy: 0.7305\n",
      "Epoch 578/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9429 - accuracy: 0.6743 - val_loss: 0.8002 - val_accuracy: 0.7143\n",
      "Epoch 579/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9772 - accuracy: 0.6702 - val_loss: 0.8251 - val_accuracy: 0.6916\n",
      "Epoch 580/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9433 - accuracy: 0.6738 - val_loss: 0.7836 - val_accuracy: 0.7143\n",
      "Epoch 581/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9462 - accuracy: 0.6836 - val_loss: 0.7557 - val_accuracy: 0.7338\n",
      "Epoch 582/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9361 - accuracy: 0.6738 - val_loss: 0.7617 - val_accuracy: 0.7273\n",
      "Epoch 583/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.0046 - accuracy: 0.6596 - val_loss: 0.7884 - val_accuracy: 0.7175\n",
      "Epoch 584/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9480 - accuracy: 0.6930 - val_loss: 0.7561 - val_accuracy: 0.7338\n",
      "Epoch 585/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.9104 - accuracy: 0.6987 - val_loss: 0.7013 - val_accuracy: 0.7565\n",
      "Epoch 586/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9359 - accuracy: 0.6743 - val_loss: 0.7040 - val_accuracy: 0.7532\n",
      "Epoch 587/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9115 - accuracy: 0.6694 - val_loss: 0.7454 - val_accuracy: 0.7435\n",
      "Epoch 588/1500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.9786 - accuracy: 0.6588 - val_loss: 0.7639 - val_accuracy: 0.7305\n",
      "Epoch 589/1500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.9255 - accuracy: 0.7020 - val_loss: 0.7739 - val_accuracy: 0.7208\n",
      "Epoch 590/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9534 - accuracy: 0.6808 - val_loss: 0.8012 - val_accuracy: 0.7045\n",
      "Epoch 591/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9611 - accuracy: 0.6694 - val_loss: 0.7657 - val_accuracy: 0.7273\n",
      "Epoch 592/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9717 - accuracy: 0.6803 - val_loss: 0.7278 - val_accuracy: 0.7597\n",
      "Epoch 593/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9480 - accuracy: 0.6712 - val_loss: 0.7537 - val_accuracy: 0.7500\n",
      "Epoch 594/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9033 - accuracy: 0.6857 - val_loss: 0.7550 - val_accuracy: 0.7403\n",
      "Epoch 595/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 1.0151 - accuracy: 0.6645 - val_loss: 0.7512 - val_accuracy: 0.7565\n",
      "Epoch 596/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9122 - accuracy: 0.6824 - val_loss: 0.7914 - val_accuracy: 0.7208\n",
      "Epoch 597/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9628 - accuracy: 0.6824 - val_loss: 0.7813 - val_accuracy: 0.7273\n",
      "Epoch 598/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9488 - accuracy: 0.6873 - val_loss: 0.7503 - val_accuracy: 0.7435\n",
      "Epoch 599/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9593 - accuracy: 0.6816 - val_loss: 0.7327 - val_accuracy: 0.7370\n",
      "Epoch 600/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9493 - accuracy: 0.6759 - val_loss: 0.7411 - val_accuracy: 0.7403\n",
      "Epoch 601/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9357 - accuracy: 0.6857 - val_loss: 0.7493 - val_accuracy: 0.7370\n",
      "Epoch 602/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9437 - accuracy: 0.6855 - val_loss: 0.7615 - val_accuracy: 0.7468\n",
      "Epoch 603/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9557 - accuracy: 0.6735 - val_loss: 0.7404 - val_accuracy: 0.7338\n",
      "Epoch 604/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9795 - accuracy: 0.6840 - val_loss: 0.7375 - val_accuracy: 0.7370\n",
      "Epoch 605/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9267 - accuracy: 0.6873 - val_loss: 0.7607 - val_accuracy: 0.7370\n",
      "Epoch 606/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.9487 - accuracy: 0.6862 - val_loss: 0.7439 - val_accuracy: 0.7338\n",
      "Epoch 607/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8819 - accuracy: 0.7142 - val_loss: 0.7406 - val_accuracy: 0.7338\n",
      "Epoch 608/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9627 - accuracy: 0.6849 - val_loss: 0.7681 - val_accuracy: 0.7240\n",
      "Epoch 609/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9821 - accuracy: 0.6678 - val_loss: 0.7762 - val_accuracy: 0.7208\n",
      "Epoch 610/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.9564 - accuracy: 0.6725 - val_loss: 0.7620 - val_accuracy: 0.7338\n",
      "Epoch 611/1500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.9385 - accuracy: 0.6938 - val_loss: 0.7481 - val_accuracy: 0.7305\n",
      "Epoch 612/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9346 - accuracy: 0.6922 - val_loss: 0.7160 - val_accuracy: 0.7435\n",
      "Epoch 613/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9585 - accuracy: 0.6946 - val_loss: 0.7151 - val_accuracy: 0.7468\n",
      "Epoch 614/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9507 - accuracy: 0.6702 - val_loss: 0.7131 - val_accuracy: 0.7403\n",
      "Epoch 615/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9300 - accuracy: 0.6775 - val_loss: 0.6862 - val_accuracy: 0.7630\n",
      "Epoch 616/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9586 - accuracy: 0.6764 - val_loss: 0.6903 - val_accuracy: 0.7630\n",
      "Epoch 617/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9654 - accuracy: 0.6710 - val_loss: 0.7518 - val_accuracy: 0.7370\n",
      "Epoch 618/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.9547 - accuracy: 0.6882 - val_loss: 0.7660 - val_accuracy: 0.7403\n",
      "Epoch 619/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9730 - accuracy: 0.6914 - val_loss: 0.7498 - val_accuracy: 0.7565\n",
      "Epoch 620/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9458 - accuracy: 0.6865 - val_loss: 0.7335 - val_accuracy: 0.7565\n",
      "Epoch 621/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9408 - accuracy: 0.6653 - val_loss: 0.7433 - val_accuracy: 0.7565\n",
      "Epoch 622/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9480 - accuracy: 0.6702 - val_loss: 0.7406 - val_accuracy: 0.7532\n",
      "Epoch 623/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9693 - accuracy: 0.6840 - val_loss: 0.7310 - val_accuracy: 0.7630\n",
      "Epoch 624/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9401 - accuracy: 0.6963 - val_loss: 0.7617 - val_accuracy: 0.7468\n",
      "Epoch 625/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9133 - accuracy: 0.6973 - val_loss: 0.7602 - val_accuracy: 0.7500\n",
      "Epoch 626/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9214 - accuracy: 0.7012 - val_loss: 0.7252 - val_accuracy: 0.7565\n",
      "Epoch 627/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9317 - accuracy: 0.6963 - val_loss: 0.7282 - val_accuracy: 0.7532\n",
      "Epoch 628/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9402 - accuracy: 0.6718 - val_loss: 0.7685 - val_accuracy: 0.7338\n",
      "Epoch 629/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 82ms/step - loss: 0.9306 - accuracy: 0.6840 - val_loss: 0.7694 - val_accuracy: 0.7273\n",
      "Epoch 630/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9037 - accuracy: 0.6824 - val_loss: 0.7533 - val_accuracy: 0.7532\n",
      "Epoch 631/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.9451 - accuracy: 0.6873 - val_loss: 0.7513 - val_accuracy: 0.7370\n",
      "Epoch 632/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9594 - accuracy: 0.6669 - val_loss: 0.7413 - val_accuracy: 0.7435\n",
      "Epoch 633/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9707 - accuracy: 0.6572 - val_loss: 0.7237 - val_accuracy: 0.7532\n",
      "Epoch 634/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9137 - accuracy: 0.7011 - val_loss: 0.7431 - val_accuracy: 0.7403\n",
      "Epoch 635/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8862 - accuracy: 0.7093 - val_loss: 0.7776 - val_accuracy: 0.7403\n",
      "Epoch 636/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9505 - accuracy: 0.6868 - val_loss: 0.7666 - val_accuracy: 0.7338\n",
      "Epoch 637/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.9112 - accuracy: 0.6710 - val_loss: 0.7303 - val_accuracy: 0.7370\n",
      "Epoch 638/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8969 - accuracy: 0.6979 - val_loss: 0.7005 - val_accuracy: 0.7532\n",
      "Epoch 639/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9033 - accuracy: 0.6995 - val_loss: 0.7284 - val_accuracy: 0.7468\n",
      "Epoch 640/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9424 - accuracy: 0.6726 - val_loss: 0.7705 - val_accuracy: 0.7403\n",
      "Epoch 641/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9342 - accuracy: 0.6800 - val_loss: 0.7507 - val_accuracy: 0.7435\n",
      "Epoch 642/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.9341 - accuracy: 0.6987 - val_loss: 0.7184 - val_accuracy: 0.7468\n",
      "Epoch 643/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9445 - accuracy: 0.6808 - val_loss: 0.7014 - val_accuracy: 0.7565\n",
      "Epoch 644/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.9170 - accuracy: 0.6751 - val_loss: 0.7137 - val_accuracy: 0.7597\n",
      "Epoch 645/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8968 - accuracy: 0.6914 - val_loss: 0.7252 - val_accuracy: 0.7468\n",
      "Epoch 646/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.9438 - accuracy: 0.6783 - val_loss: 0.7325 - val_accuracy: 0.7500\n",
      "Epoch 647/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9256 - accuracy: 0.6783 - val_loss: 0.7244 - val_accuracy: 0.7597\n",
      "Epoch 648/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9140 - accuracy: 0.6816 - val_loss: 0.7289 - val_accuracy: 0.7468\n",
      "Epoch 649/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9607 - accuracy: 0.6783 - val_loss: 0.7394 - val_accuracy: 0.7435\n",
      "Epoch 650/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9119 - accuracy: 0.6881 - val_loss: 0.7202 - val_accuracy: 0.7532\n",
      "Epoch 651/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8962 - accuracy: 0.6881 - val_loss: 0.6938 - val_accuracy: 0.7792\n",
      "Epoch 652/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9550 - accuracy: 0.6840 - val_loss: 0.6836 - val_accuracy: 0.7662\n",
      "Epoch 653/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8744 - accuracy: 0.7031 - val_loss: 0.7056 - val_accuracy: 0.7727\n",
      "Epoch 654/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8963 - accuracy: 0.6979 - val_loss: 0.7323 - val_accuracy: 0.7662\n",
      "Epoch 655/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8916 - accuracy: 0.7052 - val_loss: 0.7264 - val_accuracy: 0.7532\n",
      "Epoch 656/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9486 - accuracy: 0.6889 - val_loss: 0.7355 - val_accuracy: 0.7532\n",
      "Epoch 657/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9310 - accuracy: 0.6934 - val_loss: 0.7494 - val_accuracy: 0.7435\n",
      "Epoch 658/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9122 - accuracy: 0.7068 - val_loss: 0.7503 - val_accuracy: 0.7403\n",
      "Epoch 659/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9160 - accuracy: 0.6963 - val_loss: 0.7218 - val_accuracy: 0.7532\n",
      "Epoch 660/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8383 - accuracy: 0.7174 - val_loss: 0.6947 - val_accuracy: 0.7630\n",
      "Epoch 661/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9218 - accuracy: 0.6816 - val_loss: 0.6933 - val_accuracy: 0.7695\n",
      "Epoch 662/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.9132 - accuracy: 0.6992 - val_loss: 0.7028 - val_accuracy: 0.7695\n",
      "Epoch 663/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9090 - accuracy: 0.6946 - val_loss: 0.7355 - val_accuracy: 0.7435\n",
      "Epoch 664/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.9575 - accuracy: 0.6914 - val_loss: 0.7595 - val_accuracy: 0.7370\n",
      "Epoch 665/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8597 - accuracy: 0.7052 - val_loss: 0.7781 - val_accuracy: 0.7175\n",
      "Epoch 666/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9245 - accuracy: 0.6751 - val_loss: 0.7200 - val_accuracy: 0.7532\n",
      "Epoch 667/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9134 - accuracy: 0.7003 - val_loss: 0.6945 - val_accuracy: 0.7532\n",
      "Epoch 668/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9035 - accuracy: 0.7028 - val_loss: 0.6845 - val_accuracy: 0.7630\n",
      "Epoch 669/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8764 - accuracy: 0.7068 - val_loss: 0.6873 - val_accuracy: 0.7662\n",
      "Epoch 670/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8786 - accuracy: 0.7031 - val_loss: 0.6852 - val_accuracy: 0.7630\n",
      "Epoch 671/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8859 - accuracy: 0.7005 - val_loss: 0.7029 - val_accuracy: 0.7565\n",
      "Epoch 672/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8635 - accuracy: 0.6922 - val_loss: 0.6974 - val_accuracy: 0.7435\n",
      "Epoch 673/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8517 - accuracy: 0.7101 - val_loss: 0.6963 - val_accuracy: 0.7532\n",
      "Epoch 674/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8967 - accuracy: 0.6906 - val_loss: 0.6747 - val_accuracy: 0.7630\n",
      "Epoch 675/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8766 - accuracy: 0.6946 - val_loss: 0.6695 - val_accuracy: 0.7597\n",
      "Epoch 676/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8928 - accuracy: 0.7109 - val_loss: 0.6834 - val_accuracy: 0.7532\n",
      "Epoch 677/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9132 - accuracy: 0.6857 - val_loss: 0.7172 - val_accuracy: 0.7500\n",
      "Epoch 678/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8795 - accuracy: 0.7077 - val_loss: 0.7280 - val_accuracy: 0.7532\n",
      "Epoch 679/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9109 - accuracy: 0.6921 - val_loss: 0.6996 - val_accuracy: 0.7597\n",
      "Epoch 680/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8741 - accuracy: 0.7020 - val_loss: 0.6830 - val_accuracy: 0.7662\n",
      "Epoch 681/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8438 - accuracy: 0.7174 - val_loss: 0.6825 - val_accuracy: 0.7630\n",
      "Epoch 682/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9253 - accuracy: 0.6800 - val_loss: 0.6952 - val_accuracy: 0.7532\n",
      "Epoch 683/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9334 - accuracy: 0.6897 - val_loss: 0.7270 - val_accuracy: 0.7435\n",
      "Epoch 684/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8648 - accuracy: 0.7052 - val_loss: 0.7209 - val_accuracy: 0.7565\n",
      "Epoch 685/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8748 - accuracy: 0.7044 - val_loss: 0.6827 - val_accuracy: 0.7565\n",
      "Epoch 686/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8720 - accuracy: 0.7134 - val_loss: 0.6907 - val_accuracy: 0.7565\n",
      "Epoch 687/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8798 - accuracy: 0.6979 - val_loss: 0.6850 - val_accuracy: 0.7662\n",
      "Epoch 688/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9034 - accuracy: 0.6954 - val_loss: 0.6885 - val_accuracy: 0.7695\n",
      "Epoch 689/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8509 - accuracy: 0.7239 - val_loss: 0.6983 - val_accuracy: 0.7695\n",
      "Epoch 690/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8896 - accuracy: 0.6888 - val_loss: 0.7072 - val_accuracy: 0.7695\n",
      "Epoch 691/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8818 - accuracy: 0.6979 - val_loss: 0.6875 - val_accuracy: 0.7760\n",
      "Epoch 692/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8992 - accuracy: 0.6775 - val_loss: 0.6709 - val_accuracy: 0.7727\n",
      "Epoch 693/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8633 - accuracy: 0.7148 - val_loss: 0.6683 - val_accuracy: 0.7695\n",
      "Epoch 694/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8447 - accuracy: 0.7181 - val_loss: 0.6963 - val_accuracy: 0.7727\n",
      "Epoch 695/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8739 - accuracy: 0.7174 - val_loss: 0.7114 - val_accuracy: 0.7597\n",
      "Epoch 696/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8751 - accuracy: 0.6979 - val_loss: 0.7081 - val_accuracy: 0.7630\n",
      "Epoch 697/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.8753 - accuracy: 0.7117 - val_loss: 0.6986 - val_accuracy: 0.7532\n",
      "Epoch 698/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8550 - accuracy: 0.7003 - val_loss: 0.6984 - val_accuracy: 0.7435\n",
      "Epoch 699/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8595 - accuracy: 0.7135 - val_loss: 0.6945 - val_accuracy: 0.7532\n",
      "Epoch 700/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8830 - accuracy: 0.7068 - val_loss: 0.7238 - val_accuracy: 0.7468\n",
      "Epoch 701/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8827 - accuracy: 0.6971 - val_loss: 0.7672 - val_accuracy: 0.7370\n",
      "Epoch 702/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8166 - accuracy: 0.7272 - val_loss: 0.7456 - val_accuracy: 0.7532\n",
      "Epoch 703/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8600 - accuracy: 0.7028 - val_loss: 0.7043 - val_accuracy: 0.7695\n",
      "Epoch 704/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8803 - accuracy: 0.7020 - val_loss: 0.6868 - val_accuracy: 0.7825\n",
      "Epoch 705/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8792 - accuracy: 0.7093 - val_loss: 0.7011 - val_accuracy: 0.7727\n",
      "Epoch 706/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8651 - accuracy: 0.6914 - val_loss: 0.7399 - val_accuracy: 0.7532\n",
      "Epoch 707/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8974 - accuracy: 0.6906 - val_loss: 0.7394 - val_accuracy: 0.7500\n",
      "Epoch 708/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8447 - accuracy: 0.7215 - val_loss: 0.7091 - val_accuracy: 0.7662\n",
      "Epoch 709/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9038 - accuracy: 0.7005 - val_loss: 0.6887 - val_accuracy: 0.7597\n",
      "Epoch 710/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8482 - accuracy: 0.6999 - val_loss: 0.6955 - val_accuracy: 0.7565\n",
      "Epoch 711/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8970 - accuracy: 0.6849 - val_loss: 0.6970 - val_accuracy: 0.7565\n",
      "Epoch 712/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8580 - accuracy: 0.7194 - val_loss: 0.7035 - val_accuracy: 0.7565\n",
      "Epoch 713/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8784 - accuracy: 0.6971 - val_loss: 0.7149 - val_accuracy: 0.7468\n",
      "Epoch 714/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8253 - accuracy: 0.7191 - val_loss: 0.6871 - val_accuracy: 0.7597\n",
      "Epoch 715/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8535 - accuracy: 0.7248 - val_loss: 0.6749 - val_accuracy: 0.7727\n",
      "Epoch 716/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8279 - accuracy: 0.7207 - val_loss: 0.6763 - val_accuracy: 0.7662\n",
      "Epoch 717/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9091 - accuracy: 0.6881 - val_loss: 0.6948 - val_accuracy: 0.7597\n",
      "Epoch 718/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9025 - accuracy: 0.6816 - val_loss: 0.7154 - val_accuracy: 0.7630\n",
      "Epoch 719/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8999 - accuracy: 0.6881 - val_loss: 0.7311 - val_accuracy: 0.7565\n",
      "Epoch 720/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.9134 - accuracy: 0.6927 - val_loss: 0.7154 - val_accuracy: 0.7597\n",
      "Epoch 721/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8824 - accuracy: 0.7044 - val_loss: 0.6975 - val_accuracy: 0.7597\n",
      "Epoch 722/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.8910 - accuracy: 0.6987 - val_loss: 0.6947 - val_accuracy: 0.7695\n",
      "Epoch 723/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8232 - accuracy: 0.7174 - val_loss: 0.7035 - val_accuracy: 0.7532\n",
      "Epoch 724/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8787 - accuracy: 0.7031 - val_loss: 0.6808 - val_accuracy: 0.7662\n",
      "Epoch 725/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8531 - accuracy: 0.7150 - val_loss: 0.6792 - val_accuracy: 0.7630\n",
      "Epoch 726/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8787 - accuracy: 0.7068 - val_loss: 0.6829 - val_accuracy: 0.7597\n",
      "Epoch 727/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8743 - accuracy: 0.6954 - val_loss: 0.6856 - val_accuracy: 0.7695\n",
      "Epoch 728/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8806 - accuracy: 0.6938 - val_loss: 0.7021 - val_accuracy: 0.7695\n",
      "Epoch 729/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8547 - accuracy: 0.7150 - val_loss: 0.6945 - val_accuracy: 0.7662\n",
      "Epoch 730/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8986 - accuracy: 0.6979 - val_loss: 0.6832 - val_accuracy: 0.7695\n",
      "Epoch 731/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8813 - accuracy: 0.7109 - val_loss: 0.6851 - val_accuracy: 0.7792\n",
      "Epoch 732/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8523 - accuracy: 0.7150 - val_loss: 0.6914 - val_accuracy: 0.7792\n",
      "Epoch 733/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8710 - accuracy: 0.7011 - val_loss: 0.6943 - val_accuracy: 0.7760\n",
      "Epoch 734/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8473 - accuracy: 0.7077 - val_loss: 0.6735 - val_accuracy: 0.7792\n",
      "Epoch 735/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8584 - accuracy: 0.7011 - val_loss: 0.6653 - val_accuracy: 0.7792\n",
      "Epoch 736/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8260 - accuracy: 0.7207 - val_loss: 0.6444 - val_accuracy: 0.7955\n",
      "Epoch 737/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8855 - accuracy: 0.7036 - val_loss: 0.6535 - val_accuracy: 0.7890\n",
      "Epoch 738/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8525 - accuracy: 0.7182 - val_loss: 0.6579 - val_accuracy: 0.7857\n",
      "Epoch 739/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8442 - accuracy: 0.7148 - val_loss: 0.6755 - val_accuracy: 0.7760\n",
      "Epoch 740/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8723 - accuracy: 0.7191 - val_loss: 0.6829 - val_accuracy: 0.7792\n",
      "Epoch 741/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8085 - accuracy: 0.7313 - val_loss: 0.6698 - val_accuracy: 0.7857\n",
      "Epoch 742/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8685 - accuracy: 0.6963 - val_loss: 0.6559 - val_accuracy: 0.7792\n",
      "Epoch 743/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 59ms/step - loss: 0.8117 - accuracy: 0.7191 - val_loss: 0.6482 - val_accuracy: 0.7890\n",
      "Epoch 744/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8331 - accuracy: 0.7174 - val_loss: 0.6349 - val_accuracy: 0.7825\n",
      "Epoch 745/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8276 - accuracy: 0.7096 - val_loss: 0.6618 - val_accuracy: 0.7630\n",
      "Epoch 746/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8911 - accuracy: 0.7150 - val_loss: 0.6807 - val_accuracy: 0.7597\n",
      "Epoch 747/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8415 - accuracy: 0.7070 - val_loss: 0.6894 - val_accuracy: 0.7597\n",
      "Epoch 748/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8458 - accuracy: 0.7150 - val_loss: 0.6897 - val_accuracy: 0.7630\n",
      "Epoch 749/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7823 - accuracy: 0.7296 - val_loss: 0.6875 - val_accuracy: 0.7597\n",
      "Epoch 750/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8261 - accuracy: 0.7142 - val_loss: 0.6706 - val_accuracy: 0.7630\n",
      "Epoch 751/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8308 - accuracy: 0.7101 - val_loss: 0.6672 - val_accuracy: 0.7727\n",
      "Epoch 752/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7994 - accuracy: 0.7344 - val_loss: 0.6775 - val_accuracy: 0.7597\n",
      "Epoch 753/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8336 - accuracy: 0.7223 - val_loss: 0.6862 - val_accuracy: 0.7565\n",
      "Epoch 754/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8051 - accuracy: 0.7288 - val_loss: 0.6792 - val_accuracy: 0.7727\n",
      "Epoch 755/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8581 - accuracy: 0.7280 - val_loss: 0.6433 - val_accuracy: 0.7857\n",
      "Epoch 756/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8375 - accuracy: 0.7060 - val_loss: 0.6433 - val_accuracy: 0.7955\n",
      "Epoch 757/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8186 - accuracy: 0.7363 - val_loss: 0.6400 - val_accuracy: 0.7760\n",
      "Epoch 758/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8699 - accuracy: 0.6971 - val_loss: 0.6375 - val_accuracy: 0.7760\n",
      "Epoch 759/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8236 - accuracy: 0.7182 - val_loss: 0.6522 - val_accuracy: 0.7760\n",
      "Epoch 760/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8300 - accuracy: 0.7166 - val_loss: 0.6690 - val_accuracy: 0.7760\n",
      "Epoch 761/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8478 - accuracy: 0.7182 - val_loss: 0.6783 - val_accuracy: 0.7565\n",
      "Epoch 762/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8584 - accuracy: 0.7003 - val_loss: 0.7071 - val_accuracy: 0.7597\n",
      "Epoch 763/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8248 - accuracy: 0.7158 - val_loss: 0.7180 - val_accuracy: 0.7565\n",
      "Epoch 764/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8211 - accuracy: 0.7264 - val_loss: 0.7079 - val_accuracy: 0.7695\n",
      "Epoch 765/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8183 - accuracy: 0.7220 - val_loss: 0.6930 - val_accuracy: 0.7662\n",
      "Epoch 766/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.9004 - accuracy: 0.7011 - val_loss: 0.6940 - val_accuracy: 0.7630\n",
      "Epoch 767/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8209 - accuracy: 0.7233 - val_loss: 0.6796 - val_accuracy: 0.7727\n",
      "Epoch 768/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8326 - accuracy: 0.7223 - val_loss: 0.6706 - val_accuracy: 0.7695\n",
      "Epoch 769/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8553 - accuracy: 0.6865 - val_loss: 0.6731 - val_accuracy: 0.7662\n",
      "Epoch 770/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7870 - accuracy: 0.7264 - val_loss: 0.6681 - val_accuracy: 0.7630\n",
      "Epoch 771/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8212 - accuracy: 0.7256 - val_loss: 0.6912 - val_accuracy: 0.7630\n",
      "Epoch 772/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7782 - accuracy: 0.7329 - val_loss: 0.6793 - val_accuracy: 0.7760\n",
      "Epoch 773/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8338 - accuracy: 0.7239 - val_loss: 0.6741 - val_accuracy: 0.7695\n",
      "Epoch 774/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8493 - accuracy: 0.7096 - val_loss: 0.6823 - val_accuracy: 0.7727\n",
      "Epoch 775/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8129 - accuracy: 0.7142 - val_loss: 0.6871 - val_accuracy: 0.7662\n",
      "Epoch 776/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8121 - accuracy: 0.7324 - val_loss: 0.6669 - val_accuracy: 0.7760\n",
      "Epoch 777/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8336 - accuracy: 0.7240 - val_loss: 0.6553 - val_accuracy: 0.7760\n",
      "Epoch 778/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8227 - accuracy: 0.7207 - val_loss: 0.6526 - val_accuracy: 0.7695\n",
      "Epoch 779/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8899 - accuracy: 0.6800 - val_loss: 0.6846 - val_accuracy: 0.7597\n",
      "Epoch 780/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8118 - accuracy: 0.7288 - val_loss: 0.6930 - val_accuracy: 0.7597\n",
      "Epoch 781/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8181 - accuracy: 0.7298 - val_loss: 0.6631 - val_accuracy: 0.7825\n",
      "Epoch 782/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8043 - accuracy: 0.7117 - val_loss: 0.6557 - val_accuracy: 0.7565\n",
      "Epoch 783/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8110 - accuracy: 0.7350 - val_loss: 0.6758 - val_accuracy: 0.7500\n",
      "Epoch 784/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8426 - accuracy: 0.7166 - val_loss: 0.6903 - val_accuracy: 0.7630\n",
      "Epoch 785/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8087 - accuracy: 0.7451 - val_loss: 0.6990 - val_accuracy: 0.7597\n",
      "Epoch 786/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8118 - accuracy: 0.7223 - val_loss: 0.6903 - val_accuracy: 0.7500\n",
      "Epoch 787/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7850 - accuracy: 0.7378 - val_loss: 0.6617 - val_accuracy: 0.7565\n",
      "Epoch 788/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8000 - accuracy: 0.7223 - val_loss: 0.6421 - val_accuracy: 0.7792\n",
      "Epoch 789/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8173 - accuracy: 0.7044 - val_loss: 0.6609 - val_accuracy: 0.7662\n",
      "Epoch 790/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8315 - accuracy: 0.7174 - val_loss: 0.6928 - val_accuracy: 0.7597\n",
      "Epoch 791/1500\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.8601 - accuracy: 0.7158 - val_loss: 0.6752 - val_accuracy: 0.7825\n",
      "Epoch 792/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8155 - accuracy: 0.7288 - val_loss: 0.6355 - val_accuracy: 0.7857\n",
      "Epoch 793/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8130 - accuracy: 0.7134 - val_loss: 0.6329 - val_accuracy: 0.8052\n",
      "Epoch 794/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8118 - accuracy: 0.7150 - val_loss: 0.6728 - val_accuracy: 0.7792\n",
      "Epoch 795/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7923 - accuracy: 0.7402 - val_loss: 0.6783 - val_accuracy: 0.7760\n",
      "Epoch 796/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7449 - accuracy: 0.7728 - val_loss: 0.6699 - val_accuracy: 0.7792\n",
      "Epoch 797/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.8183 - accuracy: 0.7248 - val_loss: 0.6491 - val_accuracy: 0.7662\n",
      "Epoch 798/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7893 - accuracy: 0.7353 - val_loss: 0.6486 - val_accuracy: 0.7597\n",
      "Epoch 799/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8355 - accuracy: 0.7292 - val_loss: 0.6645 - val_accuracy: 0.7630\n",
      "Epoch 800/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8349 - accuracy: 0.7003 - val_loss: 0.6801 - val_accuracy: 0.7532\n",
      "Epoch 801/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8148 - accuracy: 0.7199 - val_loss: 0.6824 - val_accuracy: 0.7532\n",
      "Epoch 802/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8317 - accuracy: 0.7215 - val_loss: 0.6687 - val_accuracy: 0.7468\n",
      "Epoch 803/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8290 - accuracy: 0.7191 - val_loss: 0.6655 - val_accuracy: 0.7500\n",
      "Epoch 804/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7757 - accuracy: 0.7353 - val_loss: 0.6589 - val_accuracy: 0.7532\n",
      "Epoch 805/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8184 - accuracy: 0.7378 - val_loss: 0.6478 - val_accuracy: 0.7857\n",
      "Epoch 806/1500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.8161 - accuracy: 0.7117 - val_loss: 0.6280 - val_accuracy: 0.7922\n",
      "Epoch 807/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8358 - accuracy: 0.7272 - val_loss: 0.6274 - val_accuracy: 0.8019\n",
      "Epoch 808/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8259 - accuracy: 0.7182 - val_loss: 0.6346 - val_accuracy: 0.7825\n",
      "Epoch 809/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8098 - accuracy: 0.7264 - val_loss: 0.6366 - val_accuracy: 0.7857\n",
      "Epoch 810/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8097 - accuracy: 0.7427 - val_loss: 0.6512 - val_accuracy: 0.7695\n",
      "Epoch 811/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7645 - accuracy: 0.7362 - val_loss: 0.6396 - val_accuracy: 0.7760\n",
      "Epoch 812/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.8174 - accuracy: 0.7150 - val_loss: 0.6329 - val_accuracy: 0.7857\n",
      "Epoch 813/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8175 - accuracy: 0.7253 - val_loss: 0.6482 - val_accuracy: 0.7857\n",
      "Epoch 814/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8431 - accuracy: 0.7264 - val_loss: 0.6844 - val_accuracy: 0.7695\n",
      "Epoch 815/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7998 - accuracy: 0.7362 - val_loss: 0.6679 - val_accuracy: 0.7695\n",
      "Epoch 816/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8144 - accuracy: 0.7296 - val_loss: 0.6265 - val_accuracy: 0.7792\n",
      "Epoch 817/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.7694 - accuracy: 0.7345 - val_loss: 0.6154 - val_accuracy: 0.7922\n",
      "Epoch 818/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7974 - accuracy: 0.7329 - val_loss: 0.6332 - val_accuracy: 0.7857\n",
      "Epoch 819/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.8258 - accuracy: 0.7109 - val_loss: 0.6678 - val_accuracy: 0.7630\n",
      "Epoch 820/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8184 - accuracy: 0.7362 - val_loss: 0.6684 - val_accuracy: 0.7630\n",
      "Epoch 821/1500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7868 - accuracy: 0.7427 - val_loss: 0.6540 - val_accuracy: 0.7727\n",
      "Epoch 822/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7925 - accuracy: 0.7298 - val_loss: 0.6370 - val_accuracy: 0.7727\n",
      "Epoch 823/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8126 - accuracy: 0.7288 - val_loss: 0.6349 - val_accuracy: 0.7890\n",
      "Epoch 824/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8103 - accuracy: 0.7264 - val_loss: 0.6597 - val_accuracy: 0.7695\n",
      "Epoch 825/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8105 - accuracy: 0.7233 - val_loss: 0.6718 - val_accuracy: 0.7825\n",
      "Epoch 826/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7687 - accuracy: 0.7288 - val_loss: 0.6371 - val_accuracy: 0.7825\n",
      "Epoch 827/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8246 - accuracy: 0.7207 - val_loss: 0.6190 - val_accuracy: 0.7890\n",
      "Epoch 828/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8718 - accuracy: 0.6995 - val_loss: 0.6466 - val_accuracy: 0.7825\n",
      "Epoch 829/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7990 - accuracy: 0.7259 - val_loss: 0.6886 - val_accuracy: 0.7792\n",
      "Epoch 830/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7830 - accuracy: 0.7370 - val_loss: 0.6663 - val_accuracy: 0.7727\n",
      "Epoch 831/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8137 - accuracy: 0.7240 - val_loss: 0.6341 - val_accuracy: 0.7760\n",
      "Epoch 832/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8305 - accuracy: 0.7305 - val_loss: 0.6616 - val_accuracy: 0.7597\n",
      "Epoch 833/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7500 - accuracy: 0.7467 - val_loss: 0.6673 - val_accuracy: 0.7565\n",
      "Epoch 834/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7899 - accuracy: 0.7298 - val_loss: 0.6523 - val_accuracy: 0.7597\n",
      "Epoch 835/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8102 - accuracy: 0.7248 - val_loss: 0.6478 - val_accuracy: 0.7565\n",
      "Epoch 836/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8170 - accuracy: 0.7362 - val_loss: 0.6584 - val_accuracy: 0.7532\n",
      "Epoch 837/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7878 - accuracy: 0.7370 - val_loss: 0.6592 - val_accuracy: 0.7597\n",
      "Epoch 838/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8320 - accuracy: 0.7096 - val_loss: 0.6607 - val_accuracy: 0.7630\n",
      "Epoch 839/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7841 - accuracy: 0.7435 - val_loss: 0.6516 - val_accuracy: 0.7695\n",
      "Epoch 840/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8101 - accuracy: 0.7231 - val_loss: 0.6298 - val_accuracy: 0.7727\n",
      "Epoch 841/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8690 - accuracy: 0.7051 - val_loss: 0.6301 - val_accuracy: 0.7890\n",
      "Epoch 842/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8216 - accuracy: 0.7191 - val_loss: 0.6437 - val_accuracy: 0.7825\n",
      "Epoch 843/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8160 - accuracy: 0.7135 - val_loss: 0.6426 - val_accuracy: 0.7890\n",
      "Epoch 844/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8335 - accuracy: 0.7025 - val_loss: 0.6406 - val_accuracy: 0.7825\n",
      "Epoch 845/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8276 - accuracy: 0.7231 - val_loss: 0.6494 - val_accuracy: 0.7825\n",
      "Epoch 846/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8042 - accuracy: 0.7199 - val_loss: 0.6483 - val_accuracy: 0.7825\n",
      "Epoch 847/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7833 - accuracy: 0.7419 - val_loss: 0.6296 - val_accuracy: 0.7890\n",
      "Epoch 848/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7962 - accuracy: 0.7345 - val_loss: 0.6103 - val_accuracy: 0.7857\n",
      "Epoch 849/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7777 - accuracy: 0.7409 - val_loss: 0.6065 - val_accuracy: 0.7760\n",
      "Epoch 850/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7673 - accuracy: 0.7248 - val_loss: 0.6090 - val_accuracy: 0.7760\n",
      "Epoch 851/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8057 - accuracy: 0.7166 - val_loss: 0.6109 - val_accuracy: 0.7890\n",
      "Epoch 852/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7405 - accuracy: 0.7647 - val_loss: 0.6219 - val_accuracy: 0.7792\n",
      "Epoch 853/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7881 - accuracy: 0.7337 - val_loss: 0.6459 - val_accuracy: 0.7662\n",
      "Epoch 854/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.8236 - accuracy: 0.7239 - val_loss: 0.6441 - val_accuracy: 0.7662\n",
      "Epoch 855/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7725 - accuracy: 0.7454 - val_loss: 0.6290 - val_accuracy: 0.7760\n",
      "Epoch 856/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7322 - accuracy: 0.7370 - val_loss: 0.6196 - val_accuracy: 0.7857\n",
      "Epoch 857/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 79ms/step - loss: 0.7749 - accuracy: 0.7448 - val_loss: 0.6180 - val_accuracy: 0.7760\n",
      "Epoch 858/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7808 - accuracy: 0.7353 - val_loss: 0.6248 - val_accuracy: 0.7630\n",
      "Epoch 859/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7751 - accuracy: 0.7500 - val_loss: 0.6184 - val_accuracy: 0.7695\n",
      "Epoch 860/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8011 - accuracy: 0.7288 - val_loss: 0.6378 - val_accuracy: 0.7760\n",
      "Epoch 861/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8169 - accuracy: 0.7410 - val_loss: 0.6524 - val_accuracy: 0.7727\n",
      "Epoch 862/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7991 - accuracy: 0.7239 - val_loss: 0.6598 - val_accuracy: 0.7727\n",
      "Epoch 863/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7764 - accuracy: 0.7655 - val_loss: 0.6485 - val_accuracy: 0.7760\n",
      "Epoch 864/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8342 - accuracy: 0.7068 - val_loss: 0.6360 - val_accuracy: 0.7630\n",
      "Epoch 865/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7901 - accuracy: 0.7389 - val_loss: 0.6318 - val_accuracy: 0.7630\n",
      "Epoch 866/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7998 - accuracy: 0.7402 - val_loss: 0.6513 - val_accuracy: 0.7727\n",
      "Epoch 867/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7793 - accuracy: 0.7394 - val_loss: 0.6353 - val_accuracy: 0.7695\n",
      "Epoch 868/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7779 - accuracy: 0.7467 - val_loss: 0.6325 - val_accuracy: 0.7760\n",
      "Epoch 869/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7984 - accuracy: 0.7443 - val_loss: 0.6306 - val_accuracy: 0.7792\n",
      "Epoch 870/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7748 - accuracy: 0.7441 - val_loss: 0.6410 - val_accuracy: 0.7825\n",
      "Epoch 871/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7614 - accuracy: 0.7329 - val_loss: 0.6502 - val_accuracy: 0.7727\n",
      "Epoch 872/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7748 - accuracy: 0.7402 - val_loss: 0.6484 - val_accuracy: 0.7792\n",
      "Epoch 873/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6900 - accuracy: 0.7712 - val_loss: 0.6237 - val_accuracy: 0.7727\n",
      "Epoch 874/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8186 - accuracy: 0.7125 - val_loss: 0.6156 - val_accuracy: 0.7792\n",
      "Epoch 875/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7883 - accuracy: 0.7321 - val_loss: 0.6326 - val_accuracy: 0.7792\n",
      "Epoch 876/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7638 - accuracy: 0.7427 - val_loss: 0.6505 - val_accuracy: 0.7597\n",
      "Epoch 877/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7154 - accuracy: 0.7573 - val_loss: 0.6278 - val_accuracy: 0.7727\n",
      "Epoch 878/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8263 - accuracy: 0.7174 - val_loss: 0.6159 - val_accuracy: 0.7825\n",
      "Epoch 879/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7589 - accuracy: 0.7337 - val_loss: 0.6081 - val_accuracy: 0.8019\n",
      "Epoch 880/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8014 - accuracy: 0.7362 - val_loss: 0.6192 - val_accuracy: 0.7792\n",
      "Epoch 881/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7934 - accuracy: 0.7410 - val_loss: 0.6537 - val_accuracy: 0.7857\n",
      "Epoch 882/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8025 - accuracy: 0.7280 - val_loss: 0.6589 - val_accuracy: 0.7857\n",
      "Epoch 883/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7696 - accuracy: 0.7350 - val_loss: 0.6395 - val_accuracy: 0.7857\n",
      "Epoch 884/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7824 - accuracy: 0.7256 - val_loss: 0.6133 - val_accuracy: 0.7792\n",
      "Epoch 885/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8796 - accuracy: 0.7060 - val_loss: 0.6226 - val_accuracy: 0.7857\n",
      "Epoch 886/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8181 - accuracy: 0.7142 - val_loss: 0.6432 - val_accuracy: 0.7760\n",
      "Epoch 887/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7714 - accuracy: 0.7435 - val_loss: 0.6510 - val_accuracy: 0.7727\n",
      "Epoch 888/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7447 - accuracy: 0.7476 - val_loss: 0.6226 - val_accuracy: 0.7890\n",
      "Epoch 889/1500\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.7726 - accuracy: 0.7215 - val_loss: 0.6232 - val_accuracy: 0.7825\n",
      "Epoch 890/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7605 - accuracy: 0.7428 - val_loss: 0.6334 - val_accuracy: 0.7792\n",
      "Epoch 891/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7691 - accuracy: 0.7296 - val_loss: 0.6478 - val_accuracy: 0.7792\n",
      "Epoch 892/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7838 - accuracy: 0.7288 - val_loss: 0.6450 - val_accuracy: 0.7825\n",
      "Epoch 893/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7703 - accuracy: 0.7476 - val_loss: 0.6439 - val_accuracy: 0.7760\n",
      "Epoch 894/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7915 - accuracy: 0.7248 - val_loss: 0.6437 - val_accuracy: 0.7727\n",
      "Epoch 895/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7972 - accuracy: 0.7296 - val_loss: 0.6461 - val_accuracy: 0.7760\n",
      "Epoch 896/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7719 - accuracy: 0.7410 - val_loss: 0.6619 - val_accuracy: 0.7792\n",
      "Epoch 897/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7791 - accuracy: 0.7443 - val_loss: 0.6445 - val_accuracy: 0.7760\n",
      "Epoch 898/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7716 - accuracy: 0.7443 - val_loss: 0.6282 - val_accuracy: 0.7792\n",
      "Epoch 899/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7565 - accuracy: 0.7461 - val_loss: 0.6222 - val_accuracy: 0.7760\n",
      "Epoch 900/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7700 - accuracy: 0.7474 - val_loss: 0.6294 - val_accuracy: 0.7630\n",
      "Epoch 901/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7522 - accuracy: 0.7378 - val_loss: 0.6523 - val_accuracy: 0.7532\n",
      "Epoch 902/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7752 - accuracy: 0.7337 - val_loss: 0.6562 - val_accuracy: 0.7662\n",
      "Epoch 903/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7647 - accuracy: 0.7378 - val_loss: 0.6416 - val_accuracy: 0.7857\n",
      "Epoch 904/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7274 - accuracy: 0.7614 - val_loss: 0.6263 - val_accuracy: 0.7955\n",
      "Epoch 905/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7960 - accuracy: 0.7231 - val_loss: 0.6221 - val_accuracy: 0.7922\n",
      "Epoch 906/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7597 - accuracy: 0.7396 - val_loss: 0.6228 - val_accuracy: 0.7857\n",
      "Epoch 907/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7531 - accuracy: 0.7539 - val_loss: 0.6432 - val_accuracy: 0.7792\n",
      "Epoch 908/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7513 - accuracy: 0.7480 - val_loss: 0.6678 - val_accuracy: 0.7695\n",
      "Epoch 909/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7799 - accuracy: 0.7285 - val_loss: 0.6460 - val_accuracy: 0.7857\n",
      "Epoch 910/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7655 - accuracy: 0.7272 - val_loss: 0.6138 - val_accuracy: 0.7955\n",
      "Epoch 911/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8049 - accuracy: 0.7223 - val_loss: 0.6165 - val_accuracy: 0.7987\n",
      "Epoch 912/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7246 - accuracy: 0.7591 - val_loss: 0.6470 - val_accuracy: 0.7792\n",
      "Epoch 913/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7317 - accuracy: 0.7720 - val_loss: 0.6374 - val_accuracy: 0.7825\n",
      "Epoch 914/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7641 - accuracy: 0.7296 - val_loss: 0.5931 - val_accuracy: 0.8052\n",
      "Epoch 915/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8068 - accuracy: 0.7337 - val_loss: 0.5826 - val_accuracy: 0.7987\n",
      "Epoch 916/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7740 - accuracy: 0.7459 - val_loss: 0.6134 - val_accuracy: 0.7857\n",
      "Epoch 917/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7642 - accuracy: 0.7500 - val_loss: 0.6349 - val_accuracy: 0.7760\n",
      "Epoch 918/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.8224 - accuracy: 0.7182 - val_loss: 0.6255 - val_accuracy: 0.7825\n",
      "Epoch 919/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7442 - accuracy: 0.7533 - val_loss: 0.6282 - val_accuracy: 0.7825\n",
      "Epoch 920/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7905 - accuracy: 0.7396 - val_loss: 0.6278 - val_accuracy: 0.7825\n",
      "Epoch 921/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7522 - accuracy: 0.7508 - val_loss: 0.6272 - val_accuracy: 0.7857\n",
      "Epoch 922/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8034 - accuracy: 0.7410 - val_loss: 0.6287 - val_accuracy: 0.7825\n",
      "Epoch 923/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7471 - accuracy: 0.7524 - val_loss: 0.6369 - val_accuracy: 0.7792\n",
      "Epoch 924/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7926 - accuracy: 0.7549 - val_loss: 0.6179 - val_accuracy: 0.7727\n",
      "Epoch 925/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7700 - accuracy: 0.7363 - val_loss: 0.6073 - val_accuracy: 0.7792\n",
      "Epoch 926/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7771 - accuracy: 0.7337 - val_loss: 0.6071 - val_accuracy: 0.7695\n",
      "Epoch 927/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7455 - accuracy: 0.7467 - val_loss: 0.6065 - val_accuracy: 0.7825\n",
      "Epoch 928/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7840 - accuracy: 0.7296 - val_loss: 0.6104 - val_accuracy: 0.7760\n",
      "Epoch 929/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7146 - accuracy: 0.7708 - val_loss: 0.6223 - val_accuracy: 0.7857\n",
      "Epoch 930/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7320 - accuracy: 0.7552 - val_loss: 0.6263 - val_accuracy: 0.7857\n",
      "Epoch 931/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7766 - accuracy: 0.7484 - val_loss: 0.6250 - val_accuracy: 0.7890\n",
      "Epoch 932/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7658 - accuracy: 0.7285 - val_loss: 0.6166 - val_accuracy: 0.7955\n",
      "Epoch 933/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7948 - accuracy: 0.7461 - val_loss: 0.6162 - val_accuracy: 0.7955\n",
      "Epoch 934/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7415 - accuracy: 0.7467 - val_loss: 0.5917 - val_accuracy: 0.7890\n",
      "Epoch 935/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7995 - accuracy: 0.7305 - val_loss: 0.5833 - val_accuracy: 0.8052\n",
      "Epoch 936/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7462 - accuracy: 0.7386 - val_loss: 0.5874 - val_accuracy: 0.8084\n",
      "Epoch 937/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7592 - accuracy: 0.7492 - val_loss: 0.6193 - val_accuracy: 0.7727\n",
      "Epoch 938/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6953 - accuracy: 0.7647 - val_loss: 0.6231 - val_accuracy: 0.7792\n",
      "Epoch 939/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7766 - accuracy: 0.7396 - val_loss: 0.5979 - val_accuracy: 0.7890\n",
      "Epoch 940/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7369 - accuracy: 0.7557 - val_loss: 0.5825 - val_accuracy: 0.7922\n",
      "Epoch 941/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7295 - accuracy: 0.7516 - val_loss: 0.5941 - val_accuracy: 0.7955\n",
      "Epoch 942/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7278 - accuracy: 0.7704 - val_loss: 0.6008 - val_accuracy: 0.7890\n",
      "Epoch 943/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7468 - accuracy: 0.7492 - val_loss: 0.5935 - val_accuracy: 0.7890\n",
      "Epoch 944/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7412 - accuracy: 0.7378 - val_loss: 0.5870 - val_accuracy: 0.7955\n",
      "Epoch 945/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7391 - accuracy: 0.7394 - val_loss: 0.6056 - val_accuracy: 0.7987\n",
      "Epoch 946/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7239 - accuracy: 0.7598 - val_loss: 0.6281 - val_accuracy: 0.7987\n",
      "Epoch 947/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7463 - accuracy: 0.7443 - val_loss: 0.6214 - val_accuracy: 0.7792\n",
      "Epoch 948/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7438 - accuracy: 0.7448 - val_loss: 0.6078 - val_accuracy: 0.7890\n",
      "Epoch 949/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7417 - accuracy: 0.7638 - val_loss: 0.5919 - val_accuracy: 0.7955\n",
      "Epoch 950/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6920 - accuracy: 0.7679 - val_loss: 0.5917 - val_accuracy: 0.7987\n",
      "Epoch 951/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7269 - accuracy: 0.7451 - val_loss: 0.5935 - val_accuracy: 0.8084\n",
      "Epoch 952/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7557 - accuracy: 0.7248 - val_loss: 0.5936 - val_accuracy: 0.8052\n",
      "Epoch 953/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7446 - accuracy: 0.7492 - val_loss: 0.5830 - val_accuracy: 0.8019\n",
      "Epoch 954/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7926 - accuracy: 0.7415 - val_loss: 0.5853 - val_accuracy: 0.8019\n",
      "Epoch 955/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7541 - accuracy: 0.7435 - val_loss: 0.5807 - val_accuracy: 0.8019\n",
      "Epoch 956/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7261 - accuracy: 0.7598 - val_loss: 0.5823 - val_accuracy: 0.7955\n",
      "Epoch 957/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.8021 - accuracy: 0.7345 - val_loss: 0.5853 - val_accuracy: 0.7987\n",
      "Epoch 958/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7985 - accuracy: 0.7248 - val_loss: 0.6085 - val_accuracy: 0.7890\n",
      "Epoch 959/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7668 - accuracy: 0.7362 - val_loss: 0.6072 - val_accuracy: 0.7922\n",
      "Epoch 960/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7481 - accuracy: 0.7573 - val_loss: 0.6064 - val_accuracy: 0.8019\n",
      "Epoch 961/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7706 - accuracy: 0.7476 - val_loss: 0.6086 - val_accuracy: 0.7987\n",
      "Epoch 962/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7488 - accuracy: 0.7573 - val_loss: 0.6047 - val_accuracy: 0.7987\n",
      "Epoch 963/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7276 - accuracy: 0.7565 - val_loss: 0.6011 - val_accuracy: 0.7955\n",
      "Epoch 964/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7843 - accuracy: 0.7541 - val_loss: 0.6164 - val_accuracy: 0.7987\n",
      "Epoch 965/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7468 - accuracy: 0.7650 - val_loss: 0.6174 - val_accuracy: 0.7922\n",
      "Epoch 966/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7120 - accuracy: 0.7451 - val_loss: 0.6164 - val_accuracy: 0.7955\n",
      "Epoch 967/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7860 - accuracy: 0.7443 - val_loss: 0.6295 - val_accuracy: 0.7955\n",
      "Epoch 968/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7341 - accuracy: 0.7549 - val_loss: 0.6287 - val_accuracy: 0.7955\n",
      "Epoch 969/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7633 - accuracy: 0.7378 - val_loss: 0.6236 - val_accuracy: 0.7922\n",
      "Epoch 970/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7627 - accuracy: 0.7492 - val_loss: 0.6194 - val_accuracy: 0.7922\n",
      "Epoch 971/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7550 - accuracy: 0.7419 - val_loss: 0.6129 - val_accuracy: 0.7987\n",
      "Epoch 972/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7349 - accuracy: 0.7565 - val_loss: 0.6137 - val_accuracy: 0.7890\n",
      "Epoch 973/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7630 - accuracy: 0.7410 - val_loss: 0.6295 - val_accuracy: 0.7890\n",
      "Epoch 974/1500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7277 - accuracy: 0.7565 - val_loss: 0.6323 - val_accuracy: 0.7890\n",
      "Epoch 975/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.7539 - accuracy: 0.7378 - val_loss: 0.6120 - val_accuracy: 0.7792\n",
      "Epoch 976/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7720 - accuracy: 0.7337 - val_loss: 0.5994 - val_accuracy: 0.7955\n",
      "Epoch 977/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7320 - accuracy: 0.7526 - val_loss: 0.6076 - val_accuracy: 0.7922\n",
      "Epoch 978/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7419 - accuracy: 0.7370 - val_loss: 0.6070 - val_accuracy: 0.7922\n",
      "Epoch 979/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6917 - accuracy: 0.7744 - val_loss: 0.6229 - val_accuracy: 0.7825\n",
      "Epoch 980/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7600 - accuracy: 0.7363 - val_loss: 0.6102 - val_accuracy: 0.7857\n",
      "Epoch 981/1500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7754 - accuracy: 0.7484 - val_loss: 0.6178 - val_accuracy: 0.7890\n",
      "Epoch 982/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7442 - accuracy: 0.7451 - val_loss: 0.6144 - val_accuracy: 0.7890\n",
      "Epoch 983/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7419 - accuracy: 0.7552 - val_loss: 0.6277 - val_accuracy: 0.7857\n",
      "Epoch 984/1500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.7041 - accuracy: 0.7682 - val_loss: 0.6089 - val_accuracy: 0.7857\n",
      "Epoch 985/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7514 - accuracy: 0.7630 - val_loss: 0.6068 - val_accuracy: 0.7792\n",
      "Epoch 986/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7472 - accuracy: 0.7549 - val_loss: 0.6189 - val_accuracy: 0.7792\n",
      "Epoch 987/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6991 - accuracy: 0.7541 - val_loss: 0.6275 - val_accuracy: 0.7857\n",
      "Epoch 988/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7673 - accuracy: 0.7484 - val_loss: 0.6136 - val_accuracy: 0.7890\n",
      "Epoch 989/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6949 - accuracy: 0.7671 - val_loss: 0.5876 - val_accuracy: 0.7955\n",
      "Epoch 990/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7675 - accuracy: 0.7539 - val_loss: 0.5733 - val_accuracy: 0.8084\n",
      "Epoch 991/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7563 - accuracy: 0.7474 - val_loss: 0.5666 - val_accuracy: 0.8019\n",
      "Epoch 992/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7545 - accuracy: 0.7422 - val_loss: 0.5839 - val_accuracy: 0.7922\n",
      "Epoch 993/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6816 - accuracy: 0.7606 - val_loss: 0.6024 - val_accuracy: 0.7922\n",
      "Epoch 994/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7345 - accuracy: 0.7467 - val_loss: 0.6002 - val_accuracy: 0.7955\n",
      "Epoch 995/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7081 - accuracy: 0.7572 - val_loss: 0.5919 - val_accuracy: 0.7857\n",
      "Epoch 996/1500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7282 - accuracy: 0.7606 - val_loss: 0.6038 - val_accuracy: 0.7922\n",
      "Epoch 997/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7972 - accuracy: 0.7288 - val_loss: 0.6416 - val_accuracy: 0.7825\n",
      "Epoch 998/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6919 - accuracy: 0.7773 - val_loss: 0.6315 - val_accuracy: 0.7792\n",
      "Epoch 999/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7134 - accuracy: 0.7655 - val_loss: 0.6193 - val_accuracy: 0.7922\n",
      "Epoch 1000/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7125 - accuracy: 0.7441 - val_loss: 0.6180 - val_accuracy: 0.7955\n",
      "Epoch 1001/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7550 - accuracy: 0.7467 - val_loss: 0.5929 - val_accuracy: 0.8019\n",
      "Epoch 1002/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7249 - accuracy: 0.7557 - val_loss: 0.5900 - val_accuracy: 0.7987\n",
      "Epoch 1003/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7348 - accuracy: 0.7500 - val_loss: 0.6047 - val_accuracy: 0.8019\n",
      "Epoch 1004/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7489 - accuracy: 0.7520 - val_loss: 0.5922 - val_accuracy: 0.7987\n",
      "Epoch 1005/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7150 - accuracy: 0.7590 - val_loss: 0.5829 - val_accuracy: 0.7987\n",
      "Epoch 1006/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7162 - accuracy: 0.7669 - val_loss: 0.5818 - val_accuracy: 0.7955\n",
      "Epoch 1007/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7150 - accuracy: 0.7611 - val_loss: 0.5937 - val_accuracy: 0.7987\n",
      "Epoch 1008/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6954 - accuracy: 0.7565 - val_loss: 0.5952 - val_accuracy: 0.7987\n",
      "Epoch 1009/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6945 - accuracy: 0.7590 - val_loss: 0.5892 - val_accuracy: 0.8117\n",
      "Epoch 1010/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7162 - accuracy: 0.7611 - val_loss: 0.6075 - val_accuracy: 0.7825\n",
      "Epoch 1011/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7313 - accuracy: 0.7513 - val_loss: 0.6220 - val_accuracy: 0.7890\n",
      "Epoch 1012/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7568 - accuracy: 0.7474 - val_loss: 0.6109 - val_accuracy: 0.7792\n",
      "Epoch 1013/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7074 - accuracy: 0.7524 - val_loss: 0.5989 - val_accuracy: 0.7760\n",
      "Epoch 1014/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7001 - accuracy: 0.7650 - val_loss: 0.5941 - val_accuracy: 0.7857\n",
      "Epoch 1015/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7798 - accuracy: 0.7410 - val_loss: 0.6054 - val_accuracy: 0.7792\n",
      "Epoch 1016/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7044 - accuracy: 0.7590 - val_loss: 0.5907 - val_accuracy: 0.7987\n",
      "Epoch 1017/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7097 - accuracy: 0.7492 - val_loss: 0.5848 - val_accuracy: 0.7890\n",
      "Epoch 1018/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7278 - accuracy: 0.7524 - val_loss: 0.5952 - val_accuracy: 0.7825\n",
      "Epoch 1019/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7154 - accuracy: 0.7695 - val_loss: 0.6149 - val_accuracy: 0.7857\n",
      "Epoch 1020/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6783 - accuracy: 0.7630 - val_loss: 0.5985 - val_accuracy: 0.7792\n",
      "Epoch 1021/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6721 - accuracy: 0.7663 - val_loss: 0.5779 - val_accuracy: 0.7955\n",
      "Epoch 1022/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7576 - accuracy: 0.7524 - val_loss: 0.5862 - val_accuracy: 0.7890\n",
      "Epoch 1023/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6905 - accuracy: 0.7598 - val_loss: 0.5967 - val_accuracy: 0.7825\n",
      "Epoch 1024/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7194 - accuracy: 0.7541 - val_loss: 0.5896 - val_accuracy: 0.7955\n",
      "Epoch 1025/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7008 - accuracy: 0.7679 - val_loss: 0.6103 - val_accuracy: 0.7825\n",
      "Epoch 1026/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7208 - accuracy: 0.7516 - val_loss: 0.6168 - val_accuracy: 0.7695\n",
      "Epoch 1027/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6816 - accuracy: 0.7858 - val_loss: 0.6226 - val_accuracy: 0.7890\n",
      "Epoch 1028/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7444 - accuracy: 0.7419 - val_loss: 0.6190 - val_accuracy: 0.7922\n",
      "Epoch 1029/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7841 - accuracy: 0.7296 - val_loss: 0.5976 - val_accuracy: 0.7955\n",
      "Epoch 1030/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7637 - accuracy: 0.7454 - val_loss: 0.5966 - val_accuracy: 0.7922\n",
      "Epoch 1031/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7226 - accuracy: 0.7549 - val_loss: 0.5961 - val_accuracy: 0.7792\n",
      "Epoch 1032/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7845 - accuracy: 0.7476 - val_loss: 0.5979 - val_accuracy: 0.7825\n",
      "Epoch 1033/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6764 - accuracy: 0.7695 - val_loss: 0.6039 - val_accuracy: 0.7890\n",
      "Epoch 1034/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7302 - accuracy: 0.7655 - val_loss: 0.6065 - val_accuracy: 0.7922\n",
      "Epoch 1035/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6979 - accuracy: 0.7590 - val_loss: 0.6020 - val_accuracy: 0.7825\n",
      "Epoch 1036/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7583 - accuracy: 0.7581 - val_loss: 0.5972 - val_accuracy: 0.7727\n",
      "Epoch 1037/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7118 - accuracy: 0.7541 - val_loss: 0.6143 - val_accuracy: 0.7792\n",
      "Epoch 1038/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7107 - accuracy: 0.7565 - val_loss: 0.6469 - val_accuracy: 0.7890\n",
      "Epoch 1039/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7143 - accuracy: 0.7590 - val_loss: 0.6510 - val_accuracy: 0.7857\n",
      "Epoch 1040/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7412 - accuracy: 0.7324 - val_loss: 0.6366 - val_accuracy: 0.7825\n",
      "Epoch 1041/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7148 - accuracy: 0.7643 - val_loss: 0.6160 - val_accuracy: 0.7857\n",
      "Epoch 1042/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7251 - accuracy: 0.7500 - val_loss: 0.5975 - val_accuracy: 0.7890\n",
      "Epoch 1043/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7158 - accuracy: 0.7617 - val_loss: 0.5851 - val_accuracy: 0.7955\n",
      "Epoch 1044/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7392 - accuracy: 0.7533 - val_loss: 0.5693 - val_accuracy: 0.8084\n",
      "Epoch 1045/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6932 - accuracy: 0.7708 - val_loss: 0.5831 - val_accuracy: 0.7955\n",
      "Epoch 1046/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7415 - accuracy: 0.7500 - val_loss: 0.6143 - val_accuracy: 0.8019\n",
      "Epoch 1047/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7040 - accuracy: 0.7581 - val_loss: 0.6326 - val_accuracy: 0.7987\n",
      "Epoch 1048/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7192 - accuracy: 0.7524 - val_loss: 0.6038 - val_accuracy: 0.7987\n",
      "Epoch 1049/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6930 - accuracy: 0.7744 - val_loss: 0.5759 - val_accuracy: 0.7987\n",
      "Epoch 1050/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7288 - accuracy: 0.7565 - val_loss: 0.5796 - val_accuracy: 0.8019\n",
      "Epoch 1051/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7111 - accuracy: 0.7721 - val_loss: 0.5854 - val_accuracy: 0.7987\n",
      "Epoch 1052/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7161 - accuracy: 0.7647 - val_loss: 0.5948 - val_accuracy: 0.8084\n",
      "Epoch 1053/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6896 - accuracy: 0.7606 - val_loss: 0.6043 - val_accuracy: 0.8019\n",
      "Epoch 1054/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7025 - accuracy: 0.7671 - val_loss: 0.6082 - val_accuracy: 0.7890\n",
      "Epoch 1055/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6837 - accuracy: 0.7734 - val_loss: 0.6167 - val_accuracy: 0.7825\n",
      "Epoch 1056/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6826 - accuracy: 0.7695 - val_loss: 0.6197 - val_accuracy: 0.7890\n",
      "Epoch 1057/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7314 - accuracy: 0.7606 - val_loss: 0.6353 - val_accuracy: 0.7857\n",
      "Epoch 1058/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7196 - accuracy: 0.7682 - val_loss: 0.6265 - val_accuracy: 0.7857\n",
      "Epoch 1059/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6854 - accuracy: 0.7704 - val_loss: 0.6144 - val_accuracy: 0.8084\n",
      "Epoch 1060/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7092 - accuracy: 0.7622 - val_loss: 0.6275 - val_accuracy: 0.8019\n",
      "Epoch 1061/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7143 - accuracy: 0.7598 - val_loss: 0.6210 - val_accuracy: 0.7857\n",
      "Epoch 1062/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7546 - accuracy: 0.7516 - val_loss: 0.5955 - val_accuracy: 0.7987\n",
      "Epoch 1063/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6807 - accuracy: 0.7777 - val_loss: 0.5956 - val_accuracy: 0.7922\n",
      "Epoch 1064/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7585 - accuracy: 0.7419 - val_loss: 0.6144 - val_accuracy: 0.7857\n",
      "Epoch 1065/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7025 - accuracy: 0.7643 - val_loss: 0.6220 - val_accuracy: 0.7825\n",
      "Epoch 1066/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7229 - accuracy: 0.7500 - val_loss: 0.6116 - val_accuracy: 0.7955\n",
      "Epoch 1067/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7065 - accuracy: 0.7606 - val_loss: 0.6043 - val_accuracy: 0.7987\n",
      "Epoch 1068/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7398 - accuracy: 0.7559 - val_loss: 0.6189 - val_accuracy: 0.7922\n",
      "Epoch 1069/1500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.76 - 0s 62ms/step - loss: 0.6800 - accuracy: 0.7671 - val_loss: 0.6328 - val_accuracy: 0.7922\n",
      "Epoch 1070/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6887 - accuracy: 0.7712 - val_loss: 0.6145 - val_accuracy: 0.7857\n",
      "Epoch 1071/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7054 - accuracy: 0.7500 - val_loss: 0.5906 - val_accuracy: 0.7922\n",
      "Epoch 1072/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6437 - accuracy: 0.7866 - val_loss: 0.5905 - val_accuracy: 0.7825\n",
      "Epoch 1073/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6726 - accuracy: 0.7637 - val_loss: 0.5928 - val_accuracy: 0.7922\n",
      "Epoch 1074/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7058 - accuracy: 0.7614 - val_loss: 0.6080 - val_accuracy: 0.7922\n",
      "Epoch 1075/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6953 - accuracy: 0.7624 - val_loss: 0.6095 - val_accuracy: 0.7922\n",
      "Epoch 1076/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7132 - accuracy: 0.7508 - val_loss: 0.5998 - val_accuracy: 0.7825\n",
      "Epoch 1077/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6780 - accuracy: 0.7793 - val_loss: 0.6105 - val_accuracy: 0.7955\n",
      "Epoch 1078/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6746 - accuracy: 0.7777 - val_loss: 0.6044 - val_accuracy: 0.7955\n",
      "Epoch 1079/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6707 - accuracy: 0.7818 - val_loss: 0.6009 - val_accuracy: 0.7922\n",
      "Epoch 1080/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7242 - accuracy: 0.7598 - val_loss: 0.5900 - val_accuracy: 0.7987\n",
      "Epoch 1081/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6962 - accuracy: 0.7712 - val_loss: 0.5955 - val_accuracy: 0.7825\n",
      "Epoch 1082/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6767 - accuracy: 0.7741 - val_loss: 0.5860 - val_accuracy: 0.8019\n",
      "Epoch 1083/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7186 - accuracy: 0.7508 - val_loss: 0.5794 - val_accuracy: 0.7987\n",
      "Epoch 1084/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6730 - accuracy: 0.7638 - val_loss: 0.5811 - val_accuracy: 0.7955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1085/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6790 - accuracy: 0.7682 - val_loss: 0.5840 - val_accuracy: 0.7987\n",
      "Epoch 1086/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6908 - accuracy: 0.7761 - val_loss: 0.5802 - val_accuracy: 0.7987\n",
      "Epoch 1087/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6880 - accuracy: 0.7598 - val_loss: 0.5874 - val_accuracy: 0.8019\n",
      "Epoch 1088/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6751 - accuracy: 0.7715 - val_loss: 0.5847 - val_accuracy: 0.7955\n",
      "Epoch 1089/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6954 - accuracy: 0.7557 - val_loss: 0.6079 - val_accuracy: 0.7857\n",
      "Epoch 1090/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6871 - accuracy: 0.7557 - val_loss: 0.6151 - val_accuracy: 0.7727\n",
      "Epoch 1091/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6944 - accuracy: 0.7715 - val_loss: 0.6256 - val_accuracy: 0.7760\n",
      "Epoch 1092/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6846 - accuracy: 0.7643 - val_loss: 0.6368 - val_accuracy: 0.7825\n",
      "Epoch 1093/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7244 - accuracy: 0.7573 - val_loss: 0.6355 - val_accuracy: 0.7760\n",
      "Epoch 1094/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6832 - accuracy: 0.7704 - val_loss: 0.6192 - val_accuracy: 0.7727\n",
      "Epoch 1095/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6949 - accuracy: 0.7630 - val_loss: 0.6137 - val_accuracy: 0.7825\n",
      "Epoch 1096/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6667 - accuracy: 0.7712 - val_loss: 0.5889 - val_accuracy: 0.7922\n",
      "Epoch 1097/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6696 - accuracy: 0.7785 - val_loss: 0.5618 - val_accuracy: 0.8084\n",
      "Epoch 1098/1500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.6815 - accuracy: 0.7773 - val_loss: 0.5708 - val_accuracy: 0.8052\n",
      "Epoch 1099/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7060 - accuracy: 0.7581 - val_loss: 0.5970 - val_accuracy: 0.7955\n",
      "Epoch 1100/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7016 - accuracy: 0.7598 - val_loss: 0.6107 - val_accuracy: 0.7890\n",
      "Epoch 1101/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6993 - accuracy: 0.7585 - val_loss: 0.6193 - val_accuracy: 0.7792\n",
      "Epoch 1102/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6693 - accuracy: 0.7704 - val_loss: 0.6084 - val_accuracy: 0.7825\n",
      "Epoch 1103/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6673 - accuracy: 0.7842 - val_loss: 0.6071 - val_accuracy: 0.7825\n",
      "Epoch 1104/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6991 - accuracy: 0.7630 - val_loss: 0.6409 - val_accuracy: 0.7792\n",
      "Epoch 1105/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6722 - accuracy: 0.7679 - val_loss: 0.6557 - val_accuracy: 0.7727\n",
      "Epoch 1106/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7307 - accuracy: 0.7573 - val_loss: 0.6223 - val_accuracy: 0.7760\n",
      "Epoch 1107/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6684 - accuracy: 0.7679 - val_loss: 0.5664 - val_accuracy: 0.8019\n",
      "Epoch 1108/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6777 - accuracy: 0.7728 - val_loss: 0.5658 - val_accuracy: 0.8052\n",
      "Epoch 1109/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6396 - accuracy: 0.7744 - val_loss: 0.5820 - val_accuracy: 0.8052\n",
      "Epoch 1110/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6656 - accuracy: 0.7809 - val_loss: 0.6112 - val_accuracy: 0.7890\n",
      "Epoch 1111/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7091 - accuracy: 0.7606 - val_loss: 0.6065 - val_accuracy: 0.7857\n",
      "Epoch 1112/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7057 - accuracy: 0.7480 - val_loss: 0.5947 - val_accuracy: 0.7922\n",
      "Epoch 1113/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6966 - accuracy: 0.7520 - val_loss: 0.5955 - val_accuracy: 0.8052\n",
      "Epoch 1114/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7338 - accuracy: 0.7712 - val_loss: 0.5987 - val_accuracy: 0.7922\n",
      "Epoch 1115/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6459 - accuracy: 0.7702 - val_loss: 0.5800 - val_accuracy: 0.7987\n",
      "Epoch 1116/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6990 - accuracy: 0.7663 - val_loss: 0.5582 - val_accuracy: 0.7987\n",
      "Epoch 1117/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6647 - accuracy: 0.7663 - val_loss: 0.5625 - val_accuracy: 0.8019\n",
      "Epoch 1118/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7230 - accuracy: 0.7638 - val_loss: 0.5923 - val_accuracy: 0.8019\n",
      "Epoch 1119/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7109 - accuracy: 0.7533 - val_loss: 0.6057 - val_accuracy: 0.7922\n",
      "Epoch 1120/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6710 - accuracy: 0.7728 - val_loss: 0.6243 - val_accuracy: 0.7727\n",
      "Epoch 1121/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6696 - accuracy: 0.7695 - val_loss: 0.6054 - val_accuracy: 0.7825\n",
      "Epoch 1122/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7205 - accuracy: 0.7484 - val_loss: 0.5948 - val_accuracy: 0.7890\n",
      "Epoch 1123/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7239 - accuracy: 0.7507 - val_loss: 0.5991 - val_accuracy: 0.7857\n",
      "Epoch 1124/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6745 - accuracy: 0.7614 - val_loss: 0.5873 - val_accuracy: 0.7825\n",
      "Epoch 1125/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7150 - accuracy: 0.7712 - val_loss: 0.5724 - val_accuracy: 0.7922\n",
      "Epoch 1126/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6816 - accuracy: 0.7720 - val_loss: 0.5589 - val_accuracy: 0.7955\n",
      "Epoch 1127/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6686 - accuracy: 0.7647 - val_loss: 0.5791 - val_accuracy: 0.7890\n",
      "Epoch 1128/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6670 - accuracy: 0.7598 - val_loss: 0.6091 - val_accuracy: 0.7825\n",
      "Epoch 1129/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6847 - accuracy: 0.7695 - val_loss: 0.6013 - val_accuracy: 0.7760\n",
      "Epoch 1130/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6696 - accuracy: 0.7630 - val_loss: 0.5834 - val_accuracy: 0.7890\n",
      "Epoch 1131/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6727 - accuracy: 0.7793 - val_loss: 0.5734 - val_accuracy: 0.7987\n",
      "Epoch 1132/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6819 - accuracy: 0.7842 - val_loss: 0.5871 - val_accuracy: 0.7987\n",
      "Epoch 1133/1500\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.6613 - accuracy: 0.7728 - val_loss: 0.6026 - val_accuracy: 0.7922\n",
      "Epoch 1134/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6698 - accuracy: 0.7777 - val_loss: 0.5752 - val_accuracy: 0.7857\n",
      "Epoch 1135/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6728 - accuracy: 0.7637 - val_loss: 0.5724 - val_accuracy: 0.7825\n",
      "Epoch 1136/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7026 - accuracy: 0.7557 - val_loss: 0.5958 - val_accuracy: 0.7760\n",
      "Epoch 1137/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6571 - accuracy: 0.7728 - val_loss: 0.6216 - val_accuracy: 0.7792\n",
      "Epoch 1138/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6824 - accuracy: 0.7655 - val_loss: 0.6188 - val_accuracy: 0.7760\n",
      "Epoch 1139/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6899 - accuracy: 0.7752 - val_loss: 0.6179 - val_accuracy: 0.7792\n",
      "Epoch 1140/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6645 - accuracy: 0.7702 - val_loss: 0.6055 - val_accuracy: 0.7857\n",
      "Epoch 1141/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6835 - accuracy: 0.7769 - val_loss: 0.5993 - val_accuracy: 0.7890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1142/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6496 - accuracy: 0.7826 - val_loss: 0.5918 - val_accuracy: 0.7857\n",
      "Epoch 1143/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6875 - accuracy: 0.7786 - val_loss: 0.6000 - val_accuracy: 0.7825\n",
      "Epoch 1144/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6737 - accuracy: 0.7834 - val_loss: 0.6073 - val_accuracy: 0.7922\n",
      "Epoch 1145/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6857 - accuracy: 0.7728 - val_loss: 0.6069 - val_accuracy: 0.7922\n",
      "Epoch 1146/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6619 - accuracy: 0.7818 - val_loss: 0.5968 - val_accuracy: 0.7922\n",
      "Epoch 1147/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7229 - accuracy: 0.7541 - val_loss: 0.5939 - val_accuracy: 0.7987\n",
      "Epoch 1148/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6782 - accuracy: 0.7630 - val_loss: 0.5956 - val_accuracy: 0.7825\n",
      "Epoch 1149/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6934 - accuracy: 0.7687 - val_loss: 0.6083 - val_accuracy: 0.7857\n",
      "Epoch 1150/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6811 - accuracy: 0.7679 - val_loss: 0.6114 - val_accuracy: 0.7922\n",
      "Epoch 1151/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6751 - accuracy: 0.7801 - val_loss: 0.6049 - val_accuracy: 0.7857\n",
      "Epoch 1152/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6875 - accuracy: 0.7826 - val_loss: 0.5875 - val_accuracy: 0.7922\n",
      "Epoch 1153/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.7688 - accuracy: 0.7524 - val_loss: 0.6092 - val_accuracy: 0.7857\n",
      "Epoch 1154/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6642 - accuracy: 0.7785 - val_loss: 0.6253 - val_accuracy: 0.7727\n",
      "Epoch 1155/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6611 - accuracy: 0.7622 - val_loss: 0.6274 - val_accuracy: 0.7825\n",
      "Epoch 1156/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6745 - accuracy: 0.7834 - val_loss: 0.6066 - val_accuracy: 0.7890\n",
      "Epoch 1157/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6723 - accuracy: 0.7728 - val_loss: 0.5891 - val_accuracy: 0.7890\n",
      "Epoch 1158/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6687 - accuracy: 0.7687 - val_loss: 0.5811 - val_accuracy: 0.7825\n",
      "Epoch 1159/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6952 - accuracy: 0.7663 - val_loss: 0.5966 - val_accuracy: 0.7727\n",
      "Epoch 1160/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7231 - accuracy: 0.7500 - val_loss: 0.6136 - val_accuracy: 0.7727\n",
      "Epoch 1161/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6734 - accuracy: 0.7671 - val_loss: 0.6137 - val_accuracy: 0.7792\n",
      "Epoch 1162/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6453 - accuracy: 0.7839 - val_loss: 0.6119 - val_accuracy: 0.7890\n",
      "Epoch 1163/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6636 - accuracy: 0.7565 - val_loss: 0.6195 - val_accuracy: 0.7760\n",
      "Epoch 1164/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6995 - accuracy: 0.7546 - val_loss: 0.6190 - val_accuracy: 0.7792\n",
      "Epoch 1165/1500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7187 - accuracy: 0.7549 - val_loss: 0.5770 - val_accuracy: 0.7890\n",
      "Epoch 1166/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6766 - accuracy: 0.7695 - val_loss: 0.5698 - val_accuracy: 0.7922\n",
      "Epoch 1167/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6694 - accuracy: 0.7741 - val_loss: 0.5765 - val_accuracy: 0.7890\n",
      "Epoch 1168/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6749 - accuracy: 0.7524 - val_loss: 0.6066 - val_accuracy: 0.7760\n",
      "Epoch 1169/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7035 - accuracy: 0.7647 - val_loss: 0.6152 - val_accuracy: 0.7695\n",
      "Epoch 1170/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6529 - accuracy: 0.7769 - val_loss: 0.6121 - val_accuracy: 0.7857\n",
      "Epoch 1171/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6482 - accuracy: 0.7761 - val_loss: 0.5920 - val_accuracy: 0.7890\n",
      "Epoch 1172/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6558 - accuracy: 0.7793 - val_loss: 0.5861 - val_accuracy: 0.7890\n",
      "Epoch 1173/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6969 - accuracy: 0.7590 - val_loss: 0.5927 - val_accuracy: 0.7955\n",
      "Epoch 1174/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6460 - accuracy: 0.7852 - val_loss: 0.5885 - val_accuracy: 0.7987\n",
      "Epoch 1175/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6905 - accuracy: 0.7622 - val_loss: 0.5868 - val_accuracy: 0.7922\n",
      "Epoch 1176/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7016 - accuracy: 0.7679 - val_loss: 0.5907 - val_accuracy: 0.7857\n",
      "Epoch 1177/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6794 - accuracy: 0.7858 - val_loss: 0.5895 - val_accuracy: 0.7987\n",
      "Epoch 1178/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6427 - accuracy: 0.7883 - val_loss: 0.5976 - val_accuracy: 0.7987\n",
      "Epoch 1179/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6529 - accuracy: 0.7899 - val_loss: 0.5956 - val_accuracy: 0.7987\n",
      "Epoch 1180/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6502 - accuracy: 0.7809 - val_loss: 0.5787 - val_accuracy: 0.7987\n",
      "Epoch 1181/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6322 - accuracy: 0.7875 - val_loss: 0.5651 - val_accuracy: 0.8019\n",
      "Epoch 1182/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6814 - accuracy: 0.7695 - val_loss: 0.5768 - val_accuracy: 0.7955\n",
      "Epoch 1183/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6372 - accuracy: 0.7932 - val_loss: 0.6127 - val_accuracy: 0.7890\n",
      "Epoch 1184/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6949 - accuracy: 0.7565 - val_loss: 0.6237 - val_accuracy: 0.7922\n",
      "Epoch 1185/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6685 - accuracy: 0.7826 - val_loss: 0.6076 - val_accuracy: 0.7922\n",
      "Epoch 1186/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6659 - accuracy: 0.7799 - val_loss: 0.6190 - val_accuracy: 0.7760\n",
      "Epoch 1187/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6338 - accuracy: 0.7842 - val_loss: 0.6335 - val_accuracy: 0.7825\n",
      "Epoch 1188/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6678 - accuracy: 0.7809 - val_loss: 0.6438 - val_accuracy: 0.7760\n",
      "Epoch 1189/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6797 - accuracy: 0.7747 - val_loss: 0.6260 - val_accuracy: 0.7825\n",
      "Epoch 1190/1500\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.7029 - accuracy: 0.7687 - val_loss: 0.6011 - val_accuracy: 0.7825\n",
      "Epoch 1191/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6713 - accuracy: 0.7799 - val_loss: 0.5829 - val_accuracy: 0.7890\n",
      "Epoch 1192/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6434 - accuracy: 0.7793 - val_loss: 0.5814 - val_accuracy: 0.7955\n",
      "Epoch 1193/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6921 - accuracy: 0.7671 - val_loss: 0.6097 - val_accuracy: 0.7890\n",
      "Epoch 1194/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7007 - accuracy: 0.7467 - val_loss: 0.6287 - val_accuracy: 0.7857\n",
      "Epoch 1195/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6968 - accuracy: 0.7638 - val_loss: 0.5895 - val_accuracy: 0.7857\n",
      "Epoch 1196/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6854 - accuracy: 0.7734 - val_loss: 0.5780 - val_accuracy: 0.7890\n",
      "Epoch 1197/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7248 - accuracy: 0.7704 - val_loss: 0.5764 - val_accuracy: 0.7890\n",
      "Epoch 1198/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.7021 - accuracy: 0.7704 - val_loss: 0.5930 - val_accuracy: 0.7890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1199/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6596 - accuracy: 0.7793 - val_loss: 0.6119 - val_accuracy: 0.7922\n",
      "Epoch 1200/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6731 - accuracy: 0.7704 - val_loss: 0.6152 - val_accuracy: 0.7890\n",
      "Epoch 1201/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6804 - accuracy: 0.7647 - val_loss: 0.6141 - val_accuracy: 0.7857\n",
      "Epoch 1202/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6686 - accuracy: 0.7769 - val_loss: 0.6139 - val_accuracy: 0.7987\n",
      "Epoch 1203/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6711 - accuracy: 0.7761 - val_loss: 0.6348 - val_accuracy: 0.7955\n",
      "Epoch 1204/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6900 - accuracy: 0.7687 - val_loss: 0.6149 - val_accuracy: 0.7825\n",
      "Epoch 1205/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6570 - accuracy: 0.7606 - val_loss: 0.5705 - val_accuracy: 0.7955\n",
      "Epoch 1206/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6896 - accuracy: 0.7695 - val_loss: 0.5649 - val_accuracy: 0.8052\n",
      "Epoch 1207/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6880 - accuracy: 0.7638 - val_loss: 0.5916 - val_accuracy: 0.7890\n",
      "Epoch 1208/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6411 - accuracy: 0.7679 - val_loss: 0.6118 - val_accuracy: 0.7987\n",
      "Epoch 1209/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6455 - accuracy: 0.7818 - val_loss: 0.6187 - val_accuracy: 0.7955\n",
      "Epoch 1210/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6785 - accuracy: 0.7842 - val_loss: 0.6180 - val_accuracy: 0.7955\n",
      "Epoch 1211/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6830 - accuracy: 0.7704 - val_loss: 0.6012 - val_accuracy: 0.7890\n",
      "Epoch 1212/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6709 - accuracy: 0.7682 - val_loss: 0.5994 - val_accuracy: 0.7890\n",
      "Epoch 1213/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6715 - accuracy: 0.7754 - val_loss: 0.5919 - val_accuracy: 0.7955\n",
      "Epoch 1214/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6652 - accuracy: 0.7744 - val_loss: 0.5946 - val_accuracy: 0.7955\n",
      "Epoch 1215/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6916 - accuracy: 0.7702 - val_loss: 0.6095 - val_accuracy: 0.8052\n",
      "Epoch 1216/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6208 - accuracy: 0.7915 - val_loss: 0.5861 - val_accuracy: 0.8117\n",
      "Epoch 1217/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6394 - accuracy: 0.7769 - val_loss: 0.5543 - val_accuracy: 0.7955\n",
      "Epoch 1218/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6774 - accuracy: 0.7598 - val_loss: 0.5476 - val_accuracy: 0.8084\n",
      "Epoch 1219/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6679 - accuracy: 0.7826 - val_loss: 0.5702 - val_accuracy: 0.7955\n",
      "Epoch 1220/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6660 - accuracy: 0.7785 - val_loss: 0.6169 - val_accuracy: 0.7922\n",
      "Epoch 1221/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6231 - accuracy: 0.7964 - val_loss: 0.6300 - val_accuracy: 0.7922\n",
      "Epoch 1222/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6564 - accuracy: 0.7801 - val_loss: 0.6238 - val_accuracy: 0.7890\n",
      "Epoch 1223/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6740 - accuracy: 0.7655 - val_loss: 0.6349 - val_accuracy: 0.8019\n",
      "Epoch 1224/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6548 - accuracy: 0.7752 - val_loss: 0.6423 - val_accuracy: 0.7890\n",
      "Epoch 1225/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6631 - accuracy: 0.7687 - val_loss: 0.6361 - val_accuracy: 0.7987\n",
      "Epoch 1226/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6340 - accuracy: 0.7806 - val_loss: 0.6029 - val_accuracy: 0.7857\n",
      "Epoch 1227/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6514 - accuracy: 0.7741 - val_loss: 0.6005 - val_accuracy: 0.7857\n",
      "Epoch 1228/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6499 - accuracy: 0.7708 - val_loss: 0.6122 - val_accuracy: 0.7857\n",
      "Epoch 1229/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6798 - accuracy: 0.7712 - val_loss: 0.6134 - val_accuracy: 0.7825\n",
      "Epoch 1230/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6615 - accuracy: 0.7785 - val_loss: 0.5914 - val_accuracy: 0.7890\n",
      "Epoch 1231/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6761 - accuracy: 0.7712 - val_loss: 0.5740 - val_accuracy: 0.7955\n",
      "Epoch 1232/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6467 - accuracy: 0.7858 - val_loss: 0.5802 - val_accuracy: 0.7922\n",
      "Epoch 1233/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6626 - accuracy: 0.7801 - val_loss: 0.6161 - val_accuracy: 0.8052\n",
      "Epoch 1234/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6343 - accuracy: 0.7865 - val_loss: 0.6307 - val_accuracy: 0.8117\n",
      "Epoch 1235/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6684 - accuracy: 0.7676 - val_loss: 0.6325 - val_accuracy: 0.7955\n",
      "Epoch 1236/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6346 - accuracy: 0.7842 - val_loss: 0.6246 - val_accuracy: 0.7857\n",
      "Epoch 1237/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7087 - accuracy: 0.7573 - val_loss: 0.5962 - val_accuracy: 0.7987\n",
      "Epoch 1238/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6582 - accuracy: 0.7812 - val_loss: 0.5792 - val_accuracy: 0.7922\n",
      "Epoch 1239/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6392 - accuracy: 0.7839 - val_loss: 0.5597 - val_accuracy: 0.8019\n",
      "Epoch 1240/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6323 - accuracy: 0.7866 - val_loss: 0.5792 - val_accuracy: 0.7955\n",
      "Epoch 1241/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6430 - accuracy: 0.7826 - val_loss: 0.6135 - val_accuracy: 0.7825\n",
      "Epoch 1242/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6630 - accuracy: 0.7614 - val_loss: 0.6385 - val_accuracy: 0.7792\n",
      "Epoch 1243/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6877 - accuracy: 0.7809 - val_loss: 0.6319 - val_accuracy: 0.7857\n",
      "Epoch 1244/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6321 - accuracy: 0.7834 - val_loss: 0.6053 - val_accuracy: 0.7857\n",
      "Epoch 1245/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6729 - accuracy: 0.7734 - val_loss: 0.5988 - val_accuracy: 0.7987\n",
      "Epoch 1246/1500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6721 - accuracy: 0.7752 - val_loss: 0.5910 - val_accuracy: 0.7955\n",
      "Epoch 1247/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6310 - accuracy: 0.7801 - val_loss: 0.5780 - val_accuracy: 0.8019\n",
      "Epoch 1248/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6396 - accuracy: 0.7834 - val_loss: 0.5936 - val_accuracy: 0.8052\n",
      "Epoch 1249/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6745 - accuracy: 0.7736 - val_loss: 0.6417 - val_accuracy: 0.7955\n",
      "Epoch 1250/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6492 - accuracy: 0.7875 - val_loss: 0.6580 - val_accuracy: 0.7825\n",
      "Epoch 1251/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6522 - accuracy: 0.7801 - val_loss: 0.6162 - val_accuracy: 0.7955\n",
      "Epoch 1252/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6663 - accuracy: 0.7761 - val_loss: 0.5724 - val_accuracy: 0.8019\n",
      "Epoch 1253/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6336 - accuracy: 0.7866 - val_loss: 0.5723 - val_accuracy: 0.7987\n",
      "Epoch 1254/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6786 - accuracy: 0.7754 - val_loss: 0.5709 - val_accuracy: 0.8019\n",
      "Epoch 1255/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6916 - accuracy: 0.7744 - val_loss: 0.5882 - val_accuracy: 0.8117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1256/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6684 - accuracy: 0.7850 - val_loss: 0.5939 - val_accuracy: 0.8052\n",
      "Epoch 1257/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6549 - accuracy: 0.7712 - val_loss: 0.6079 - val_accuracy: 0.7955\n",
      "Epoch 1258/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6916 - accuracy: 0.7769 - val_loss: 0.6163 - val_accuracy: 0.7987\n",
      "Epoch 1259/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6135 - accuracy: 0.7907 - val_loss: 0.5756 - val_accuracy: 0.8052\n",
      "Epoch 1260/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6624 - accuracy: 0.7865 - val_loss: 0.5799 - val_accuracy: 0.8052\n",
      "Epoch 1261/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6429 - accuracy: 0.7754 - val_loss: 0.5964 - val_accuracy: 0.8052\n",
      "Epoch 1262/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6267 - accuracy: 0.7793 - val_loss: 0.5907 - val_accuracy: 0.8117\n",
      "Epoch 1263/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6664 - accuracy: 0.7669 - val_loss: 0.5889 - val_accuracy: 0.8084\n",
      "Epoch 1264/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6735 - accuracy: 0.7761 - val_loss: 0.6052 - val_accuracy: 0.8052\n",
      "Epoch 1265/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6648 - accuracy: 0.7747 - val_loss: 0.6126 - val_accuracy: 0.7987\n",
      "Epoch 1266/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6391 - accuracy: 0.7871 - val_loss: 0.6097 - val_accuracy: 0.7955\n",
      "Epoch 1267/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6385 - accuracy: 0.7858 - val_loss: 0.5970 - val_accuracy: 0.7922\n",
      "Epoch 1268/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6731 - accuracy: 0.7638 - val_loss: 0.5920 - val_accuracy: 0.7890\n",
      "Epoch 1269/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6582 - accuracy: 0.7834 - val_loss: 0.5826 - val_accuracy: 0.7955\n",
      "Epoch 1270/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6237 - accuracy: 0.7940 - val_loss: 0.5758 - val_accuracy: 0.7955\n",
      "Epoch 1271/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6541 - accuracy: 0.7761 - val_loss: 0.5688 - val_accuracy: 0.7955\n",
      "Epoch 1272/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6423 - accuracy: 0.7842 - val_loss: 0.5828 - val_accuracy: 0.7955\n",
      "Epoch 1273/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6223 - accuracy: 0.7915 - val_loss: 0.6040 - val_accuracy: 0.7955\n",
      "Epoch 1274/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6563 - accuracy: 0.7786 - val_loss: 0.5960 - val_accuracy: 0.7955\n",
      "Epoch 1275/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6090 - accuracy: 0.7948 - val_loss: 0.5695 - val_accuracy: 0.8117\n",
      "Epoch 1276/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6140 - accuracy: 0.7948 - val_loss: 0.5568 - val_accuracy: 0.8182\n",
      "Epoch 1277/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6664 - accuracy: 0.7769 - val_loss: 0.5809 - val_accuracy: 0.7955\n",
      "Epoch 1278/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6457 - accuracy: 0.7786 - val_loss: 0.6112 - val_accuracy: 0.7890\n",
      "Epoch 1279/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6853 - accuracy: 0.7647 - val_loss: 0.6068 - val_accuracy: 0.7890\n",
      "Epoch 1280/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6733 - accuracy: 0.7541 - val_loss: 0.6041 - val_accuracy: 0.8052\n",
      "Epoch 1281/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6436 - accuracy: 0.7818 - val_loss: 0.6165 - val_accuracy: 0.8019\n",
      "Epoch 1282/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6084 - accuracy: 0.7907 - val_loss: 0.6041 - val_accuracy: 0.8052\n",
      "Epoch 1283/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6562 - accuracy: 0.7839 - val_loss: 0.5965 - val_accuracy: 0.7987\n",
      "Epoch 1284/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6663 - accuracy: 0.7728 - val_loss: 0.5820 - val_accuracy: 0.8019\n",
      "Epoch 1285/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6421 - accuracy: 0.8013 - val_loss: 0.5733 - val_accuracy: 0.8019\n",
      "Epoch 1286/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6648 - accuracy: 0.7809 - val_loss: 0.5872 - val_accuracy: 0.8117\n",
      "Epoch 1287/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6180 - accuracy: 0.7826 - val_loss: 0.6084 - val_accuracy: 0.8117\n",
      "Epoch 1288/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6662 - accuracy: 0.7777 - val_loss: 0.6129 - val_accuracy: 0.8019\n",
      "Epoch 1289/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6468 - accuracy: 0.7875 - val_loss: 0.6141 - val_accuracy: 0.7857\n",
      "Epoch 1290/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6210 - accuracy: 0.7899 - val_loss: 0.6446 - val_accuracy: 0.7890\n",
      "Epoch 1291/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6702 - accuracy: 0.7752 - val_loss: 0.6503 - val_accuracy: 0.7760\n",
      "Epoch 1292/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6313 - accuracy: 0.7695 - val_loss: 0.6468 - val_accuracy: 0.7825\n",
      "Epoch 1293/1500\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.6541 - accuracy: 0.7845 - val_loss: 0.6066 - val_accuracy: 0.7890\n",
      "Epoch 1294/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6188 - accuracy: 0.7907 - val_loss: 0.5823 - val_accuracy: 0.8019\n",
      "Epoch 1295/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6522 - accuracy: 0.7736 - val_loss: 0.5896 - val_accuracy: 0.7890\n",
      "Epoch 1296/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6673 - accuracy: 0.7871 - val_loss: 0.6165 - val_accuracy: 0.7857\n",
      "Epoch 1297/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6338 - accuracy: 0.7923 - val_loss: 0.6303 - val_accuracy: 0.7825\n",
      "Epoch 1298/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6290 - accuracy: 0.7884 - val_loss: 0.6263 - val_accuracy: 0.7857\n",
      "Epoch 1299/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6345 - accuracy: 0.7777 - val_loss: 0.5920 - val_accuracy: 0.7922\n",
      "Epoch 1300/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6582 - accuracy: 0.7689 - val_loss: 0.5761 - val_accuracy: 0.7987\n",
      "Epoch 1301/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5815 - accuracy: 0.8037 - val_loss: 0.6194 - val_accuracy: 0.7857\n",
      "Epoch 1302/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6026 - accuracy: 0.8054 - val_loss: 0.6452 - val_accuracy: 0.7857\n",
      "Epoch 1303/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6813 - accuracy: 0.7702 - val_loss: 0.6502 - val_accuracy: 0.7922\n",
      "Epoch 1304/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6468 - accuracy: 0.7910 - val_loss: 0.6538 - val_accuracy: 0.7857\n",
      "Epoch 1305/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6563 - accuracy: 0.7785 - val_loss: 0.6443 - val_accuracy: 0.7890\n",
      "Epoch 1306/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6270 - accuracy: 0.7819 - val_loss: 0.6474 - val_accuracy: 0.7825\n",
      "Epoch 1307/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6383 - accuracy: 0.7728 - val_loss: 0.6310 - val_accuracy: 0.7792\n",
      "Epoch 1308/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6567 - accuracy: 0.7826 - val_loss: 0.6286 - val_accuracy: 0.7760\n",
      "Epoch 1309/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6344 - accuracy: 0.7899 - val_loss: 0.5969 - val_accuracy: 0.7857\n",
      "Epoch 1310/1500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6892 - accuracy: 0.7549 - val_loss: 0.5899 - val_accuracy: 0.7987\n",
      "Epoch 1311/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6174 - accuracy: 0.7793 - val_loss: 0.5808 - val_accuracy: 0.8052\n",
      "Epoch 1312/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6355 - accuracy: 0.7883 - val_loss: 0.5937 - val_accuracy: 0.7987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1313/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6491 - accuracy: 0.7875 - val_loss: 0.6095 - val_accuracy: 0.8117\n",
      "Epoch 1314/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5943 - accuracy: 0.7997 - val_loss: 0.6050 - val_accuracy: 0.8084\n",
      "Epoch 1315/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6021 - accuracy: 0.7995 - val_loss: 0.5858 - val_accuracy: 0.8052\n",
      "Epoch 1316/1500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6299 - accuracy: 0.7752 - val_loss: 0.5814 - val_accuracy: 0.8019\n",
      "Epoch 1317/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6209 - accuracy: 0.7940 - val_loss: 0.5850 - val_accuracy: 0.7955\n",
      "Epoch 1318/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6350 - accuracy: 0.7891 - val_loss: 0.5631 - val_accuracy: 0.7825\n",
      "Epoch 1319/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6331 - accuracy: 0.7777 - val_loss: 0.5871 - val_accuracy: 0.7955\n",
      "Epoch 1320/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6680 - accuracy: 0.7793 - val_loss: 0.6849 - val_accuracy: 0.7792\n",
      "Epoch 1321/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6367 - accuracy: 0.7989 - val_loss: 0.6750 - val_accuracy: 0.7955\n",
      "Epoch 1322/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6665 - accuracy: 0.7702 - val_loss: 0.6371 - val_accuracy: 0.8052\n",
      "Epoch 1323/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6500 - accuracy: 0.7720 - val_loss: 0.6323 - val_accuracy: 0.7922\n",
      "Epoch 1324/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6383 - accuracy: 0.7910 - val_loss: 0.6638 - val_accuracy: 0.7922\n",
      "Epoch 1325/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6040 - accuracy: 0.7989 - val_loss: 0.6651 - val_accuracy: 0.7857\n",
      "Epoch 1326/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6224 - accuracy: 0.7875 - val_loss: 0.6624 - val_accuracy: 0.7792\n",
      "Epoch 1327/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6030 - accuracy: 0.7875 - val_loss: 0.6213 - val_accuracy: 0.8019\n",
      "Epoch 1328/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6381 - accuracy: 0.7834 - val_loss: 0.5901 - val_accuracy: 0.7987\n",
      "Epoch 1329/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6432 - accuracy: 0.7897 - val_loss: 0.5942 - val_accuracy: 0.8117\n",
      "Epoch 1330/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6402 - accuracy: 0.7769 - val_loss: 0.6200 - val_accuracy: 0.7987\n",
      "Epoch 1331/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6412 - accuracy: 0.7812 - val_loss: 0.6311 - val_accuracy: 0.7922\n",
      "Epoch 1332/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6612 - accuracy: 0.7695 - val_loss: 0.6410 - val_accuracy: 0.7857\n",
      "Epoch 1333/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6281 - accuracy: 0.7826 - val_loss: 0.6341 - val_accuracy: 0.7825\n",
      "Epoch 1334/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5955 - accuracy: 0.7995 - val_loss: 0.6115 - val_accuracy: 0.7857\n",
      "Epoch 1335/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6175 - accuracy: 0.7923 - val_loss: 0.5968 - val_accuracy: 0.7922\n",
      "Epoch 1336/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6291 - accuracy: 0.7785 - val_loss: 0.5812 - val_accuracy: 0.8019\n",
      "Epoch 1337/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6525 - accuracy: 0.7866 - val_loss: 0.5932 - val_accuracy: 0.7955\n",
      "Epoch 1338/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6193 - accuracy: 0.7761 - val_loss: 0.6087 - val_accuracy: 0.7955\n",
      "Epoch 1339/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.5898 - accuracy: 0.7980 - val_loss: 0.6059 - val_accuracy: 0.7987\n",
      "Epoch 1340/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6350 - accuracy: 0.7899 - val_loss: 0.5924 - val_accuracy: 0.8084\n",
      "Epoch 1341/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6354 - accuracy: 0.7793 - val_loss: 0.5976 - val_accuracy: 0.8052\n",
      "Epoch 1342/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6278 - accuracy: 0.7826 - val_loss: 0.6099 - val_accuracy: 0.7987\n",
      "Epoch 1343/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6593 - accuracy: 0.7801 - val_loss: 0.6384 - val_accuracy: 0.7890\n",
      "Epoch 1344/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.5879 - accuracy: 0.8078 - val_loss: 0.6397 - val_accuracy: 0.7857\n",
      "Epoch 1345/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6632 - accuracy: 0.7819 - val_loss: 0.6465 - val_accuracy: 0.7857\n",
      "Epoch 1346/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6599 - accuracy: 0.7687 - val_loss: 0.6431 - val_accuracy: 0.7922\n",
      "Epoch 1347/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6420 - accuracy: 0.7891 - val_loss: 0.6100 - val_accuracy: 0.7955\n",
      "Epoch 1348/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6184 - accuracy: 0.7826 - val_loss: 0.5775 - val_accuracy: 0.8019\n",
      "Epoch 1349/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6390 - accuracy: 0.7780 - val_loss: 0.5674 - val_accuracy: 0.8019\n",
      "Epoch 1350/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6078 - accuracy: 0.7969 - val_loss: 0.6022 - val_accuracy: 0.7922\n",
      "Epoch 1351/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6144 - accuracy: 0.7891 - val_loss: 0.6386 - val_accuracy: 0.7695\n",
      "Epoch 1352/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6392 - accuracy: 0.7852 - val_loss: 0.6394 - val_accuracy: 0.7792\n",
      "Epoch 1353/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6243 - accuracy: 0.7780 - val_loss: 0.6185 - val_accuracy: 0.7727\n",
      "Epoch 1354/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6065 - accuracy: 0.8021 - val_loss: 0.5897 - val_accuracy: 0.7825\n",
      "Epoch 1355/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6079 - accuracy: 0.7940 - val_loss: 0.5900 - val_accuracy: 0.7955\n",
      "Epoch 1356/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6462 - accuracy: 0.7878 - val_loss: 0.5981 - val_accuracy: 0.7792\n",
      "Epoch 1357/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6803 - accuracy: 0.7622 - val_loss: 0.6291 - val_accuracy: 0.7890\n",
      "Epoch 1358/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6122 - accuracy: 0.7834 - val_loss: 0.6506 - val_accuracy: 0.7857\n",
      "Epoch 1359/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6579 - accuracy: 0.7818 - val_loss: 0.6403 - val_accuracy: 0.7792\n",
      "Epoch 1360/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6279 - accuracy: 0.7850 - val_loss: 0.6008 - val_accuracy: 0.7955\n",
      "Epoch 1361/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6178 - accuracy: 0.7897 - val_loss: 0.5888 - val_accuracy: 0.8019\n",
      "Epoch 1362/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6243 - accuracy: 0.7858 - val_loss: 0.6143 - val_accuracy: 0.8084\n",
      "Epoch 1363/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6511 - accuracy: 0.7780 - val_loss: 0.6711 - val_accuracy: 0.7890\n",
      "Epoch 1364/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6295 - accuracy: 0.7907 - val_loss: 0.6892 - val_accuracy: 0.7695\n",
      "Epoch 1365/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6397 - accuracy: 0.7842 - val_loss: 0.6571 - val_accuracy: 0.7825\n",
      "Epoch 1366/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6796 - accuracy: 0.7785 - val_loss: 0.6245 - val_accuracy: 0.7922\n",
      "Epoch 1367/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6585 - accuracy: 0.7891 - val_loss: 0.6350 - val_accuracy: 0.7955\n",
      "Epoch 1368/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6089 - accuracy: 0.8021 - val_loss: 0.6453 - val_accuracy: 0.7890\n",
      "Epoch 1369/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6038 - accuracy: 0.7964 - val_loss: 0.6246 - val_accuracy: 0.7955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1370/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6838 - accuracy: 0.7780 - val_loss: 0.6183 - val_accuracy: 0.8019\n",
      "Epoch 1371/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6453 - accuracy: 0.7752 - val_loss: 0.6059 - val_accuracy: 0.7987\n",
      "Epoch 1372/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.5952 - accuracy: 0.7801 - val_loss: 0.5974 - val_accuracy: 0.7922\n",
      "Epoch 1373/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6597 - accuracy: 0.7769 - val_loss: 0.5996 - val_accuracy: 0.7890\n",
      "Epoch 1374/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6058 - accuracy: 0.7989 - val_loss: 0.6064 - val_accuracy: 0.7987\n",
      "Epoch 1375/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6566 - accuracy: 0.7834 - val_loss: 0.6297 - val_accuracy: 0.7922\n",
      "Epoch 1376/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6804 - accuracy: 0.7818 - val_loss: 0.6293 - val_accuracy: 0.8084\n",
      "Epoch 1377/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.5971 - accuracy: 0.7883 - val_loss: 0.6309 - val_accuracy: 0.7825\n",
      "Epoch 1378/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6100 - accuracy: 0.7982 - val_loss: 0.6133 - val_accuracy: 0.7825\n",
      "Epoch 1379/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6748 - accuracy: 0.7866 - val_loss: 0.6245 - val_accuracy: 0.7760\n",
      "Epoch 1380/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6327 - accuracy: 0.7940 - val_loss: 0.6462 - val_accuracy: 0.7727\n",
      "Epoch 1381/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6218 - accuracy: 0.7980 - val_loss: 0.6281 - val_accuracy: 0.7792\n",
      "Epoch 1382/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6392 - accuracy: 0.7793 - val_loss: 0.6219 - val_accuracy: 0.7955\n",
      "Epoch 1383/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6353 - accuracy: 0.7826 - val_loss: 0.6273 - val_accuracy: 0.7955\n",
      "Epoch 1384/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5964 - accuracy: 0.8037 - val_loss: 0.6463 - val_accuracy: 0.7955\n",
      "Epoch 1385/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6806 - accuracy: 0.7801 - val_loss: 0.6537 - val_accuracy: 0.7922\n",
      "Epoch 1386/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6148 - accuracy: 0.7878 - val_loss: 0.6294 - val_accuracy: 0.8019\n",
      "Epoch 1387/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6151 - accuracy: 0.7917 - val_loss: 0.5769 - val_accuracy: 0.8117\n",
      "Epoch 1388/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7018 - accuracy: 0.7647 - val_loss: 0.5635 - val_accuracy: 0.8052\n",
      "Epoch 1389/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5972 - accuracy: 0.7943 - val_loss: 0.5840 - val_accuracy: 0.8019\n",
      "Epoch 1390/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5766 - accuracy: 0.8094 - val_loss: 0.6020 - val_accuracy: 0.7987\n",
      "Epoch 1391/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6032 - accuracy: 0.7964 - val_loss: 0.5978 - val_accuracy: 0.8052\n",
      "Epoch 1392/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6449 - accuracy: 0.7744 - val_loss: 0.5975 - val_accuracy: 0.8149\n",
      "Epoch 1393/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6209 - accuracy: 0.7917 - val_loss: 0.6061 - val_accuracy: 0.8149\n",
      "Epoch 1394/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5895 - accuracy: 0.7980 - val_loss: 0.6007 - val_accuracy: 0.8052\n",
      "Epoch 1395/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6663 - accuracy: 0.7826 - val_loss: 0.6346 - val_accuracy: 0.7857\n",
      "Epoch 1396/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6272 - accuracy: 0.7842 - val_loss: 0.6152 - val_accuracy: 0.8019\n",
      "Epoch 1397/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6129 - accuracy: 0.7915 - val_loss: 0.5990 - val_accuracy: 0.8019\n",
      "Epoch 1398/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6064 - accuracy: 0.7897 - val_loss: 0.6002 - val_accuracy: 0.7987\n",
      "Epoch 1399/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6442 - accuracy: 0.7809 - val_loss: 0.6211 - val_accuracy: 0.7955\n",
      "Epoch 1400/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.5919 - accuracy: 0.8027 - val_loss: 0.6295 - val_accuracy: 0.7922\n",
      "Epoch 1401/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.5896 - accuracy: 0.7923 - val_loss: 0.6183 - val_accuracy: 0.8019\n",
      "Epoch 1402/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5781 - accuracy: 0.7997 - val_loss: 0.6027 - val_accuracy: 0.8117\n",
      "Epoch 1403/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5855 - accuracy: 0.8135 - val_loss: 0.5953 - val_accuracy: 0.8084\n",
      "Epoch 1404/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5838 - accuracy: 0.8177 - val_loss: 0.5955 - val_accuracy: 0.8117\n",
      "Epoch 1405/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6221 - accuracy: 0.7923 - val_loss: 0.6331 - val_accuracy: 0.7890\n",
      "Epoch 1406/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6507 - accuracy: 0.7801 - val_loss: 0.6682 - val_accuracy: 0.7760\n",
      "Epoch 1407/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6321 - accuracy: 0.7910 - val_loss: 0.6127 - val_accuracy: 0.8052\n",
      "Epoch 1408/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6254 - accuracy: 0.7923 - val_loss: 0.5876 - val_accuracy: 0.8052\n",
      "Epoch 1409/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6390 - accuracy: 0.7907 - val_loss: 0.5983 - val_accuracy: 0.8019\n",
      "Epoch 1410/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.5893 - accuracy: 0.7932 - val_loss: 0.6136 - val_accuracy: 0.7955\n",
      "Epoch 1411/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6477 - accuracy: 0.7793 - val_loss: 0.5807 - val_accuracy: 0.8149\n",
      "Epoch 1412/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5785 - accuracy: 0.8127 - val_loss: 0.5703 - val_accuracy: 0.7955\n",
      "Epoch 1413/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5969 - accuracy: 0.7969 - val_loss: 0.5921 - val_accuracy: 0.7792\n",
      "Epoch 1414/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6429 - accuracy: 0.7923 - val_loss: 0.6086 - val_accuracy: 0.7922\n",
      "Epoch 1415/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6348 - accuracy: 0.7899 - val_loss: 0.6193 - val_accuracy: 0.7922\n",
      "Epoch 1416/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6410 - accuracy: 0.7793 - val_loss: 0.6278 - val_accuracy: 0.7955\n",
      "Epoch 1417/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6655 - accuracy: 0.7741 - val_loss: 0.6200 - val_accuracy: 0.8052\n",
      "Epoch 1418/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6265 - accuracy: 0.7899 - val_loss: 0.6098 - val_accuracy: 0.8052\n",
      "Epoch 1419/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6346 - accuracy: 0.7777 - val_loss: 0.5837 - val_accuracy: 0.8149\n",
      "Epoch 1420/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6366 - accuracy: 0.7834 - val_loss: 0.5812 - val_accuracy: 0.8019\n",
      "Epoch 1421/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6304 - accuracy: 0.7687 - val_loss: 0.5858 - val_accuracy: 0.8052\n",
      "Epoch 1422/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6095 - accuracy: 0.7834 - val_loss: 0.5908 - val_accuracy: 0.8052\n",
      "Epoch 1423/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5973 - accuracy: 0.7932 - val_loss: 0.5955 - val_accuracy: 0.7922\n",
      "Epoch 1424/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6410 - accuracy: 0.7972 - val_loss: 0.6070 - val_accuracy: 0.7922\n",
      "Epoch 1425/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6338 - accuracy: 0.7809 - val_loss: 0.6324 - val_accuracy: 0.7890\n",
      "Epoch 1426/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6155 - accuracy: 0.7989 - val_loss: 0.6368 - val_accuracy: 0.7987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1427/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6214 - accuracy: 0.7875 - val_loss: 0.6293 - val_accuracy: 0.7955\n",
      "Epoch 1428/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6018 - accuracy: 0.8013 - val_loss: 0.6107 - val_accuracy: 0.8084\n",
      "Epoch 1429/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6327 - accuracy: 0.7915 - val_loss: 0.6103 - val_accuracy: 0.8019\n",
      "Epoch 1430/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6331 - accuracy: 0.7980 - val_loss: 0.6080 - val_accuracy: 0.8019\n",
      "Epoch 1431/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6051 - accuracy: 0.7871 - val_loss: 0.5977 - val_accuracy: 0.7987\n",
      "Epoch 1432/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.5970 - accuracy: 0.7891 - val_loss: 0.5852 - val_accuracy: 0.8052\n",
      "Epoch 1433/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6132 - accuracy: 0.7975 - val_loss: 0.5826 - val_accuracy: 0.7987\n",
      "Epoch 1434/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.5680 - accuracy: 0.8092 - val_loss: 0.5833 - val_accuracy: 0.7955\n",
      "Epoch 1435/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6223 - accuracy: 0.7834 - val_loss: 0.5896 - val_accuracy: 0.7955\n",
      "Epoch 1436/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6056 - accuracy: 0.7891 - val_loss: 0.5913 - val_accuracy: 0.8019\n",
      "Epoch 1437/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5768 - accuracy: 0.8037 - val_loss: 0.6067 - val_accuracy: 0.8052\n",
      "Epoch 1438/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6066 - accuracy: 0.7923 - val_loss: 0.6395 - val_accuracy: 0.8019\n",
      "Epoch 1439/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6005 - accuracy: 0.7975 - val_loss: 0.6738 - val_accuracy: 0.7987\n",
      "Epoch 1440/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6795 - accuracy: 0.7598 - val_loss: 0.6705 - val_accuracy: 0.8084\n",
      "Epoch 1441/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6328 - accuracy: 0.7801 - val_loss: 0.6531 - val_accuracy: 0.8019\n",
      "Epoch 1442/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6289 - accuracy: 0.7899 - val_loss: 0.6268 - val_accuracy: 0.8052\n",
      "Epoch 1443/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.5926 - accuracy: 0.8086 - val_loss: 0.6025 - val_accuracy: 0.8019\n",
      "Epoch 1444/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.5864 - accuracy: 0.7878 - val_loss: 0.6169 - val_accuracy: 0.7955\n",
      "Epoch 1445/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6180 - accuracy: 0.7891 - val_loss: 0.6254 - val_accuracy: 0.7922\n",
      "Epoch 1446/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6119 - accuracy: 0.7899 - val_loss: 0.6217 - val_accuracy: 0.8019\n",
      "Epoch 1447/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6149 - accuracy: 0.7956 - val_loss: 0.6081 - val_accuracy: 0.8117\n",
      "Epoch 1448/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.5986 - accuracy: 0.7883 - val_loss: 0.5899 - val_accuracy: 0.8117\n",
      "Epoch 1449/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6021 - accuracy: 0.7930 - val_loss: 0.5905 - val_accuracy: 0.8214\n",
      "Epoch 1450/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6139 - accuracy: 0.8070 - val_loss: 0.6278 - val_accuracy: 0.8019\n",
      "Epoch 1451/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6227 - accuracy: 0.7997 - val_loss: 0.6349 - val_accuracy: 0.8052\n",
      "Epoch 1452/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6071 - accuracy: 0.7904 - val_loss: 0.6130 - val_accuracy: 0.7987\n",
      "Epoch 1453/1500\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.6259 - accuracy: 0.7910 - val_loss: 0.6012 - val_accuracy: 0.8052\n",
      "Epoch 1454/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.6105 - accuracy: 0.7932 - val_loss: 0.5895 - val_accuracy: 0.8084\n",
      "Epoch 1455/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6495 - accuracy: 0.7875 - val_loss: 0.5933 - val_accuracy: 0.8052\n",
      "Epoch 1456/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6211 - accuracy: 0.7940 - val_loss: 0.6151 - val_accuracy: 0.8019\n",
      "Epoch 1457/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5864 - accuracy: 0.7989 - val_loss: 0.5887 - val_accuracy: 0.8084\n",
      "Epoch 1458/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5881 - accuracy: 0.8200 - val_loss: 0.5543 - val_accuracy: 0.8052\n",
      "Epoch 1459/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5559 - accuracy: 0.8092 - val_loss: 0.5410 - val_accuracy: 0.8019\n",
      "Epoch 1460/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6080 - accuracy: 0.7850 - val_loss: 0.5609 - val_accuracy: 0.8052\n",
      "Epoch 1461/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6021 - accuracy: 0.7969 - val_loss: 0.5969 - val_accuracy: 0.8052\n",
      "Epoch 1462/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6366 - accuracy: 0.7839 - val_loss: 0.6153 - val_accuracy: 0.8019\n",
      "Epoch 1463/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5331 - accuracy: 0.8210 - val_loss: 0.6011 - val_accuracy: 0.8019\n",
      "Epoch 1464/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6359 - accuracy: 0.7875 - val_loss: 0.5912 - val_accuracy: 0.8149\n",
      "Epoch 1465/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6046 - accuracy: 0.7972 - val_loss: 0.6387 - val_accuracy: 0.8019\n",
      "Epoch 1466/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6554 - accuracy: 0.7845 - val_loss: 0.7088 - val_accuracy: 0.7792\n",
      "Epoch 1467/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6250 - accuracy: 0.7875 - val_loss: 0.6748 - val_accuracy: 0.7727\n",
      "Epoch 1468/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5944 - accuracy: 0.8013 - val_loss: 0.5923 - val_accuracy: 0.8084\n",
      "Epoch 1469/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6288 - accuracy: 0.7943 - val_loss: 0.5746 - val_accuracy: 0.8084\n",
      "Epoch 1470/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5348 - accuracy: 0.8217 - val_loss: 0.5775 - val_accuracy: 0.7987\n",
      "Epoch 1471/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6333 - accuracy: 0.7818 - val_loss: 0.5804 - val_accuracy: 0.8084\n",
      "Epoch 1472/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.5889 - accuracy: 0.8079 - val_loss: 0.5838 - val_accuracy: 0.7987\n",
      "Epoch 1473/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6233 - accuracy: 0.7989 - val_loss: 0.5807 - val_accuracy: 0.8052\n",
      "Epoch 1474/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6597 - accuracy: 0.7839 - val_loss: 0.5852 - val_accuracy: 0.8052\n",
      "Epoch 1475/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6393 - accuracy: 0.7712 - val_loss: 0.6038 - val_accuracy: 0.8084\n",
      "Epoch 1476/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6107 - accuracy: 0.7932 - val_loss: 0.5939 - val_accuracy: 0.8117\n",
      "Epoch 1477/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6490 - accuracy: 0.7785 - val_loss: 0.5932 - val_accuracy: 0.8214\n",
      "Epoch 1478/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6184 - accuracy: 0.7866 - val_loss: 0.6082 - val_accuracy: 0.8084\n",
      "Epoch 1479/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6021 - accuracy: 0.8014 - val_loss: 0.5901 - val_accuracy: 0.8084\n",
      "Epoch 1480/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6129 - accuracy: 0.7834 - val_loss: 0.5792 - val_accuracy: 0.8052\n",
      "Epoch 1481/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.5800 - accuracy: 0.7932 - val_loss: 0.5990 - val_accuracy: 0.7987\n",
      "Epoch 1482/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.5787 - accuracy: 0.8029 - val_loss: 0.6255 - val_accuracy: 0.8084\n",
      "Epoch 1483/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5941 - accuracy: 0.7801 - val_loss: 0.6246 - val_accuracy: 0.8019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1484/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6107 - accuracy: 0.7980 - val_loss: 0.5904 - val_accuracy: 0.8149\n",
      "Epoch 1485/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6127 - accuracy: 0.7899 - val_loss: 0.5815 - val_accuracy: 0.8149\n",
      "Epoch 1486/1500\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.6343 - accuracy: 0.7818 - val_loss: 0.5835 - val_accuracy: 0.8149\n",
      "Epoch 1487/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6207 - accuracy: 0.8005 - val_loss: 0.6034 - val_accuracy: 0.8052\n",
      "Epoch 1488/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.5839 - accuracy: 0.7956 - val_loss: 0.5995 - val_accuracy: 0.8052\n",
      "Epoch 1489/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.5731 - accuracy: 0.8151 - val_loss: 0.5935 - val_accuracy: 0.7922\n",
      "Epoch 1490/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6085 - accuracy: 0.7940 - val_loss: 0.5707 - val_accuracy: 0.8019\n",
      "Epoch 1491/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6076 - accuracy: 0.7891 - val_loss: 0.5634 - val_accuracy: 0.8084\n",
      "Epoch 1492/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5571 - accuracy: 0.8014 - val_loss: 0.5753 - val_accuracy: 0.8019\n",
      "Epoch 1493/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6160 - accuracy: 0.7997 - val_loss: 0.5971 - val_accuracy: 0.7955\n",
      "Epoch 1494/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.5830 - accuracy: 0.8034 - val_loss: 0.6116 - val_accuracy: 0.7922\n",
      "Epoch 1495/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5854 - accuracy: 0.7915 - val_loss: 0.5917 - val_accuracy: 0.8052\n",
      "Epoch 1496/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6518 - accuracy: 0.7842 - val_loss: 0.5703 - val_accuracy: 0.8084\n",
      "Epoch 1497/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6112 - accuracy: 0.7899 - val_loss: 0.5785 - val_accuracy: 0.8149\n",
      "Epoch 1498/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6057 - accuracy: 0.8037 - val_loss: 0.5920 - val_accuracy: 0.8117\n",
      "Epoch 1499/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.5998 - accuracy: 0.8078 - val_loss: 0.6121 - val_accuracy: 0.7955\n",
      "Epoch 1500/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5894 - accuracy: 0.7975 - val_loss: 0.6282 - val_accuracy: 0.7955\n",
      "CNN: Epochs=1500, Train accuracy=0.82166, Validation accuracy=0.82143\n"
     ]
    }
   ],
   "source": [
    "epochs = 1500\n",
    "batch_size = 512\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1#, callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2603262,
     "status": "ok",
     "timestamp": 1598167802346,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "9bcd067b-5514-491c-8c63-db77d4fc6967"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####relu 대신 leaky relu 써보자########\n",
    "#####후에 early stopping도 추가 ########\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1598178326978,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "sTKcFoyikcjV"
   },
   "outputs": [],
   "source": [
    "#model_10: ResNet - residual block 구성\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D\n",
    ")\n",
    "\n",
    "def conv1(x):\n",
    "    x = Conv2D(64, (7,7), strides=(2,2), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv2(x, filter_in=64, filter_out=256):\n",
    "    x = MaxPooling2D((3,3), 2)(x)\n",
    "    \n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(1):#3):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "        \n",
    "    return x\n",
    "\n",
    "def conv3(x, filter_in=128, filter_out=512):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(2):#4):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv4(x, filter_in=256, filter_out=1024):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(1):#6):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv5(x, filter_in=512, filter_out=2048):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(1):#3):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_55\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1110 (Conv2D)            (None, 14, 14, 64)   3200        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1110 (Batch (None, 14, 14, 64)   256         conv2d_1110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_545 (LeakyReLU)     (None, 14, 14, 64)   0           batch_normalization_1110[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 6, 6, 64)     0           leaky_re_lu_545[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1111 (Conv2D)            (None, 6, 6, 32)     2080        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1111 (Batch (None, 6, 6, 32)     128         conv2d_1111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_546 (LeakyReLU)     (None, 6, 6, 32)     0           batch_normalization_1111[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1112 (Conv2D)            (None, 6, 6, 32)     9248        leaky_re_lu_546[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1112 (Batch (None, 6, 6, 32)     128         conv2d_1112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_547 (LeakyReLU)     (None, 6, 6, 32)     0           batch_normalization_1112[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1113 (Conv2D)            (None, 6, 6, 64)     2112        leaky_re_lu_547[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1114 (Conv2D)            (None, 6, 6, 64)     4160        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1113 (Batch (None, 6, 6, 64)     256         conv2d_1113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1114 (Batch (None, 6, 6, 64)     256         conv2d_1114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_326 (Add)                   (None, 6, 6, 64)     0           batch_normalization_1113[0][0]   \n",
      "                                                                 batch_normalization_1114[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_548 (LeakyReLU)     (None, 6, 6, 64)     0           add_326[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 6, 6, 64)     0           leaky_re_lu_548[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1115 (Conv2D)            (None, 3, 3, 32)     2080        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1115 (Batch (None, 3, 3, 32)     128         conv2d_1115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_549 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1115[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1116 (Conv2D)            (None, 3, 3, 32)     9248        leaky_re_lu_549[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1116 (Batch (None, 3, 3, 32)     128         conv2d_1116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_550 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1116[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1117 (Conv2D)            (None, 3, 3, 64)     2112        leaky_re_lu_550[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1118 (Conv2D)            (None, 3, 3, 64)     4160        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1117 (Batch (None, 3, 3, 64)     256         conv2d_1117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1118 (Batch (None, 3, 3, 64)     256         conv2d_1118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_327 (Add)                   (None, 3, 3, 64)     0           batch_normalization_1117[0][0]   \n",
      "                                                                 batch_normalization_1118[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_551 (LeakyReLU)     (None, 3, 3, 64)     0           add_327[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1119 (Conv2D)            (None, 3, 3, 32)     2080        leaky_re_lu_551[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1119 (Batch (None, 3, 3, 32)     128         conv2d_1119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_552 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1119[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1120 (Conv2D)            (None, 3, 3, 32)     9248        leaky_re_lu_552[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1120 (Batch (None, 3, 3, 32)     128         conv2d_1120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_553 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1120[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1121 (Conv2D)            (None, 3, 3, 64)     2112        leaky_re_lu_553[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1121 (Batch (None, 3, 3, 64)     256         conv2d_1121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_328 (Add)                   (None, 3, 3, 64)     0           batch_normalization_1121[0][0]   \n",
      "                                                                 leaky_re_lu_551[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_554 (LeakyReLU)     (None, 3, 3, 64)     0           add_328[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 3, 3, 64)     0           leaky_re_lu_554[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1122 (Conv2D)            (None, 2, 2, 64)     4160        dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1122 (Batch (None, 2, 2, 64)     256         conv2d_1122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_555 (LeakyReLU)     (None, 2, 2, 64)     0           batch_normalization_1122[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1123 (Conv2D)            (None, 2, 2, 64)     36928       leaky_re_lu_555[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1123 (Batch (None, 2, 2, 64)     256         conv2d_1123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_556 (LeakyReLU)     (None, 2, 2, 64)     0           batch_normalization_1123[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1124 (Conv2D)            (None, 2, 2, 128)    8320        leaky_re_lu_556[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1125 (Conv2D)            (None, 2, 2, 128)    8320        dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1124 (Batch (None, 2, 2, 128)    512         conv2d_1124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1125 (Batch (None, 2, 2, 128)    512         conv2d_1125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_329 (Add)                   (None, 2, 2, 128)    0           batch_normalization_1124[0][0]   \n",
      "                                                                 batch_normalization_1125[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_557 (LeakyReLU)     (None, 2, 2, 128)    0           add_329[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 2, 2, 128)    0           leaky_re_lu_557[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1126 (Conv2D)            (None, 1, 1, 64)     8256        dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1126 (Batch (None, 1, 1, 64)     256         conv2d_1126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_558 (LeakyReLU)     (None, 1, 1, 64)     0           batch_normalization_1126[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1127 (Conv2D)            (None, 1, 1, 64)     36928       leaky_re_lu_558[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1127 (Batch (None, 1, 1, 64)     256         conv2d_1127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_559 (LeakyReLU)     (None, 1, 1, 64)     0           batch_normalization_1127[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1128 (Conv2D)            (None, 1, 1, 128)    8320        leaky_re_lu_559[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1129 (Conv2D)            (None, 1, 1, 128)    16512       dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1128 (Batch (None, 1, 1, 128)    512         conv2d_1128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1129 (Batch (None, 1, 1, 128)    512         conv2d_1129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_330 (Add)                   (None, 1, 1, 128)    0           batch_normalization_1128[0][0]   \n",
      "                                                                 batch_normalization_1129[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_560 (LeakyReLU)     (None, 1, 1, 128)    0           add_330[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1, 1, 128)    0           leaky_re_lu_560[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_27 (Gl (None, 128)          0           dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 10)           1290        global_average_pooling2d_27[0][0]\n",
      "==================================================================================================\n",
      "Total params: 186,250\n",
      "Trainable params: 183,562\n",
      "Non-trainable params: 2,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "#모델링\n",
    "classes = 10\n",
    "tensor_in = Input(shape= train_X.shape[1:], dtype='float32', name='input')\n",
    "\n",
    "x = conv1(tensor_in)\n",
    "x = conv2(x, 32, 64)\n",
    "x = Dropout(0.4)(x)\n",
    "x = conv3(x, 32, 64)\n",
    "x = Dropout(0.4)(x)\n",
    "x = conv4(x, 64, 128)\n",
    "x = Dropout(0.4)(x)\n",
    "x = conv5(x, 64, 128)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "tensor_out = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(tensor_in, tensor_out)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "#Adam(0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19652,
     "status": "error",
     "timestamp": 1598178350080,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "cb892981-08ed-4ba9-af29-c492b265fb8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 3.3559 - accuracy: 0.0964 - val_loss: 2.9831 - val_accuracy: 0.0877\n",
      "Epoch 2/4000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3912 - accuracy: 0.1006 - val_loss: 2.8385 - val_accuracy: 0.0909\n",
      "Epoch 3/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3649 - accuracy: 0.0992 - val_loss: 2.7397 - val_accuracy: 0.0974\n",
      "Epoch 4/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1698 - accuracy: 0.1159 - val_loss: 2.6587 - val_accuracy: 0.0942\n",
      "Epoch 5/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.2307 - accuracy: 0.1103 - val_loss: 2.5902 - val_accuracy: 0.0974\n",
      "Epoch 6/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.1670 - accuracy: 0.1045 - val_loss: 2.5337 - val_accuracy: 0.0877\n",
      "Epoch 7/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.1895 - accuracy: 0.1034 - val_loss: 2.4875 - val_accuracy: 0.0877\n",
      "Epoch 8/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1855 - accuracy: 0.0918 - val_loss: 2.4508 - val_accuracy: 0.0877\n",
      "Epoch 9/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.1438 - accuracy: 0.1084 - val_loss: 2.4196 - val_accuracy: 0.0877\n",
      "Epoch 10/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1243 - accuracy: 0.0922 - val_loss: 2.3934 - val_accuracy: 0.0877\n",
      "Epoch 11/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9914 - accuracy: 0.1229 - val_loss: 2.3719 - val_accuracy: 0.0942\n",
      "Epoch 12/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.0302 - accuracy: 0.1159 - val_loss: 2.3548 - val_accuracy: 0.1006\n",
      "Epoch 13/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9630 - accuracy: 0.1075 - val_loss: 2.3416 - val_accuracy: 0.0974\n",
      "Epoch 14/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9993 - accuracy: 0.0978 - val_loss: 2.3315 - val_accuracy: 0.0942\n",
      "Epoch 15/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.9481 - accuracy: 0.1201 - val_loss: 2.3232 - val_accuracy: 0.0942\n",
      "Epoch 16/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.9802 - accuracy: 0.1064 - val_loss: 2.3178 - val_accuracy: 0.0844\n",
      "Epoch 17/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.9274 - accuracy: 0.0967 - val_loss: 2.3124 - val_accuracy: 0.0877\n",
      "Epoch 18/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.9336 - accuracy: 0.1045 - val_loss: 2.3080 - val_accuracy: 0.0779\n",
      "Epoch 19/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.9374 - accuracy: 0.1094 - val_loss: 2.3037 - val_accuracy: 0.0714\n",
      "Epoch 20/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.9103 - accuracy: 0.1084 - val_loss: 2.2997 - val_accuracy: 0.0844\n",
      "Epoch 21/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.8997 - accuracy: 0.1094 - val_loss: 2.2950 - val_accuracy: 0.0779\n",
      "Epoch 22/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.9298 - accuracy: 0.1006 - val_loss: 2.2913 - val_accuracy: 0.0877\n",
      "Epoch 23/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.8956 - accuracy: 0.1104 - val_loss: 2.2893 - val_accuracy: 0.1234\n",
      "Epoch 24/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.8087 - accuracy: 0.1173 - val_loss: 2.2888 - val_accuracy: 0.1234\n",
      "Epoch 25/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.8729 - accuracy: 0.0938 - val_loss: 2.2878 - val_accuracy: 0.1299\n",
      "Epoch 26/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.8045 - accuracy: 0.1035 - val_loss: 2.2858 - val_accuracy: 0.1461\n",
      "Epoch 27/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.8440 - accuracy: 0.1123 - val_loss: 2.2831 - val_accuracy: 0.1461\n",
      "Epoch 28/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.7647 - accuracy: 0.1075 - val_loss: 2.2809 - val_accuracy: 0.1494\n",
      "Epoch 29/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.7985 - accuracy: 0.1182 - val_loss: 2.2792 - val_accuracy: 0.1623\n",
      "Epoch 30/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.7777 - accuracy: 0.1123 - val_loss: 2.2777 - val_accuracy: 0.1623\n",
      "Epoch 31/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.7981 - accuracy: 0.1103 - val_loss: 2.2766 - val_accuracy: 0.1688\n",
      "Epoch 32/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.7751 - accuracy: 0.1341 - val_loss: 2.2756 - val_accuracy: 0.1591\n",
      "Epoch 33/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.7998 - accuracy: 0.1034 - val_loss: 2.2743 - val_accuracy: 0.1494\n",
      "Epoch 34/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.7351 - accuracy: 0.1117 - val_loss: 2.2738 - val_accuracy: 0.1494\n",
      "Epoch 35/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.7202 - accuracy: 0.1016 - val_loss: 2.2736 - val_accuracy: 0.1494\n",
      "Epoch 36/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.7096 - accuracy: 0.0977 - val_loss: 2.2730 - val_accuracy: 0.1526\n",
      "Epoch 37/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6793 - accuracy: 0.1211 - val_loss: 2.2721 - val_accuracy: 0.1558\n",
      "Epoch 38/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6852 - accuracy: 0.1201 - val_loss: 2.2715 - val_accuracy: 0.1623\n",
      "Epoch 39/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6476 - accuracy: 0.1173 - val_loss: 2.2712 - val_accuracy: 0.1494\n",
      "Epoch 40/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6726 - accuracy: 0.1201 - val_loss: 2.2709 - val_accuracy: 0.1429\n",
      "Epoch 41/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.7411 - accuracy: 0.0964 - val_loss: 2.2704 - val_accuracy: 0.1396\n",
      "Epoch 42/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.6740 - accuracy: 0.1103 - val_loss: 2.2700 - val_accuracy: 0.1461\n",
      "Epoch 43/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6002 - accuracy: 0.1201 - val_loss: 2.2693 - val_accuracy: 0.1461\n",
      "Epoch 44/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6609 - accuracy: 0.1182 - val_loss: 2.2677 - val_accuracy: 0.1461\n",
      "Epoch 45/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6416 - accuracy: 0.1187 - val_loss: 2.2665 - val_accuracy: 0.1331\n",
      "Epoch 46/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.5942 - accuracy: 0.1327 - val_loss: 2.2659 - val_accuracy: 0.1331\n",
      "Epoch 47/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6864 - accuracy: 0.1201 - val_loss: 2.2653 - val_accuracy: 0.1331\n",
      "Epoch 48/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6283 - accuracy: 0.1173 - val_loss: 2.2650 - val_accuracy: 0.1266\n",
      "Epoch 49/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6614 - accuracy: 0.1113 - val_loss: 2.2652 - val_accuracy: 0.1266\n",
      "Epoch 50/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6383 - accuracy: 0.1143 - val_loss: 2.2658 - val_accuracy: 0.1039\n",
      "Epoch 51/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5500 - accuracy: 0.1230 - val_loss: 2.2660 - val_accuracy: 0.0909\n",
      "Epoch 52/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5997 - accuracy: 0.1229 - val_loss: 2.2663 - val_accuracy: 0.0942\n",
      "Epoch 53/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5509 - accuracy: 0.1117 - val_loss: 2.2665 - val_accuracy: 0.1039\n",
      "Epoch 54/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5918 - accuracy: 0.1035 - val_loss: 2.2666 - val_accuracy: 0.1006\n",
      "Epoch 55/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6295 - accuracy: 0.1075 - val_loss: 2.2662 - val_accuracy: 0.1136\n",
      "Epoch 56/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5616 - accuracy: 0.1299 - val_loss: 2.2654 - val_accuracy: 0.1136\n",
      "Epoch 57/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5678 - accuracy: 0.1240 - val_loss: 2.2648 - val_accuracy: 0.1201\n",
      "Epoch 58/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5844 - accuracy: 0.1113 - val_loss: 2.2640 - val_accuracy: 0.1266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5125 - accuracy: 0.1260 - val_loss: 2.2632 - val_accuracy: 0.1266\n",
      "Epoch 60/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5432 - accuracy: 0.1089 - val_loss: 2.2628 - val_accuracy: 0.1396\n",
      "Epoch 61/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5274 - accuracy: 0.1397 - val_loss: 2.2621 - val_accuracy: 0.1429\n",
      "Epoch 62/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4883 - accuracy: 0.1221 - val_loss: 2.2610 - val_accuracy: 0.1429\n",
      "Epoch 63/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5257 - accuracy: 0.1074 - val_loss: 2.2594 - val_accuracy: 0.1396\n",
      "Epoch 64/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5400 - accuracy: 0.1172 - val_loss: 2.2577 - val_accuracy: 0.1494\n",
      "Epoch 65/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.4593 - accuracy: 0.1397 - val_loss: 2.2554 - val_accuracy: 0.1526\n",
      "Epoch 66/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5329 - accuracy: 0.0978 - val_loss: 2.2535 - val_accuracy: 0.1558\n",
      "Epoch 67/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5395 - accuracy: 0.1104 - val_loss: 2.2516 - val_accuracy: 0.1591\n",
      "Epoch 68/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4761 - accuracy: 0.1369 - val_loss: 2.2500 - val_accuracy: 0.1526\n",
      "Epoch 69/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4866 - accuracy: 0.1143 - val_loss: 2.2481 - val_accuracy: 0.1591\n",
      "Epoch 70/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4883 - accuracy: 0.1240 - val_loss: 2.2463 - val_accuracy: 0.1656\n",
      "Epoch 71/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5064 - accuracy: 0.0978 - val_loss: 2.2451 - val_accuracy: 0.1656\n",
      "Epoch 72/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4676 - accuracy: 0.1243 - val_loss: 2.2438 - val_accuracy: 0.1753\n",
      "Epoch 73/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4555 - accuracy: 0.1299 - val_loss: 2.2427 - val_accuracy: 0.1753\n",
      "Epoch 74/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4463 - accuracy: 0.1162 - val_loss: 2.2417 - val_accuracy: 0.1753\n",
      "Epoch 75/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.5065 - accuracy: 0.1117 - val_loss: 2.2411 - val_accuracy: 0.1786\n",
      "Epoch 76/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4623 - accuracy: 0.1215 - val_loss: 2.2408 - val_accuracy: 0.1851\n",
      "Epoch 77/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4452 - accuracy: 0.1279 - val_loss: 2.2406 - val_accuracy: 0.1916\n",
      "Epoch 78/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4190 - accuracy: 0.1397 - val_loss: 2.2399 - val_accuracy: 0.1948\n",
      "Epoch 79/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3879 - accuracy: 0.1465 - val_loss: 2.2393 - val_accuracy: 0.1981\n",
      "Epoch 80/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4164 - accuracy: 0.1439 - val_loss: 2.2384 - val_accuracy: 0.2045\n",
      "Epoch 81/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4606 - accuracy: 0.1279 - val_loss: 2.2370 - val_accuracy: 0.2013\n",
      "Epoch 82/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4072 - accuracy: 0.1215 - val_loss: 2.2357 - val_accuracy: 0.2078\n",
      "Epoch 83/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4046 - accuracy: 0.1285 - val_loss: 2.2349 - val_accuracy: 0.2143\n",
      "Epoch 84/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4548 - accuracy: 0.1182 - val_loss: 2.2342 - val_accuracy: 0.2143\n",
      "Epoch 85/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4058 - accuracy: 0.1229 - val_loss: 2.2339 - val_accuracy: 0.2175\n",
      "Epoch 86/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3797 - accuracy: 0.1383 - val_loss: 2.2337 - val_accuracy: 0.2175\n",
      "Epoch 87/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4110 - accuracy: 0.1152 - val_loss: 2.2335 - val_accuracy: 0.2143\n",
      "Epoch 88/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3521 - accuracy: 0.1387 - val_loss: 2.2331 - val_accuracy: 0.2110\n",
      "Epoch 89/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3638 - accuracy: 0.1387 - val_loss: 2.2329 - val_accuracy: 0.2143\n",
      "Epoch 90/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3966 - accuracy: 0.1318 - val_loss: 2.2322 - val_accuracy: 0.2110\n",
      "Epoch 91/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4077 - accuracy: 0.1411 - val_loss: 2.2315 - val_accuracy: 0.2110\n",
      "Epoch 92/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4299 - accuracy: 0.1162 - val_loss: 2.2309 - val_accuracy: 0.2078\n",
      "Epoch 93/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.4087 - accuracy: 0.1173 - val_loss: 2.2301 - val_accuracy: 0.2045\n",
      "Epoch 94/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3998 - accuracy: 0.1201 - val_loss: 2.2298 - val_accuracy: 0.2045\n",
      "Epoch 95/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3701 - accuracy: 0.1318 - val_loss: 2.2299 - val_accuracy: 0.1916\n",
      "Epoch 96/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3499 - accuracy: 0.1523 - val_loss: 2.2298 - val_accuracy: 0.1981\n",
      "Epoch 97/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3331 - accuracy: 0.1397 - val_loss: 2.2297 - val_accuracy: 0.1948\n",
      "Epoch 98/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3632 - accuracy: 0.1396 - val_loss: 2.2293 - val_accuracy: 0.1851\n",
      "Epoch 99/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3237 - accuracy: 0.1377 - val_loss: 2.2291 - val_accuracy: 0.1851\n",
      "Epoch 100/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3340 - accuracy: 0.1522 - val_loss: 2.2291 - val_accuracy: 0.1753\n",
      "Epoch 101/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3520 - accuracy: 0.1328 - val_loss: 2.2291 - val_accuracy: 0.1721\n",
      "Epoch 102/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3483 - accuracy: 0.1436 - val_loss: 2.2288 - val_accuracy: 0.1721\n",
      "Epoch 103/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3411 - accuracy: 0.1397 - val_loss: 2.2284 - val_accuracy: 0.1753\n",
      "Epoch 104/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3522 - accuracy: 0.1230 - val_loss: 2.2280 - val_accuracy: 0.1786\n",
      "Epoch 105/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3097 - accuracy: 0.1522 - val_loss: 2.2270 - val_accuracy: 0.1786\n",
      "Epoch 106/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3151 - accuracy: 0.1383 - val_loss: 2.2258 - val_accuracy: 0.1753\n",
      "Epoch 107/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3008 - accuracy: 0.1383 - val_loss: 2.2246 - val_accuracy: 0.1786\n",
      "Epoch 108/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3459 - accuracy: 0.1670 - val_loss: 2.2234 - val_accuracy: 0.1786\n",
      "Epoch 109/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.3234 - accuracy: 0.1425 - val_loss: 2.2220 - val_accuracy: 0.1721\n",
      "Epoch 110/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3314 - accuracy: 0.1327 - val_loss: 2.2209 - val_accuracy: 0.1753\n",
      "Epoch 111/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3012 - accuracy: 0.1445 - val_loss: 2.2200 - val_accuracy: 0.1753\n",
      "Epoch 112/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2940 - accuracy: 0.1611 - val_loss: 2.2197 - val_accuracy: 0.1753\n",
      "Epoch 113/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3067 - accuracy: 0.1494 - val_loss: 2.2197 - val_accuracy: 0.1786\n",
      "Epoch 114/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3240 - accuracy: 0.1475 - val_loss: 2.2198 - val_accuracy: 0.1721\n",
      "Epoch 115/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3044 - accuracy: 0.1536 - val_loss: 2.2196 - val_accuracy: 0.1721\n",
      "Epoch 116/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3216 - accuracy: 0.1426 - val_loss: 2.2196 - val_accuracy: 0.1688\n",
      "Epoch 117/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2946 - accuracy: 0.1582 - val_loss: 2.2195 - val_accuracy: 0.1623\n",
      "Epoch 118/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3182 - accuracy: 0.1494 - val_loss: 2.2194 - val_accuracy: 0.1591\n",
      "Epoch 119/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2904 - accuracy: 0.1522 - val_loss: 2.2200 - val_accuracy: 0.1591\n",
      "Epoch 120/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3126 - accuracy: 0.1411 - val_loss: 2.2204 - val_accuracy: 0.1623\n",
      "Epoch 121/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2908 - accuracy: 0.1425 - val_loss: 2.2208 - val_accuracy: 0.1623\n",
      "Epoch 122/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2812 - accuracy: 0.1494 - val_loss: 2.2213 - val_accuracy: 0.1591\n",
      "Epoch 123/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2891 - accuracy: 0.1611 - val_loss: 2.2217 - val_accuracy: 0.1623\n",
      "Epoch 124/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2812 - accuracy: 0.1582 - val_loss: 2.2223 - val_accuracy: 0.1591\n",
      "Epoch 125/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2875 - accuracy: 0.1620 - val_loss: 2.2226 - val_accuracy: 0.1656\n",
      "Epoch 126/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2675 - accuracy: 0.1480 - val_loss: 2.2232 - val_accuracy: 0.1656\n",
      "Epoch 127/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2595 - accuracy: 0.1582 - val_loss: 2.2241 - val_accuracy: 0.1688\n",
      "Epoch 128/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2503 - accuracy: 0.1533 - val_loss: 2.2248 - val_accuracy: 0.1656\n",
      "Epoch 129/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2835 - accuracy: 0.1550 - val_loss: 2.2254 - val_accuracy: 0.1623\n",
      "Epoch 130/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2858 - accuracy: 0.1357 - val_loss: 2.2258 - val_accuracy: 0.1623\n",
      "Epoch 131/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2739 - accuracy: 0.1453 - val_loss: 2.2260 - val_accuracy: 0.1656\n",
      "Epoch 132/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2702 - accuracy: 0.1466 - val_loss: 2.2265 - val_accuracy: 0.1656\n",
      "Epoch 133/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3002 - accuracy: 0.1676 - val_loss: 2.2271 - val_accuracy: 0.1623\n",
      "Epoch 134/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2528 - accuracy: 0.1718 - val_loss: 2.2274 - val_accuracy: 0.1656\n",
      "Epoch 135/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2330 - accuracy: 0.1777 - val_loss: 2.2279 - val_accuracy: 0.1591\n",
      "Epoch 136/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2760 - accuracy: 0.1670 - val_loss: 2.2280 - val_accuracy: 0.1656\n",
      "Epoch 137/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2546 - accuracy: 0.1927 - val_loss: 2.2277 - val_accuracy: 0.1721\n",
      "Epoch 138/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2613 - accuracy: 0.1718 - val_loss: 2.2272 - val_accuracy: 0.1721\n",
      "Epoch 139/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2706 - accuracy: 0.1718 - val_loss: 2.2270 - val_accuracy: 0.1786\n",
      "Epoch 140/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2356 - accuracy: 0.1983 - val_loss: 2.2266 - val_accuracy: 0.1786\n",
      "Epoch 141/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2645 - accuracy: 0.1718 - val_loss: 2.2263 - val_accuracy: 0.1721\n",
      "Epoch 142/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2663 - accuracy: 0.1578 - val_loss: 2.2260 - val_accuracy: 0.1721\n",
      "Epoch 143/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2167 - accuracy: 0.1606 - val_loss: 2.2256 - val_accuracy: 0.1721\n",
      "Epoch 144/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2437 - accuracy: 0.1718 - val_loss: 2.2249 - val_accuracy: 0.1688\n",
      "Epoch 145/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2428 - accuracy: 0.1855 - val_loss: 2.2244 - val_accuracy: 0.1688\n",
      "Epoch 146/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2283 - accuracy: 0.1787 - val_loss: 2.2238 - val_accuracy: 0.1688\n",
      "Epoch 147/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2133 - accuracy: 0.1774 - val_loss: 2.2234 - val_accuracy: 0.1688\n",
      "Epoch 148/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2701 - accuracy: 0.1572 - val_loss: 2.2229 - val_accuracy: 0.1688\n",
      "Epoch 149/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2627 - accuracy: 0.1453 - val_loss: 2.2220 - val_accuracy: 0.1656\n",
      "Epoch 150/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2380 - accuracy: 0.1899 - val_loss: 2.2210 - val_accuracy: 0.1656\n",
      "Epoch 151/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2115 - accuracy: 0.1788 - val_loss: 2.2202 - val_accuracy: 0.1656\n",
      "Epoch 152/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2306 - accuracy: 0.1758 - val_loss: 2.2194 - val_accuracy: 0.1656\n",
      "Epoch 153/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2532 - accuracy: 0.1620 - val_loss: 2.2186 - val_accuracy: 0.1656\n",
      "Epoch 154/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2219 - accuracy: 0.1738 - val_loss: 2.2178 - val_accuracy: 0.1656\n",
      "Epoch 155/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2022 - accuracy: 0.1904 - val_loss: 2.2168 - val_accuracy: 0.1688\n",
      "Epoch 156/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2022 - accuracy: 0.2053 - val_loss: 2.2159 - val_accuracy: 0.1688\n",
      "Epoch 157/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2579 - accuracy: 0.1550 - val_loss: 2.2148 - val_accuracy: 0.1688\n",
      "Epoch 158/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2149 - accuracy: 0.1746 - val_loss: 2.2137 - val_accuracy: 0.1656\n",
      "Epoch 159/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1968 - accuracy: 0.1983 - val_loss: 2.2126 - val_accuracy: 0.1656\n",
      "Epoch 160/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2303 - accuracy: 0.1760 - val_loss: 2.2119 - val_accuracy: 0.1688\n",
      "Epoch 161/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2400 - accuracy: 0.1718 - val_loss: 2.2108 - val_accuracy: 0.1688\n",
      "Epoch 162/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2168 - accuracy: 0.2025 - val_loss: 2.2101 - val_accuracy: 0.1688\n",
      "Epoch 163/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2140 - accuracy: 0.1758 - val_loss: 2.2098 - val_accuracy: 0.1656\n",
      "Epoch 164/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2132 - accuracy: 0.1816 - val_loss: 2.2095 - val_accuracy: 0.1656\n",
      "Epoch 165/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1809 - accuracy: 0.1895 - val_loss: 2.2088 - val_accuracy: 0.1688\n",
      "Epoch 166/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2010 - accuracy: 0.2039 - val_loss: 2.2081 - val_accuracy: 0.1688\n",
      "Epoch 167/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1956 - accuracy: 0.1758 - val_loss: 2.2073 - val_accuracy: 0.1721\n",
      "Epoch 168/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1959 - accuracy: 0.2080 - val_loss: 2.2070 - val_accuracy: 0.1721\n",
      "Epoch 169/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1950 - accuracy: 0.1816 - val_loss: 2.2066 - val_accuracy: 0.1721\n",
      "Epoch 170/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1816 - accuracy: 0.1634 - val_loss: 2.2061 - val_accuracy: 0.1721\n",
      "Epoch 171/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1798 - accuracy: 0.1963 - val_loss: 2.2057 - val_accuracy: 0.1721\n",
      "Epoch 172/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1617 - accuracy: 0.2039 - val_loss: 2.2055 - val_accuracy: 0.1721\n",
      "Epoch 173/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1894 - accuracy: 0.1983 - val_loss: 2.2052 - val_accuracy: 0.1721\n",
      "Epoch 174/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1680 - accuracy: 0.1982 - val_loss: 2.2050 - val_accuracy: 0.1721\n",
      "Epoch 175/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1786 - accuracy: 0.1802 - val_loss: 2.2041 - val_accuracy: 0.1721\n",
      "Epoch 176/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2019 - accuracy: 0.1738 - val_loss: 2.2034 - val_accuracy: 0.1721\n",
      "Epoch 177/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1919 - accuracy: 0.1992 - val_loss: 2.2026 - val_accuracy: 0.1721\n",
      "Epoch 178/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2139 - accuracy: 0.2053 - val_loss: 2.2020 - val_accuracy: 0.1721\n",
      "Epoch 179/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2114 - accuracy: 0.1865 - val_loss: 2.2013 - val_accuracy: 0.1656\n",
      "Epoch 180/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1730 - accuracy: 0.2179 - val_loss: 2.2006 - val_accuracy: 0.1656\n",
      "Epoch 181/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2014 - accuracy: 0.1992 - val_loss: 2.2000 - val_accuracy: 0.1721\n",
      "Epoch 182/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1690 - accuracy: 0.1875 - val_loss: 2.1996 - val_accuracy: 0.1721\n",
      "Epoch 183/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2087 - accuracy: 0.1969 - val_loss: 2.1992 - val_accuracy: 0.1721\n",
      "Epoch 184/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1676 - accuracy: 0.2053 - val_loss: 2.1983 - val_accuracy: 0.1721\n",
      "Epoch 185/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1885 - accuracy: 0.2041 - val_loss: 2.1969 - val_accuracy: 0.1721\n",
      "Epoch 186/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2122 - accuracy: 0.1858 - val_loss: 2.1953 - val_accuracy: 0.1753\n",
      "Epoch 187/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1820 - accuracy: 0.1982 - val_loss: 2.1940 - val_accuracy: 0.1786\n",
      "Epoch 188/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1766 - accuracy: 0.2011 - val_loss: 2.1923 - val_accuracy: 0.1786\n",
      "Epoch 189/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2107 - accuracy: 0.1885 - val_loss: 2.1909 - val_accuracy: 0.1786\n",
      "Epoch 190/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2146 - accuracy: 0.1760 - val_loss: 2.1890 - val_accuracy: 0.1818\n",
      "Epoch 191/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.1718 - accuracy: 0.1855 - val_loss: 2.1872 - val_accuracy: 0.1818\n",
      "Epoch 192/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1746 - accuracy: 0.1982 - val_loss: 2.1854 - val_accuracy: 0.1818\n",
      "Epoch 193/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2023 - accuracy: 0.1777 - val_loss: 2.1829 - val_accuracy: 0.1818\n",
      "Epoch 194/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2024 - accuracy: 0.2100 - val_loss: 2.1802 - val_accuracy: 0.1818\n",
      "Epoch 195/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1585 - accuracy: 0.2080 - val_loss: 2.1775 - val_accuracy: 0.1851\n",
      "Epoch 196/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1401 - accuracy: 0.2217 - val_loss: 2.1745 - val_accuracy: 0.1883\n",
      "Epoch 197/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1467 - accuracy: 0.1875 - val_loss: 2.1723 - val_accuracy: 0.1981\n",
      "Epoch 198/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1732 - accuracy: 0.2051 - val_loss: 2.1703 - val_accuracy: 0.1981\n",
      "Epoch 199/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1484 - accuracy: 0.2188 - val_loss: 2.1687 - val_accuracy: 0.2013\n",
      "Epoch 200/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1584 - accuracy: 0.2021 - val_loss: 2.1670 - val_accuracy: 0.2013\n",
      "Epoch 201/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1931 - accuracy: 0.1797 - val_loss: 2.1653 - val_accuracy: 0.2013\n",
      "Epoch 202/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1412 - accuracy: 0.2137 - val_loss: 2.1633 - val_accuracy: 0.2013\n",
      "Epoch 203/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1323 - accuracy: 0.2095 - val_loss: 2.1615 - val_accuracy: 0.1981\n",
      "Epoch 204/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1471 - accuracy: 0.2039 - val_loss: 2.1597 - val_accuracy: 0.2013\n",
      "Epoch 205/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1368 - accuracy: 0.1955 - val_loss: 2.1572 - val_accuracy: 0.2013\n",
      "Epoch 206/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1311 - accuracy: 0.2129 - val_loss: 2.1551 - val_accuracy: 0.2013\n",
      "Epoch 207/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1406 - accuracy: 0.1899 - val_loss: 2.1531 - val_accuracy: 0.2013\n",
      "Epoch 208/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1558 - accuracy: 0.2053 - val_loss: 2.1514 - val_accuracy: 0.2045\n",
      "Epoch 209/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1261 - accuracy: 0.2137 - val_loss: 2.1493 - val_accuracy: 0.2045\n",
      "Epoch 210/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1715 - accuracy: 0.1885 - val_loss: 2.1473 - val_accuracy: 0.2045\n",
      "Epoch 211/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1577 - accuracy: 0.2053 - val_loss: 2.1458 - val_accuracy: 0.2078\n",
      "Epoch 212/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1351 - accuracy: 0.2165 - val_loss: 2.1449 - val_accuracy: 0.2045\n",
      "Epoch 213/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1383 - accuracy: 0.2178 - val_loss: 2.1439 - val_accuracy: 0.2045\n",
      "Epoch 214/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1622 - accuracy: 0.2291 - val_loss: 2.1430 - val_accuracy: 0.2078\n",
      "Epoch 215/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1480 - accuracy: 0.2285 - val_loss: 2.1421 - val_accuracy: 0.2078\n",
      "Epoch 216/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1390 - accuracy: 0.2011 - val_loss: 2.1399 - val_accuracy: 0.2078\n",
      "Epoch 217/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1444 - accuracy: 0.2053 - val_loss: 2.1376 - val_accuracy: 0.2078\n",
      "Epoch 218/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1850 - accuracy: 0.2137 - val_loss: 2.1349 - val_accuracy: 0.2110\n",
      "Epoch 219/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1292 - accuracy: 0.2179 - val_loss: 2.1321 - val_accuracy: 0.2110\n",
      "Epoch 220/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1204 - accuracy: 0.2165 - val_loss: 2.1286 - val_accuracy: 0.2110\n",
      "Epoch 221/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1258 - accuracy: 0.2263 - val_loss: 2.1254 - val_accuracy: 0.2143\n",
      "Epoch 222/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1010 - accuracy: 0.2227 - val_loss: 2.1222 - val_accuracy: 0.2175\n",
      "Epoch 223/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1552 - accuracy: 0.2025 - val_loss: 2.1190 - val_accuracy: 0.2143\n",
      "Epoch 224/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1127 - accuracy: 0.2275 - val_loss: 2.1162 - val_accuracy: 0.2175\n",
      "Epoch 225/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1418 - accuracy: 0.2119 - val_loss: 2.1131 - val_accuracy: 0.2175\n",
      "Epoch 226/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0871 - accuracy: 0.2363 - val_loss: 2.1098 - val_accuracy: 0.2208\n",
      "Epoch 227/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1232 - accuracy: 0.2179 - val_loss: 2.1059 - val_accuracy: 0.2240\n",
      "Epoch 228/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1206 - accuracy: 0.2139 - val_loss: 2.1022 - val_accuracy: 0.2338\n",
      "Epoch 229/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1185 - accuracy: 0.2197 - val_loss: 2.0987 - val_accuracy: 0.2403\n",
      "Epoch 230/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1185 - accuracy: 0.2129 - val_loss: 2.0950 - val_accuracy: 0.2435\n",
      "Epoch 231/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1206 - accuracy: 0.2324 - val_loss: 2.0918 - val_accuracy: 0.2532\n",
      "Epoch 232/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0932 - accuracy: 0.2295 - val_loss: 2.0886 - val_accuracy: 0.2565\n",
      "Epoch 233/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0808 - accuracy: 0.2444 - val_loss: 2.0855 - val_accuracy: 0.2532\n",
      "Epoch 234/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1255 - accuracy: 0.2129 - val_loss: 2.0821 - val_accuracy: 0.2565\n",
      "Epoch 235/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1120 - accuracy: 0.2067 - val_loss: 2.0785 - val_accuracy: 0.2532\n",
      "Epoch 236/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0946 - accuracy: 0.2412 - val_loss: 2.0746 - val_accuracy: 0.2532\n",
      "Epoch 237/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1240 - accuracy: 0.2129 - val_loss: 2.0713 - val_accuracy: 0.2565\n",
      "Epoch 238/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0851 - accuracy: 0.2472 - val_loss: 2.0675 - val_accuracy: 0.2597\n",
      "Epoch 239/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1002 - accuracy: 0.2486 - val_loss: 2.0642 - val_accuracy: 0.2630\n",
      "Epoch 240/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1133 - accuracy: 0.2168 - val_loss: 2.0607 - val_accuracy: 0.2630\n",
      "Epoch 241/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1023 - accuracy: 0.2304 - val_loss: 2.0572 - val_accuracy: 0.2630\n",
      "Epoch 242/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0934 - accuracy: 0.2277 - val_loss: 2.0543 - val_accuracy: 0.2662\n",
      "Epoch 243/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1203 - accuracy: 0.2236 - val_loss: 2.0513 - val_accuracy: 0.2727\n",
      "Epoch 244/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1033 - accuracy: 0.2430 - val_loss: 2.0483 - val_accuracy: 0.2727\n",
      "Epoch 245/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1030 - accuracy: 0.2275 - val_loss: 2.0453 - val_accuracy: 0.2727\n",
      "Epoch 246/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0593 - accuracy: 0.2486 - val_loss: 2.0426 - val_accuracy: 0.2727\n",
      "Epoch 247/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0693 - accuracy: 0.2514 - val_loss: 2.0396 - val_accuracy: 0.2727\n",
      "Epoch 248/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1035 - accuracy: 0.2246 - val_loss: 2.0363 - val_accuracy: 0.2792\n",
      "Epoch 249/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0828 - accuracy: 0.2402 - val_loss: 2.0325 - val_accuracy: 0.2825\n",
      "Epoch 250/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1161 - accuracy: 0.2165 - val_loss: 2.0288 - val_accuracy: 0.2792\n",
      "Epoch 251/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0988 - accuracy: 0.2263 - val_loss: 2.0252 - val_accuracy: 0.2825\n",
      "Epoch 252/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1203 - accuracy: 0.2221 - val_loss: 2.0225 - val_accuracy: 0.2857\n",
      "Epoch 253/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0827 - accuracy: 0.2458 - val_loss: 2.0201 - val_accuracy: 0.2890\n",
      "Epoch 254/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0977 - accuracy: 0.2277 - val_loss: 2.0172 - val_accuracy: 0.2857\n",
      "Epoch 255/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0797 - accuracy: 0.2556 - val_loss: 2.0153 - val_accuracy: 0.2857\n",
      "Epoch 256/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0725 - accuracy: 0.2193 - val_loss: 2.0129 - val_accuracy: 0.2857\n",
      "Epoch 257/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0562 - accuracy: 0.2332 - val_loss: 2.0105 - val_accuracy: 0.2890\n",
      "Epoch 258/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0791 - accuracy: 0.2500 - val_loss: 2.0086 - val_accuracy: 0.2890\n",
      "Epoch 259/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0801 - accuracy: 0.2598 - val_loss: 2.0059 - val_accuracy: 0.2922\n",
      "Epoch 260/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1156 - accuracy: 0.2119 - val_loss: 2.0036 - val_accuracy: 0.2955\n",
      "Epoch 261/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0819 - accuracy: 0.2383 - val_loss: 2.0012 - val_accuracy: 0.3052\n",
      "Epoch 262/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0728 - accuracy: 0.2461 - val_loss: 1.9988 - val_accuracy: 0.3052\n",
      "Epoch 263/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0481 - accuracy: 0.2388 - val_loss: 1.9970 - val_accuracy: 0.3084\n",
      "Epoch 264/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0779 - accuracy: 0.2314 - val_loss: 1.9959 - val_accuracy: 0.3052\n",
      "Epoch 265/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0924 - accuracy: 0.2318 - val_loss: 1.9948 - val_accuracy: 0.3084\n",
      "Epoch 266/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0777 - accuracy: 0.2458 - val_loss: 1.9940 - val_accuracy: 0.3084\n",
      "Epoch 267/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0806 - accuracy: 0.2373 - val_loss: 1.9937 - val_accuracy: 0.3052\n",
      "Epoch 268/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0797 - accuracy: 0.2588 - val_loss: 1.9935 - val_accuracy: 0.3052\n",
      "Epoch 269/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0805 - accuracy: 0.2412 - val_loss: 1.9931 - val_accuracy: 0.3052\n",
      "Epoch 270/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0862 - accuracy: 0.2346 - val_loss: 1.9932 - val_accuracy: 0.3084\n",
      "Epoch 271/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0440 - accuracy: 0.2422 - val_loss: 1.9935 - val_accuracy: 0.3084\n",
      "Epoch 272/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0698 - accuracy: 0.2668 - val_loss: 1.9933 - val_accuracy: 0.3052\n",
      "Epoch 273/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0571 - accuracy: 0.2346 - val_loss: 1.9933 - val_accuracy: 0.2987\n",
      "Epoch 274/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0629 - accuracy: 0.2373 - val_loss: 1.9932 - val_accuracy: 0.2987\n",
      "Epoch 275/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0600 - accuracy: 0.2451 - val_loss: 1.9924 - val_accuracy: 0.2987\n",
      "Epoch 276/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0086 - accuracy: 0.2654 - val_loss: 1.9911 - val_accuracy: 0.3019\n",
      "Epoch 277/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0556 - accuracy: 0.2556 - val_loss: 1.9896 - val_accuracy: 0.2987\n",
      "Epoch 278/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0520 - accuracy: 0.2471 - val_loss: 1.9873 - val_accuracy: 0.3019\n",
      "Epoch 279/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0358 - accuracy: 0.2626 - val_loss: 1.9848 - val_accuracy: 0.3084\n",
      "Epoch 280/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0671 - accuracy: 0.2480 - val_loss: 1.9824 - val_accuracy: 0.3084\n",
      "Epoch 281/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0628 - accuracy: 0.2542 - val_loss: 1.9794 - val_accuracy: 0.3084\n",
      "Epoch 282/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0584 - accuracy: 0.2373 - val_loss: 1.9767 - val_accuracy: 0.3084\n",
      "Epoch 283/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0437 - accuracy: 0.2416 - val_loss: 1.9743 - val_accuracy: 0.3084\n",
      "Epoch 284/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0222 - accuracy: 0.2549 - val_loss: 1.9717 - val_accuracy: 0.3084\n",
      "Epoch 285/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0259 - accuracy: 0.2578 - val_loss: 1.9696 - val_accuracy: 0.3117\n",
      "Epoch 286/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0739 - accuracy: 0.2291 - val_loss: 1.9677 - val_accuracy: 0.3117\n",
      "Epoch 287/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0455 - accuracy: 0.2334 - val_loss: 1.9660 - val_accuracy: 0.3149\n",
      "Epoch 288/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0462 - accuracy: 0.2461 - val_loss: 1.9639 - val_accuracy: 0.3149\n",
      "Epoch 289/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0128 - accuracy: 0.2640 - val_loss: 1.9619 - val_accuracy: 0.3149\n",
      "Epoch 290/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0888 - accuracy: 0.2275 - val_loss: 1.9600 - val_accuracy: 0.3149\n",
      "Epoch 291/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0489 - accuracy: 0.2612 - val_loss: 1.9577 - val_accuracy: 0.3214\n",
      "Epoch 292/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0396 - accuracy: 0.2263 - val_loss: 1.9554 - val_accuracy: 0.3279\n",
      "Epoch 293/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0554 - accuracy: 0.2432 - val_loss: 1.9534 - val_accuracy: 0.3247\n",
      "Epoch 294/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0396 - accuracy: 0.2451 - val_loss: 1.9514 - val_accuracy: 0.3247\n",
      "Epoch 295/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0494 - accuracy: 0.2151 - val_loss: 1.9489 - val_accuracy: 0.3247\n",
      "Epoch 296/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0098 - accuracy: 0.2500 - val_loss: 1.9462 - val_accuracy: 0.3214\n",
      "Epoch 297/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0277 - accuracy: 0.2588 - val_loss: 1.9442 - val_accuracy: 0.3214\n",
      "Epoch 298/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0255 - accuracy: 0.2568 - val_loss: 1.9419 - val_accuracy: 0.3247\n",
      "Epoch 299/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0248 - accuracy: 0.2627 - val_loss: 1.9392 - val_accuracy: 0.3214\n",
      "Epoch 300/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9828 - accuracy: 0.2835 - val_loss: 1.9362 - val_accuracy: 0.3247\n",
      "Epoch 301/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0449 - accuracy: 0.2490 - val_loss: 1.9333 - val_accuracy: 0.3279\n",
      "Epoch 302/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0045 - accuracy: 0.2626 - val_loss: 1.9300 - val_accuracy: 0.3312\n",
      "Epoch 303/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0000 - accuracy: 0.2709 - val_loss: 1.9270 - val_accuracy: 0.3312\n",
      "Epoch 304/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0594 - accuracy: 0.2451 - val_loss: 1.9240 - val_accuracy: 0.3377\n",
      "Epoch 305/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0447 - accuracy: 0.2451 - val_loss: 1.9209 - val_accuracy: 0.3312\n",
      "Epoch 306/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0293 - accuracy: 0.2570 - val_loss: 1.9182 - val_accuracy: 0.3377\n",
      "Epoch 307/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0244 - accuracy: 0.2607 - val_loss: 1.9156 - val_accuracy: 0.3377\n",
      "Epoch 308/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0381 - accuracy: 0.2626 - val_loss: 1.9125 - val_accuracy: 0.3344\n",
      "Epoch 309/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0239 - accuracy: 0.2444 - val_loss: 1.9098 - val_accuracy: 0.3279\n",
      "Epoch 310/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0252 - accuracy: 0.2598 - val_loss: 1.9074 - val_accuracy: 0.3312\n",
      "Epoch 311/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0314 - accuracy: 0.2598 - val_loss: 1.9052 - val_accuracy: 0.3344\n",
      "Epoch 312/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0347 - accuracy: 0.2480 - val_loss: 1.9032 - val_accuracy: 0.3377\n",
      "Epoch 313/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0213 - accuracy: 0.2500 - val_loss: 1.9013 - val_accuracy: 0.3377\n",
      "Epoch 314/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0423 - accuracy: 0.2416 - val_loss: 1.8996 - val_accuracy: 0.3377\n",
      "Epoch 315/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0011 - accuracy: 0.2705 - val_loss: 1.8977 - val_accuracy: 0.3409\n",
      "Epoch 316/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9923 - accuracy: 0.2835 - val_loss: 1.8956 - val_accuracy: 0.3409\n",
      "Epoch 317/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0386 - accuracy: 0.2676 - val_loss: 1.8937 - val_accuracy: 0.3442\n",
      "Epoch 318/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9954 - accuracy: 0.2696 - val_loss: 1.8925 - val_accuracy: 0.3409\n",
      "Epoch 319/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0152 - accuracy: 0.2542 - val_loss: 1.8908 - val_accuracy: 0.3409\n",
      "Epoch 320/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0153 - accuracy: 0.2812 - val_loss: 1.8889 - val_accuracy: 0.3409\n",
      "Epoch 321/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0059 - accuracy: 0.2500 - val_loss: 1.8870 - val_accuracy: 0.3442\n",
      "Epoch 322/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9839 - accuracy: 0.2773 - val_loss: 1.8851 - val_accuracy: 0.3474\n",
      "Epoch 323/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9993 - accuracy: 0.2654 - val_loss: 1.8835 - val_accuracy: 0.3474\n",
      "Epoch 324/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9535 - accuracy: 0.2696 - val_loss: 1.8817 - val_accuracy: 0.3474\n",
      "Epoch 325/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9963 - accuracy: 0.2646 - val_loss: 1.8803 - val_accuracy: 0.3539\n",
      "Epoch 326/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9773 - accuracy: 0.2765 - val_loss: 1.8785 - val_accuracy: 0.3539\n",
      "Epoch 327/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9544 - accuracy: 0.2765 - val_loss: 1.8763 - val_accuracy: 0.3539\n",
      "Epoch 328/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0005 - accuracy: 0.2852 - val_loss: 1.8741 - val_accuracy: 0.3506\n",
      "Epoch 329/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9589 - accuracy: 0.2765 - val_loss: 1.8719 - val_accuracy: 0.3474\n",
      "Epoch 330/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9891 - accuracy: 0.2812 - val_loss: 1.8698 - val_accuracy: 0.3442\n",
      "Epoch 331/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9549 - accuracy: 0.2835 - val_loss: 1.8680 - val_accuracy: 0.3442\n",
      "Epoch 332/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9890 - accuracy: 0.2793 - val_loss: 1.8667 - val_accuracy: 0.3442\n",
      "Epoch 333/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0520 - accuracy: 0.2640 - val_loss: 1.8654 - val_accuracy: 0.3474\n",
      "Epoch 334/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0096 - accuracy: 0.2668 - val_loss: 1.8640 - val_accuracy: 0.3571\n",
      "Epoch 335/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0059 - accuracy: 0.2709 - val_loss: 1.8626 - val_accuracy: 0.3604\n",
      "Epoch 336/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9571 - accuracy: 0.2910 - val_loss: 1.8614 - val_accuracy: 0.3669\n",
      "Epoch 337/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9605 - accuracy: 0.2863 - val_loss: 1.8607 - val_accuracy: 0.3669\n",
      "Epoch 338/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9971 - accuracy: 0.2754 - val_loss: 1.8600 - val_accuracy: 0.3669\n",
      "Epoch 339/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9862 - accuracy: 0.2715 - val_loss: 1.8593 - val_accuracy: 0.3669\n",
      "Epoch 340/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9800 - accuracy: 0.2588 - val_loss: 1.8584 - val_accuracy: 0.3669\n",
      "Epoch 341/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9975 - accuracy: 0.2764 - val_loss: 1.8575 - val_accuracy: 0.3701\n",
      "Epoch 342/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9911 - accuracy: 0.2779 - val_loss: 1.8572 - val_accuracy: 0.3669\n",
      "Epoch 343/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9413 - accuracy: 0.2793 - val_loss: 1.8574 - val_accuracy: 0.3701\n",
      "Epoch 344/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9650 - accuracy: 0.2920 - val_loss: 1.8581 - val_accuracy: 0.3701\n",
      "Epoch 345/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9999 - accuracy: 0.2891 - val_loss: 1.8589 - val_accuracy: 0.3539\n",
      "Epoch 346/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9990 - accuracy: 0.2773 - val_loss: 1.8587 - val_accuracy: 0.3539\n",
      "Epoch 347/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9737 - accuracy: 0.2705 - val_loss: 1.8586 - val_accuracy: 0.3506\n",
      "Epoch 348/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9434 - accuracy: 0.2807 - val_loss: 1.8587 - val_accuracy: 0.3474\n",
      "Epoch 349/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9447 - accuracy: 0.2947 - val_loss: 1.8589 - val_accuracy: 0.3506\n",
      "Epoch 350/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9582 - accuracy: 0.3037 - val_loss: 1.8585 - val_accuracy: 0.3506\n",
      "Epoch 351/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9674 - accuracy: 0.2988 - val_loss: 1.8582 - val_accuracy: 0.3539\n",
      "Epoch 352/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9510 - accuracy: 0.2891 - val_loss: 1.8579 - val_accuracy: 0.3506\n",
      "Epoch 353/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9726 - accuracy: 0.2686 - val_loss: 1.8577 - val_accuracy: 0.3506\n",
      "Epoch 354/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9484 - accuracy: 0.2877 - val_loss: 1.8561 - val_accuracy: 0.3474\n",
      "Epoch 355/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9809 - accuracy: 0.2751 - val_loss: 1.8544 - val_accuracy: 0.3474\n",
      "Epoch 356/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9939 - accuracy: 0.2695 - val_loss: 1.8524 - val_accuracy: 0.3539\n",
      "Epoch 357/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9397 - accuracy: 0.2821 - val_loss: 1.8506 - val_accuracy: 0.3571\n",
      "Epoch 358/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9535 - accuracy: 0.2975 - val_loss: 1.8487 - val_accuracy: 0.3571\n",
      "Epoch 359/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9550 - accuracy: 0.2861 - val_loss: 1.8468 - val_accuracy: 0.3539\n",
      "Epoch 360/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9286 - accuracy: 0.2959 - val_loss: 1.8452 - val_accuracy: 0.3539\n",
      "Epoch 361/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9754 - accuracy: 0.2737 - val_loss: 1.8439 - val_accuracy: 0.3539\n",
      "Epoch 362/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9472 - accuracy: 0.2930 - val_loss: 1.8429 - val_accuracy: 0.3506\n",
      "Epoch 363/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9797 - accuracy: 0.2822 - val_loss: 1.8422 - val_accuracy: 0.3539\n",
      "Epoch 364/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9927 - accuracy: 0.2696 - val_loss: 1.8425 - val_accuracy: 0.3539\n",
      "Epoch 365/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9455 - accuracy: 0.2877 - val_loss: 1.8420 - val_accuracy: 0.3442\n",
      "Epoch 366/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9382 - accuracy: 0.3047 - val_loss: 1.8423 - val_accuracy: 0.3506\n",
      "Epoch 367/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9277 - accuracy: 0.2877 - val_loss: 1.8427 - val_accuracy: 0.3474\n",
      "Epoch 368/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9952 - accuracy: 0.2961 - val_loss: 1.8434 - val_accuracy: 0.3506\n",
      "Epoch 369/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9678 - accuracy: 0.3073 - val_loss: 1.8433 - val_accuracy: 0.3506\n",
      "Epoch 370/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9726 - accuracy: 0.2849 - val_loss: 1.8433 - val_accuracy: 0.3474\n",
      "Epoch 371/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9246 - accuracy: 0.2812 - val_loss: 1.8429 - val_accuracy: 0.3474\n",
      "Epoch 372/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9261 - accuracy: 0.2919 - val_loss: 1.8427 - val_accuracy: 0.3506\n",
      "Epoch 373/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9329 - accuracy: 0.3212 - val_loss: 1.8423 - val_accuracy: 0.3506\n",
      "Epoch 374/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8883 - accuracy: 0.3142 - val_loss: 1.8417 - val_accuracy: 0.3571\n",
      "Epoch 375/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9271 - accuracy: 0.2822 - val_loss: 1.8421 - val_accuracy: 0.3539\n",
      "Epoch 376/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9685 - accuracy: 0.2773 - val_loss: 1.8424 - val_accuracy: 0.3474\n",
      "Epoch 377/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9721 - accuracy: 0.2695 - val_loss: 1.8417 - val_accuracy: 0.3377\n",
      "Epoch 378/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9083 - accuracy: 0.3008 - val_loss: 1.8408 - val_accuracy: 0.3442\n",
      "Epoch 379/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9955 - accuracy: 0.2490 - val_loss: 1.8402 - val_accuracy: 0.3474\n",
      "Epoch 380/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9398 - accuracy: 0.2910 - val_loss: 1.8398 - val_accuracy: 0.3539\n",
      "Epoch 381/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9353 - accuracy: 0.2598 - val_loss: 1.8387 - val_accuracy: 0.3442\n",
      "Epoch 382/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9358 - accuracy: 0.2849 - val_loss: 1.8369 - val_accuracy: 0.3474\n",
      "Epoch 383/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9614 - accuracy: 0.2988 - val_loss: 1.8341 - val_accuracy: 0.3604\n",
      "Epoch 384/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9227 - accuracy: 0.3125 - val_loss: 1.8326 - val_accuracy: 0.3636\n",
      "Epoch 385/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9161 - accuracy: 0.2947 - val_loss: 1.8311 - val_accuracy: 0.3604\n",
      "Epoch 386/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9448 - accuracy: 0.2919 - val_loss: 1.8293 - val_accuracy: 0.3571\n",
      "Epoch 387/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9263 - accuracy: 0.3128 - val_loss: 1.8270 - val_accuracy: 0.3571\n",
      "Epoch 388/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9316 - accuracy: 0.2919 - val_loss: 1.8235 - val_accuracy: 0.3539\n",
      "Epoch 389/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9325 - accuracy: 0.2765 - val_loss: 1.8206 - val_accuracy: 0.3506\n",
      "Epoch 390/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9410 - accuracy: 0.3003 - val_loss: 1.8192 - val_accuracy: 0.3506\n",
      "Epoch 391/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9161 - accuracy: 0.3115 - val_loss: 1.8181 - val_accuracy: 0.3474\n",
      "Epoch 392/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.9065 - accuracy: 0.3073 - val_loss: 1.8180 - val_accuracy: 0.3442\n",
      "Epoch 393/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9596 - accuracy: 0.2861 - val_loss: 1.8176 - val_accuracy: 0.3474\n",
      "Epoch 394/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9255 - accuracy: 0.3031 - val_loss: 1.8173 - val_accuracy: 0.3442\n",
      "Epoch 395/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8801 - accuracy: 0.3268 - val_loss: 1.8183 - val_accuracy: 0.3474\n",
      "Epoch 396/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9085 - accuracy: 0.2807 - val_loss: 1.8201 - val_accuracy: 0.3474\n",
      "Epoch 397/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9141 - accuracy: 0.3057 - val_loss: 1.8218 - val_accuracy: 0.3442\n",
      "Epoch 398/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8977 - accuracy: 0.3174 - val_loss: 1.8225 - val_accuracy: 0.3442\n",
      "Epoch 399/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8875 - accuracy: 0.3096 - val_loss: 1.8223 - val_accuracy: 0.3377\n",
      "Epoch 400/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9010 - accuracy: 0.2989 - val_loss: 1.8206 - val_accuracy: 0.3377\n",
      "Epoch 401/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9063 - accuracy: 0.3076 - val_loss: 1.8186 - val_accuracy: 0.3377\n",
      "Epoch 402/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9480 - accuracy: 0.3008 - val_loss: 1.8158 - val_accuracy: 0.3344\n",
      "Epoch 403/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9268 - accuracy: 0.2793 - val_loss: 1.8129 - val_accuracy: 0.3377\n",
      "Epoch 404/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8918 - accuracy: 0.3252 - val_loss: 1.8107 - val_accuracy: 0.3344\n",
      "Epoch 405/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9472 - accuracy: 0.2696 - val_loss: 1.8092 - val_accuracy: 0.3312\n",
      "Epoch 406/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8684 - accuracy: 0.3213 - val_loss: 1.8075 - val_accuracy: 0.3344\n",
      "Epoch 407/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9073 - accuracy: 0.2891 - val_loss: 1.8057 - val_accuracy: 0.3344\n",
      "Epoch 408/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8962 - accuracy: 0.2919 - val_loss: 1.8036 - val_accuracy: 0.3409\n",
      "Epoch 409/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9189 - accuracy: 0.3128 - val_loss: 1.8019 - val_accuracy: 0.3409\n",
      "Epoch 410/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8658 - accuracy: 0.3296 - val_loss: 1.8021 - val_accuracy: 0.3442\n",
      "Epoch 411/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9183 - accuracy: 0.3066 - val_loss: 1.8034 - val_accuracy: 0.3442\n",
      "Epoch 412/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8913 - accuracy: 0.3203 - val_loss: 1.8046 - val_accuracy: 0.3442\n",
      "Epoch 413/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8446 - accuracy: 0.3422 - val_loss: 1.8044 - val_accuracy: 0.3409\n",
      "Epoch 414/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9138 - accuracy: 0.3115 - val_loss: 1.8053 - val_accuracy: 0.3474\n",
      "Epoch 415/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8883 - accuracy: 0.3254 - val_loss: 1.8054 - val_accuracy: 0.3506\n",
      "Epoch 416/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8969 - accuracy: 0.3018 - val_loss: 1.8058 - val_accuracy: 0.3539\n",
      "Epoch 417/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8922 - accuracy: 0.3174 - val_loss: 1.8056 - val_accuracy: 0.3571\n",
      "Epoch 418/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9302 - accuracy: 0.2979 - val_loss: 1.8052 - val_accuracy: 0.3571\n",
      "Epoch 419/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9076 - accuracy: 0.3045 - val_loss: 1.8053 - val_accuracy: 0.3604\n",
      "Epoch 420/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8810 - accuracy: 0.3115 - val_loss: 1.8071 - val_accuracy: 0.3474\n",
      "Epoch 421/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8740 - accuracy: 0.3154 - val_loss: 1.8124 - val_accuracy: 0.3409\n",
      "Epoch 422/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8824 - accuracy: 0.3066 - val_loss: 1.8188 - val_accuracy: 0.3312\n",
      "Epoch 423/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8842 - accuracy: 0.3184 - val_loss: 1.8254 - val_accuracy: 0.3409\n",
      "Epoch 424/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8933 - accuracy: 0.3128 - val_loss: 1.8320 - val_accuracy: 0.3442\n",
      "Epoch 425/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8834 - accuracy: 0.2863 - val_loss: 1.8393 - val_accuracy: 0.3377\n",
      "Epoch 426/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8840 - accuracy: 0.3296 - val_loss: 1.8454 - val_accuracy: 0.3409\n",
      "Epoch 427/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8881 - accuracy: 0.2975 - val_loss: 1.8513 - val_accuracy: 0.3377\n",
      "Epoch 428/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8968 - accuracy: 0.3254 - val_loss: 1.8560 - val_accuracy: 0.3344\n",
      "Epoch 429/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8623 - accuracy: 0.3240 - val_loss: 1.8570 - val_accuracy: 0.3344\n",
      "Epoch 430/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8365 - accuracy: 0.3394 - val_loss: 1.8578 - val_accuracy: 0.3344\n",
      "Epoch 431/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8770 - accuracy: 0.3017 - val_loss: 1.8606 - val_accuracy: 0.3442\n",
      "Epoch 432/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8551 - accuracy: 0.3223 - val_loss: 1.8626 - val_accuracy: 0.3409\n",
      "Epoch 433/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9068 - accuracy: 0.2975 - val_loss: 1.8629 - val_accuracy: 0.3377\n",
      "Epoch 434/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8600 - accuracy: 0.2961 - val_loss: 1.8640 - val_accuracy: 0.3442\n",
      "Epoch 435/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8897 - accuracy: 0.3045 - val_loss: 1.8639 - val_accuracy: 0.3409\n",
      "Epoch 436/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8355 - accuracy: 0.3226 - val_loss: 1.8623 - val_accuracy: 0.3506\n",
      "Epoch 437/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8581 - accuracy: 0.3242 - val_loss: 1.8601 - val_accuracy: 0.3506\n",
      "Epoch 438/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8511 - accuracy: 0.3492 - val_loss: 1.8577 - val_accuracy: 0.3506\n",
      "Epoch 439/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8709 - accuracy: 0.3268 - val_loss: 1.8535 - val_accuracy: 0.3539\n",
      "Epoch 440/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8920 - accuracy: 0.3340 - val_loss: 1.8518 - val_accuracy: 0.3571\n",
      "Epoch 441/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8658 - accuracy: 0.3125 - val_loss: 1.8503 - val_accuracy: 0.3474\n",
      "Epoch 442/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8687 - accuracy: 0.3184 - val_loss: 1.8494 - val_accuracy: 0.3442\n",
      "Epoch 443/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8975 - accuracy: 0.3156 - val_loss: 1.8475 - val_accuracy: 0.3442\n",
      "Epoch 444/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8763 - accuracy: 0.3184 - val_loss: 1.8466 - val_accuracy: 0.3442\n",
      "Epoch 445/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8470 - accuracy: 0.3311 - val_loss: 1.8444 - val_accuracy: 0.3409\n",
      "Epoch 446/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8536 - accuracy: 0.3320 - val_loss: 1.8414 - val_accuracy: 0.3409\n",
      "Epoch 447/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8940 - accuracy: 0.3057 - val_loss: 1.8354 - val_accuracy: 0.3377\n",
      "Epoch 448/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8440 - accuracy: 0.3436 - val_loss: 1.8288 - val_accuracy: 0.3474\n",
      "Epoch 449/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9002 - accuracy: 0.3008 - val_loss: 1.8236 - val_accuracy: 0.3506\n",
      "Epoch 450/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7917 - accuracy: 0.3447 - val_loss: 1.8187 - val_accuracy: 0.3539\n",
      "Epoch 451/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8829 - accuracy: 0.3226 - val_loss: 1.8188 - val_accuracy: 0.3604\n",
      "Epoch 452/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8578 - accuracy: 0.3324 - val_loss: 1.8170 - val_accuracy: 0.3636\n",
      "Epoch 453/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8481 - accuracy: 0.3350 - val_loss: 1.8149 - val_accuracy: 0.3604\n",
      "Epoch 454/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8577 - accuracy: 0.3203 - val_loss: 1.8114 - val_accuracy: 0.3604\n",
      "Epoch 455/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8583 - accuracy: 0.3589 - val_loss: 1.8093 - val_accuracy: 0.3669\n",
      "Epoch 456/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8264 - accuracy: 0.3296 - val_loss: 1.8053 - val_accuracy: 0.3604\n",
      "Epoch 457/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8083 - accuracy: 0.3359 - val_loss: 1.8047 - val_accuracy: 0.3636\n",
      "Epoch 458/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8524 - accuracy: 0.3394 - val_loss: 1.8032 - val_accuracy: 0.3604\n",
      "Epoch 459/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8776 - accuracy: 0.3212 - val_loss: 1.8046 - val_accuracy: 0.3604\n",
      "Epoch 460/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8629 - accuracy: 0.3301 - val_loss: 1.8085 - val_accuracy: 0.3604\n",
      "Epoch 461/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8264 - accuracy: 0.3379 - val_loss: 1.8104 - val_accuracy: 0.3571\n",
      "Epoch 462/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8559 - accuracy: 0.3073 - val_loss: 1.8134 - val_accuracy: 0.3604\n",
      "Epoch 463/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8730 - accuracy: 0.3301 - val_loss: 1.8128 - val_accuracy: 0.3669\n",
      "Epoch 464/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8597 - accuracy: 0.3115 - val_loss: 1.8094 - val_accuracy: 0.3734\n",
      "Epoch 465/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8641 - accuracy: 0.3232 - val_loss: 1.8037 - val_accuracy: 0.3701\n",
      "Epoch 466/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8560 - accuracy: 0.3310 - val_loss: 1.7978 - val_accuracy: 0.3734\n",
      "Epoch 467/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8111 - accuracy: 0.3389 - val_loss: 1.7955 - val_accuracy: 0.3734\n",
      "Epoch 468/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8004 - accuracy: 0.3643 - val_loss: 1.7922 - val_accuracy: 0.3734\n",
      "Epoch 469/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8318 - accuracy: 0.3366 - val_loss: 1.7886 - val_accuracy: 0.3734\n",
      "Epoch 470/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8958 - accuracy: 0.3142 - val_loss: 1.7882 - val_accuracy: 0.3799\n",
      "Epoch 471/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8146 - accuracy: 0.3535 - val_loss: 1.7869 - val_accuracy: 0.3766\n",
      "Epoch 472/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8420 - accuracy: 0.3359 - val_loss: 1.7819 - val_accuracy: 0.3831\n",
      "Epoch 473/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8736 - accuracy: 0.3223 - val_loss: 1.7812 - val_accuracy: 0.3831\n",
      "Epoch 474/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8617 - accuracy: 0.3154 - val_loss: 1.7799 - val_accuracy: 0.3896\n",
      "Epoch 475/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8009 - accuracy: 0.3525 - val_loss: 1.7772 - val_accuracy: 0.3864\n",
      "Epoch 476/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7664 - accuracy: 0.3855 - val_loss: 1.7766 - val_accuracy: 0.3831\n",
      "Epoch 477/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8544 - accuracy: 0.3418 - val_loss: 1.7804 - val_accuracy: 0.3831\n",
      "Epoch 478/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8332 - accuracy: 0.3394 - val_loss: 1.7867 - val_accuracy: 0.3734\n",
      "Epoch 479/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8566 - accuracy: 0.3164 - val_loss: 1.7923 - val_accuracy: 0.3669\n",
      "Epoch 480/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7948 - accuracy: 0.3506 - val_loss: 1.7968 - val_accuracy: 0.3669\n",
      "Epoch 481/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8510 - accuracy: 0.3324 - val_loss: 1.7996 - val_accuracy: 0.3636\n",
      "Epoch 482/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8282 - accuracy: 0.3226 - val_loss: 1.7990 - val_accuracy: 0.3539\n",
      "Epoch 483/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8268 - accuracy: 0.3340 - val_loss: 1.7980 - val_accuracy: 0.3506\n",
      "Epoch 484/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8206 - accuracy: 0.3380 - val_loss: 1.7956 - val_accuracy: 0.3539\n",
      "Epoch 485/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8415 - accuracy: 0.3226 - val_loss: 1.7881 - val_accuracy: 0.3506\n",
      "Epoch 486/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8145 - accuracy: 0.3398 - val_loss: 1.7828 - val_accuracy: 0.3539\n",
      "Epoch 487/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8073 - accuracy: 0.3450 - val_loss: 1.7773 - val_accuracy: 0.3539\n",
      "Epoch 488/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8636 - accuracy: 0.3296 - val_loss: 1.7735 - val_accuracy: 0.3604\n",
      "Epoch 489/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8207 - accuracy: 0.3478 - val_loss: 1.7697 - val_accuracy: 0.3701\n",
      "Epoch 490/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7944 - accuracy: 0.3352 - val_loss: 1.7680 - val_accuracy: 0.3734\n",
      "Epoch 491/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8106 - accuracy: 0.3545 - val_loss: 1.7699 - val_accuracy: 0.3636\n",
      "Epoch 492/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7820 - accuracy: 0.3645 - val_loss: 1.7717 - val_accuracy: 0.3636\n",
      "Epoch 493/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7965 - accuracy: 0.3545 - val_loss: 1.7724 - val_accuracy: 0.3669\n",
      "Epoch 494/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8038 - accuracy: 0.3545 - val_loss: 1.7743 - val_accuracy: 0.3604\n",
      "Epoch 495/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8015 - accuracy: 0.3311 - val_loss: 1.7737 - val_accuracy: 0.3669\n",
      "Epoch 496/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8159 - accuracy: 0.3645 - val_loss: 1.7705 - val_accuracy: 0.3701\n",
      "Epoch 497/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7747 - accuracy: 0.3506 - val_loss: 1.7701 - val_accuracy: 0.3701\n",
      "Epoch 498/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7997 - accuracy: 0.3366 - val_loss: 1.7712 - val_accuracy: 0.3766\n",
      "Epoch 499/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8252 - accuracy: 0.3408 - val_loss: 1.7723 - val_accuracy: 0.3766\n",
      "Epoch 500/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7924 - accuracy: 0.3603 - val_loss: 1.7711 - val_accuracy: 0.3701\n",
      "Epoch 501/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7998 - accuracy: 0.3623 - val_loss: 1.7697 - val_accuracy: 0.3701\n",
      "Epoch 502/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7461 - accuracy: 0.3673 - val_loss: 1.7696 - val_accuracy: 0.3766\n",
      "Epoch 503/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8202 - accuracy: 0.3428 - val_loss: 1.7699 - val_accuracy: 0.3799\n",
      "Epoch 504/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7757 - accuracy: 0.3575 - val_loss: 1.7747 - val_accuracy: 0.3799\n",
      "Epoch 505/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7889 - accuracy: 0.3438 - val_loss: 1.7793 - val_accuracy: 0.3929\n",
      "Epoch 506/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8505 - accuracy: 0.3457 - val_loss: 1.7849 - val_accuracy: 0.3929\n",
      "Epoch 507/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7454 - accuracy: 0.3613 - val_loss: 1.7914 - val_accuracy: 0.3864\n",
      "Epoch 508/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7862 - accuracy: 0.3659 - val_loss: 1.7917 - val_accuracy: 0.3766\n",
      "Epoch 509/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7821 - accuracy: 0.3574 - val_loss: 1.7896 - val_accuracy: 0.3799\n",
      "Epoch 510/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7747 - accuracy: 0.3827 - val_loss: 1.7916 - val_accuracy: 0.3831\n",
      "Epoch 511/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7877 - accuracy: 0.3394 - val_loss: 1.7981 - val_accuracy: 0.3831\n",
      "Epoch 512/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7930 - accuracy: 0.3301 - val_loss: 1.7987 - val_accuracy: 0.3864\n",
      "Epoch 513/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7948 - accuracy: 0.3589 - val_loss: 1.7977 - val_accuracy: 0.3799\n",
      "Epoch 514/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7508 - accuracy: 0.3841 - val_loss: 1.7888 - val_accuracy: 0.3799\n",
      "Epoch 515/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8231 - accuracy: 0.3633 - val_loss: 1.7782 - val_accuracy: 0.3799\n",
      "Epoch 516/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7667 - accuracy: 0.3613 - val_loss: 1.7692 - val_accuracy: 0.3864\n",
      "Epoch 517/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7579 - accuracy: 0.3662 - val_loss: 1.7585 - val_accuracy: 0.3929\n",
      "Epoch 518/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7807 - accuracy: 0.3877 - val_loss: 1.7494 - val_accuracy: 0.3994\n",
      "Epoch 519/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8183 - accuracy: 0.3575 - val_loss: 1.7454 - val_accuracy: 0.3961\n",
      "Epoch 520/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7888 - accuracy: 0.3506 - val_loss: 1.7421 - val_accuracy: 0.4026\n",
      "Epoch 521/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7857 - accuracy: 0.3545 - val_loss: 1.7419 - val_accuracy: 0.4058\n",
      "Epoch 522/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7937 - accuracy: 0.3564 - val_loss: 1.7420 - val_accuracy: 0.4058\n",
      "Epoch 523/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7209 - accuracy: 0.3760 - val_loss: 1.7473 - val_accuracy: 0.4058\n",
      "Epoch 524/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7500 - accuracy: 0.3715 - val_loss: 1.7538 - val_accuracy: 0.4026\n",
      "Epoch 525/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7649 - accuracy: 0.3623 - val_loss: 1.7567 - val_accuracy: 0.3929\n",
      "Epoch 526/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7615 - accuracy: 0.3701 - val_loss: 1.7585 - val_accuracy: 0.3961\n",
      "Epoch 527/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7256 - accuracy: 0.3827 - val_loss: 1.7574 - val_accuracy: 0.3896\n",
      "Epoch 528/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7641 - accuracy: 0.3561 - val_loss: 1.7580 - val_accuracy: 0.3896\n",
      "Epoch 529/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8166 - accuracy: 0.3324 - val_loss: 1.7620 - val_accuracy: 0.3831\n",
      "Epoch 530/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7592 - accuracy: 0.3643 - val_loss: 1.7665 - val_accuracy: 0.3896\n",
      "Epoch 531/4000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.7779 - accuracy: 0.3691 - val_loss: 1.7733 - val_accuracy: 0.3929\n",
      "Epoch 532/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7917 - accuracy: 0.3547 - val_loss: 1.7799 - val_accuracy: 0.3766\n",
      "Epoch 533/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7314 - accuracy: 0.3623 - val_loss: 1.7833 - val_accuracy: 0.3734\n",
      "Epoch 534/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7458 - accuracy: 0.3545 - val_loss: 1.7897 - val_accuracy: 0.3701\n",
      "Epoch 535/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7813 - accuracy: 0.3682 - val_loss: 1.7934 - val_accuracy: 0.3571\n",
      "Epoch 536/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7974 - accuracy: 0.3545 - val_loss: 1.7980 - val_accuracy: 0.3571\n",
      "Epoch 537/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7621 - accuracy: 0.3687 - val_loss: 1.7912 - val_accuracy: 0.3539\n",
      "Epoch 538/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7576 - accuracy: 0.3623 - val_loss: 1.7842 - val_accuracy: 0.3571\n",
      "Epoch 539/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7553 - accuracy: 0.3603 - val_loss: 1.7714 - val_accuracy: 0.3604\n",
      "Epoch 540/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7355 - accuracy: 0.3785 - val_loss: 1.7638 - val_accuracy: 0.3571\n",
      "Epoch 541/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7588 - accuracy: 0.3603 - val_loss: 1.7515 - val_accuracy: 0.3669\n",
      "Epoch 542/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7852 - accuracy: 0.3506 - val_loss: 1.7394 - val_accuracy: 0.3701\n",
      "Epoch 543/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7214 - accuracy: 0.3818 - val_loss: 1.7276 - val_accuracy: 0.3701\n",
      "Epoch 544/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7153 - accuracy: 0.3771 - val_loss: 1.7180 - val_accuracy: 0.3734\n",
      "Epoch 545/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7467 - accuracy: 0.3687 - val_loss: 1.7093 - val_accuracy: 0.3766\n",
      "Epoch 546/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7987 - accuracy: 0.3715 - val_loss: 1.7081 - val_accuracy: 0.3864\n",
      "Epoch 547/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7348 - accuracy: 0.3827 - val_loss: 1.7091 - val_accuracy: 0.3896\n",
      "Epoch 548/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7409 - accuracy: 0.3750 - val_loss: 1.7157 - val_accuracy: 0.3864\n",
      "Epoch 549/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7478 - accuracy: 0.3662 - val_loss: 1.7222 - val_accuracy: 0.3929\n",
      "Epoch 550/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7613 - accuracy: 0.3883 - val_loss: 1.7329 - val_accuracy: 0.3831\n",
      "Epoch 551/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7600 - accuracy: 0.3926 - val_loss: 1.7500 - val_accuracy: 0.3669\n",
      "Epoch 552/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7130 - accuracy: 0.3799 - val_loss: 1.7676 - val_accuracy: 0.3636\n",
      "Epoch 553/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7134 - accuracy: 0.3779 - val_loss: 1.7839 - val_accuracy: 0.3506\n",
      "Epoch 554/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7428 - accuracy: 0.3711 - val_loss: 1.7935 - val_accuracy: 0.3442\n",
      "Epoch 555/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7343 - accuracy: 0.3613 - val_loss: 1.7928 - val_accuracy: 0.3506\n",
      "Epoch 556/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7138 - accuracy: 0.3883 - val_loss: 1.7862 - val_accuracy: 0.3539\n",
      "Epoch 557/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7365 - accuracy: 0.3828 - val_loss: 1.7790 - val_accuracy: 0.3669\n",
      "Epoch 558/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7590 - accuracy: 0.3869 - val_loss: 1.7659 - val_accuracy: 0.3701\n",
      "Epoch 559/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7145 - accuracy: 0.3799 - val_loss: 1.7487 - val_accuracy: 0.3766\n",
      "Epoch 560/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7828 - accuracy: 0.3561 - val_loss: 1.7287 - val_accuracy: 0.3766\n",
      "Epoch 561/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7297 - accuracy: 0.3841 - val_loss: 1.7048 - val_accuracy: 0.3994\n",
      "Epoch 562/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7589 - accuracy: 0.3564 - val_loss: 1.6893 - val_accuracy: 0.3961\n",
      "Epoch 563/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6991 - accuracy: 0.4064 - val_loss: 1.6819 - val_accuracy: 0.3961\n",
      "Epoch 564/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7228 - accuracy: 0.3701 - val_loss: 1.6746 - val_accuracy: 0.4026\n",
      "Epoch 565/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.7471 - accuracy: 0.3799 - val_loss: 1.6689 - val_accuracy: 0.4091\n",
      "Epoch 566/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7440 - accuracy: 0.3740 - val_loss: 1.6683 - val_accuracy: 0.4188\n",
      "Epoch 567/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7205 - accuracy: 0.3897 - val_loss: 1.6759 - val_accuracy: 0.4058\n",
      "Epoch 568/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7970 - accuracy: 0.3575 - val_loss: 1.6833 - val_accuracy: 0.3994\n",
      "Epoch 569/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7093 - accuracy: 0.3818 - val_loss: 1.6889 - val_accuracy: 0.3961\n",
      "Epoch 570/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7370 - accuracy: 0.3809 - val_loss: 1.6954 - val_accuracy: 0.3929\n",
      "Epoch 571/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7134 - accuracy: 0.3848 - val_loss: 1.7006 - val_accuracy: 0.3961\n",
      "Epoch 572/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7228 - accuracy: 0.3730 - val_loss: 1.7113 - val_accuracy: 0.3961\n",
      "Epoch 573/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7321 - accuracy: 0.3682 - val_loss: 1.7224 - val_accuracy: 0.3929\n",
      "Epoch 574/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6684 - accuracy: 0.3841 - val_loss: 1.7364 - val_accuracy: 0.3929\n",
      "Epoch 575/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7624 - accuracy: 0.3855 - val_loss: 1.7542 - val_accuracy: 0.3734\n",
      "Epoch 576/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7189 - accuracy: 0.3838 - val_loss: 1.7671 - val_accuracy: 0.3669\n",
      "Epoch 577/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7412 - accuracy: 0.3925 - val_loss: 1.7671 - val_accuracy: 0.3701\n",
      "Epoch 578/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7068 - accuracy: 0.4008 - val_loss: 1.7639 - val_accuracy: 0.3604\n",
      "Epoch 579/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7091 - accuracy: 0.3883 - val_loss: 1.7634 - val_accuracy: 0.3636\n",
      "Epoch 580/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7340 - accuracy: 0.3757 - val_loss: 1.7624 - val_accuracy: 0.3734\n",
      "Epoch 581/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6879 - accuracy: 0.3877 - val_loss: 1.7544 - val_accuracy: 0.3864\n",
      "Epoch 582/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6881 - accuracy: 0.3945 - val_loss: 1.7478 - val_accuracy: 0.3864\n",
      "Epoch 583/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.7315 - accuracy: 0.3789 - val_loss: 1.7498 - val_accuracy: 0.3766\n",
      "Epoch 584/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6798 - accuracy: 0.3682 - val_loss: 1.7493 - val_accuracy: 0.3701\n",
      "Epoch 585/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7261 - accuracy: 0.3799 - val_loss: 1.7448 - val_accuracy: 0.3669\n",
      "Epoch 586/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7184 - accuracy: 0.3799 - val_loss: 1.7394 - val_accuracy: 0.3734\n",
      "Epoch 587/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6941 - accuracy: 0.3911 - val_loss: 1.7376 - val_accuracy: 0.3864\n",
      "Epoch 588/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7525 - accuracy: 0.4050 - val_loss: 1.7329 - val_accuracy: 0.3994\n",
      "Epoch 589/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7219 - accuracy: 0.3799 - val_loss: 1.7374 - val_accuracy: 0.3961\n",
      "Epoch 590/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7002 - accuracy: 0.3799 - val_loss: 1.7442 - val_accuracy: 0.3929\n",
      "Epoch 591/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7481 - accuracy: 0.3939 - val_loss: 1.7491 - val_accuracy: 0.3929\n",
      "Epoch 592/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7025 - accuracy: 0.3955 - val_loss: 1.7480 - val_accuracy: 0.3896\n",
      "Epoch 593/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6981 - accuracy: 0.3965 - val_loss: 1.7434 - val_accuracy: 0.3994\n",
      "Epoch 594/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6890 - accuracy: 0.3715 - val_loss: 1.7278 - val_accuracy: 0.4123\n",
      "Epoch 595/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6764 - accuracy: 0.3848 - val_loss: 1.7149 - val_accuracy: 0.4351\n",
      "Epoch 596/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6944 - accuracy: 0.3984 - val_loss: 1.7054 - val_accuracy: 0.4383\n",
      "Epoch 597/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7222 - accuracy: 0.3855 - val_loss: 1.7011 - val_accuracy: 0.4448\n",
      "Epoch 598/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6766 - accuracy: 0.4008 - val_loss: 1.6940 - val_accuracy: 0.4318\n",
      "Epoch 599/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6734 - accuracy: 0.3925 - val_loss: 1.6840 - val_accuracy: 0.4156\n",
      "Epoch 600/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6755 - accuracy: 0.4014 - val_loss: 1.6777 - val_accuracy: 0.4156\n",
      "Epoch 601/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6798 - accuracy: 0.4053 - val_loss: 1.6746 - val_accuracy: 0.4221\n",
      "Epoch 602/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6707 - accuracy: 0.3994 - val_loss: 1.6743 - val_accuracy: 0.4123\n",
      "Epoch 603/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6608 - accuracy: 0.3715 - val_loss: 1.6758 - val_accuracy: 0.4123\n",
      "Epoch 604/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6829 - accuracy: 0.4092 - val_loss: 1.6696 - val_accuracy: 0.4156\n",
      "Epoch 605/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6842 - accuracy: 0.3740 - val_loss: 1.6661 - val_accuracy: 0.4156\n",
      "Epoch 606/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7011 - accuracy: 0.3785 - val_loss: 1.6641 - val_accuracy: 0.4156\n",
      "Epoch 607/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7208 - accuracy: 0.3994 - val_loss: 1.6600 - val_accuracy: 0.4156\n",
      "Epoch 608/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6888 - accuracy: 0.3939 - val_loss: 1.6521 - val_accuracy: 0.4188\n",
      "Epoch 609/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6762 - accuracy: 0.3955 - val_loss: 1.6456 - val_accuracy: 0.4156\n",
      "Epoch 610/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6581 - accuracy: 0.3771 - val_loss: 1.6384 - val_accuracy: 0.4123\n",
      "Epoch 611/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7205 - accuracy: 0.3869 - val_loss: 1.6354 - val_accuracy: 0.4156\n",
      "Epoch 612/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6656 - accuracy: 0.3925 - val_loss: 1.6401 - val_accuracy: 0.4123\n",
      "Epoch 613/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6885 - accuracy: 0.3855 - val_loss: 1.6445 - val_accuracy: 0.4058\n",
      "Epoch 614/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6498 - accuracy: 0.4131 - val_loss: 1.6476 - val_accuracy: 0.4058\n",
      "Epoch 615/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6637 - accuracy: 0.4092 - val_loss: 1.6487 - val_accuracy: 0.4156\n",
      "Epoch 616/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6697 - accuracy: 0.3975 - val_loss: 1.6455 - val_accuracy: 0.4123\n",
      "Epoch 617/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6582 - accuracy: 0.3945 - val_loss: 1.6469 - val_accuracy: 0.4091\n",
      "Epoch 618/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6783 - accuracy: 0.3729 - val_loss: 1.6429 - val_accuracy: 0.4091\n",
      "Epoch 619/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6634 - accuracy: 0.4082 - val_loss: 1.6411 - val_accuracy: 0.4091\n",
      "Epoch 620/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6352 - accuracy: 0.4268 - val_loss: 1.6461 - val_accuracy: 0.4058\n",
      "Epoch 621/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6208 - accuracy: 0.4274 - val_loss: 1.6506 - val_accuracy: 0.4026\n",
      "Epoch 622/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6067 - accuracy: 0.4248 - val_loss: 1.6506 - val_accuracy: 0.3961\n",
      "Epoch 623/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6125 - accuracy: 0.4148 - val_loss: 1.6433 - val_accuracy: 0.4026\n",
      "Epoch 624/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6824 - accuracy: 0.3785 - val_loss: 1.6374 - val_accuracy: 0.4058\n",
      "Epoch 625/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6609 - accuracy: 0.3953 - val_loss: 1.6378 - val_accuracy: 0.4091\n",
      "Epoch 626/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6794 - accuracy: 0.3911 - val_loss: 1.6330 - val_accuracy: 0.4156\n",
      "Epoch 627/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6312 - accuracy: 0.4218 - val_loss: 1.6296 - val_accuracy: 0.4286\n",
      "Epoch 628/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6682 - accuracy: 0.3926 - val_loss: 1.6319 - val_accuracy: 0.4286\n",
      "Epoch 629/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6551 - accuracy: 0.4053 - val_loss: 1.6304 - val_accuracy: 0.4286\n",
      "Epoch 630/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6635 - accuracy: 0.4062 - val_loss: 1.6291 - val_accuracy: 0.4318\n",
      "Epoch 631/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6157 - accuracy: 0.4358 - val_loss: 1.6192 - val_accuracy: 0.4286\n",
      "Epoch 632/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6572 - accuracy: 0.4150 - val_loss: 1.6079 - val_accuracy: 0.4253\n",
      "Epoch 633/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6116 - accuracy: 0.3841 - val_loss: 1.6030 - val_accuracy: 0.4188\n",
      "Epoch 634/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6371 - accuracy: 0.4092 - val_loss: 1.6054 - val_accuracy: 0.4123\n",
      "Epoch 635/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6415 - accuracy: 0.4180 - val_loss: 1.6094 - val_accuracy: 0.4123\n",
      "Epoch 636/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5665 - accuracy: 0.4623 - val_loss: 1.6132 - val_accuracy: 0.4123\n",
      "Epoch 637/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6309 - accuracy: 0.4092 - val_loss: 1.6168 - val_accuracy: 0.4156\n",
      "Epoch 638/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6288 - accuracy: 0.3966 - val_loss: 1.6328 - val_accuracy: 0.4026\n",
      "Epoch 639/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6444 - accuracy: 0.3966 - val_loss: 1.6602 - val_accuracy: 0.3961\n",
      "Epoch 640/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6324 - accuracy: 0.4326 - val_loss: 1.6767 - val_accuracy: 0.3864\n",
      "Epoch 641/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6478 - accuracy: 0.4092 - val_loss: 1.6879 - val_accuracy: 0.3799\n",
      "Epoch 642/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5976 - accuracy: 0.4404 - val_loss: 1.6852 - val_accuracy: 0.3734\n",
      "Epoch 643/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6436 - accuracy: 0.4078 - val_loss: 1.6834 - val_accuracy: 0.3799\n",
      "Epoch 644/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5841 - accuracy: 0.4413 - val_loss: 1.6736 - val_accuracy: 0.3864\n",
      "Epoch 645/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5913 - accuracy: 0.4375 - val_loss: 1.6684 - val_accuracy: 0.3929\n",
      "Epoch 646/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6228 - accuracy: 0.4302 - val_loss: 1.6474 - val_accuracy: 0.3994\n",
      "Epoch 647/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6160 - accuracy: 0.4232 - val_loss: 1.6307 - val_accuracy: 0.4123\n",
      "Epoch 648/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6200 - accuracy: 0.4160 - val_loss: 1.6227 - val_accuracy: 0.4058\n",
      "Epoch 649/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.6305 - accuracy: 0.4204 - val_loss: 1.6278 - val_accuracy: 0.4026\n",
      "Epoch 650/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6452 - accuracy: 0.4062 - val_loss: 1.6333 - val_accuracy: 0.3994\n",
      "Epoch 651/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.5975 - accuracy: 0.4287 - val_loss: 1.6406 - val_accuracy: 0.4026\n",
      "Epoch 652/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6645 - accuracy: 0.3994 - val_loss: 1.6591 - val_accuracy: 0.4026\n",
      "Epoch 653/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6095 - accuracy: 0.4344 - val_loss: 1.6669 - val_accuracy: 0.3994\n",
      "Epoch 654/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6142 - accuracy: 0.4365 - val_loss: 1.6786 - val_accuracy: 0.3994\n",
      "Epoch 655/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6085 - accuracy: 0.4219 - val_loss: 1.7038 - val_accuracy: 0.3864\n",
      "Epoch 656/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5762 - accuracy: 0.4344 - val_loss: 1.7316 - val_accuracy: 0.3766\n",
      "Epoch 657/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6403 - accuracy: 0.3980 - val_loss: 1.7588 - val_accuracy: 0.3636\n",
      "Epoch 658/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6134 - accuracy: 0.4344 - val_loss: 1.7753 - val_accuracy: 0.3539\n",
      "Epoch 659/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5713 - accuracy: 0.4453 - val_loss: 1.7847 - val_accuracy: 0.3474\n",
      "Epoch 660/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6416 - accuracy: 0.4180 - val_loss: 1.7659 - val_accuracy: 0.3539\n",
      "Epoch 661/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6087 - accuracy: 0.4160 - val_loss: 1.7423 - val_accuracy: 0.3571\n",
      "Epoch 662/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6524 - accuracy: 0.4043 - val_loss: 1.7128 - val_accuracy: 0.3636\n",
      "Epoch 663/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5952 - accuracy: 0.4469 - val_loss: 1.6996 - val_accuracy: 0.3701\n",
      "Epoch 664/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6128 - accuracy: 0.4260 - val_loss: 1.6917 - val_accuracy: 0.3864\n",
      "Epoch 665/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5972 - accuracy: 0.4258 - val_loss: 1.6817 - val_accuracy: 0.3929\n",
      "Epoch 666/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6267 - accuracy: 0.4248 - val_loss: 1.6825 - val_accuracy: 0.3961\n",
      "Epoch 667/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6041 - accuracy: 0.4316 - val_loss: 1.7037 - val_accuracy: 0.3961\n",
      "Epoch 668/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5960 - accuracy: 0.4229 - val_loss: 1.7212 - val_accuracy: 0.3896\n",
      "Epoch 669/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5946 - accuracy: 0.4326 - val_loss: 1.7393 - val_accuracy: 0.3831\n",
      "Epoch 670/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5285 - accuracy: 0.4707 - val_loss: 1.7748 - val_accuracy: 0.3734\n",
      "Epoch 671/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6249 - accuracy: 0.4277 - val_loss: 1.8000 - val_accuracy: 0.3799\n",
      "Epoch 672/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6198 - accuracy: 0.4078 - val_loss: 1.8248 - val_accuracy: 0.3539\n",
      "Epoch 673/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5998 - accuracy: 0.4473 - val_loss: 1.8460 - val_accuracy: 0.3636\n",
      "Epoch 674/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5328 - accuracy: 0.4525 - val_loss: 1.8757 - val_accuracy: 0.3539\n",
      "Epoch 675/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5719 - accuracy: 0.4246 - val_loss: 1.9096 - val_accuracy: 0.3506\n",
      "Epoch 676/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5857 - accuracy: 0.4365 - val_loss: 1.9202 - val_accuracy: 0.3474\n",
      "Epoch 677/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5858 - accuracy: 0.4346 - val_loss: 1.9217 - val_accuracy: 0.3442\n",
      "Epoch 678/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6060 - accuracy: 0.4189 - val_loss: 1.9186 - val_accuracy: 0.3506\n",
      "Epoch 679/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5820 - accuracy: 0.4395 - val_loss: 1.9027 - val_accuracy: 0.3669\n",
      "Epoch 680/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5858 - accuracy: 0.4297 - val_loss: 1.8687 - val_accuracy: 0.3669\n",
      "Epoch 681/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6138 - accuracy: 0.4246 - val_loss: 1.8310 - val_accuracy: 0.3766\n",
      "Epoch 682/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5906 - accuracy: 0.4274 - val_loss: 1.8187 - val_accuracy: 0.3734\n",
      "Epoch 683/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5511 - accuracy: 0.4482 - val_loss: 1.7984 - val_accuracy: 0.3799\n",
      "Epoch 684/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5453 - accuracy: 0.4805 - val_loss: 1.7833 - val_accuracy: 0.3831\n",
      "Epoch 685/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5992 - accuracy: 0.4372 - val_loss: 1.7586 - val_accuracy: 0.3961\n",
      "Epoch 686/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5111 - accuracy: 0.4679 - val_loss: 1.7241 - val_accuracy: 0.4188\n",
      "Epoch 687/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5403 - accuracy: 0.4497 - val_loss: 1.7022 - val_accuracy: 0.4221\n",
      "Epoch 688/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5863 - accuracy: 0.4434 - val_loss: 1.6880 - val_accuracy: 0.4253\n",
      "Epoch 689/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5563 - accuracy: 0.4463 - val_loss: 1.6771 - val_accuracy: 0.4221\n",
      "Epoch 690/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6243 - accuracy: 0.4473 - val_loss: 1.6693 - val_accuracy: 0.4253\n",
      "Epoch 691/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6311 - accuracy: 0.4258 - val_loss: 1.6727 - val_accuracy: 0.4188\n",
      "Epoch 692/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5840 - accuracy: 0.4473 - val_loss: 1.6878 - val_accuracy: 0.4156\n",
      "Epoch 693/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6189 - accuracy: 0.4148 - val_loss: 1.6820 - val_accuracy: 0.4091\n",
      "Epoch 694/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5941 - accuracy: 0.4268 - val_loss: 1.6657 - val_accuracy: 0.4026\n",
      "Epoch 695/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5959 - accuracy: 0.4204 - val_loss: 1.6644 - val_accuracy: 0.4091\n",
      "Epoch 696/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.5733 - accuracy: 0.4385 - val_loss: 1.6632 - val_accuracy: 0.4026\n",
      "Epoch 697/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5681 - accuracy: 0.4623 - val_loss: 1.6741 - val_accuracy: 0.4058\n",
      "Epoch 698/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5561 - accuracy: 0.4455 - val_loss: 1.6878 - val_accuracy: 0.4058\n",
      "Epoch 699/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5873 - accuracy: 0.4232 - val_loss: 1.6955 - val_accuracy: 0.4058\n",
      "Epoch 700/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5446 - accuracy: 0.4511 - val_loss: 1.7057 - val_accuracy: 0.4123\n",
      "Epoch 701/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5872 - accuracy: 0.4229 - val_loss: 1.7195 - val_accuracy: 0.4156\n",
      "Epoch 702/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5166 - accuracy: 0.4648 - val_loss: 1.7370 - val_accuracy: 0.4058\n",
      "Epoch 703/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5653 - accuracy: 0.4502 - val_loss: 1.7330 - val_accuracy: 0.4091\n",
      "Epoch 704/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5344 - accuracy: 0.4721 - val_loss: 1.7153 - val_accuracy: 0.4026\n",
      "Epoch 705/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5869 - accuracy: 0.4427 - val_loss: 1.6833 - val_accuracy: 0.4091\n",
      "Epoch 706/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5709 - accuracy: 0.4427 - val_loss: 1.6447 - val_accuracy: 0.4318\n",
      "Epoch 707/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5777 - accuracy: 0.4232 - val_loss: 1.6179 - val_accuracy: 0.4416\n",
      "Epoch 708/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5407 - accuracy: 0.4473 - val_loss: 1.6053 - val_accuracy: 0.4253\n",
      "Epoch 709/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4912 - accuracy: 0.4916 - val_loss: 1.6027 - val_accuracy: 0.4253\n",
      "Epoch 710/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5456 - accuracy: 0.4441 - val_loss: 1.6127 - val_accuracy: 0.4318\n",
      "Epoch 711/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5115 - accuracy: 0.4609 - val_loss: 1.6349 - val_accuracy: 0.4221\n",
      "Epoch 712/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5735 - accuracy: 0.4372 - val_loss: 1.6648 - val_accuracy: 0.4286\n",
      "Epoch 713/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5834 - accuracy: 0.4427 - val_loss: 1.6863 - val_accuracy: 0.4286\n",
      "Epoch 714/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5099 - accuracy: 0.4511 - val_loss: 1.6976 - val_accuracy: 0.4253\n",
      "Epoch 715/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5118 - accuracy: 0.4483 - val_loss: 1.7049 - val_accuracy: 0.4286\n",
      "Epoch 716/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5498 - accuracy: 0.4385 - val_loss: 1.7359 - val_accuracy: 0.4188\n",
      "Epoch 717/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5733 - accuracy: 0.4531 - val_loss: 1.7627 - val_accuracy: 0.4253\n",
      "Epoch 718/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6073 - accuracy: 0.4455 - val_loss: 1.7659 - val_accuracy: 0.4156\n",
      "Epoch 719/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5623 - accuracy: 0.4512 - val_loss: 1.7584 - val_accuracy: 0.4091\n",
      "Epoch 720/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5585 - accuracy: 0.4497 - val_loss: 1.7295 - val_accuracy: 0.4091\n",
      "Epoch 721/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5287 - accuracy: 0.4648 - val_loss: 1.7050 - val_accuracy: 0.4123\n",
      "Epoch 722/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5233 - accuracy: 0.4539 - val_loss: 1.6762 - val_accuracy: 0.4286\n",
      "Epoch 723/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5720 - accuracy: 0.4570 - val_loss: 1.6618 - val_accuracy: 0.4351\n",
      "Epoch 724/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.5398 - accuracy: 0.4385 - val_loss: 1.6425 - val_accuracy: 0.4286\n",
      "Epoch 725/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5238 - accuracy: 0.4735 - val_loss: 1.6348 - val_accuracy: 0.4383\n",
      "Epoch 726/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5358 - accuracy: 0.4346 - val_loss: 1.6219 - val_accuracy: 0.4286\n",
      "Epoch 727/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5477 - accuracy: 0.4375 - val_loss: 1.6230 - val_accuracy: 0.4253\n",
      "Epoch 728/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5539 - accuracy: 0.4609 - val_loss: 1.6520 - val_accuracy: 0.4286\n",
      "Epoch 729/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5495 - accuracy: 0.4443 - val_loss: 1.6880 - val_accuracy: 0.4253\n",
      "Epoch 730/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5704 - accuracy: 0.4512 - val_loss: 1.7378 - val_accuracy: 0.4091\n",
      "Epoch 731/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5436 - accuracy: 0.4372 - val_loss: 1.7719 - val_accuracy: 0.3929\n",
      "Epoch 732/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5033 - accuracy: 0.4832 - val_loss: 1.8041 - val_accuracy: 0.3896\n",
      "Epoch 733/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4818 - accuracy: 0.4688 - val_loss: 1.8246 - val_accuracy: 0.3896\n",
      "Epoch 734/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5168 - accuracy: 0.4665 - val_loss: 1.8390 - val_accuracy: 0.3929\n",
      "Epoch 735/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4832 - accuracy: 0.4832 - val_loss: 1.8350 - val_accuracy: 0.3864\n",
      "Epoch 736/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5548 - accuracy: 0.4629 - val_loss: 1.8167 - val_accuracy: 0.3864\n",
      "Epoch 737/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5146 - accuracy: 0.4567 - val_loss: 1.7861 - val_accuracy: 0.4058\n",
      "Epoch 738/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5058 - accuracy: 0.4629 - val_loss: 1.7575 - val_accuracy: 0.4221\n",
      "Epoch 739/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5439 - accuracy: 0.4629 - val_loss: 1.7356 - val_accuracy: 0.4286\n",
      "Epoch 740/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5140 - accuracy: 0.4665 - val_loss: 1.7176 - val_accuracy: 0.4253\n",
      "Epoch 741/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5434 - accuracy: 0.4385 - val_loss: 1.6918 - val_accuracy: 0.4318\n",
      "Epoch 742/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5144 - accuracy: 0.4561 - val_loss: 1.6837 - val_accuracy: 0.4416\n",
      "Epoch 743/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5436 - accuracy: 0.4424 - val_loss: 1.6720 - val_accuracy: 0.4416\n",
      "Epoch 744/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4480 - accuracy: 0.4863 - val_loss: 1.6591 - val_accuracy: 0.4578\n",
      "Epoch 745/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4985 - accuracy: 0.4658 - val_loss: 1.6400 - val_accuracy: 0.4740\n",
      "Epoch 746/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4812 - accuracy: 0.4930 - val_loss: 1.6397 - val_accuracy: 0.4740\n",
      "Epoch 747/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4869 - accuracy: 0.4777 - val_loss: 1.6422 - val_accuracy: 0.4643\n",
      "Epoch 748/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5227 - accuracy: 0.4619 - val_loss: 1.6581 - val_accuracy: 0.4643\n",
      "Epoch 749/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5058 - accuracy: 0.4883 - val_loss: 1.6809 - val_accuracy: 0.4481\n",
      "Epoch 750/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4914 - accuracy: 0.4637 - val_loss: 1.7199 - val_accuracy: 0.4513\n",
      "Epoch 751/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4260 - accuracy: 0.4893 - val_loss: 1.7274 - val_accuracy: 0.4513\n",
      "Epoch 752/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5018 - accuracy: 0.4749 - val_loss: 1.7418 - val_accuracy: 0.4513\n",
      "Epoch 753/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5324 - accuracy: 0.4580 - val_loss: 1.7508 - val_accuracy: 0.4416\n",
      "Epoch 754/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4748 - accuracy: 0.4986 - val_loss: 1.7667 - val_accuracy: 0.4286\n",
      "Epoch 755/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4889 - accuracy: 0.4531 - val_loss: 1.8024 - val_accuracy: 0.4123\n",
      "Epoch 756/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4378 - accuracy: 0.4818 - val_loss: 1.8136 - val_accuracy: 0.4058\n",
      "Epoch 757/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5222 - accuracy: 0.4749 - val_loss: 1.8019 - val_accuracy: 0.4026\n",
      "Epoch 758/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4883 - accuracy: 0.4561 - val_loss: 1.7842 - val_accuracy: 0.4123\n",
      "Epoch 759/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4126 - accuracy: 0.5084 - val_loss: 1.7697 - val_accuracy: 0.4253\n",
      "Epoch 760/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5006 - accuracy: 0.4763 - val_loss: 1.7495 - val_accuracy: 0.4221\n",
      "Epoch 761/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4827 - accuracy: 0.4777 - val_loss: 1.7587 - val_accuracy: 0.4156\n",
      "Epoch 762/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5156 - accuracy: 0.4619 - val_loss: 1.7641 - val_accuracy: 0.4188\n",
      "Epoch 763/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5076 - accuracy: 0.4854 - val_loss: 1.7513 - val_accuracy: 0.4156\n",
      "Epoch 764/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5051 - accuracy: 0.4902 - val_loss: 1.7357 - val_accuracy: 0.4253\n",
      "Epoch 765/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5127 - accuracy: 0.4648 - val_loss: 1.7012 - val_accuracy: 0.4351\n",
      "Epoch 766/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4729 - accuracy: 0.4893 - val_loss: 1.6586 - val_accuracy: 0.4578\n",
      "Epoch 767/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5038 - accuracy: 0.4541 - val_loss: 1.6225 - val_accuracy: 0.4610\n",
      "Epoch 768/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4828 - accuracy: 0.4551 - val_loss: 1.6023 - val_accuracy: 0.4675\n",
      "Epoch 769/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5376 - accuracy: 0.4570 - val_loss: 1.6138 - val_accuracy: 0.4675\n",
      "Epoch 770/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5237 - accuracy: 0.4581 - val_loss: 1.6395 - val_accuracy: 0.4578\n",
      "Epoch 771/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4244 - accuracy: 0.4980 - val_loss: 1.6819 - val_accuracy: 0.4513\n",
      "Epoch 772/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4494 - accuracy: 0.5029 - val_loss: 1.7164 - val_accuracy: 0.4448\n",
      "Epoch 773/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4398 - accuracy: 0.5049 - val_loss: 1.7336 - val_accuracy: 0.4481\n",
      "Epoch 774/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4663 - accuracy: 0.4971 - val_loss: 1.7239 - val_accuracy: 0.4481\n",
      "Epoch 775/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4581 - accuracy: 0.4912 - val_loss: 1.6973 - val_accuracy: 0.4545\n",
      "Epoch 776/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4970 - accuracy: 0.4763 - val_loss: 1.6658 - val_accuracy: 0.4513\n",
      "Epoch 777/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4716 - accuracy: 0.4749 - val_loss: 1.6285 - val_accuracy: 0.4481\n",
      "Epoch 778/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4713 - accuracy: 0.4581 - val_loss: 1.6019 - val_accuracy: 0.4708\n",
      "Epoch 779/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4712 - accuracy: 0.4805 - val_loss: 1.5725 - val_accuracy: 0.4805\n",
      "Epoch 780/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4604 - accuracy: 0.4912 - val_loss: 1.5799 - val_accuracy: 0.4708\n",
      "Epoch 781/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4386 - accuracy: 0.5000 - val_loss: 1.5996 - val_accuracy: 0.4610\n",
      "Epoch 782/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4999 - accuracy: 0.4521 - val_loss: 1.6234 - val_accuracy: 0.4513\n",
      "Epoch 783/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4763 - accuracy: 0.4846 - val_loss: 1.6433 - val_accuracy: 0.4481\n",
      "Epoch 784/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4370 - accuracy: 0.4844 - val_loss: 1.6817 - val_accuracy: 0.4416\n",
      "Epoch 785/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4838 - accuracy: 0.4814 - val_loss: 1.6983 - val_accuracy: 0.4221\n",
      "Epoch 786/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4875 - accuracy: 0.4648 - val_loss: 1.7065 - val_accuracy: 0.4188\n",
      "Epoch 787/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4166 - accuracy: 0.5195 - val_loss: 1.7167 - val_accuracy: 0.4188\n",
      "Epoch 788/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4795 - accuracy: 0.5056 - val_loss: 1.7298 - val_accuracy: 0.4253\n",
      "Epoch 789/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4437 - accuracy: 0.5000 - val_loss: 1.7600 - val_accuracy: 0.3994\n",
      "Epoch 790/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4772 - accuracy: 0.4600 - val_loss: 1.7997 - val_accuracy: 0.3864\n",
      "Epoch 791/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4200 - accuracy: 0.5070 - val_loss: 1.8403 - val_accuracy: 0.3734\n",
      "Epoch 792/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4505 - accuracy: 0.5020 - val_loss: 1.8690 - val_accuracy: 0.3636\n",
      "Epoch 793/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4551 - accuracy: 0.4958 - val_loss: 1.8537 - val_accuracy: 0.3734\n",
      "Epoch 794/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4530 - accuracy: 0.4922 - val_loss: 1.8092 - val_accuracy: 0.3864\n",
      "Epoch 795/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4218 - accuracy: 0.4961 - val_loss: 1.7451 - val_accuracy: 0.3961\n",
      "Epoch 796/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4171 - accuracy: 0.5000 - val_loss: 1.6662 - val_accuracy: 0.4481\n",
      "Epoch 797/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4841 - accuracy: 0.4860 - val_loss: 1.5957 - val_accuracy: 0.4578\n",
      "Epoch 798/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4419 - accuracy: 0.4971 - val_loss: 1.5350 - val_accuracy: 0.4773\n",
      "Epoch 799/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5279 - accuracy: 0.4791 - val_loss: 1.5053 - val_accuracy: 0.4903\n",
      "Epoch 800/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3891 - accuracy: 0.5127 - val_loss: 1.5096 - val_accuracy: 0.4805\n",
      "Epoch 801/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4008 - accuracy: 0.5196 - val_loss: 1.5345 - val_accuracy: 0.4740\n",
      "Epoch 802/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4908 - accuracy: 0.4912 - val_loss: 1.5697 - val_accuracy: 0.4610\n",
      "Epoch 803/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4793 - accuracy: 0.4902 - val_loss: 1.6084 - val_accuracy: 0.4513\n",
      "Epoch 804/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4159 - accuracy: 0.5014 - val_loss: 1.6332 - val_accuracy: 0.4481\n",
      "Epoch 805/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4300 - accuracy: 0.5056 - val_loss: 1.6493 - val_accuracy: 0.4513\n",
      "Epoch 806/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4428 - accuracy: 0.5117 - val_loss: 1.6644 - val_accuracy: 0.4351\n",
      "Epoch 807/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4198 - accuracy: 0.5168 - val_loss: 1.6511 - val_accuracy: 0.4448\n",
      "Epoch 808/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4233 - accuracy: 0.5078 - val_loss: 1.6395 - val_accuracy: 0.4740\n",
      "Epoch 809/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4610 - accuracy: 0.4932 - val_loss: 1.6328 - val_accuracy: 0.4708\n",
      "Epoch 810/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3646 - accuracy: 0.5265 - val_loss: 1.6317 - val_accuracy: 0.4708\n",
      "Epoch 811/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5046 - accuracy: 0.4756 - val_loss: 1.6441 - val_accuracy: 0.4675\n",
      "Epoch 812/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3783 - accuracy: 0.5205 - val_loss: 1.6438 - val_accuracy: 0.4740\n",
      "Epoch 813/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4211 - accuracy: 0.4986 - val_loss: 1.6663 - val_accuracy: 0.4708\n",
      "Epoch 814/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4284 - accuracy: 0.4707 - val_loss: 1.6786 - val_accuracy: 0.4773\n",
      "Epoch 815/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4586 - accuracy: 0.5014 - val_loss: 1.6835 - val_accuracy: 0.4675\n",
      "Epoch 816/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3773 - accuracy: 0.5000 - val_loss: 1.6734 - val_accuracy: 0.4675\n",
      "Epoch 817/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4373 - accuracy: 0.5010 - val_loss: 1.6915 - val_accuracy: 0.4578\n",
      "Epoch 818/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3527 - accuracy: 0.5244 - val_loss: 1.6629 - val_accuracy: 0.4610\n",
      "Epoch 819/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4532 - accuracy: 0.4736 - val_loss: 1.6324 - val_accuracy: 0.4675\n",
      "Epoch 820/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4458 - accuracy: 0.4775 - val_loss: 1.5807 - val_accuracy: 0.5000\n",
      "Epoch 821/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3821 - accuracy: 0.5084 - val_loss: 1.5442 - val_accuracy: 0.5065\n",
      "Epoch 822/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4027 - accuracy: 0.5215 - val_loss: 1.5180 - val_accuracy: 0.5065\n",
      "Epoch 823/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4147 - accuracy: 0.5117 - val_loss: 1.5108 - val_accuracy: 0.5097\n",
      "Epoch 824/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4128 - accuracy: 0.5215 - val_loss: 1.4865 - val_accuracy: 0.5097\n",
      "Epoch 825/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4097 - accuracy: 0.5168 - val_loss: 1.4634 - val_accuracy: 0.5065\n",
      "Epoch 826/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3858 - accuracy: 0.5059 - val_loss: 1.4573 - val_accuracy: 0.5097\n",
      "Epoch 827/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4263 - accuracy: 0.5039 - val_loss: 1.4654 - val_accuracy: 0.5000\n",
      "Epoch 828/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4518 - accuracy: 0.5112 - val_loss: 1.4920 - val_accuracy: 0.4968\n",
      "Epoch 829/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3736 - accuracy: 0.5205 - val_loss: 1.5204 - val_accuracy: 0.4805\n",
      "Epoch 830/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3801 - accuracy: 0.5154 - val_loss: 1.5425 - val_accuracy: 0.4740\n",
      "Epoch 831/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4409 - accuracy: 0.4888 - val_loss: 1.5773 - val_accuracy: 0.4578\n",
      "Epoch 832/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4313 - accuracy: 0.5020 - val_loss: 1.5919 - val_accuracy: 0.4643\n",
      "Epoch 833/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3570 - accuracy: 0.5117 - val_loss: 1.6133 - val_accuracy: 0.4545\n",
      "Epoch 834/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4642 - accuracy: 0.4824 - val_loss: 1.6446 - val_accuracy: 0.4513\n",
      "Epoch 835/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4592 - accuracy: 0.4972 - val_loss: 1.6875 - val_accuracy: 0.4351\n",
      "Epoch 836/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4106 - accuracy: 0.5042 - val_loss: 1.7135 - val_accuracy: 0.4351\n",
      "Epoch 837/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4167 - accuracy: 0.5088 - val_loss: 1.7175 - val_accuracy: 0.4318\n",
      "Epoch 838/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4241 - accuracy: 0.5029 - val_loss: 1.7105 - val_accuracy: 0.4351\n",
      "Epoch 839/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3715 - accuracy: 0.5176 - val_loss: 1.6894 - val_accuracy: 0.4383\n",
      "Epoch 840/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3994 - accuracy: 0.5127 - val_loss: 1.6540 - val_accuracy: 0.4416\n",
      "Epoch 841/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3995 - accuracy: 0.5112 - val_loss: 1.6073 - val_accuracy: 0.4578\n",
      "Epoch 842/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4275 - accuracy: 0.4902 - val_loss: 1.5738 - val_accuracy: 0.4773\n",
      "Epoch 843/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4395 - accuracy: 0.5088 - val_loss: 1.5593 - val_accuracy: 0.4935\n",
      "Epoch 844/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4444 - accuracy: 0.4902 - val_loss: 1.5699 - val_accuracy: 0.4968\n",
      "Epoch 845/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.3818 - accuracy: 0.5137 - val_loss: 1.5729 - val_accuracy: 0.5000\n",
      "Epoch 846/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3768 - accuracy: 0.5209 - val_loss: 1.5924 - val_accuracy: 0.4968\n",
      "Epoch 847/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3845 - accuracy: 0.5098 - val_loss: 1.6226 - val_accuracy: 0.4903\n",
      "Epoch 848/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3693 - accuracy: 0.5223 - val_loss: 1.6651 - val_accuracy: 0.4643\n",
      "Epoch 849/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4593 - accuracy: 0.4688 - val_loss: 1.6818 - val_accuracy: 0.4513\n",
      "Epoch 850/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3737 - accuracy: 0.5251 - val_loss: 1.6788 - val_accuracy: 0.4578\n",
      "Epoch 851/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3912 - accuracy: 0.5209 - val_loss: 1.6425 - val_accuracy: 0.4675\n",
      "Epoch 852/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3572 - accuracy: 0.5279 - val_loss: 1.6020 - val_accuracy: 0.4935\n",
      "Epoch 853/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3872 - accuracy: 0.5215 - val_loss: 1.5691 - val_accuracy: 0.5065\n",
      "Epoch 854/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3964 - accuracy: 0.5237 - val_loss: 1.5512 - val_accuracy: 0.5130\n",
      "Epoch 855/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3991 - accuracy: 0.4860 - val_loss: 1.5636 - val_accuracy: 0.5065\n",
      "Epoch 856/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3838 - accuracy: 0.5168 - val_loss: 1.6140 - val_accuracy: 0.4805\n",
      "Epoch 857/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3809 - accuracy: 0.5168 - val_loss: 1.6831 - val_accuracy: 0.4643\n",
      "Epoch 858/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4559 - accuracy: 0.4717 - val_loss: 1.7616 - val_accuracy: 0.4610\n",
      "Epoch 859/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4036 - accuracy: 0.5042 - val_loss: 1.8207 - val_accuracy: 0.4351\n",
      "Epoch 860/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4042 - accuracy: 0.5146 - val_loss: 1.8310 - val_accuracy: 0.4221\n",
      "Epoch 861/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3770 - accuracy: 0.5312 - val_loss: 1.8074 - val_accuracy: 0.4253\n",
      "Epoch 862/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4181 - accuracy: 0.5166 - val_loss: 1.7462 - val_accuracy: 0.4416\n",
      "Epoch 863/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3957 - accuracy: 0.5042 - val_loss: 1.6836 - val_accuracy: 0.4416\n",
      "Epoch 864/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3345 - accuracy: 0.5303 - val_loss: 1.6011 - val_accuracy: 0.4578\n",
      "Epoch 865/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3598 - accuracy: 0.5056 - val_loss: 1.5240 - val_accuracy: 0.5000\n",
      "Epoch 866/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4047 - accuracy: 0.5098 - val_loss: 1.4670 - val_accuracy: 0.5000\n",
      "Epoch 867/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3726 - accuracy: 0.5293 - val_loss: 1.4255 - val_accuracy: 0.5162\n",
      "Epoch 868/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3714 - accuracy: 0.5307 - val_loss: 1.4034 - val_accuracy: 0.5227\n",
      "Epoch 869/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3140 - accuracy: 0.5461 - val_loss: 1.3990 - val_accuracy: 0.5227\n",
      "Epoch 870/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4051 - accuracy: 0.5029 - val_loss: 1.4138 - val_accuracy: 0.5000\n",
      "Epoch 871/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4190 - accuracy: 0.5056 - val_loss: 1.4236 - val_accuracy: 0.5000\n",
      "Epoch 872/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3586 - accuracy: 0.5137 - val_loss: 1.4368 - val_accuracy: 0.5065\n",
      "Epoch 873/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3692 - accuracy: 0.5283 - val_loss: 1.4527 - val_accuracy: 0.5032\n",
      "Epoch 874/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3924 - accuracy: 0.4971 - val_loss: 1.4545 - val_accuracy: 0.5032\n",
      "Epoch 875/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3846 - accuracy: 0.5244 - val_loss: 1.4524 - val_accuracy: 0.5000\n",
      "Epoch 876/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3925 - accuracy: 0.5237 - val_loss: 1.4216 - val_accuracy: 0.5032\n",
      "Epoch 877/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3159 - accuracy: 0.5349 - val_loss: 1.4207 - val_accuracy: 0.5227\n",
      "Epoch 878/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3254 - accuracy: 0.5140 - val_loss: 1.4073 - val_accuracy: 0.5325\n",
      "Epoch 879/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3727 - accuracy: 0.5049 - val_loss: 1.3997 - val_accuracy: 0.5195\n",
      "Epoch 880/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3822 - accuracy: 0.5405 - val_loss: 1.4094 - val_accuracy: 0.5162\n",
      "Epoch 881/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3383 - accuracy: 0.5447 - val_loss: 1.4127 - val_accuracy: 0.5260\n",
      "Epoch 882/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2981 - accuracy: 0.5381 - val_loss: 1.4097 - val_accuracy: 0.5292\n",
      "Epoch 883/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3659 - accuracy: 0.5293 - val_loss: 1.3846 - val_accuracy: 0.5390\n",
      "Epoch 884/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3282 - accuracy: 0.5503 - val_loss: 1.3725 - val_accuracy: 0.5584\n",
      "Epoch 885/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3638 - accuracy: 0.5293 - val_loss: 1.3757 - val_accuracy: 0.5390\n",
      "Epoch 886/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3353 - accuracy: 0.5205 - val_loss: 1.3694 - val_accuracy: 0.5422\n",
      "Epoch 887/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3359 - accuracy: 0.5489 - val_loss: 1.3837 - val_accuracy: 0.5422\n",
      "Epoch 888/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3828 - accuracy: 0.5166 - val_loss: 1.4001 - val_accuracy: 0.5422\n",
      "Epoch 889/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3681 - accuracy: 0.5293 - val_loss: 1.4160 - val_accuracy: 0.5325\n",
      "Epoch 890/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3639 - accuracy: 0.5234 - val_loss: 1.4392 - val_accuracy: 0.5195\n",
      "Epoch 891/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3419 - accuracy: 0.5215 - val_loss: 1.4680 - val_accuracy: 0.5097\n",
      "Epoch 892/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3912 - accuracy: 0.5196 - val_loss: 1.4957 - val_accuracy: 0.5032\n",
      "Epoch 893/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3234 - accuracy: 0.5391 - val_loss: 1.5021 - val_accuracy: 0.5032\n",
      "Epoch 894/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3155 - accuracy: 0.5461 - val_loss: 1.5160 - val_accuracy: 0.5130\n",
      "Epoch 895/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3471 - accuracy: 0.5293 - val_loss: 1.5128 - val_accuracy: 0.5162\n",
      "Epoch 896/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3495 - accuracy: 0.5312 - val_loss: 1.4913 - val_accuracy: 0.5357\n",
      "Epoch 897/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3539 - accuracy: 0.5410 - val_loss: 1.4703 - val_accuracy: 0.5390\n",
      "Epoch 898/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3278 - accuracy: 0.5461 - val_loss: 1.4680 - val_accuracy: 0.5325\n",
      "Epoch 899/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3410 - accuracy: 0.5363 - val_loss: 1.4914 - val_accuracy: 0.5260\n",
      "Epoch 900/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3818 - accuracy: 0.5342 - val_loss: 1.5187 - val_accuracy: 0.5032\n",
      "Epoch 901/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2892 - accuracy: 0.5587 - val_loss: 1.5582 - val_accuracy: 0.4935\n",
      "Epoch 902/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3647 - accuracy: 0.5156 - val_loss: 1.5847 - val_accuracy: 0.4675\n",
      "Epoch 903/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3581 - accuracy: 0.5196 - val_loss: 1.6094 - val_accuracy: 0.4708\n",
      "Epoch 904/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3901 - accuracy: 0.5166 - val_loss: 1.6019 - val_accuracy: 0.4643\n",
      "Epoch 905/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3265 - accuracy: 0.5447 - val_loss: 1.5383 - val_accuracy: 0.4935\n",
      "Epoch 906/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4168 - accuracy: 0.4980 - val_loss: 1.4607 - val_accuracy: 0.5065\n",
      "Epoch 907/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3289 - accuracy: 0.5312 - val_loss: 1.4006 - val_accuracy: 0.5390\n",
      "Epoch 908/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2939 - accuracy: 0.5391 - val_loss: 1.3503 - val_accuracy: 0.5584\n",
      "Epoch 909/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2607 - accuracy: 0.5664 - val_loss: 1.3155 - val_accuracy: 0.5714\n",
      "Epoch 910/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3326 - accuracy: 0.5264 - val_loss: 1.3267 - val_accuracy: 0.5649\n",
      "Epoch 911/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3743 - accuracy: 0.5430 - val_loss: 1.3765 - val_accuracy: 0.5649\n",
      "Epoch 912/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3084 - accuracy: 0.5391 - val_loss: 1.4301 - val_accuracy: 0.5325\n",
      "Epoch 913/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3619 - accuracy: 0.5391 - val_loss: 1.4874 - val_accuracy: 0.5000\n",
      "Epoch 914/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3717 - accuracy: 0.5056 - val_loss: 1.5587 - val_accuracy: 0.4935\n",
      "Epoch 915/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3069 - accuracy: 0.5400 - val_loss: 1.5937 - val_accuracy: 0.4935\n",
      "Epoch 916/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3357 - accuracy: 0.5293 - val_loss: 1.5925 - val_accuracy: 0.4903\n",
      "Epoch 917/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3160 - accuracy: 0.5447 - val_loss: 1.5271 - val_accuracy: 0.5097\n",
      "Epoch 918/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2883 - accuracy: 0.5352 - val_loss: 1.4380 - val_accuracy: 0.5455\n",
      "Epoch 919/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3326 - accuracy: 0.5405 - val_loss: 1.3378 - val_accuracy: 0.5519\n",
      "Epoch 920/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2804 - accuracy: 0.5447 - val_loss: 1.2743 - val_accuracy: 0.5877\n",
      "Epoch 921/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3016 - accuracy: 0.5419 - val_loss: 1.2591 - val_accuracy: 0.5779\n",
      "Epoch 922/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3541 - accuracy: 0.5215 - val_loss: 1.2579 - val_accuracy: 0.5714\n",
      "Epoch 923/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3443 - accuracy: 0.5469 - val_loss: 1.2582 - val_accuracy: 0.5714\n",
      "Epoch 924/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2793 - accuracy: 0.5791 - val_loss: 1.2566 - val_accuracy: 0.5682\n",
      "Epoch 925/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3545 - accuracy: 0.5127 - val_loss: 1.2667 - val_accuracy: 0.5682\n",
      "Epoch 926/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2874 - accuracy: 0.5684 - val_loss: 1.2817 - val_accuracy: 0.5617\n",
      "Epoch 927/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3433 - accuracy: 0.5400 - val_loss: 1.3108 - val_accuracy: 0.5455\n",
      "Epoch 928/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3176 - accuracy: 0.5449 - val_loss: 1.3352 - val_accuracy: 0.5552\n",
      "Epoch 929/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3236 - accuracy: 0.5531 - val_loss: 1.3524 - val_accuracy: 0.5617\n",
      "Epoch 930/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3221 - accuracy: 0.5391 - val_loss: 1.3609 - val_accuracy: 0.5584\n",
      "Epoch 931/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3309 - accuracy: 0.5405 - val_loss: 1.3658 - val_accuracy: 0.5584\n",
      "Epoch 932/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3239 - accuracy: 0.5307 - val_loss: 1.3637 - val_accuracy: 0.5552\n",
      "Epoch 933/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2940 - accuracy: 0.5654 - val_loss: 1.3485 - val_accuracy: 0.5519\n",
      "Epoch 934/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3136 - accuracy: 0.5283 - val_loss: 1.3362 - val_accuracy: 0.5487\n",
      "Epoch 935/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4034 - accuracy: 0.5059 - val_loss: 1.3224 - val_accuracy: 0.5357\n",
      "Epoch 936/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2514 - accuracy: 0.5670 - val_loss: 1.3044 - val_accuracy: 0.5455\n",
      "Epoch 937/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3037 - accuracy: 0.5537 - val_loss: 1.2966 - val_accuracy: 0.5487\n",
      "Epoch 938/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3572 - accuracy: 0.5377 - val_loss: 1.2978 - val_accuracy: 0.5487\n",
      "Epoch 939/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3051 - accuracy: 0.5405 - val_loss: 1.3024 - val_accuracy: 0.5487\n",
      "Epoch 940/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2912 - accuracy: 0.5517 - val_loss: 1.3066 - val_accuracy: 0.5682\n",
      "Epoch 941/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3205 - accuracy: 0.5488 - val_loss: 1.3203 - val_accuracy: 0.5682\n",
      "Epoch 942/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2849 - accuracy: 0.5488 - val_loss: 1.3381 - val_accuracy: 0.5682\n",
      "Epoch 943/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2901 - accuracy: 0.5479 - val_loss: 1.3529 - val_accuracy: 0.5682\n",
      "Epoch 944/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3216 - accuracy: 0.5475 - val_loss: 1.3626 - val_accuracy: 0.5682\n",
      "Epoch 945/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3260 - accuracy: 0.5459 - val_loss: 1.3667 - val_accuracy: 0.5584\n",
      "Epoch 946/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3646 - accuracy: 0.5332 - val_loss: 1.3805 - val_accuracy: 0.5649\n",
      "Epoch 947/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2985 - accuracy: 0.5573 - val_loss: 1.3764 - val_accuracy: 0.5584\n",
      "Epoch 948/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2870 - accuracy: 0.5625 - val_loss: 1.3640 - val_accuracy: 0.5584\n",
      "Epoch 949/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3424 - accuracy: 0.5363 - val_loss: 1.3870 - val_accuracy: 0.5390\n",
      "Epoch 950/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3188 - accuracy: 0.5527 - val_loss: 1.4148 - val_accuracy: 0.5357\n",
      "Epoch 951/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2151 - accuracy: 0.5964 - val_loss: 1.4349 - val_accuracy: 0.5097\n",
      "Epoch 952/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3106 - accuracy: 0.5670 - val_loss: 1.4317 - val_accuracy: 0.5130\n",
      "Epoch 953/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3203 - accuracy: 0.5332 - val_loss: 1.4000 - val_accuracy: 0.5260\n",
      "Epoch 954/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3411 - accuracy: 0.5615 - val_loss: 1.3700 - val_accuracy: 0.5487\n",
      "Epoch 955/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2619 - accuracy: 0.5625 - val_loss: 1.3487 - val_accuracy: 0.5519\n",
      "Epoch 956/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3376 - accuracy: 0.5307 - val_loss: 1.3520 - val_accuracy: 0.5519\n",
      "Epoch 957/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2801 - accuracy: 0.5596 - val_loss: 1.3690 - val_accuracy: 0.5487\n",
      "Epoch 958/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2976 - accuracy: 0.5557 - val_loss: 1.3788 - val_accuracy: 0.5390\n",
      "Epoch 959/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.3114 - accuracy: 0.5566 - val_loss: 1.3939 - val_accuracy: 0.5292\n",
      "Epoch 960/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2899 - accuracy: 0.5469 - val_loss: 1.4102 - val_accuracy: 0.5357\n",
      "Epoch 961/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2487 - accuracy: 0.5605 - val_loss: 1.4042 - val_accuracy: 0.5292\n",
      "Epoch 962/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3254 - accuracy: 0.5559 - val_loss: 1.4001 - val_accuracy: 0.5487\n",
      "Epoch 963/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2823 - accuracy: 0.5587 - val_loss: 1.3831 - val_accuracy: 0.5519\n",
      "Epoch 964/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2883 - accuracy: 0.5645 - val_loss: 1.3745 - val_accuracy: 0.5519\n",
      "Epoch 965/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2315 - accuracy: 0.5922 - val_loss: 1.3696 - val_accuracy: 0.5519\n",
      "Epoch 966/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2646 - accuracy: 0.5586 - val_loss: 1.3680 - val_accuracy: 0.5422\n",
      "Epoch 967/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2727 - accuracy: 0.5547 - val_loss: 1.3589 - val_accuracy: 0.5390\n",
      "Epoch 968/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2436 - accuracy: 0.5754 - val_loss: 1.3888 - val_accuracy: 0.5292\n",
      "Epoch 969/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2587 - accuracy: 0.5508 - val_loss: 1.4223 - val_accuracy: 0.5162\n",
      "Epoch 970/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3311 - accuracy: 0.5251 - val_loss: 1.4360 - val_accuracy: 0.5000\n",
      "Epoch 971/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2989 - accuracy: 0.5469 - val_loss: 1.4211 - val_accuracy: 0.5162\n",
      "Epoch 972/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3307 - accuracy: 0.5391 - val_loss: 1.3917 - val_accuracy: 0.5195\n",
      "Epoch 973/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3652 - accuracy: 0.5279 - val_loss: 1.3415 - val_accuracy: 0.5519\n",
      "Epoch 974/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2571 - accuracy: 0.5628 - val_loss: 1.2995 - val_accuracy: 0.5942\n",
      "Epoch 975/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2777 - accuracy: 0.5517 - val_loss: 1.2724 - val_accuracy: 0.5877\n",
      "Epoch 976/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2493 - accuracy: 0.5449 - val_loss: 1.2528 - val_accuracy: 0.5942\n",
      "Epoch 977/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2969 - accuracy: 0.5782 - val_loss: 1.2469 - val_accuracy: 0.5812\n",
      "Epoch 978/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2366 - accuracy: 0.5537 - val_loss: 1.2363 - val_accuracy: 0.5909\n",
      "Epoch 979/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2482 - accuracy: 0.5674 - val_loss: 1.2214 - val_accuracy: 0.5877\n",
      "Epoch 980/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2860 - accuracy: 0.5615 - val_loss: 1.2124 - val_accuracy: 0.5877\n",
      "Epoch 981/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2731 - accuracy: 0.5566 - val_loss: 1.2105 - val_accuracy: 0.5844\n",
      "Epoch 982/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2722 - accuracy: 0.5656 - val_loss: 1.2077 - val_accuracy: 0.5844\n",
      "Epoch 983/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2639 - accuracy: 0.5587 - val_loss: 1.2073 - val_accuracy: 0.5779\n",
      "Epoch 984/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2682 - accuracy: 0.5531 - val_loss: 1.2074 - val_accuracy: 0.5779\n",
      "Epoch 985/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3016 - accuracy: 0.5410 - val_loss: 1.2065 - val_accuracy: 0.5747\n",
      "Epoch 986/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2664 - accuracy: 0.5850 - val_loss: 1.2045 - val_accuracy: 0.5844\n",
      "Epoch 987/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2396 - accuracy: 0.5684 - val_loss: 1.2141 - val_accuracy: 0.5877\n",
      "Epoch 988/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2594 - accuracy: 0.5547 - val_loss: 1.2313 - val_accuracy: 0.5779\n",
      "Epoch 989/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2828 - accuracy: 0.5596 - val_loss: 1.2458 - val_accuracy: 0.5747\n",
      "Epoch 990/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2766 - accuracy: 0.5615 - val_loss: 1.2788 - val_accuracy: 0.5584\n",
      "Epoch 991/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2349 - accuracy: 0.5635 - val_loss: 1.3154 - val_accuracy: 0.5682\n",
      "Epoch 992/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2864 - accuracy: 0.5537 - val_loss: 1.3475 - val_accuracy: 0.5552\n",
      "Epoch 993/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2056 - accuracy: 0.5684 - val_loss: 1.3577 - val_accuracy: 0.5519\n",
      "Epoch 994/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2787 - accuracy: 0.5656 - val_loss: 1.3880 - val_accuracy: 0.5390\n",
      "Epoch 995/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2270 - accuracy: 0.5752 - val_loss: 1.4091 - val_accuracy: 0.5357\n",
      "Epoch 996/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2299 - accuracy: 0.5791 - val_loss: 1.4271 - val_accuracy: 0.5390\n",
      "Epoch 997/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3195 - accuracy: 0.5503 - val_loss: 1.4356 - val_accuracy: 0.5325\n",
      "Epoch 998/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3091 - accuracy: 0.5419 - val_loss: 1.4181 - val_accuracy: 0.5455\n",
      "Epoch 999/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1796 - accuracy: 0.5830 - val_loss: 1.3944 - val_accuracy: 0.5422\n",
      "Epoch 1000/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2275 - accuracy: 0.5964 - val_loss: 1.3657 - val_accuracy: 0.5422\n",
      "Epoch 1001/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2496 - accuracy: 0.5605 - val_loss: 1.3458 - val_accuracy: 0.5519\n",
      "Epoch 1002/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3094 - accuracy: 0.5419 - val_loss: 1.3266 - val_accuracy: 0.5617\n",
      "Epoch 1003/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2852 - accuracy: 0.5693 - val_loss: 1.3198 - val_accuracy: 0.5714\n",
      "Epoch 1004/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2692 - accuracy: 0.5559 - val_loss: 1.3230 - val_accuracy: 0.5649\n",
      "Epoch 1005/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2253 - accuracy: 0.5768 - val_loss: 1.3626 - val_accuracy: 0.5617\n",
      "Epoch 1006/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3211 - accuracy: 0.5527 - val_loss: 1.4025 - val_accuracy: 0.5455\n",
      "Epoch 1007/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2109 - accuracy: 0.5908 - val_loss: 1.4461 - val_accuracy: 0.5390\n",
      "Epoch 1008/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2215 - accuracy: 0.5908 - val_loss: 1.4856 - val_accuracy: 0.5260\n",
      "Epoch 1009/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2146 - accuracy: 0.5850 - val_loss: 1.5216 - val_accuracy: 0.5032\n",
      "Epoch 1010/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2612 - accuracy: 0.5605 - val_loss: 1.5464 - val_accuracy: 0.4968\n",
      "Epoch 1011/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2605 - accuracy: 0.5475 - val_loss: 1.5206 - val_accuracy: 0.4968\n",
      "Epoch 1012/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2525 - accuracy: 0.5615 - val_loss: 1.4652 - val_accuracy: 0.5000\n",
      "Epoch 1013/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2098 - accuracy: 0.5967 - val_loss: 1.4040 - val_accuracy: 0.5162\n",
      "Epoch 1014/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2532 - accuracy: 0.5664 - val_loss: 1.3500 - val_accuracy: 0.5487\n",
      "Epoch 1015/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2125 - accuracy: 0.5752 - val_loss: 1.3102 - val_accuracy: 0.5682\n",
      "Epoch 1016/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2197 - accuracy: 0.5820 - val_loss: 1.2945 - val_accuracy: 0.5649\n",
      "Epoch 1017/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1753 - accuracy: 0.5964 - val_loss: 1.2956 - val_accuracy: 0.5617\n",
      "Epoch 1018/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1910 - accuracy: 0.5964 - val_loss: 1.2753 - val_accuracy: 0.5682\n",
      "Epoch 1019/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2292 - accuracy: 0.5880 - val_loss: 1.2599 - val_accuracy: 0.5682\n",
      "Epoch 1020/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2336 - accuracy: 0.5573 - val_loss: 1.2335 - val_accuracy: 0.5747\n",
      "Epoch 1021/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2254 - accuracy: 0.5752 - val_loss: 1.2215 - val_accuracy: 0.5877\n",
      "Epoch 1022/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2316 - accuracy: 0.5879 - val_loss: 1.2124 - val_accuracy: 0.5877\n",
      "Epoch 1023/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2390 - accuracy: 0.5573 - val_loss: 1.2050 - val_accuracy: 0.5974\n",
      "Epoch 1024/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2341 - accuracy: 0.5869 - val_loss: 1.2068 - val_accuracy: 0.5909\n",
      "Epoch 1025/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2464 - accuracy: 0.5670 - val_loss: 1.2098 - val_accuracy: 0.5844\n",
      "Epoch 1026/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2463 - accuracy: 0.5811 - val_loss: 1.2191 - val_accuracy: 0.5877\n",
      "Epoch 1027/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2501 - accuracy: 0.5938 - val_loss: 1.2250 - val_accuracy: 0.5909\n",
      "Epoch 1028/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2204 - accuracy: 0.5967 - val_loss: 1.2247 - val_accuracy: 0.5909\n",
      "Epoch 1029/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2077 - accuracy: 0.5859 - val_loss: 1.2222 - val_accuracy: 0.5909\n",
      "Epoch 1030/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2088 - accuracy: 0.5801 - val_loss: 1.2268 - val_accuracy: 0.5909\n",
      "Epoch 1031/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2132 - accuracy: 0.5824 - val_loss: 1.2318 - val_accuracy: 0.5877\n",
      "Epoch 1032/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2084 - accuracy: 0.5859 - val_loss: 1.2400 - val_accuracy: 0.6006\n",
      "Epoch 1033/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2413 - accuracy: 0.5740 - val_loss: 1.2206 - val_accuracy: 0.5974\n",
      "Epoch 1034/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2341 - accuracy: 0.5781 - val_loss: 1.2012 - val_accuracy: 0.6136\n",
      "Epoch 1035/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2146 - accuracy: 0.5684 - val_loss: 1.1807 - val_accuracy: 0.6136\n",
      "Epoch 1036/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1905 - accuracy: 0.5810 - val_loss: 1.1795 - val_accuracy: 0.6104\n",
      "Epoch 1037/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2256 - accuracy: 0.5754 - val_loss: 1.1923 - val_accuracy: 0.6234\n",
      "Epoch 1038/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2068 - accuracy: 0.5947 - val_loss: 1.2094 - val_accuracy: 0.6104\n",
      "Epoch 1039/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1566 - accuracy: 0.5967 - val_loss: 1.2216 - val_accuracy: 0.6104\n",
      "Epoch 1040/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2035 - accuracy: 0.5723 - val_loss: 1.2212 - val_accuracy: 0.6136\n",
      "Epoch 1041/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2102 - accuracy: 0.5938 - val_loss: 1.2267 - val_accuracy: 0.6039\n",
      "Epoch 1042/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3049 - accuracy: 0.5381 - val_loss: 1.2409 - val_accuracy: 0.5877\n",
      "Epoch 1043/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2020 - accuracy: 0.5964 - val_loss: 1.2421 - val_accuracy: 0.5844\n",
      "Epoch 1044/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1811 - accuracy: 0.6034 - val_loss: 1.2356 - val_accuracy: 0.5877\n",
      "Epoch 1045/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2283 - accuracy: 0.5824 - val_loss: 1.2307 - val_accuracy: 0.5942\n",
      "Epoch 1046/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1843 - accuracy: 0.5824 - val_loss: 1.2222 - val_accuracy: 0.5909\n",
      "Epoch 1047/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2413 - accuracy: 0.5820 - val_loss: 1.2179 - val_accuracy: 0.5877\n",
      "Epoch 1048/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1547 - accuracy: 0.6034 - val_loss: 1.2327 - val_accuracy: 0.5779\n",
      "Epoch 1049/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1930 - accuracy: 0.5918 - val_loss: 1.2416 - val_accuracy: 0.5812\n",
      "Epoch 1050/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2373 - accuracy: 0.5726 - val_loss: 1.2754 - val_accuracy: 0.5779\n",
      "Epoch 1051/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1375 - accuracy: 0.5936 - val_loss: 1.2791 - val_accuracy: 0.5747\n",
      "Epoch 1052/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1452 - accuracy: 0.6064 - val_loss: 1.2705 - val_accuracy: 0.5779\n",
      "Epoch 1053/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2193 - accuracy: 0.5824 - val_loss: 1.2199 - val_accuracy: 0.5909\n",
      "Epoch 1054/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2235 - accuracy: 0.5850 - val_loss: 1.1808 - val_accuracy: 0.5942\n",
      "Epoch 1055/4000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.2586 - accuracy: 0.5830 - val_loss: 1.1383 - val_accuracy: 0.6169\n",
      "Epoch 1056/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1504 - accuracy: 0.6094 - val_loss: 1.1146 - val_accuracy: 0.6396\n",
      "Epoch 1057/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1464 - accuracy: 0.6047 - val_loss: 1.1010 - val_accuracy: 0.6429\n",
      "Epoch 1058/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1601 - accuracy: 0.5824 - val_loss: 1.1084 - val_accuracy: 0.6429\n",
      "Epoch 1059/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2111 - accuracy: 0.5889 - val_loss: 1.1201 - val_accuracy: 0.6494\n",
      "Epoch 1060/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2084 - accuracy: 0.5796 - val_loss: 1.1405 - val_accuracy: 0.6429\n",
      "Epoch 1061/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1662 - accuracy: 0.5928 - val_loss: 1.1681 - val_accuracy: 0.6201\n",
      "Epoch 1062/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1768 - accuracy: 0.6064 - val_loss: 1.1934 - val_accuracy: 0.6104\n",
      "Epoch 1063/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2121 - accuracy: 0.5791 - val_loss: 1.2133 - val_accuracy: 0.6039\n",
      "Epoch 1064/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2324 - accuracy: 0.5880 - val_loss: 1.2318 - val_accuracy: 0.5974\n",
      "Epoch 1065/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1184 - accuracy: 0.6133 - val_loss: 1.2224 - val_accuracy: 0.5974\n",
      "Epoch 1066/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1656 - accuracy: 0.6075 - val_loss: 1.1857 - val_accuracy: 0.6071\n",
      "Epoch 1067/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2457 - accuracy: 0.5596 - val_loss: 1.1480 - val_accuracy: 0.6201\n",
      "Epoch 1068/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2215 - accuracy: 0.5782 - val_loss: 1.1353 - val_accuracy: 0.6136\n",
      "Epoch 1069/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1842 - accuracy: 0.5894 - val_loss: 1.1675 - val_accuracy: 0.6006\n",
      "Epoch 1070/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1944 - accuracy: 0.5768 - val_loss: 1.1901 - val_accuracy: 0.5974\n",
      "Epoch 1071/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1533 - accuracy: 0.6133 - val_loss: 1.2279 - val_accuracy: 0.5974\n",
      "Epoch 1072/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1871 - accuracy: 0.5781 - val_loss: 1.2759 - val_accuracy: 0.5714\n",
      "Epoch 1073/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2172 - accuracy: 0.5918 - val_loss: 1.3023 - val_accuracy: 0.5487\n",
      "Epoch 1074/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1602 - accuracy: 0.6075 - val_loss: 1.3132 - val_accuracy: 0.5455\n",
      "Epoch 1075/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1793 - accuracy: 0.5879 - val_loss: 1.2748 - val_accuracy: 0.5487\n",
      "Epoch 1076/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1855 - accuracy: 0.5922 - val_loss: 1.2248 - val_accuracy: 0.5844\n",
      "Epoch 1077/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1803 - accuracy: 0.6145 - val_loss: 1.1837 - val_accuracy: 0.6006\n",
      "Epoch 1078/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1468 - accuracy: 0.5986 - val_loss: 1.1491 - val_accuracy: 0.6039\n",
      "Epoch 1079/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2290 - accuracy: 0.5852 - val_loss: 1.1247 - val_accuracy: 0.6169\n",
      "Epoch 1080/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1844 - accuracy: 0.5938 - val_loss: 1.1126 - val_accuracy: 0.6331\n",
      "Epoch 1081/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1199 - accuracy: 0.6215 - val_loss: 1.1024 - val_accuracy: 0.6299\n",
      "Epoch 1082/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1666 - accuracy: 0.5879 - val_loss: 1.1049 - val_accuracy: 0.6266\n",
      "Epoch 1083/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2073 - accuracy: 0.5782 - val_loss: 1.1068 - val_accuracy: 0.6201\n",
      "Epoch 1084/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1817 - accuracy: 0.6084 - val_loss: 1.1121 - val_accuracy: 0.6104\n",
      "Epoch 1085/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1556 - accuracy: 0.6089 - val_loss: 1.1186 - val_accuracy: 0.6136\n",
      "Epoch 1086/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1980 - accuracy: 0.5964 - val_loss: 1.1272 - val_accuracy: 0.6104\n",
      "Epoch 1087/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1287 - accuracy: 0.6064 - val_loss: 1.1387 - val_accuracy: 0.6104\n",
      "Epoch 1088/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2165 - accuracy: 0.5645 - val_loss: 1.1521 - val_accuracy: 0.5974\n",
      "Epoch 1089/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2081 - accuracy: 0.5936 - val_loss: 1.1560 - val_accuracy: 0.5942\n",
      "Epoch 1090/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1520 - accuracy: 0.6074 - val_loss: 1.1616 - val_accuracy: 0.5909\n",
      "Epoch 1091/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1097 - accuracy: 0.6411 - val_loss: 1.1606 - val_accuracy: 0.5942\n",
      "Epoch 1092/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1542 - accuracy: 0.6035 - val_loss: 1.1517 - val_accuracy: 0.5974\n",
      "Epoch 1093/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1316 - accuracy: 0.6211 - val_loss: 1.1421 - val_accuracy: 0.6006\n",
      "Epoch 1094/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1748 - accuracy: 0.6133 - val_loss: 1.1180 - val_accuracy: 0.6071\n",
      "Epoch 1095/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1326 - accuracy: 0.6025 - val_loss: 1.0961 - val_accuracy: 0.6234\n",
      "Epoch 1096/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2117 - accuracy: 0.5740 - val_loss: 1.0878 - val_accuracy: 0.6201\n",
      "Epoch 1097/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1867 - accuracy: 0.5894 - val_loss: 1.0914 - val_accuracy: 0.6136\n",
      "Epoch 1098/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1341 - accuracy: 0.6103 - val_loss: 1.0949 - val_accuracy: 0.6201\n",
      "Epoch 1099/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1416 - accuracy: 0.6162 - val_loss: 1.0887 - val_accuracy: 0.6299\n",
      "Epoch 1100/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1185 - accuracy: 0.6103 - val_loss: 1.0843 - val_accuracy: 0.6201\n",
      "Epoch 1101/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1187 - accuracy: 0.6103 - val_loss: 1.0835 - val_accuracy: 0.6169\n",
      "Epoch 1102/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1604 - accuracy: 0.6074 - val_loss: 1.0937 - val_accuracy: 0.6136\n",
      "Epoch 1103/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1000 - accuracy: 0.6289 - val_loss: 1.1091 - val_accuracy: 0.6071\n",
      "Epoch 1104/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2400 - accuracy: 0.5503 - val_loss: 1.1244 - val_accuracy: 0.5974\n",
      "Epoch 1105/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1718 - accuracy: 0.6016 - val_loss: 1.1428 - val_accuracy: 0.6006\n",
      "Epoch 1106/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1989 - accuracy: 0.5889 - val_loss: 1.1635 - val_accuracy: 0.6039\n",
      "Epoch 1107/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0755 - accuracy: 0.6215 - val_loss: 1.1907 - val_accuracy: 0.5942\n",
      "Epoch 1108/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0999 - accuracy: 0.6162 - val_loss: 1.2165 - val_accuracy: 0.5844\n",
      "Epoch 1109/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1175 - accuracy: 0.6271 - val_loss: 1.2531 - val_accuracy: 0.5747\n",
      "Epoch 1110/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1693 - accuracy: 0.6145 - val_loss: 1.2761 - val_accuracy: 0.5552\n",
      "Epoch 1111/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0948 - accuracy: 0.6145 - val_loss: 1.2962 - val_accuracy: 0.5617\n",
      "Epoch 1112/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1637 - accuracy: 0.6123 - val_loss: 1.3033 - val_accuracy: 0.5519\n",
      "Epoch 1113/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1495 - accuracy: 0.6240 - val_loss: 1.3104 - val_accuracy: 0.5487\n",
      "Epoch 1114/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1391 - accuracy: 0.6172 - val_loss: 1.2822 - val_accuracy: 0.5584\n",
      "Epoch 1115/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1197 - accuracy: 0.6172 - val_loss: 1.2699 - val_accuracy: 0.5519\n",
      "Epoch 1116/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2109 - accuracy: 0.6020 - val_loss: 1.2795 - val_accuracy: 0.5682\n",
      "Epoch 1117/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1681 - accuracy: 0.5894 - val_loss: 1.3234 - val_accuracy: 0.5682\n",
      "Epoch 1118/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0816 - accuracy: 0.6104 - val_loss: 1.3892 - val_accuracy: 0.5519\n",
      "Epoch 1119/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1038 - accuracy: 0.6133 - val_loss: 1.4714 - val_accuracy: 0.5390\n",
      "Epoch 1120/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0930 - accuracy: 0.6313 - val_loss: 1.5615 - val_accuracy: 0.5162\n",
      "Epoch 1121/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0933 - accuracy: 0.6377 - val_loss: 1.6096 - val_accuracy: 0.5227\n",
      "Epoch 1122/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1404 - accuracy: 0.6201 - val_loss: 1.6209 - val_accuracy: 0.5097\n",
      "Epoch 1123/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1227 - accuracy: 0.6020 - val_loss: 1.6042 - val_accuracy: 0.5097\n",
      "Epoch 1124/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1682 - accuracy: 0.6104 - val_loss: 1.5164 - val_accuracy: 0.5195\n",
      "Epoch 1125/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1325 - accuracy: 0.6173 - val_loss: 1.4168 - val_accuracy: 0.5519\n",
      "Epoch 1126/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1113 - accuracy: 0.6201 - val_loss: 1.3176 - val_accuracy: 0.5682\n",
      "Epoch 1127/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1382 - accuracy: 0.6299 - val_loss: 1.2583 - val_accuracy: 0.5844\n",
      "Epoch 1128/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0894 - accuracy: 0.6145 - val_loss: 1.2020 - val_accuracy: 0.5909\n",
      "Epoch 1129/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1406 - accuracy: 0.6143 - val_loss: 1.1726 - val_accuracy: 0.5974\n",
      "Epoch 1130/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2017 - accuracy: 0.5908 - val_loss: 1.1679 - val_accuracy: 0.5877\n",
      "Epoch 1131/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1071 - accuracy: 0.6191 - val_loss: 1.1714 - val_accuracy: 0.5942\n",
      "Epoch 1132/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0936 - accuracy: 0.6162 - val_loss: 1.1613 - val_accuracy: 0.5974\n",
      "Epoch 1133/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1135 - accuracy: 0.6243 - val_loss: 1.1484 - val_accuracy: 0.5974\n",
      "Epoch 1134/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0885 - accuracy: 0.6445 - val_loss: 1.1313 - val_accuracy: 0.6006\n",
      "Epoch 1135/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1138 - accuracy: 0.6313 - val_loss: 1.1324 - val_accuracy: 0.5942\n",
      "Epoch 1136/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1588 - accuracy: 0.5838 - val_loss: 1.1542 - val_accuracy: 0.5942\n",
      "Epoch 1137/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1655 - accuracy: 0.6094 - val_loss: 1.1956 - val_accuracy: 0.5844\n",
      "Epoch 1138/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1088 - accuracy: 0.6172 - val_loss: 1.2373 - val_accuracy: 0.5649\n",
      "Epoch 1139/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1132 - accuracy: 0.6211 - val_loss: 1.2824 - val_accuracy: 0.5487\n",
      "Epoch 1140/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0894 - accuracy: 0.6215 - val_loss: 1.3260 - val_accuracy: 0.5390\n",
      "Epoch 1141/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1443 - accuracy: 0.5922 - val_loss: 1.3226 - val_accuracy: 0.5390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1142/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0452 - accuracy: 0.6367 - val_loss: 1.2961 - val_accuracy: 0.5357\n",
      "Epoch 1143/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1183 - accuracy: 0.6123 - val_loss: 1.2720 - val_accuracy: 0.5455\n",
      "Epoch 1144/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1568 - accuracy: 0.5936 - val_loss: 1.2268 - val_accuracy: 0.5682\n",
      "Epoch 1145/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1254 - accuracy: 0.6257 - val_loss: 1.1817 - val_accuracy: 0.5747\n",
      "Epoch 1146/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1072 - accuracy: 0.6243 - val_loss: 1.1469 - val_accuracy: 0.5942\n",
      "Epoch 1147/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1222 - accuracy: 0.6229 - val_loss: 1.1315 - val_accuracy: 0.5974\n",
      "Epoch 1148/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1087 - accuracy: 0.6377 - val_loss: 1.1400 - val_accuracy: 0.6006\n",
      "Epoch 1149/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1174 - accuracy: 0.6075 - val_loss: 1.1578 - val_accuracy: 0.6006\n",
      "Epoch 1150/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0727 - accuracy: 0.6299 - val_loss: 1.1622 - val_accuracy: 0.6039\n",
      "Epoch 1151/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1116 - accuracy: 0.6341 - val_loss: 1.1592 - val_accuracy: 0.6136\n",
      "Epoch 1152/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1283 - accuracy: 0.6094 - val_loss: 1.1501 - val_accuracy: 0.6039\n",
      "Epoch 1153/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0821 - accuracy: 0.6257 - val_loss: 1.1577 - val_accuracy: 0.6136\n",
      "Epoch 1154/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1092 - accuracy: 0.6260 - val_loss: 1.1685 - val_accuracy: 0.5942\n",
      "Epoch 1155/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1123 - accuracy: 0.6211 - val_loss: 1.1631 - val_accuracy: 0.5909\n",
      "Epoch 1156/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0523 - accuracy: 0.6466 - val_loss: 1.1604 - val_accuracy: 0.5942\n",
      "Epoch 1157/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0600 - accuracy: 0.6270 - val_loss: 1.1506 - val_accuracy: 0.6104\n",
      "Epoch 1158/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.0771 - accuracy: 0.6285 - val_loss: 1.1488 - val_accuracy: 0.6136\n",
      "Epoch 1159/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0744 - accuracy: 0.6230 - val_loss: 1.1392 - val_accuracy: 0.6234\n",
      "Epoch 1160/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1228 - accuracy: 0.6369 - val_loss: 1.1312 - val_accuracy: 0.6169\n",
      "Epoch 1161/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0662 - accuracy: 0.6309 - val_loss: 1.1282 - val_accuracy: 0.5942\n",
      "Epoch 1162/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1267 - accuracy: 0.6215 - val_loss: 1.1308 - val_accuracy: 0.5747\n",
      "Epoch 1163/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0885 - accuracy: 0.6230 - val_loss: 1.1315 - val_accuracy: 0.5747\n",
      "Epoch 1164/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0370 - accuracy: 0.6338 - val_loss: 1.1388 - val_accuracy: 0.5812\n",
      "Epoch 1165/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0981 - accuracy: 0.6285 - val_loss: 1.1546 - val_accuracy: 0.5779\n",
      "Epoch 1166/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0811 - accuracy: 0.6211 - val_loss: 1.1694 - val_accuracy: 0.5714\n",
      "Epoch 1167/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1701 - accuracy: 0.6006 - val_loss: 1.1787 - val_accuracy: 0.5747\n",
      "Epoch 1168/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1059 - accuracy: 0.6494 - val_loss: 1.1804 - val_accuracy: 0.5779\n",
      "Epoch 1169/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0844 - accuracy: 0.6369 - val_loss: 1.1846 - val_accuracy: 0.5779\n",
      "Epoch 1170/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0303 - accuracy: 0.6504 - val_loss: 1.1970 - val_accuracy: 0.5844\n",
      "Epoch 1171/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0819 - accuracy: 0.6426 - val_loss: 1.2008 - val_accuracy: 0.5909\n",
      "Epoch 1172/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1226 - accuracy: 0.6162 - val_loss: 1.1930 - val_accuracy: 0.5779\n",
      "Epoch 1173/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0357 - accuracy: 0.6550 - val_loss: 1.1889 - val_accuracy: 0.5844\n",
      "Epoch 1174/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0722 - accuracy: 0.6397 - val_loss: 1.1821 - val_accuracy: 0.5747\n",
      "Epoch 1175/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0585 - accuracy: 0.6426 - val_loss: 1.1738 - val_accuracy: 0.5779\n",
      "Epoch 1176/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0388 - accuracy: 0.6536 - val_loss: 1.1643 - val_accuracy: 0.5877\n",
      "Epoch 1177/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1054 - accuracy: 0.6240 - val_loss: 1.1613 - val_accuracy: 0.5974\n",
      "Epoch 1178/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0460 - accuracy: 0.6387 - val_loss: 1.1633 - val_accuracy: 0.5942\n",
      "Epoch 1179/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1101 - accuracy: 0.6270 - val_loss: 1.1798 - val_accuracy: 0.5812\n",
      "Epoch 1180/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1432 - accuracy: 0.6327 - val_loss: 1.1917 - val_accuracy: 0.5747\n",
      "Epoch 1181/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0415 - accuracy: 0.6439 - val_loss: 1.1889 - val_accuracy: 0.6104\n",
      "Epoch 1182/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0912 - accuracy: 0.6387 - val_loss: 1.1673 - val_accuracy: 0.6104\n",
      "Epoch 1183/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1005 - accuracy: 0.6131 - val_loss: 1.1425 - val_accuracy: 0.6169\n",
      "Epoch 1184/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0978 - accuracy: 0.6328 - val_loss: 1.1180 - val_accuracy: 0.6234\n",
      "Epoch 1185/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0899 - accuracy: 0.6289 - val_loss: 1.0981 - val_accuracy: 0.6039\n",
      "Epoch 1186/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0244 - accuracy: 0.6508 - val_loss: 1.0873 - val_accuracy: 0.6169\n",
      "Epoch 1187/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1087 - accuracy: 0.6240 - val_loss: 1.1045 - val_accuracy: 0.6169\n",
      "Epoch 1188/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0618 - accuracy: 0.6348 - val_loss: 1.1269 - val_accuracy: 0.6104\n",
      "Epoch 1189/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0734 - accuracy: 0.6260 - val_loss: 1.1488 - val_accuracy: 0.5942\n",
      "Epoch 1190/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0806 - accuracy: 0.6289 - val_loss: 1.1920 - val_accuracy: 0.5974\n",
      "Epoch 1191/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0684 - accuracy: 0.6377 - val_loss: 1.2183 - val_accuracy: 0.5909\n",
      "Epoch 1192/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0424 - accuracy: 0.6369 - val_loss: 1.2524 - val_accuracy: 0.5877\n",
      "Epoch 1193/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0467 - accuracy: 0.6426 - val_loss: 1.2665 - val_accuracy: 0.5844\n",
      "Epoch 1194/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0370 - accuracy: 0.6536 - val_loss: 1.2554 - val_accuracy: 0.5844\n",
      "Epoch 1195/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0374 - accuracy: 0.6480 - val_loss: 1.2496 - val_accuracy: 0.5877\n",
      "Epoch 1196/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0797 - accuracy: 0.6113 - val_loss: 1.2572 - val_accuracy: 0.5844\n",
      "Epoch 1197/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0541 - accuracy: 0.6543 - val_loss: 1.2729 - val_accuracy: 0.5812\n",
      "Epoch 1198/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0505 - accuracy: 0.6355 - val_loss: 1.3056 - val_accuracy: 0.5649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1199/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1041 - accuracy: 0.6191 - val_loss: 1.3476 - val_accuracy: 0.5714\n",
      "Epoch 1200/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0735 - accuracy: 0.6348 - val_loss: 1.3675 - val_accuracy: 0.5617\n",
      "Epoch 1201/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0849 - accuracy: 0.6338 - val_loss: 1.3686 - val_accuracy: 0.5584\n",
      "Epoch 1202/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0975 - accuracy: 0.6445 - val_loss: 1.3793 - val_accuracy: 0.5552\n",
      "Epoch 1203/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0328 - accuracy: 0.6523 - val_loss: 1.3727 - val_accuracy: 0.5617\n",
      "Epoch 1204/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0505 - accuracy: 0.6257 - val_loss: 1.3932 - val_accuracy: 0.5455\n",
      "Epoch 1205/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0169 - accuracy: 0.6522 - val_loss: 1.4052 - val_accuracy: 0.5455\n",
      "Epoch 1206/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0235 - accuracy: 0.6465 - val_loss: 1.4137 - val_accuracy: 0.5390\n",
      "Epoch 1207/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0551 - accuracy: 0.6367 - val_loss: 1.4393 - val_accuracy: 0.5357\n",
      "Epoch 1208/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0090 - accuracy: 0.6522 - val_loss: 1.4223 - val_accuracy: 0.5325\n",
      "Epoch 1209/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1371 - accuracy: 0.6182 - val_loss: 1.3974 - val_accuracy: 0.5390\n",
      "Epoch 1210/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0428 - accuracy: 0.6411 - val_loss: 1.3710 - val_accuracy: 0.5422\n",
      "Epoch 1211/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1033 - accuracy: 0.6250 - val_loss: 1.3407 - val_accuracy: 0.5552\n",
      "Epoch 1212/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1013 - accuracy: 0.6172 - val_loss: 1.3072 - val_accuracy: 0.5682\n",
      "Epoch 1213/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0115 - accuracy: 0.6704 - val_loss: 1.3113 - val_accuracy: 0.5714\n",
      "Epoch 1214/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0264 - accuracy: 0.6357 - val_loss: 1.3278 - val_accuracy: 0.5682\n",
      "Epoch 1215/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0848 - accuracy: 0.6367 - val_loss: 1.3459 - val_accuracy: 0.5487\n",
      "Epoch 1216/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0575 - accuracy: 0.6465 - val_loss: 1.3490 - val_accuracy: 0.5487\n",
      "Epoch 1217/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0033 - accuracy: 0.6662 - val_loss: 1.3412 - val_accuracy: 0.5455\n",
      "Epoch 1218/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0377 - accuracy: 0.6411 - val_loss: 1.3149 - val_accuracy: 0.5552\n",
      "Epoch 1219/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0666 - accuracy: 0.6355 - val_loss: 1.2897 - val_accuracy: 0.5519\n",
      "Epoch 1220/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0136 - accuracy: 0.6550 - val_loss: 1.2604 - val_accuracy: 0.5682\n",
      "Epoch 1221/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9955 - accuracy: 0.6650 - val_loss: 1.2333 - val_accuracy: 0.5682\n",
      "Epoch 1222/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0765 - accuracy: 0.6318 - val_loss: 1.2057 - val_accuracy: 0.5779\n",
      "Epoch 1223/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0546 - accuracy: 0.6387 - val_loss: 1.1909 - val_accuracy: 0.5844\n",
      "Epoch 1224/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0430 - accuracy: 0.6455 - val_loss: 1.2011 - val_accuracy: 0.5812\n",
      "Epoch 1225/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0412 - accuracy: 0.6522 - val_loss: 1.2430 - val_accuracy: 0.5747\n",
      "Epoch 1226/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0388 - accuracy: 0.6533 - val_loss: 1.2949 - val_accuracy: 0.5649\n",
      "Epoch 1227/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0026 - accuracy: 0.6611 - val_loss: 1.3389 - val_accuracy: 0.5487\n",
      "Epoch 1228/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0843 - accuracy: 0.6355 - val_loss: 1.3568 - val_accuracy: 0.5519\n",
      "Epoch 1229/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0324 - accuracy: 0.6411 - val_loss: 1.3612 - val_accuracy: 0.5487\n",
      "Epoch 1230/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0718 - accuracy: 0.6367 - val_loss: 1.3389 - val_accuracy: 0.5552\n",
      "Epoch 1231/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0991 - accuracy: 0.6313 - val_loss: 1.3441 - val_accuracy: 0.5617\n",
      "Epoch 1232/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0451 - accuracy: 0.6348 - val_loss: 1.3693 - val_accuracy: 0.5552\n",
      "Epoch 1233/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0908 - accuracy: 0.6466 - val_loss: 1.3741 - val_accuracy: 0.5552\n",
      "Epoch 1234/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0111 - accuracy: 0.6709 - val_loss: 1.4032 - val_accuracy: 0.5519\n",
      "Epoch 1235/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0466 - accuracy: 0.6377 - val_loss: 1.4311 - val_accuracy: 0.5357\n",
      "Epoch 1236/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0357 - accuracy: 0.6453 - val_loss: 1.4237 - val_accuracy: 0.5357\n",
      "Epoch 1237/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9842 - accuracy: 0.6729 - val_loss: 1.4091 - val_accuracy: 0.5455\n",
      "Epoch 1238/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0321 - accuracy: 0.6453 - val_loss: 1.3565 - val_accuracy: 0.5617\n",
      "Epoch 1239/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0915 - accuracy: 0.6338 - val_loss: 1.3121 - val_accuracy: 0.5682\n",
      "Epoch 1240/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0205 - accuracy: 0.6536 - val_loss: 1.2630 - val_accuracy: 0.5747\n",
      "Epoch 1241/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0268 - accuracy: 0.6508 - val_loss: 1.2469 - val_accuracy: 0.5779\n",
      "Epoch 1242/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0682 - accuracy: 0.6285 - val_loss: 1.2306 - val_accuracy: 0.5747\n",
      "Epoch 1243/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0793 - accuracy: 0.6313 - val_loss: 1.2186 - val_accuracy: 0.5877\n",
      "Epoch 1244/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9883 - accuracy: 0.6650 - val_loss: 1.2180 - val_accuracy: 0.5877\n",
      "Epoch 1245/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0763 - accuracy: 0.6327 - val_loss: 1.2305 - val_accuracy: 0.5844\n",
      "Epoch 1246/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0585 - accuracy: 0.6411 - val_loss: 1.2647 - val_accuracy: 0.5779\n",
      "Epoch 1247/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0076 - accuracy: 0.6523 - val_loss: 1.2985 - val_accuracy: 0.5779\n",
      "Epoch 1248/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0817 - accuracy: 0.6250 - val_loss: 1.3202 - val_accuracy: 0.5812\n",
      "Epoch 1249/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0303 - accuracy: 0.6411 - val_loss: 1.3177 - val_accuracy: 0.5747\n",
      "Epoch 1250/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0017 - accuracy: 0.6582 - val_loss: 1.3021 - val_accuracy: 0.5682\n",
      "Epoch 1251/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0408 - accuracy: 0.6872 - val_loss: 1.2974 - val_accuracy: 0.5617\n",
      "Epoch 1252/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0425 - accuracy: 0.6550 - val_loss: 1.2969 - val_accuracy: 0.5422\n",
      "Epoch 1253/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0416 - accuracy: 0.6522 - val_loss: 1.3080 - val_accuracy: 0.5292\n",
      "Epoch 1254/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0324 - accuracy: 0.6564 - val_loss: 1.2976 - val_accuracy: 0.5390\n",
      "Epoch 1255/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1154 - accuracy: 0.6348 - val_loss: 1.2649 - val_accuracy: 0.5519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1256/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9710 - accuracy: 0.6660 - val_loss: 1.2305 - val_accuracy: 0.5682\n",
      "Epoch 1257/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0238 - accuracy: 0.6606 - val_loss: 1.2512 - val_accuracy: 0.5812\n",
      "Epoch 1258/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.0424 - accuracy: 0.6494 - val_loss: 1.2700 - val_accuracy: 0.5779\n",
      "Epoch 1259/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1036 - accuracy: 0.6055 - val_loss: 1.2601 - val_accuracy: 0.5779\n",
      "Epoch 1260/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0136 - accuracy: 0.6634 - val_loss: 1.2257 - val_accuracy: 0.5942\n",
      "Epoch 1261/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9823 - accuracy: 0.6816 - val_loss: 1.1874 - val_accuracy: 0.5974\n",
      "Epoch 1262/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0253 - accuracy: 0.6453 - val_loss: 1.1527 - val_accuracy: 0.5942\n",
      "Epoch 1263/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0434 - accuracy: 0.6533 - val_loss: 1.1384 - val_accuracy: 0.5974\n",
      "Epoch 1264/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0067 - accuracy: 0.6504 - val_loss: 1.1308 - val_accuracy: 0.5909\n",
      "Epoch 1265/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0381 - accuracy: 0.6299 - val_loss: 1.1456 - val_accuracy: 0.6104\n",
      "Epoch 1266/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0040 - accuracy: 0.6572 - val_loss: 1.1615 - val_accuracy: 0.6071\n",
      "Epoch 1267/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9896 - accuracy: 0.6660 - val_loss: 1.1733 - val_accuracy: 0.5909\n",
      "Epoch 1268/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9906 - accuracy: 0.6729 - val_loss: 1.1880 - val_accuracy: 0.5942\n",
      "Epoch 1269/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9883 - accuracy: 0.6816 - val_loss: 1.1986 - val_accuracy: 0.5844\n",
      "Epoch 1270/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0412 - accuracy: 0.6406 - val_loss: 1.1911 - val_accuracy: 0.5812\n",
      "Epoch 1271/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0655 - accuracy: 0.6397 - val_loss: 1.1705 - val_accuracy: 0.5877\n",
      "Epoch 1272/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0183 - accuracy: 0.6508 - val_loss: 1.1399 - val_accuracy: 0.5974\n",
      "Epoch 1273/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9494 - accuracy: 0.6680 - val_loss: 1.1046 - val_accuracy: 0.6071\n",
      "Epoch 1274/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0437 - accuracy: 0.6369 - val_loss: 1.0852 - val_accuracy: 0.6104\n",
      "Epoch 1275/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0316 - accuracy: 0.6536 - val_loss: 1.0759 - val_accuracy: 0.6104\n",
      "Epoch 1276/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0409 - accuracy: 0.6313 - val_loss: 1.0758 - val_accuracy: 0.6039\n",
      "Epoch 1277/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0658 - accuracy: 0.6494 - val_loss: 1.0758 - val_accuracy: 0.6136\n",
      "Epoch 1278/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9940 - accuracy: 0.6662 - val_loss: 1.0959 - val_accuracy: 0.6234\n",
      "Epoch 1279/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9522 - accuracy: 0.6865 - val_loss: 1.1112 - val_accuracy: 0.6136\n",
      "Epoch 1280/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9935 - accuracy: 0.6631 - val_loss: 1.1101 - val_accuracy: 0.6234\n",
      "Epoch 1281/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9629 - accuracy: 0.6788 - val_loss: 1.0902 - val_accuracy: 0.6266\n",
      "Epoch 1282/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0311 - accuracy: 0.6660 - val_loss: 1.0708 - val_accuracy: 0.6331\n",
      "Epoch 1283/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9700 - accuracy: 0.6453 - val_loss: 1.0571 - val_accuracy: 0.6364\n",
      "Epoch 1284/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9929 - accuracy: 0.6680 - val_loss: 1.0640 - val_accuracy: 0.6299\n",
      "Epoch 1285/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0177 - accuracy: 0.6648 - val_loss: 1.0841 - val_accuracy: 0.6169\n",
      "Epoch 1286/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0257 - accuracy: 0.6578 - val_loss: 1.1142 - val_accuracy: 0.6201\n",
      "Epoch 1287/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0137 - accuracy: 0.6436 - val_loss: 1.1546 - val_accuracy: 0.6006\n",
      "Epoch 1288/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9735 - accuracy: 0.6662 - val_loss: 1.2072 - val_accuracy: 0.6006\n",
      "Epoch 1289/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9555 - accuracy: 0.6924 - val_loss: 1.2431 - val_accuracy: 0.6071\n",
      "Epoch 1290/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9863 - accuracy: 0.6690 - val_loss: 1.2512 - val_accuracy: 0.5974\n",
      "Epoch 1291/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9833 - accuracy: 0.6484 - val_loss: 1.2292 - val_accuracy: 0.6071\n",
      "Epoch 1292/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9950 - accuracy: 0.6572 - val_loss: 1.2171 - val_accuracy: 0.5942\n",
      "Epoch 1293/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0168 - accuracy: 0.6550 - val_loss: 1.2084 - val_accuracy: 0.6006\n",
      "Epoch 1294/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9739 - accuracy: 0.6955 - val_loss: 1.1851 - val_accuracy: 0.6201\n",
      "Epoch 1295/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9530 - accuracy: 0.6872 - val_loss: 1.1399 - val_accuracy: 0.6201\n",
      "Epoch 1296/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0168 - accuracy: 0.6621 - val_loss: 1.1148 - val_accuracy: 0.6136\n",
      "Epoch 1297/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9978 - accuracy: 0.6611 - val_loss: 1.1065 - val_accuracy: 0.6136\n",
      "Epoch 1298/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9997 - accuracy: 0.6578 - val_loss: 1.1015 - val_accuracy: 0.6201\n",
      "Epoch 1299/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9799 - accuracy: 0.6802 - val_loss: 1.1128 - val_accuracy: 0.6201\n",
      "Epoch 1300/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9750 - accuracy: 0.6738 - val_loss: 1.1304 - val_accuracy: 0.6136\n",
      "Epoch 1301/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9795 - accuracy: 0.6760 - val_loss: 1.1459 - val_accuracy: 0.6071\n",
      "Epoch 1302/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9485 - accuracy: 0.6758 - val_loss: 1.1549 - val_accuracy: 0.6039\n",
      "Epoch 1303/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9432 - accuracy: 0.6760 - val_loss: 1.1561 - val_accuracy: 0.6006\n",
      "Epoch 1304/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0031 - accuracy: 0.6611 - val_loss: 1.1693 - val_accuracy: 0.5974\n",
      "Epoch 1305/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0025 - accuracy: 0.6641 - val_loss: 1.1589 - val_accuracy: 0.6039\n",
      "Epoch 1306/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9675 - accuracy: 0.6631 - val_loss: 1.1347 - val_accuracy: 0.6136\n",
      "Epoch 1307/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9737 - accuracy: 0.6777 - val_loss: 1.1015 - val_accuracy: 0.6299\n",
      "Epoch 1308/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9655 - accuracy: 0.6797 - val_loss: 1.0749 - val_accuracy: 0.6364\n",
      "Epoch 1309/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9393 - accuracy: 0.6875 - val_loss: 1.0584 - val_accuracy: 0.6429\n",
      "Epoch 1310/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9726 - accuracy: 0.6592 - val_loss: 1.0465 - val_accuracy: 0.6396\n",
      "Epoch 1311/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9466 - accuracy: 0.6844 - val_loss: 1.0427 - val_accuracy: 0.6494\n",
      "Epoch 1312/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9486 - accuracy: 0.6865 - val_loss: 1.0410 - val_accuracy: 0.6461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1313/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9726 - accuracy: 0.6816 - val_loss: 1.0493 - val_accuracy: 0.6266\n",
      "Epoch 1314/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0321 - accuracy: 0.6602 - val_loss: 1.0572 - val_accuracy: 0.6266\n",
      "Epoch 1315/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9759 - accuracy: 0.6699 - val_loss: 1.0698 - val_accuracy: 0.6364\n",
      "Epoch 1316/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9165 - accuracy: 0.6836 - val_loss: 1.0696 - val_accuracy: 0.6299\n",
      "Epoch 1317/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9605 - accuracy: 0.6924 - val_loss: 1.0667 - val_accuracy: 0.6364\n",
      "Epoch 1318/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9307 - accuracy: 0.6758 - val_loss: 1.0716 - val_accuracy: 0.6364\n",
      "Epoch 1319/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9961 - accuracy: 0.6718 - val_loss: 1.0687 - val_accuracy: 0.6429\n",
      "Epoch 1320/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9725 - accuracy: 0.6718 - val_loss: 1.0691 - val_accuracy: 0.6331\n",
      "Epoch 1321/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9605 - accuracy: 0.6802 - val_loss: 1.0539 - val_accuracy: 0.6364\n",
      "Epoch 1322/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9323 - accuracy: 0.6768 - val_loss: 1.0502 - val_accuracy: 0.6266\n",
      "Epoch 1323/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9543 - accuracy: 0.6858 - val_loss: 1.0570 - val_accuracy: 0.6266\n",
      "Epoch 1324/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9393 - accuracy: 0.6844 - val_loss: 1.0673 - val_accuracy: 0.6299\n",
      "Epoch 1325/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9339 - accuracy: 0.6746 - val_loss: 1.0852 - val_accuracy: 0.6234\n",
      "Epoch 1326/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0095 - accuracy: 0.6504 - val_loss: 1.0984 - val_accuracy: 0.6169\n",
      "Epoch 1327/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9856 - accuracy: 0.6729 - val_loss: 1.0902 - val_accuracy: 0.6039\n",
      "Epoch 1328/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9673 - accuracy: 0.6621 - val_loss: 1.0793 - val_accuracy: 0.6006\n",
      "Epoch 1329/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9301 - accuracy: 0.6941 - val_loss: 1.0763 - val_accuracy: 0.6201\n",
      "Epoch 1330/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9668 - accuracy: 0.6830 - val_loss: 1.0749 - val_accuracy: 0.6234\n",
      "Epoch 1331/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9747 - accuracy: 0.6729 - val_loss: 1.0815 - val_accuracy: 0.6234\n",
      "Epoch 1332/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9257 - accuracy: 0.6969 - val_loss: 1.0964 - val_accuracy: 0.6071\n",
      "Epoch 1333/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0539 - accuracy: 0.6328 - val_loss: 1.1074 - val_accuracy: 0.6104\n",
      "Epoch 1334/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9592 - accuracy: 0.6774 - val_loss: 1.1167 - val_accuracy: 0.6104\n",
      "Epoch 1335/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9716 - accuracy: 0.6592 - val_loss: 1.1390 - val_accuracy: 0.6104\n",
      "Epoch 1336/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9502 - accuracy: 0.6816 - val_loss: 1.1435 - val_accuracy: 0.6071\n",
      "Epoch 1337/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9798 - accuracy: 0.6872 - val_loss: 1.1409 - val_accuracy: 0.6136\n",
      "Epoch 1338/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9908 - accuracy: 0.6606 - val_loss: 1.1430 - val_accuracy: 0.6169\n",
      "Epoch 1339/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9257 - accuracy: 0.6844 - val_loss: 1.1365 - val_accuracy: 0.6104\n",
      "Epoch 1340/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9422 - accuracy: 0.6895 - val_loss: 1.1272 - val_accuracy: 0.6169\n",
      "Epoch 1341/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9653 - accuracy: 0.6621 - val_loss: 1.1096 - val_accuracy: 0.6201\n",
      "Epoch 1342/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9158 - accuracy: 0.6963 - val_loss: 1.0835 - val_accuracy: 0.6331\n",
      "Epoch 1343/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9845 - accuracy: 0.6689 - val_loss: 1.0830 - val_accuracy: 0.6364\n",
      "Epoch 1344/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8784 - accuracy: 0.7123 - val_loss: 1.0837 - val_accuracy: 0.6299\n",
      "Epoch 1345/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9445 - accuracy: 0.6872 - val_loss: 1.0930 - val_accuracy: 0.6396\n",
      "Epoch 1346/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9643 - accuracy: 0.6802 - val_loss: 1.0989 - val_accuracy: 0.6266\n",
      "Epoch 1347/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0106 - accuracy: 0.6582 - val_loss: 1.1112 - val_accuracy: 0.6234\n",
      "Epoch 1348/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9384 - accuracy: 0.6858 - val_loss: 1.1537 - val_accuracy: 0.6136\n",
      "Epoch 1349/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9545 - accuracy: 0.6885 - val_loss: 1.2026 - val_accuracy: 0.6039\n",
      "Epoch 1350/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9433 - accuracy: 0.6620 - val_loss: 1.2300 - val_accuracy: 0.5974\n",
      "Epoch 1351/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9353 - accuracy: 0.6885 - val_loss: 1.2798 - val_accuracy: 0.5877\n",
      "Epoch 1352/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9376 - accuracy: 0.6914 - val_loss: 1.3333 - val_accuracy: 0.5779\n",
      "Epoch 1353/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9750 - accuracy: 0.6564 - val_loss: 1.3509 - val_accuracy: 0.5617\n",
      "Epoch 1354/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9598 - accuracy: 0.6621 - val_loss: 1.3297 - val_accuracy: 0.5487\n",
      "Epoch 1355/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9071 - accuracy: 0.6973 - val_loss: 1.2970 - val_accuracy: 0.5487\n",
      "Epoch 1356/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9436 - accuracy: 0.6927 - val_loss: 1.2562 - val_accuracy: 0.5584\n",
      "Epoch 1357/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9916 - accuracy: 0.6494 - val_loss: 1.2166 - val_accuracy: 0.5812\n",
      "Epoch 1358/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9619 - accuracy: 0.6836 - val_loss: 1.1843 - val_accuracy: 0.5779\n",
      "Epoch 1359/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9463 - accuracy: 0.6830 - val_loss: 1.1707 - val_accuracy: 0.5844\n",
      "Epoch 1360/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9711 - accuracy: 0.6816 - val_loss: 1.1553 - val_accuracy: 0.6039\n",
      "Epoch 1361/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9865 - accuracy: 0.6592 - val_loss: 1.1503 - val_accuracy: 0.6234\n",
      "Epoch 1362/4000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9266 - accuracy: 0.6807 - val_loss: 1.1422 - val_accuracy: 0.6169\n",
      "Epoch 1363/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9628 - accuracy: 0.6983 - val_loss: 1.1501 - val_accuracy: 0.6169\n",
      "Epoch 1364/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9037 - accuracy: 0.6914 - val_loss: 1.1645 - val_accuracy: 0.6071\n",
      "Epoch 1365/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9316 - accuracy: 0.6904 - val_loss: 1.1633 - val_accuracy: 0.6136\n",
      "Epoch 1366/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0076 - accuracy: 0.6602 - val_loss: 1.1713 - val_accuracy: 0.6136\n",
      "Epoch 1367/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9260 - accuracy: 0.6826 - val_loss: 1.1902 - val_accuracy: 0.5909\n",
      "Epoch 1368/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8984 - accuracy: 0.7053 - val_loss: 1.1988 - val_accuracy: 0.5909\n",
      "Epoch 1369/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9653 - accuracy: 0.6855 - val_loss: 1.1971 - val_accuracy: 0.5909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1370/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9536 - accuracy: 0.6836 - val_loss: 1.1855 - val_accuracy: 0.5909\n",
      "Epoch 1371/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8744 - accuracy: 0.6941 - val_loss: 1.1664 - val_accuracy: 0.5877\n",
      "Epoch 1372/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9765 - accuracy: 0.6680 - val_loss: 1.1423 - val_accuracy: 0.5909\n",
      "Epoch 1373/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9388 - accuracy: 0.6760 - val_loss: 1.1295 - val_accuracy: 0.6006\n",
      "Epoch 1374/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9582 - accuracy: 0.6774 - val_loss: 1.1451 - val_accuracy: 0.5974\n",
      "Epoch 1375/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9122 - accuracy: 0.6826 - val_loss: 1.1526 - val_accuracy: 0.5974\n",
      "Epoch 1376/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9427 - accuracy: 0.6816 - val_loss: 1.1432 - val_accuracy: 0.6136\n",
      "Epoch 1377/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9284 - accuracy: 0.6895 - val_loss: 1.1468 - val_accuracy: 0.6169\n",
      "Epoch 1378/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9498 - accuracy: 0.6846 - val_loss: 1.1700 - val_accuracy: 0.6071\n",
      "Epoch 1379/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9552 - accuracy: 0.6797 - val_loss: 1.2065 - val_accuracy: 0.6006\n",
      "Epoch 1380/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9377 - accuracy: 0.6826 - val_loss: 1.2155 - val_accuracy: 0.6039\n",
      "Epoch 1381/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8888 - accuracy: 0.6924 - val_loss: 1.2180 - val_accuracy: 0.6104\n",
      "Epoch 1382/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9844 - accuracy: 0.6826 - val_loss: 1.2309 - val_accuracy: 0.6039\n",
      "Epoch 1383/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0134 - accuracy: 0.6746 - val_loss: 1.2137 - val_accuracy: 0.6039\n",
      "Epoch 1384/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8902 - accuracy: 0.7039 - val_loss: 1.1814 - val_accuracy: 0.6201\n",
      "Epoch 1385/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8643 - accuracy: 0.7151 - val_loss: 1.1582 - val_accuracy: 0.6201\n",
      "Epoch 1386/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8888 - accuracy: 0.6885 - val_loss: 1.1484 - val_accuracy: 0.6299\n",
      "Epoch 1387/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8558 - accuracy: 0.7053 - val_loss: 1.1436 - val_accuracy: 0.6299\n",
      "Epoch 1388/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9920 - accuracy: 0.6611 - val_loss: 1.1386 - val_accuracy: 0.6331\n",
      "Epoch 1389/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9511 - accuracy: 0.6924 - val_loss: 1.1259 - val_accuracy: 0.6299\n",
      "Epoch 1390/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9442 - accuracy: 0.6816 - val_loss: 1.1137 - val_accuracy: 0.6234\n",
      "Epoch 1391/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9256 - accuracy: 0.6875 - val_loss: 1.1062 - val_accuracy: 0.6201\n",
      "Epoch 1392/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9413 - accuracy: 0.7025 - val_loss: 1.1034 - val_accuracy: 0.6201\n",
      "Epoch 1393/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8948 - accuracy: 0.7151 - val_loss: 1.1014 - val_accuracy: 0.6299\n",
      "Epoch 1394/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9131 - accuracy: 0.6836 - val_loss: 1.1007 - val_accuracy: 0.6266\n",
      "Epoch 1395/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8910 - accuracy: 0.7041 - val_loss: 1.1061 - val_accuracy: 0.6266\n",
      "Epoch 1396/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8997 - accuracy: 0.7151 - val_loss: 1.1167 - val_accuracy: 0.6299\n",
      "Epoch 1397/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9383 - accuracy: 0.6858 - val_loss: 1.1273 - val_accuracy: 0.6234\n",
      "Epoch 1398/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.9202 - accuracy: 0.7002 - val_loss: 1.1291 - val_accuracy: 0.6299\n",
      "Epoch 1399/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9362 - accuracy: 0.6913 - val_loss: 1.1293 - val_accuracy: 0.6364\n",
      "Epoch 1400/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8703 - accuracy: 0.7031 - val_loss: 1.1147 - val_accuracy: 0.6396\n",
      "Epoch 1401/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9006 - accuracy: 0.6941 - val_loss: 1.1004 - val_accuracy: 0.6429\n",
      "Epoch 1402/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9688 - accuracy: 0.6816 - val_loss: 1.0894 - val_accuracy: 0.6494\n",
      "Epoch 1403/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9083 - accuracy: 0.6872 - val_loss: 1.0921 - val_accuracy: 0.6429\n",
      "Epoch 1404/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8995 - accuracy: 0.6973 - val_loss: 1.1014 - val_accuracy: 0.6396\n",
      "Epoch 1405/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8987 - accuracy: 0.6885 - val_loss: 1.1067 - val_accuracy: 0.6364\n",
      "Epoch 1406/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9403 - accuracy: 0.6885 - val_loss: 1.1118 - val_accuracy: 0.6299\n",
      "Epoch 1407/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9787 - accuracy: 0.6826 - val_loss: 1.1092 - val_accuracy: 0.6266\n",
      "Epoch 1408/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9291 - accuracy: 0.6846 - val_loss: 1.1050 - val_accuracy: 0.6201\n",
      "Epoch 1409/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8551 - accuracy: 0.7197 - val_loss: 1.1097 - val_accuracy: 0.6201\n",
      "Epoch 1410/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9232 - accuracy: 0.7109 - val_loss: 1.1210 - val_accuracy: 0.6136\n",
      "Epoch 1411/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9108 - accuracy: 0.6787 - val_loss: 1.1281 - val_accuracy: 0.6266\n",
      "Epoch 1412/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8607 - accuracy: 0.7039 - val_loss: 1.1325 - val_accuracy: 0.6104\n",
      "Epoch 1413/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8824 - accuracy: 0.7002 - val_loss: 1.1291 - val_accuracy: 0.6136\n",
      "Epoch 1414/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9167 - accuracy: 0.6943 - val_loss: 1.1197 - val_accuracy: 0.6071\n",
      "Epoch 1415/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9447 - accuracy: 0.6899 - val_loss: 1.1122 - val_accuracy: 0.6396\n",
      "Epoch 1416/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8932 - accuracy: 0.7051 - val_loss: 1.1062 - val_accuracy: 0.6364\n",
      "Epoch 1417/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9209 - accuracy: 0.6934 - val_loss: 1.0899 - val_accuracy: 0.6331\n",
      "Epoch 1418/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9057 - accuracy: 0.6913 - val_loss: 1.0770 - val_accuracy: 0.6429\n",
      "Epoch 1419/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8591 - accuracy: 0.7137 - val_loss: 1.0628 - val_accuracy: 0.6396\n",
      "Epoch 1420/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9304 - accuracy: 0.6865 - val_loss: 1.0532 - val_accuracy: 0.6494\n",
      "Epoch 1421/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8719 - accuracy: 0.6913 - val_loss: 1.0447 - val_accuracy: 0.6494\n",
      "Epoch 1422/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8761 - accuracy: 0.7109 - val_loss: 1.0419 - val_accuracy: 0.6494\n",
      "Epoch 1423/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8821 - accuracy: 0.7025 - val_loss: 1.0535 - val_accuracy: 0.6429\n",
      "Epoch 1424/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8685 - accuracy: 0.7123 - val_loss: 1.0701 - val_accuracy: 0.6396\n",
      "Epoch 1425/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8948 - accuracy: 0.6992 - val_loss: 1.0952 - val_accuracy: 0.6494\n",
      "Epoch 1426/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9342 - accuracy: 0.7081 - val_loss: 1.1479 - val_accuracy: 0.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1427/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9357 - accuracy: 0.6858 - val_loss: 1.1937 - val_accuracy: 0.6104\n",
      "Epoch 1428/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8900 - accuracy: 0.7158 - val_loss: 1.2270 - val_accuracy: 0.5974\n",
      "Epoch 1429/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8966 - accuracy: 0.6973 - val_loss: 1.1997 - val_accuracy: 0.6006\n",
      "Epoch 1430/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8488 - accuracy: 0.7123 - val_loss: 1.1691 - val_accuracy: 0.6104\n",
      "Epoch 1431/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9171 - accuracy: 0.6914 - val_loss: 1.1402 - val_accuracy: 0.6104\n",
      "Epoch 1432/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8458 - accuracy: 0.7179 - val_loss: 1.1447 - val_accuracy: 0.6071\n",
      "Epoch 1433/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9064 - accuracy: 0.6997 - val_loss: 1.1808 - val_accuracy: 0.5942\n",
      "Epoch 1434/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9279 - accuracy: 0.6913 - val_loss: 1.2626 - val_accuracy: 0.5714\n",
      "Epoch 1435/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8880 - accuracy: 0.6963 - val_loss: 1.3415 - val_accuracy: 0.5422\n",
      "Epoch 1436/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9035 - accuracy: 0.6982 - val_loss: 1.4038 - val_accuracy: 0.5325\n",
      "Epoch 1437/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8458 - accuracy: 0.7227 - val_loss: 1.4064 - val_accuracy: 0.5390\n",
      "Epoch 1438/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8818 - accuracy: 0.6802 - val_loss: 1.3843 - val_accuracy: 0.5519\n",
      "Epoch 1439/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8629 - accuracy: 0.7227 - val_loss: 1.3598 - val_accuracy: 0.5714\n",
      "Epoch 1440/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9154 - accuracy: 0.6914 - val_loss: 1.3075 - val_accuracy: 0.5714\n",
      "Epoch 1441/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9279 - accuracy: 0.6802 - val_loss: 1.2435 - val_accuracy: 0.5844\n",
      "Epoch 1442/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8411 - accuracy: 0.7246 - val_loss: 1.1859 - val_accuracy: 0.6169\n",
      "Epoch 1443/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9494 - accuracy: 0.6997 - val_loss: 1.1455 - val_accuracy: 0.6299\n",
      "Epoch 1444/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8914 - accuracy: 0.6872 - val_loss: 1.1241 - val_accuracy: 0.6299\n",
      "Epoch 1445/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9094 - accuracy: 0.6927 - val_loss: 1.1072 - val_accuracy: 0.6429\n",
      "Epoch 1446/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9300 - accuracy: 0.6816 - val_loss: 1.0969 - val_accuracy: 0.6591\n",
      "Epoch 1447/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8533 - accuracy: 0.7081 - val_loss: 1.0959 - val_accuracy: 0.6494\n",
      "Epoch 1448/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9442 - accuracy: 0.7039 - val_loss: 1.1079 - val_accuracy: 0.6429\n",
      "Epoch 1449/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8737 - accuracy: 0.6934 - val_loss: 1.1289 - val_accuracy: 0.6299\n",
      "Epoch 1450/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9435 - accuracy: 0.6943 - val_loss: 1.1628 - val_accuracy: 0.6104\n",
      "Epoch 1451/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8876 - accuracy: 0.6955 - val_loss: 1.2012 - val_accuracy: 0.5942\n",
      "Epoch 1452/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8571 - accuracy: 0.7158 - val_loss: 1.2195 - val_accuracy: 0.6039\n",
      "Epoch 1453/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8745 - accuracy: 0.7095 - val_loss: 1.2142 - val_accuracy: 0.6006\n",
      "Epoch 1454/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8962 - accuracy: 0.6816 - val_loss: 1.2048 - val_accuracy: 0.6104\n",
      "Epoch 1455/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8998 - accuracy: 0.6997 - val_loss: 1.1906 - val_accuracy: 0.6104\n",
      "Epoch 1456/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8783 - accuracy: 0.7095 - val_loss: 1.1845 - val_accuracy: 0.6104\n",
      "Epoch 1457/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8951 - accuracy: 0.7090 - val_loss: 1.1830 - val_accuracy: 0.6104\n",
      "Epoch 1458/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8616 - accuracy: 0.7168 - val_loss: 1.1866 - val_accuracy: 0.6169\n",
      "Epoch 1459/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9256 - accuracy: 0.6872 - val_loss: 1.1842 - val_accuracy: 0.6169\n",
      "Epoch 1460/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8997 - accuracy: 0.7304 - val_loss: 1.1930 - val_accuracy: 0.6071\n",
      "Epoch 1461/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8633 - accuracy: 0.7061 - val_loss: 1.1987 - val_accuracy: 0.6006\n",
      "Epoch 1462/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8313 - accuracy: 0.7246 - val_loss: 1.2185 - val_accuracy: 0.6006\n",
      "Epoch 1463/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8851 - accuracy: 0.6865 - val_loss: 1.2198 - val_accuracy: 0.6006\n",
      "Epoch 1464/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9274 - accuracy: 0.7025 - val_loss: 1.2231 - val_accuracy: 0.5942\n",
      "Epoch 1465/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8321 - accuracy: 0.7344 - val_loss: 1.2294 - val_accuracy: 0.5812\n",
      "Epoch 1466/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8925 - accuracy: 0.7012 - val_loss: 1.2300 - val_accuracy: 0.5779\n",
      "Epoch 1467/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7465 - accuracy: 0.7430 - val_loss: 1.2202 - val_accuracy: 0.5844\n",
      "Epoch 1468/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9545 - accuracy: 0.6826 - val_loss: 1.2051 - val_accuracy: 0.5909\n",
      "Epoch 1469/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8887 - accuracy: 0.7041 - val_loss: 1.1922 - val_accuracy: 0.6006\n",
      "Epoch 1470/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9131 - accuracy: 0.6807 - val_loss: 1.1658 - val_accuracy: 0.6071\n",
      "Epoch 1471/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9058 - accuracy: 0.7012 - val_loss: 1.1489 - val_accuracy: 0.6169\n",
      "Epoch 1472/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8485 - accuracy: 0.7025 - val_loss: 1.1311 - val_accuracy: 0.6136\n",
      "Epoch 1473/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8679 - accuracy: 0.7178 - val_loss: 1.1268 - val_accuracy: 0.6136\n",
      "Epoch 1474/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9061 - accuracy: 0.7109 - val_loss: 1.1533 - val_accuracy: 0.6104\n",
      "Epoch 1475/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9143 - accuracy: 0.6983 - val_loss: 1.1899 - val_accuracy: 0.6006\n",
      "Epoch 1476/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8945 - accuracy: 0.7193 - val_loss: 1.2317 - val_accuracy: 0.5812\n",
      "Epoch 1477/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8539 - accuracy: 0.7061 - val_loss: 1.2665 - val_accuracy: 0.5812\n",
      "Epoch 1478/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8097 - accuracy: 0.7304 - val_loss: 1.3005 - val_accuracy: 0.5779\n",
      "Epoch 1479/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8969 - accuracy: 0.6941 - val_loss: 1.3162 - val_accuracy: 0.5844\n",
      "Epoch 1480/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8976 - accuracy: 0.7109 - val_loss: 1.3098 - val_accuracy: 0.5909\n",
      "Epoch 1481/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8702 - accuracy: 0.7151 - val_loss: 1.2651 - val_accuracy: 0.5909\n",
      "Epoch 1482/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8343 - accuracy: 0.7285 - val_loss: 1.2263 - val_accuracy: 0.5942\n",
      "Epoch 1483/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9393 - accuracy: 0.6904 - val_loss: 1.1803 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1484/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8196 - accuracy: 0.7360 - val_loss: 1.1331 - val_accuracy: 0.6266\n",
      "Epoch 1485/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9236 - accuracy: 0.6955 - val_loss: 1.1074 - val_accuracy: 0.6331\n",
      "Epoch 1486/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8865 - accuracy: 0.7179 - val_loss: 1.0869 - val_accuracy: 0.6266\n",
      "Epoch 1487/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8274 - accuracy: 0.7053 - val_loss: 1.0880 - val_accuracy: 0.6266\n",
      "Epoch 1488/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8508 - accuracy: 0.7165 - val_loss: 1.1132 - val_accuracy: 0.6299\n",
      "Epoch 1489/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8052 - accuracy: 0.7246 - val_loss: 1.1538 - val_accuracy: 0.6071\n",
      "Epoch 1490/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8263 - accuracy: 0.7139 - val_loss: 1.1953 - val_accuracy: 0.6006\n",
      "Epoch 1491/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9064 - accuracy: 0.6997 - val_loss: 1.2296 - val_accuracy: 0.5974\n",
      "Epoch 1492/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8798 - accuracy: 0.6997 - val_loss: 1.2380 - val_accuracy: 0.6039\n",
      "Epoch 1493/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8744 - accuracy: 0.7151 - val_loss: 1.2478 - val_accuracy: 0.6201\n",
      "Epoch 1494/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9081 - accuracy: 0.6955 - val_loss: 1.2203 - val_accuracy: 0.6201\n",
      "Epoch 1495/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8304 - accuracy: 0.7137 - val_loss: 1.2004 - val_accuracy: 0.6201\n",
      "Epoch 1496/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7986 - accuracy: 0.7354 - val_loss: 1.2063 - val_accuracy: 0.6201\n",
      "Epoch 1497/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8639 - accuracy: 0.7090 - val_loss: 1.2230 - val_accuracy: 0.6104\n",
      "Epoch 1498/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8055 - accuracy: 0.7246 - val_loss: 1.2260 - val_accuracy: 0.6136\n",
      "Epoch 1499/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8519 - accuracy: 0.7277 - val_loss: 1.2344 - val_accuracy: 0.6104\n",
      "Epoch 1500/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8971 - accuracy: 0.6924 - val_loss: 1.2285 - val_accuracy: 0.6006\n",
      "Epoch 1501/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8826 - accuracy: 0.7100 - val_loss: 1.2412 - val_accuracy: 0.6006\n",
      "Epoch 1502/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8465 - accuracy: 0.7080 - val_loss: 1.2681 - val_accuracy: 0.5942\n",
      "Epoch 1503/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8492 - accuracy: 0.7263 - val_loss: 1.3118 - val_accuracy: 0.5844\n",
      "Epoch 1504/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9566 - accuracy: 0.6885 - val_loss: 1.3514 - val_accuracy: 0.5747\n",
      "Epoch 1505/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7967 - accuracy: 0.7360 - val_loss: 1.3421 - val_accuracy: 0.5714\n",
      "Epoch 1506/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8148 - accuracy: 0.7363 - val_loss: 1.3281 - val_accuracy: 0.5649\n",
      "Epoch 1507/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8455 - accuracy: 0.7318 - val_loss: 1.2703 - val_accuracy: 0.5844\n",
      "Epoch 1508/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8908 - accuracy: 0.6973 - val_loss: 1.2183 - val_accuracy: 0.5844\n",
      "Epoch 1509/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7963 - accuracy: 0.7451 - val_loss: 1.1905 - val_accuracy: 0.5909\n",
      "Epoch 1510/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8749 - accuracy: 0.7148 - val_loss: 1.1696 - val_accuracy: 0.5909\n",
      "Epoch 1511/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8397 - accuracy: 0.7109 - val_loss: 1.1635 - val_accuracy: 0.5974\n",
      "Epoch 1512/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8616 - accuracy: 0.7139 - val_loss: 1.1787 - val_accuracy: 0.6071\n",
      "Epoch 1513/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7890 - accuracy: 0.7363 - val_loss: 1.1837 - val_accuracy: 0.6104\n",
      "Epoch 1514/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8353 - accuracy: 0.7067 - val_loss: 1.1778 - val_accuracy: 0.6104\n",
      "Epoch 1515/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8678 - accuracy: 0.7067 - val_loss: 1.1698 - val_accuracy: 0.6266\n",
      "Epoch 1516/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8348 - accuracy: 0.7197 - val_loss: 1.1566 - val_accuracy: 0.6299\n",
      "Epoch 1517/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8293 - accuracy: 0.7165 - val_loss: 1.1105 - val_accuracy: 0.6364\n",
      "Epoch 1518/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7826 - accuracy: 0.7291 - val_loss: 1.0636 - val_accuracy: 0.6396\n",
      "Epoch 1519/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8577 - accuracy: 0.7061 - val_loss: 1.0426 - val_accuracy: 0.6364\n",
      "Epoch 1520/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9035 - accuracy: 0.7100 - val_loss: 1.0341 - val_accuracy: 0.6461\n",
      "Epoch 1521/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8564 - accuracy: 0.7217 - val_loss: 1.0432 - val_accuracy: 0.6461\n",
      "Epoch 1522/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8627 - accuracy: 0.7025 - val_loss: 1.0760 - val_accuracy: 0.6201\n",
      "Epoch 1523/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8553 - accuracy: 0.7100 - val_loss: 1.1286 - val_accuracy: 0.6234\n",
      "Epoch 1524/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8270 - accuracy: 0.7304 - val_loss: 1.1987 - val_accuracy: 0.6136\n",
      "Epoch 1525/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8940 - accuracy: 0.7025 - val_loss: 1.2705 - val_accuracy: 0.6104\n",
      "Epoch 1526/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8344 - accuracy: 0.7100 - val_loss: 1.3302 - val_accuracy: 0.6039\n",
      "Epoch 1527/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8503 - accuracy: 0.7100 - val_loss: 1.3597 - val_accuracy: 0.5974\n",
      "Epoch 1528/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8655 - accuracy: 0.7221 - val_loss: 1.3441 - val_accuracy: 0.5844\n",
      "Epoch 1529/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9177 - accuracy: 0.7039 - val_loss: 1.3064 - val_accuracy: 0.5877\n",
      "Epoch 1530/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8213 - accuracy: 0.7168 - val_loss: 1.2498 - val_accuracy: 0.5942\n",
      "Epoch 1531/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8432 - accuracy: 0.7090 - val_loss: 1.1923 - val_accuracy: 0.6039\n",
      "Epoch 1532/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8272 - accuracy: 0.7236 - val_loss: 1.1560 - val_accuracy: 0.5974\n",
      "Epoch 1533/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8449 - accuracy: 0.7139 - val_loss: 1.1414 - val_accuracy: 0.6039\n",
      "Epoch 1534/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8062 - accuracy: 0.7304 - val_loss: 1.1363 - val_accuracy: 0.6071\n",
      "Epoch 1535/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8321 - accuracy: 0.7266 - val_loss: 1.1553 - val_accuracy: 0.6136\n",
      "Epoch 1536/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9159 - accuracy: 0.6826 - val_loss: 1.1853 - val_accuracy: 0.6039\n",
      "Epoch 1537/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8387 - accuracy: 0.7249 - val_loss: 1.2096 - val_accuracy: 0.6006\n",
      "Epoch 1538/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8045 - accuracy: 0.7393 - val_loss: 1.2339 - val_accuracy: 0.6071\n",
      "Epoch 1539/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7916 - accuracy: 0.7354 - val_loss: 1.2542 - val_accuracy: 0.6071\n",
      "Epoch 1540/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8447 - accuracy: 0.7285 - val_loss: 1.2469 - val_accuracy: 0.6071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1541/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8375 - accuracy: 0.7363 - val_loss: 1.2163 - val_accuracy: 0.6071\n",
      "Epoch 1542/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8436 - accuracy: 0.7236 - val_loss: 1.1702 - val_accuracy: 0.6104\n",
      "Epoch 1543/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8198 - accuracy: 0.7363 - val_loss: 1.1168 - val_accuracy: 0.6169\n",
      "Epoch 1544/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9080 - accuracy: 0.6955 - val_loss: 1.0803 - val_accuracy: 0.6266\n",
      "Epoch 1545/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8448 - accuracy: 0.7193 - val_loss: 1.0735 - val_accuracy: 0.6331\n",
      "Epoch 1546/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8604 - accuracy: 0.7100 - val_loss: 1.0749 - val_accuracy: 0.6331\n",
      "Epoch 1547/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8325 - accuracy: 0.7291 - val_loss: 1.0665 - val_accuracy: 0.6364\n",
      "Epoch 1548/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8372 - accuracy: 0.7109 - val_loss: 1.0541 - val_accuracy: 0.6364\n",
      "Epoch 1549/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8037 - accuracy: 0.7324 - val_loss: 1.0441 - val_accuracy: 0.6364\n",
      "Epoch 1550/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7993 - accuracy: 0.7277 - val_loss: 1.0492 - val_accuracy: 0.6331\n",
      "Epoch 1551/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7718 - accuracy: 0.7430 - val_loss: 1.0502 - val_accuracy: 0.6201\n",
      "Epoch 1552/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8700 - accuracy: 0.7179 - val_loss: 1.0524 - val_accuracy: 0.6266\n",
      "Epoch 1553/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8574 - accuracy: 0.7263 - val_loss: 1.0832 - val_accuracy: 0.6364\n",
      "Epoch 1554/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7827 - accuracy: 0.7363 - val_loss: 1.1186 - val_accuracy: 0.6396\n",
      "Epoch 1555/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8433 - accuracy: 0.7139 - val_loss: 1.1361 - val_accuracy: 0.6429\n",
      "Epoch 1556/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8247 - accuracy: 0.7314 - val_loss: 1.1361 - val_accuracy: 0.6364\n",
      "Epoch 1557/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8376 - accuracy: 0.7188 - val_loss: 1.1350 - val_accuracy: 0.6266\n",
      "Epoch 1558/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8701 - accuracy: 0.7041 - val_loss: 1.1411 - val_accuracy: 0.6266\n",
      "Epoch 1559/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8038 - accuracy: 0.7486 - val_loss: 1.1683 - val_accuracy: 0.6299\n",
      "Epoch 1560/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8361 - accuracy: 0.7291 - val_loss: 1.1916 - val_accuracy: 0.6364\n",
      "Epoch 1561/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8526 - accuracy: 0.7002 - val_loss: 1.2352 - val_accuracy: 0.6266\n",
      "Epoch 1562/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8306 - accuracy: 0.7263 - val_loss: 1.2818 - val_accuracy: 0.6071\n",
      "Epoch 1563/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8312 - accuracy: 0.7256 - val_loss: 1.3050 - val_accuracy: 0.6039\n",
      "Epoch 1564/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8213 - accuracy: 0.7256 - val_loss: 1.3137 - val_accuracy: 0.6071\n",
      "Epoch 1565/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8195 - accuracy: 0.7188 - val_loss: 1.3012 - val_accuracy: 0.6039\n",
      "Epoch 1566/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8380 - accuracy: 0.7179 - val_loss: 1.2595 - val_accuracy: 0.6169\n",
      "Epoch 1567/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8347 - accuracy: 0.7263 - val_loss: 1.2150 - val_accuracy: 0.6234\n",
      "Epoch 1568/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7975 - accuracy: 0.7416 - val_loss: 1.1807 - val_accuracy: 0.6331\n",
      "Epoch 1569/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8593 - accuracy: 0.7285 - val_loss: 1.1622 - val_accuracy: 0.6299\n",
      "Epoch 1570/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8357 - accuracy: 0.7246 - val_loss: 1.1596 - val_accuracy: 0.6396\n",
      "Epoch 1571/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8287 - accuracy: 0.7304 - val_loss: 1.1718 - val_accuracy: 0.6234\n",
      "Epoch 1572/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7707 - accuracy: 0.7500 - val_loss: 1.1835 - val_accuracy: 0.6201\n",
      "Epoch 1573/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7625 - accuracy: 0.7432 - val_loss: 1.1978 - val_accuracy: 0.6071\n",
      "Epoch 1574/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7911 - accuracy: 0.7416 - val_loss: 1.2144 - val_accuracy: 0.6039\n",
      "Epoch 1575/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8721 - accuracy: 0.7109 - val_loss: 1.2217 - val_accuracy: 0.6039\n",
      "Epoch 1576/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8163 - accuracy: 0.7277 - val_loss: 1.2274 - val_accuracy: 0.6006\n",
      "Epoch 1577/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8256 - accuracy: 0.7332 - val_loss: 1.2392 - val_accuracy: 0.6039\n",
      "Epoch 1578/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7952 - accuracy: 0.7500 - val_loss: 1.2454 - val_accuracy: 0.5942\n",
      "Epoch 1579/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8586 - accuracy: 0.7207 - val_loss: 1.2589 - val_accuracy: 0.5877\n",
      "Epoch 1580/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7625 - accuracy: 0.7500 - val_loss: 1.2615 - val_accuracy: 0.5877\n",
      "Epoch 1581/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8174 - accuracy: 0.7129 - val_loss: 1.2707 - val_accuracy: 0.6071\n",
      "Epoch 1582/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7967 - accuracy: 0.7373 - val_loss: 1.2860 - val_accuracy: 0.6136\n",
      "Epoch 1583/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8648 - accuracy: 0.7249 - val_loss: 1.3011 - val_accuracy: 0.6201\n",
      "Epoch 1584/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7813 - accuracy: 0.7374 - val_loss: 1.3273 - val_accuracy: 0.6104\n",
      "Epoch 1585/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7681 - accuracy: 0.7514 - val_loss: 1.3552 - val_accuracy: 0.6136\n",
      "Epoch 1586/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9046 - accuracy: 0.7002 - val_loss: 1.3897 - val_accuracy: 0.6006\n",
      "Epoch 1587/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7855 - accuracy: 0.7402 - val_loss: 1.4029 - val_accuracy: 0.5844\n",
      "Epoch 1588/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8344 - accuracy: 0.7165 - val_loss: 1.3864 - val_accuracy: 0.5682\n",
      "Epoch 1589/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8183 - accuracy: 0.7295 - val_loss: 1.2935 - val_accuracy: 0.5812\n",
      "Epoch 1590/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7677 - accuracy: 0.7388 - val_loss: 1.2240 - val_accuracy: 0.6039\n",
      "Epoch 1591/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7345 - accuracy: 0.7607 - val_loss: 1.1532 - val_accuracy: 0.6136\n",
      "Epoch 1592/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7933 - accuracy: 0.7416 - val_loss: 1.1098 - val_accuracy: 0.6331\n",
      "Epoch 1593/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7945 - accuracy: 0.7305 - val_loss: 1.0901 - val_accuracy: 0.6364\n",
      "Epoch 1594/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8408 - accuracy: 0.7193 - val_loss: 1.0720 - val_accuracy: 0.6331\n",
      "Epoch 1595/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7771 - accuracy: 0.7451 - val_loss: 1.0843 - val_accuracy: 0.6331\n",
      "Epoch 1596/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7772 - accuracy: 0.7432 - val_loss: 1.1131 - val_accuracy: 0.6234\n",
      "Epoch 1597/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7762 - accuracy: 0.7528 - val_loss: 1.1691 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1598/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8128 - accuracy: 0.7318 - val_loss: 1.2305 - val_accuracy: 0.6136\n",
      "Epoch 1599/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8944 - accuracy: 0.7053 - val_loss: 1.2694 - val_accuracy: 0.6136\n",
      "Epoch 1600/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7884 - accuracy: 0.7363 - val_loss: 1.2825 - val_accuracy: 0.6104\n",
      "Epoch 1601/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8597 - accuracy: 0.7188 - val_loss: 1.2786 - val_accuracy: 0.6104\n",
      "Epoch 1602/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8242 - accuracy: 0.7383 - val_loss: 1.2005 - val_accuracy: 0.6299\n",
      "Epoch 1603/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8255 - accuracy: 0.7277 - val_loss: 1.1291 - val_accuracy: 0.6331\n",
      "Epoch 1604/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8160 - accuracy: 0.7305 - val_loss: 1.0798 - val_accuracy: 0.6396\n",
      "Epoch 1605/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8064 - accuracy: 0.7249 - val_loss: 1.0643 - val_accuracy: 0.6526\n",
      "Epoch 1606/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7960 - accuracy: 0.7422 - val_loss: 1.0683 - val_accuracy: 0.6526\n",
      "Epoch 1607/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8098 - accuracy: 0.7402 - val_loss: 1.0736 - val_accuracy: 0.6526\n",
      "Epoch 1608/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7627 - accuracy: 0.7510 - val_loss: 1.0749 - val_accuracy: 0.6558\n",
      "Epoch 1609/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8084 - accuracy: 0.7207 - val_loss: 1.0712 - val_accuracy: 0.6526\n",
      "Epoch 1610/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7149 - accuracy: 0.7849 - val_loss: 1.0790 - val_accuracy: 0.6331\n",
      "Epoch 1611/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7993 - accuracy: 0.7393 - val_loss: 1.0998 - val_accuracy: 0.6234\n",
      "Epoch 1612/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7534 - accuracy: 0.7441 - val_loss: 1.1537 - val_accuracy: 0.6104\n",
      "Epoch 1613/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7787 - accuracy: 0.7275 - val_loss: 1.2164 - val_accuracy: 0.5974\n",
      "Epoch 1614/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8202 - accuracy: 0.7067 - val_loss: 1.2711 - val_accuracy: 0.5942\n",
      "Epoch 1615/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8309 - accuracy: 0.7236 - val_loss: 1.2796 - val_accuracy: 0.5942\n",
      "Epoch 1616/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7400 - accuracy: 0.7584 - val_loss: 1.2607 - val_accuracy: 0.6039\n",
      "Epoch 1617/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7908 - accuracy: 0.7432 - val_loss: 1.2523 - val_accuracy: 0.6006\n",
      "Epoch 1618/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8026 - accuracy: 0.7430 - val_loss: 1.2600 - val_accuracy: 0.6006\n",
      "Epoch 1619/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8056 - accuracy: 0.7363 - val_loss: 1.2751 - val_accuracy: 0.6071\n",
      "Epoch 1620/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7884 - accuracy: 0.7430 - val_loss: 1.2433 - val_accuracy: 0.6169\n",
      "Epoch 1621/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7820 - accuracy: 0.7472 - val_loss: 1.2292 - val_accuracy: 0.6234\n",
      "Epoch 1622/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7503 - accuracy: 0.7500 - val_loss: 1.2295 - val_accuracy: 0.6169\n",
      "Epoch 1623/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7602 - accuracy: 0.7393 - val_loss: 1.2384 - val_accuracy: 0.6071\n",
      "Epoch 1624/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7487 - accuracy: 0.7559 - val_loss: 1.2511 - val_accuracy: 0.6104\n",
      "Epoch 1625/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7634 - accuracy: 0.7402 - val_loss: 1.2412 - val_accuracy: 0.6136\n",
      "Epoch 1626/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7598 - accuracy: 0.7584 - val_loss: 1.2770 - val_accuracy: 0.6071\n",
      "Epoch 1627/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7622 - accuracy: 0.7549 - val_loss: 1.3044 - val_accuracy: 0.6006\n",
      "Epoch 1628/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8247 - accuracy: 0.7137 - val_loss: 1.3642 - val_accuracy: 0.5974\n",
      "Epoch 1629/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7988 - accuracy: 0.7263 - val_loss: 1.3713 - val_accuracy: 0.6039\n",
      "Epoch 1630/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7436 - accuracy: 0.7402 - val_loss: 1.3485 - val_accuracy: 0.6039\n",
      "Epoch 1631/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7906 - accuracy: 0.7451 - val_loss: 1.3488 - val_accuracy: 0.5974\n",
      "Epoch 1632/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8096 - accuracy: 0.7354 - val_loss: 1.3445 - val_accuracy: 0.6006\n",
      "Epoch 1633/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7802 - accuracy: 0.7542 - val_loss: 1.3584 - val_accuracy: 0.5942\n",
      "Epoch 1634/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7959 - accuracy: 0.7263 - val_loss: 1.3926 - val_accuracy: 0.5844\n",
      "Epoch 1635/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8288 - accuracy: 0.7314 - val_loss: 1.4236 - val_accuracy: 0.5714\n",
      "Epoch 1636/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8050 - accuracy: 0.7256 - val_loss: 1.4465 - val_accuracy: 0.5779\n",
      "Epoch 1637/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8442 - accuracy: 0.7346 - val_loss: 1.4512 - val_accuracy: 0.5747\n",
      "Epoch 1638/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8026 - accuracy: 0.7249 - val_loss: 1.4816 - val_accuracy: 0.5682\n",
      "Epoch 1639/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8226 - accuracy: 0.7061 - val_loss: 1.4900 - val_accuracy: 0.5714\n",
      "Epoch 1640/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7714 - accuracy: 0.7549 - val_loss: 1.4141 - val_accuracy: 0.5714\n",
      "Epoch 1641/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7758 - accuracy: 0.7458 - val_loss: 1.3243 - val_accuracy: 0.5942\n",
      "Epoch 1642/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7783 - accuracy: 0.7472 - val_loss: 1.2360 - val_accuracy: 0.6234\n",
      "Epoch 1643/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7661 - accuracy: 0.7383 - val_loss: 1.1436 - val_accuracy: 0.6558\n",
      "Epoch 1644/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7545 - accuracy: 0.7607 - val_loss: 1.0722 - val_accuracy: 0.6591\n",
      "Epoch 1645/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7626 - accuracy: 0.7441 - val_loss: 1.0327 - val_accuracy: 0.6688\n",
      "Epoch 1646/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8158 - accuracy: 0.7221 - val_loss: 1.0154 - val_accuracy: 0.6688\n",
      "Epoch 1647/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7983 - accuracy: 0.7332 - val_loss: 1.0093 - val_accuracy: 0.6688\n",
      "Epoch 1648/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7876 - accuracy: 0.7568 - val_loss: 1.0089 - val_accuracy: 0.6558\n",
      "Epoch 1649/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7568 - accuracy: 0.7480 - val_loss: 1.0226 - val_accuracy: 0.6494\n",
      "Epoch 1650/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7577 - accuracy: 0.7514 - val_loss: 1.0334 - val_accuracy: 0.6396\n",
      "Epoch 1651/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7662 - accuracy: 0.7458 - val_loss: 1.0285 - val_accuracy: 0.6396\n",
      "Epoch 1652/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7625 - accuracy: 0.7471 - val_loss: 1.0182 - val_accuracy: 0.6558\n",
      "Epoch 1653/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7673 - accuracy: 0.7441 - val_loss: 1.0165 - val_accuracy: 0.6558\n",
      "Epoch 1654/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7711 - accuracy: 0.7412 - val_loss: 1.0209 - val_accuracy: 0.6688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1655/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7771 - accuracy: 0.7360 - val_loss: 1.0336 - val_accuracy: 0.6688\n",
      "Epoch 1656/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7849 - accuracy: 0.7263 - val_loss: 1.0576 - val_accuracy: 0.6623\n",
      "Epoch 1657/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8007 - accuracy: 0.7393 - val_loss: 1.0834 - val_accuracy: 0.6623\n",
      "Epoch 1658/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7628 - accuracy: 0.7556 - val_loss: 1.1362 - val_accuracy: 0.6396\n",
      "Epoch 1659/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7369 - accuracy: 0.7668 - val_loss: 1.1976 - val_accuracy: 0.6169\n",
      "Epoch 1660/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7490 - accuracy: 0.7514 - val_loss: 1.2231 - val_accuracy: 0.6266\n",
      "Epoch 1661/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7472 - accuracy: 0.7637 - val_loss: 1.2286 - val_accuracy: 0.6331\n",
      "Epoch 1662/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7751 - accuracy: 0.7332 - val_loss: 1.2220 - val_accuracy: 0.6331\n",
      "Epoch 1663/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7861 - accuracy: 0.7458 - val_loss: 1.2316 - val_accuracy: 0.6331\n",
      "Epoch 1664/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7820 - accuracy: 0.7246 - val_loss: 1.2313 - val_accuracy: 0.6364\n",
      "Epoch 1665/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7715 - accuracy: 0.7500 - val_loss: 1.2186 - val_accuracy: 0.6364\n",
      "Epoch 1666/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8326 - accuracy: 0.7295 - val_loss: 1.1937 - val_accuracy: 0.6364\n",
      "Epoch 1667/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7941 - accuracy: 0.7432 - val_loss: 1.1764 - val_accuracy: 0.6299\n",
      "Epoch 1668/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7500 - accuracy: 0.7444 - val_loss: 1.1438 - val_accuracy: 0.6364\n",
      "Epoch 1669/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7521 - accuracy: 0.7578 - val_loss: 1.1515 - val_accuracy: 0.6331\n",
      "Epoch 1670/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8471 - accuracy: 0.7346 - val_loss: 1.1752 - val_accuracy: 0.6136\n",
      "Epoch 1671/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7740 - accuracy: 0.7627 - val_loss: 1.2055 - val_accuracy: 0.6201\n",
      "Epoch 1672/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7524 - accuracy: 0.7461 - val_loss: 1.2594 - val_accuracy: 0.6169\n",
      "Epoch 1673/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7308 - accuracy: 0.7696 - val_loss: 1.3043 - val_accuracy: 0.6169\n",
      "Epoch 1674/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8147 - accuracy: 0.7332 - val_loss: 1.3798 - val_accuracy: 0.6136\n",
      "Epoch 1675/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8081 - accuracy: 0.7227 - val_loss: 1.4923 - val_accuracy: 0.5779\n",
      "Epoch 1676/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7488 - accuracy: 0.7539 - val_loss: 1.5971 - val_accuracy: 0.5552\n",
      "Epoch 1677/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8058 - accuracy: 0.7373 - val_loss: 1.6989 - val_accuracy: 0.5227\n",
      "Epoch 1678/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7618 - accuracy: 0.7472 - val_loss: 1.7155 - val_accuracy: 0.5162\n",
      "Epoch 1679/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7401 - accuracy: 0.7598 - val_loss: 1.6651 - val_accuracy: 0.5292\n",
      "Epoch 1680/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7816 - accuracy: 0.7383 - val_loss: 1.5747 - val_accuracy: 0.5487\n",
      "Epoch 1681/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7982 - accuracy: 0.7256 - val_loss: 1.4899 - val_accuracy: 0.5812\n",
      "Epoch 1682/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7709 - accuracy: 0.7528 - val_loss: 1.4254 - val_accuracy: 0.6006\n",
      "Epoch 1683/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7327 - accuracy: 0.7514 - val_loss: 1.3945 - val_accuracy: 0.6104\n",
      "Epoch 1684/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7436 - accuracy: 0.7480 - val_loss: 1.3792 - val_accuracy: 0.6201\n",
      "Epoch 1685/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6880 - accuracy: 0.7654 - val_loss: 1.3603 - val_accuracy: 0.6169\n",
      "Epoch 1686/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7825 - accuracy: 0.7291 - val_loss: 1.2998 - val_accuracy: 0.6299\n",
      "Epoch 1687/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7514 - accuracy: 0.7584 - val_loss: 1.2260 - val_accuracy: 0.6429\n",
      "Epoch 1688/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7467 - accuracy: 0.7472 - val_loss: 1.1824 - val_accuracy: 0.6591\n",
      "Epoch 1689/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7368 - accuracy: 0.7584 - val_loss: 1.1530 - val_accuracy: 0.6591\n",
      "Epoch 1690/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7708 - accuracy: 0.7490 - val_loss: 1.1288 - val_accuracy: 0.6591\n",
      "Epoch 1691/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7316 - accuracy: 0.7520 - val_loss: 1.1229 - val_accuracy: 0.6558\n",
      "Epoch 1692/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7759 - accuracy: 0.7559 - val_loss: 1.1221 - val_accuracy: 0.6656\n",
      "Epoch 1693/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8163 - accuracy: 0.7332 - val_loss: 1.1305 - val_accuracy: 0.6558\n",
      "Epoch 1694/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7632 - accuracy: 0.7539 - val_loss: 1.1232 - val_accuracy: 0.6591\n",
      "Epoch 1695/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7915 - accuracy: 0.7402 - val_loss: 1.1244 - val_accuracy: 0.6429\n",
      "Epoch 1696/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8019 - accuracy: 0.7354 - val_loss: 1.1337 - val_accuracy: 0.6364\n",
      "Epoch 1697/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7427 - accuracy: 0.7471 - val_loss: 1.1474 - val_accuracy: 0.6364\n",
      "Epoch 1698/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7859 - accuracy: 0.7277 - val_loss: 1.1344 - val_accuracy: 0.6396\n",
      "Epoch 1699/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6913 - accuracy: 0.7754 - val_loss: 1.1150 - val_accuracy: 0.6526\n",
      "Epoch 1700/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7224 - accuracy: 0.7705 - val_loss: 1.1320 - val_accuracy: 0.6558\n",
      "Epoch 1701/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7858 - accuracy: 0.7441 - val_loss: 1.1778 - val_accuracy: 0.6494\n",
      "Epoch 1702/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6778 - accuracy: 0.7821 - val_loss: 1.2494 - val_accuracy: 0.6266\n",
      "Epoch 1703/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7340 - accuracy: 0.7402 - val_loss: 1.3158 - val_accuracy: 0.6201\n",
      "Epoch 1704/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7733 - accuracy: 0.7578 - val_loss: 1.3234 - val_accuracy: 0.6201\n",
      "Epoch 1705/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7566 - accuracy: 0.7472 - val_loss: 1.3061 - val_accuracy: 0.6266\n",
      "Epoch 1706/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7531 - accuracy: 0.7640 - val_loss: 1.2717 - val_accuracy: 0.6234\n",
      "Epoch 1707/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7348 - accuracy: 0.7617 - val_loss: 1.2617 - val_accuracy: 0.6234\n",
      "Epoch 1708/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7496 - accuracy: 0.7542 - val_loss: 1.2764 - val_accuracy: 0.6266\n",
      "Epoch 1709/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7544 - accuracy: 0.7480 - val_loss: 1.2724 - val_accuracy: 0.6364\n",
      "Epoch 1710/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7183 - accuracy: 0.7607 - val_loss: 1.2576 - val_accuracy: 0.6396\n",
      "Epoch 1711/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7797 - accuracy: 0.7461 - val_loss: 1.2340 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1712/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7811 - accuracy: 0.7388 - val_loss: 1.2149 - val_accuracy: 0.6331\n",
      "Epoch 1713/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7447 - accuracy: 0.7570 - val_loss: 1.1996 - val_accuracy: 0.6266\n",
      "Epoch 1714/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7268 - accuracy: 0.7514 - val_loss: 1.1916 - val_accuracy: 0.6331\n",
      "Epoch 1715/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7172 - accuracy: 0.7656 - val_loss: 1.1834 - val_accuracy: 0.6396\n",
      "Epoch 1716/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6961 - accuracy: 0.7744 - val_loss: 1.1802 - val_accuracy: 0.6331\n",
      "Epoch 1717/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7435 - accuracy: 0.7360 - val_loss: 1.1799 - val_accuracy: 0.6396\n",
      "Epoch 1718/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7589 - accuracy: 0.7607 - val_loss: 1.1801 - val_accuracy: 0.6299\n",
      "Epoch 1719/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7081 - accuracy: 0.7656 - val_loss: 1.1673 - val_accuracy: 0.6331\n",
      "Epoch 1720/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7662 - accuracy: 0.7490 - val_loss: 1.1599 - val_accuracy: 0.6331\n",
      "Epoch 1721/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7755 - accuracy: 0.7422 - val_loss: 1.1481 - val_accuracy: 0.6364\n",
      "Epoch 1722/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8346 - accuracy: 0.7430 - val_loss: 1.1427 - val_accuracy: 0.6364\n",
      "Epoch 1723/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7711 - accuracy: 0.7514 - val_loss: 1.1473 - val_accuracy: 0.6364\n",
      "Epoch 1724/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6880 - accuracy: 0.7646 - val_loss: 1.1551 - val_accuracy: 0.6364\n",
      "Epoch 1725/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7485 - accuracy: 0.7374 - val_loss: 1.1775 - val_accuracy: 0.6169\n",
      "Epoch 1726/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7171 - accuracy: 0.7686 - val_loss: 1.1975 - val_accuracy: 0.6169\n",
      "Epoch 1727/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7352 - accuracy: 0.7490 - val_loss: 1.2084 - val_accuracy: 0.6136\n",
      "Epoch 1728/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7603 - accuracy: 0.7556 - val_loss: 1.2048 - val_accuracy: 0.6006\n",
      "Epoch 1729/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7173 - accuracy: 0.7598 - val_loss: 1.2155 - val_accuracy: 0.5974\n",
      "Epoch 1730/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7949 - accuracy: 0.7344 - val_loss: 1.2041 - val_accuracy: 0.5974\n",
      "Epoch 1731/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7199 - accuracy: 0.7637 - val_loss: 1.1900 - val_accuracy: 0.6039\n",
      "Epoch 1732/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7345 - accuracy: 0.7559 - val_loss: 1.1764 - val_accuracy: 0.6104\n",
      "Epoch 1733/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7489 - accuracy: 0.7383 - val_loss: 1.1644 - val_accuracy: 0.6234\n",
      "Epoch 1734/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7704 - accuracy: 0.7451 - val_loss: 1.1547 - val_accuracy: 0.6234\n",
      "Epoch 1735/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8425 - accuracy: 0.7137 - val_loss: 1.1369 - val_accuracy: 0.6331\n",
      "Epoch 1736/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7153 - accuracy: 0.7637 - val_loss: 1.1184 - val_accuracy: 0.6364\n",
      "Epoch 1737/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7717 - accuracy: 0.7360 - val_loss: 1.0977 - val_accuracy: 0.6494\n",
      "Epoch 1738/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7632 - accuracy: 0.7451 - val_loss: 1.0854 - val_accuracy: 0.6526\n",
      "Epoch 1739/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7458 - accuracy: 0.7500 - val_loss: 1.0737 - val_accuracy: 0.6623\n",
      "Epoch 1740/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7026 - accuracy: 0.7654 - val_loss: 1.0692 - val_accuracy: 0.6526\n",
      "Epoch 1741/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7061 - accuracy: 0.7695 - val_loss: 1.0664 - val_accuracy: 0.6558\n",
      "Epoch 1742/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7665 - accuracy: 0.7514 - val_loss: 1.0682 - val_accuracy: 0.6526\n",
      "Epoch 1743/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7839 - accuracy: 0.7441 - val_loss: 1.0812 - val_accuracy: 0.6364\n",
      "Epoch 1744/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7347 - accuracy: 0.7520 - val_loss: 1.0928 - val_accuracy: 0.6461\n",
      "Epoch 1745/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7483 - accuracy: 0.7520 - val_loss: 1.1104 - val_accuracy: 0.6299\n",
      "Epoch 1746/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7232 - accuracy: 0.7612 - val_loss: 1.1247 - val_accuracy: 0.6234\n",
      "Epoch 1747/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6910 - accuracy: 0.7723 - val_loss: 1.1207 - val_accuracy: 0.6234\n",
      "Epoch 1748/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7036 - accuracy: 0.7646 - val_loss: 1.1171 - val_accuracy: 0.6331\n",
      "Epoch 1749/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7237 - accuracy: 0.7559 - val_loss: 1.1052 - val_accuracy: 0.6558\n",
      "Epoch 1750/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7884 - accuracy: 0.7444 - val_loss: 1.1045 - val_accuracy: 0.6558\n",
      "Epoch 1751/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7583 - accuracy: 0.7607 - val_loss: 1.0985 - val_accuracy: 0.6494\n",
      "Epoch 1752/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7095 - accuracy: 0.7793 - val_loss: 1.0964 - val_accuracy: 0.6591\n",
      "Epoch 1753/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7105 - accuracy: 0.7539 - val_loss: 1.0989 - val_accuracy: 0.6558\n",
      "Epoch 1754/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7422 - accuracy: 0.7402 - val_loss: 1.1029 - val_accuracy: 0.6526\n",
      "Epoch 1755/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7082 - accuracy: 0.7542 - val_loss: 1.1077 - val_accuracy: 0.6396\n",
      "Epoch 1756/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6964 - accuracy: 0.7849 - val_loss: 1.1237 - val_accuracy: 0.6461\n",
      "Epoch 1757/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7247 - accuracy: 0.7607 - val_loss: 1.1365 - val_accuracy: 0.6396\n",
      "Epoch 1758/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7881 - accuracy: 0.7318 - val_loss: 1.1528 - val_accuracy: 0.6396\n",
      "Epoch 1759/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8142 - accuracy: 0.7291 - val_loss: 1.1605 - val_accuracy: 0.6494\n",
      "Epoch 1760/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7644 - accuracy: 0.7458 - val_loss: 1.1454 - val_accuracy: 0.6331\n",
      "Epoch 1761/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6851 - accuracy: 0.7765 - val_loss: 1.1377 - val_accuracy: 0.6429\n",
      "Epoch 1762/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7814 - accuracy: 0.7510 - val_loss: 1.1333 - val_accuracy: 0.6688\n",
      "Epoch 1763/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7646 - accuracy: 0.7500 - val_loss: 1.1311 - val_accuracy: 0.6526\n",
      "Epoch 1764/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7482 - accuracy: 0.7500 - val_loss: 1.1411 - val_accuracy: 0.6591\n",
      "Epoch 1765/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7048 - accuracy: 0.7682 - val_loss: 1.1579 - val_accuracy: 0.6623\n",
      "Epoch 1766/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7690 - accuracy: 0.7402 - val_loss: 1.1769 - val_accuracy: 0.6623\n",
      "Epoch 1767/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8039 - accuracy: 0.7402 - val_loss: 1.1936 - val_accuracy: 0.6494\n",
      "Epoch 1768/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7381 - accuracy: 0.7490 - val_loss: 1.2040 - val_accuracy: 0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1769/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7233 - accuracy: 0.7646 - val_loss: 1.2095 - val_accuracy: 0.6234\n",
      "Epoch 1770/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7225 - accuracy: 0.7715 - val_loss: 1.2088 - val_accuracy: 0.6039\n",
      "Epoch 1771/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7315 - accuracy: 0.7773 - val_loss: 1.2005 - val_accuracy: 0.6136\n",
      "Epoch 1772/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7859 - accuracy: 0.7432 - val_loss: 1.1952 - val_accuracy: 0.6299\n",
      "Epoch 1773/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6498 - accuracy: 0.7723 - val_loss: 1.1933 - val_accuracy: 0.6331\n",
      "Epoch 1774/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7555 - accuracy: 0.7556 - val_loss: 1.1831 - val_accuracy: 0.6299\n",
      "Epoch 1775/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6843 - accuracy: 0.7822 - val_loss: 1.1751 - val_accuracy: 0.6396\n",
      "Epoch 1776/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7301 - accuracy: 0.7539 - val_loss: 1.1519 - val_accuracy: 0.6396\n",
      "Epoch 1777/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7056 - accuracy: 0.7723 - val_loss: 1.1295 - val_accuracy: 0.6461\n",
      "Epoch 1778/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7269 - accuracy: 0.7705 - val_loss: 1.1013 - val_accuracy: 0.6494\n",
      "Epoch 1779/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7350 - accuracy: 0.7584 - val_loss: 1.0840 - val_accuracy: 0.6558\n",
      "Epoch 1780/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6847 - accuracy: 0.7842 - val_loss: 1.0855 - val_accuracy: 0.6429\n",
      "Epoch 1781/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6977 - accuracy: 0.7607 - val_loss: 1.1115 - val_accuracy: 0.6396\n",
      "Epoch 1782/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6904 - accuracy: 0.7779 - val_loss: 1.1430 - val_accuracy: 0.6299\n",
      "Epoch 1783/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6679 - accuracy: 0.7861 - val_loss: 1.1332 - val_accuracy: 0.6396\n",
      "Epoch 1784/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7378 - accuracy: 0.7529 - val_loss: 1.1172 - val_accuracy: 0.6429\n",
      "Epoch 1785/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7476 - accuracy: 0.7668 - val_loss: 1.0980 - val_accuracy: 0.6331\n",
      "Epoch 1786/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6572 - accuracy: 0.7877 - val_loss: 1.0854 - val_accuracy: 0.6558\n",
      "Epoch 1787/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7422 - accuracy: 0.7578 - val_loss: 1.0828 - val_accuracy: 0.6623\n",
      "Epoch 1788/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7263 - accuracy: 0.7744 - val_loss: 1.0859 - val_accuracy: 0.6558\n",
      "Epoch 1789/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7381 - accuracy: 0.7520 - val_loss: 1.0887 - val_accuracy: 0.6494\n",
      "Epoch 1790/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7064 - accuracy: 0.7656 - val_loss: 1.0927 - val_accuracy: 0.6429\n",
      "Epoch 1791/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7467 - accuracy: 0.7514 - val_loss: 1.1052 - val_accuracy: 0.6429\n",
      "Epoch 1792/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7388 - accuracy: 0.7402 - val_loss: 1.1219 - val_accuracy: 0.6364\n",
      "Epoch 1793/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7162 - accuracy: 0.7458 - val_loss: 1.1504 - val_accuracy: 0.6234\n",
      "Epoch 1794/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7827 - accuracy: 0.7682 - val_loss: 1.1757 - val_accuracy: 0.6234\n",
      "Epoch 1795/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7020 - accuracy: 0.7793 - val_loss: 1.2091 - val_accuracy: 0.6136\n",
      "Epoch 1796/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7141 - accuracy: 0.7461 - val_loss: 1.2191 - val_accuracy: 0.6006\n",
      "Epoch 1797/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6919 - accuracy: 0.7754 - val_loss: 1.1929 - val_accuracy: 0.6039\n",
      "Epoch 1798/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7114 - accuracy: 0.7744 - val_loss: 1.1651 - val_accuracy: 0.6169\n",
      "Epoch 1799/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7195 - accuracy: 0.7607 - val_loss: 1.1449 - val_accuracy: 0.6201\n",
      "Epoch 1800/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7381 - accuracy: 0.7444 - val_loss: 1.1384 - val_accuracy: 0.6299\n",
      "Epoch 1801/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7254 - accuracy: 0.7556 - val_loss: 1.1448 - val_accuracy: 0.6201\n",
      "Epoch 1802/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7356 - accuracy: 0.7682 - val_loss: 1.1565 - val_accuracy: 0.6299\n",
      "Epoch 1803/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6917 - accuracy: 0.7668 - val_loss: 1.1678 - val_accuracy: 0.6169\n",
      "Epoch 1804/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7620 - accuracy: 0.7314 - val_loss: 1.1680 - val_accuracy: 0.6266\n",
      "Epoch 1805/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7207 - accuracy: 0.7528 - val_loss: 1.1702 - val_accuracy: 0.6299\n",
      "Epoch 1806/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7138 - accuracy: 0.7656 - val_loss: 1.1737 - val_accuracy: 0.6429\n",
      "Epoch 1807/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7329 - accuracy: 0.7637 - val_loss: 1.1793 - val_accuracy: 0.6461\n",
      "Epoch 1808/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6746 - accuracy: 0.7682 - val_loss: 1.1903 - val_accuracy: 0.6429\n",
      "Epoch 1809/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7047 - accuracy: 0.7754 - val_loss: 1.2026 - val_accuracy: 0.6461\n",
      "Epoch 1810/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7652 - accuracy: 0.7617 - val_loss: 1.2021 - val_accuracy: 0.6331\n",
      "Epoch 1811/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7112 - accuracy: 0.7578 - val_loss: 1.1837 - val_accuracy: 0.6429\n",
      "Epoch 1812/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7351 - accuracy: 0.7598 - val_loss: 1.1732 - val_accuracy: 0.6526\n",
      "Epoch 1813/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6997 - accuracy: 0.7598 - val_loss: 1.1409 - val_accuracy: 0.6396\n",
      "Epoch 1814/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7389 - accuracy: 0.7549 - val_loss: 1.1252 - val_accuracy: 0.6429\n",
      "Epoch 1815/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7226 - accuracy: 0.7542 - val_loss: 1.1131 - val_accuracy: 0.6526\n",
      "Epoch 1816/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6665 - accuracy: 0.7637 - val_loss: 1.0983 - val_accuracy: 0.6558\n",
      "Epoch 1817/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7561 - accuracy: 0.7510 - val_loss: 1.0963 - val_accuracy: 0.6656\n",
      "Epoch 1818/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6433 - accuracy: 0.8017 - val_loss: 1.0987 - val_accuracy: 0.6526\n",
      "Epoch 1819/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6613 - accuracy: 0.7863 - val_loss: 1.1023 - val_accuracy: 0.6591\n",
      "Epoch 1820/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6982 - accuracy: 0.7751 - val_loss: 1.1032 - val_accuracy: 0.6591\n",
      "Epoch 1821/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7813 - accuracy: 0.7393 - val_loss: 1.1022 - val_accuracy: 0.6461\n",
      "Epoch 1822/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7379 - accuracy: 0.7612 - val_loss: 1.1018 - val_accuracy: 0.6526\n",
      "Epoch 1823/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6864 - accuracy: 0.7821 - val_loss: 1.1091 - val_accuracy: 0.6494\n",
      "Epoch 1824/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7070 - accuracy: 0.7686 - val_loss: 1.1104 - val_accuracy: 0.6396\n",
      "Epoch 1825/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6947 - accuracy: 0.7626 - val_loss: 1.1069 - val_accuracy: 0.6461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1826/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6967 - accuracy: 0.7764 - val_loss: 1.1023 - val_accuracy: 0.6494\n",
      "Epoch 1827/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6811 - accuracy: 0.7654 - val_loss: 1.1036 - val_accuracy: 0.6558\n",
      "Epoch 1828/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7056 - accuracy: 0.7654 - val_loss: 1.1111 - val_accuracy: 0.6364\n",
      "Epoch 1829/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7070 - accuracy: 0.7709 - val_loss: 1.1190 - val_accuracy: 0.6331\n",
      "Epoch 1830/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6501 - accuracy: 0.7737 - val_loss: 1.1354 - val_accuracy: 0.6396\n",
      "Epoch 1831/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6641 - accuracy: 0.7900 - val_loss: 1.1386 - val_accuracy: 0.6461\n",
      "Epoch 1832/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7132 - accuracy: 0.7751 - val_loss: 1.1505 - val_accuracy: 0.6234\n",
      "Epoch 1833/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7082 - accuracy: 0.7723 - val_loss: 1.1741 - val_accuracy: 0.6136\n",
      "Epoch 1834/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7416 - accuracy: 0.7682 - val_loss: 1.2154 - val_accuracy: 0.6136\n",
      "Epoch 1835/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6985 - accuracy: 0.7617 - val_loss: 1.2499 - val_accuracy: 0.6169\n",
      "Epoch 1836/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6808 - accuracy: 0.7835 - val_loss: 1.2694 - val_accuracy: 0.6201\n",
      "Epoch 1837/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6462 - accuracy: 0.7900 - val_loss: 1.2688 - val_accuracy: 0.6169\n",
      "Epoch 1838/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7249 - accuracy: 0.7668 - val_loss: 1.2578 - val_accuracy: 0.6201\n",
      "Epoch 1839/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6781 - accuracy: 0.7709 - val_loss: 1.2184 - val_accuracy: 0.6299\n",
      "Epoch 1840/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6904 - accuracy: 0.7793 - val_loss: 1.1944 - val_accuracy: 0.6266\n",
      "Epoch 1841/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7194 - accuracy: 0.7598 - val_loss: 1.1900 - val_accuracy: 0.6234\n",
      "Epoch 1842/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7159 - accuracy: 0.7520 - val_loss: 1.1689 - val_accuracy: 0.6331\n",
      "Epoch 1843/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6951 - accuracy: 0.7612 - val_loss: 1.1573 - val_accuracy: 0.6429\n",
      "Epoch 1844/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7588 - accuracy: 0.7627 - val_loss: 1.1399 - val_accuracy: 0.6429\n",
      "Epoch 1845/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7349 - accuracy: 0.7539 - val_loss: 1.1162 - val_accuracy: 0.6461\n",
      "Epoch 1846/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6833 - accuracy: 0.7754 - val_loss: 1.0924 - val_accuracy: 0.6623\n",
      "Epoch 1847/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7325 - accuracy: 0.7514 - val_loss: 1.0800 - val_accuracy: 0.6721\n",
      "Epoch 1848/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7253 - accuracy: 0.7637 - val_loss: 1.0731 - val_accuracy: 0.6623\n",
      "Epoch 1849/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7018 - accuracy: 0.7682 - val_loss: 1.0724 - val_accuracy: 0.6591\n",
      "Epoch 1850/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6947 - accuracy: 0.7765 - val_loss: 1.0655 - val_accuracy: 0.6656\n",
      "Epoch 1851/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7238 - accuracy: 0.7472 - val_loss: 1.0706 - val_accuracy: 0.6656\n",
      "Epoch 1852/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6507 - accuracy: 0.7835 - val_loss: 1.0746 - val_accuracy: 0.6591\n",
      "Epoch 1853/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6418 - accuracy: 0.7861 - val_loss: 1.0806 - val_accuracy: 0.6494\n",
      "Epoch 1854/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6412 - accuracy: 0.7835 - val_loss: 1.0950 - val_accuracy: 0.6461\n",
      "Epoch 1855/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6996 - accuracy: 0.7725 - val_loss: 1.0917 - val_accuracy: 0.6299\n",
      "Epoch 1856/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7660 - accuracy: 0.7416 - val_loss: 1.0762 - val_accuracy: 0.6331\n",
      "Epoch 1857/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7012 - accuracy: 0.7783 - val_loss: 1.0722 - val_accuracy: 0.6364\n",
      "Epoch 1858/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7098 - accuracy: 0.7578 - val_loss: 1.0651 - val_accuracy: 0.6429\n",
      "Epoch 1859/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6704 - accuracy: 0.7822 - val_loss: 1.0602 - val_accuracy: 0.6461\n",
      "Epoch 1860/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7046 - accuracy: 0.7737 - val_loss: 1.0700 - val_accuracy: 0.6494\n",
      "Epoch 1861/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6729 - accuracy: 0.7835 - val_loss: 1.0755 - val_accuracy: 0.6623\n",
      "Epoch 1862/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7022 - accuracy: 0.7696 - val_loss: 1.0872 - val_accuracy: 0.6526\n",
      "Epoch 1863/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6878 - accuracy: 0.7919 - val_loss: 1.1153 - val_accuracy: 0.6461\n",
      "Epoch 1864/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6640 - accuracy: 0.7705 - val_loss: 1.1417 - val_accuracy: 0.6234\n",
      "Epoch 1865/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6926 - accuracy: 0.7744 - val_loss: 1.1613 - val_accuracy: 0.6364\n",
      "Epoch 1866/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7443 - accuracy: 0.7556 - val_loss: 1.1788 - val_accuracy: 0.6266\n",
      "Epoch 1867/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6611 - accuracy: 0.7930 - val_loss: 1.1893 - val_accuracy: 0.6266\n",
      "Epoch 1868/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6616 - accuracy: 0.7723 - val_loss: 1.2057 - val_accuracy: 0.6396\n",
      "Epoch 1869/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6304 - accuracy: 0.7849 - val_loss: 1.1774 - val_accuracy: 0.6429\n",
      "Epoch 1870/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7254 - accuracy: 0.7444 - val_loss: 1.1554 - val_accuracy: 0.6494\n",
      "Epoch 1871/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7392 - accuracy: 0.7559 - val_loss: 1.1121 - val_accuracy: 0.6429\n",
      "Epoch 1872/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7488 - accuracy: 0.7486 - val_loss: 1.0876 - val_accuracy: 0.6558\n",
      "Epoch 1873/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7077 - accuracy: 0.7584 - val_loss: 1.0847 - val_accuracy: 0.6558\n",
      "Epoch 1874/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7166 - accuracy: 0.7612 - val_loss: 1.0897 - val_accuracy: 0.6526\n",
      "Epoch 1875/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6564 - accuracy: 0.7979 - val_loss: 1.0964 - val_accuracy: 0.6688\n",
      "Epoch 1876/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6658 - accuracy: 0.7807 - val_loss: 1.1135 - val_accuracy: 0.6688\n",
      "Epoch 1877/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7145 - accuracy: 0.7725 - val_loss: 1.1418 - val_accuracy: 0.6494\n",
      "Epoch 1878/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6886 - accuracy: 0.7696 - val_loss: 1.1676 - val_accuracy: 0.6429\n",
      "Epoch 1879/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6792 - accuracy: 0.7754 - val_loss: 1.1874 - val_accuracy: 0.6396\n",
      "Epoch 1880/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6374 - accuracy: 0.7919 - val_loss: 1.1951 - val_accuracy: 0.6429\n",
      "Epoch 1881/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6986 - accuracy: 0.7588 - val_loss: 1.1880 - val_accuracy: 0.6494\n",
      "Epoch 1882/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7159 - accuracy: 0.7640 - val_loss: 1.1841 - val_accuracy: 0.6526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1883/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7244 - accuracy: 0.7556 - val_loss: 1.1661 - val_accuracy: 0.6526\n",
      "Epoch 1884/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6688 - accuracy: 0.7779 - val_loss: 1.1541 - val_accuracy: 0.6623\n",
      "Epoch 1885/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6673 - accuracy: 0.7832 - val_loss: 1.1581 - val_accuracy: 0.6494\n",
      "Epoch 1886/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6670 - accuracy: 0.7910 - val_loss: 1.1488 - val_accuracy: 0.6494\n",
      "Epoch 1887/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6779 - accuracy: 0.7989 - val_loss: 1.1458 - val_accuracy: 0.6494\n",
      "Epoch 1888/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6950 - accuracy: 0.7737 - val_loss: 1.1254 - val_accuracy: 0.6526\n",
      "Epoch 1889/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6446 - accuracy: 0.7891 - val_loss: 1.1044 - val_accuracy: 0.6558\n",
      "Epoch 1890/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6868 - accuracy: 0.7754 - val_loss: 1.0922 - val_accuracy: 0.6721\n",
      "Epoch 1891/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6816 - accuracy: 0.7861 - val_loss: 1.0876 - val_accuracy: 0.6688\n",
      "Epoch 1892/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7090 - accuracy: 0.7709 - val_loss: 1.0841 - val_accuracy: 0.6623\n",
      "Epoch 1893/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6335 - accuracy: 0.7939 - val_loss: 1.0838 - val_accuracy: 0.6591\n",
      "Epoch 1894/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7100 - accuracy: 0.7584 - val_loss: 1.0854 - val_accuracy: 0.6656\n",
      "Epoch 1895/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6782 - accuracy: 0.7773 - val_loss: 1.0974 - val_accuracy: 0.6591\n",
      "Epoch 1896/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6680 - accuracy: 0.7754 - val_loss: 1.1161 - val_accuracy: 0.6591\n",
      "Epoch 1897/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6634 - accuracy: 0.7773 - val_loss: 1.1470 - val_accuracy: 0.6461\n",
      "Epoch 1898/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6308 - accuracy: 0.7881 - val_loss: 1.1778 - val_accuracy: 0.6331\n",
      "Epoch 1899/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7000 - accuracy: 0.7737 - val_loss: 1.1730 - val_accuracy: 0.6299\n",
      "Epoch 1900/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6858 - accuracy: 0.7751 - val_loss: 1.1376 - val_accuracy: 0.6461\n",
      "Epoch 1901/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7001 - accuracy: 0.7737 - val_loss: 1.1135 - val_accuracy: 0.6526\n",
      "Epoch 1902/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6523 - accuracy: 0.7979 - val_loss: 1.0816 - val_accuracy: 0.6688\n",
      "Epoch 1903/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6957 - accuracy: 0.7803 - val_loss: 1.0616 - val_accuracy: 0.6558\n",
      "Epoch 1904/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6662 - accuracy: 0.7725 - val_loss: 1.0527 - val_accuracy: 0.6494\n",
      "Epoch 1905/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6976 - accuracy: 0.7793 - val_loss: 1.0602 - val_accuracy: 0.6526\n",
      "Epoch 1906/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7118 - accuracy: 0.7682 - val_loss: 1.0671 - val_accuracy: 0.6623\n",
      "Epoch 1907/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6673 - accuracy: 0.7891 - val_loss: 1.0802 - val_accuracy: 0.6591\n",
      "Epoch 1908/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6439 - accuracy: 0.7910 - val_loss: 1.0907 - val_accuracy: 0.6494\n",
      "Epoch 1909/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6337 - accuracy: 0.7905 - val_loss: 1.0852 - val_accuracy: 0.6526\n",
      "Epoch 1910/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6140 - accuracy: 0.7947 - val_loss: 1.0835 - val_accuracy: 0.6558\n",
      "Epoch 1911/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6348 - accuracy: 0.7988 - val_loss: 1.0830 - val_accuracy: 0.6591\n",
      "Epoch 1912/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6259 - accuracy: 0.7920 - val_loss: 1.0756 - val_accuracy: 0.6688\n",
      "Epoch 1913/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7136 - accuracy: 0.7500 - val_loss: 1.0766 - val_accuracy: 0.6688\n",
      "Epoch 1914/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6701 - accuracy: 0.7779 - val_loss: 1.0837 - val_accuracy: 0.6558\n",
      "Epoch 1915/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6902 - accuracy: 0.7754 - val_loss: 1.0956 - val_accuracy: 0.6558\n",
      "Epoch 1916/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6947 - accuracy: 0.7598 - val_loss: 1.1134 - val_accuracy: 0.6526\n",
      "Epoch 1917/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6229 - accuracy: 0.7891 - val_loss: 1.1368 - val_accuracy: 0.6429\n",
      "Epoch 1918/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6191 - accuracy: 0.7947 - val_loss: 1.1460 - val_accuracy: 0.6396\n",
      "Epoch 1919/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6380 - accuracy: 0.7849 - val_loss: 1.1432 - val_accuracy: 0.6396\n",
      "Epoch 1920/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6908 - accuracy: 0.7905 - val_loss: 1.1317 - val_accuracy: 0.6429\n",
      "Epoch 1921/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7101 - accuracy: 0.7695 - val_loss: 1.1085 - val_accuracy: 0.6591\n",
      "Epoch 1922/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6516 - accuracy: 0.7822 - val_loss: 1.0868 - val_accuracy: 0.6558\n",
      "Epoch 1923/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6344 - accuracy: 0.7871 - val_loss: 1.0669 - val_accuracy: 0.6623\n",
      "Epoch 1924/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6888 - accuracy: 0.7734 - val_loss: 1.0469 - val_accuracy: 0.6591\n",
      "Epoch 1925/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6453 - accuracy: 0.7949 - val_loss: 1.0353 - val_accuracy: 0.6656\n",
      "Epoch 1926/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6616 - accuracy: 0.7737 - val_loss: 1.0257 - val_accuracy: 0.6883\n",
      "Epoch 1927/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6574 - accuracy: 0.7734 - val_loss: 1.0259 - val_accuracy: 0.6981\n",
      "Epoch 1928/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6293 - accuracy: 0.8047 - val_loss: 1.0353 - val_accuracy: 0.6981\n",
      "Epoch 1929/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6559 - accuracy: 0.7852 - val_loss: 1.0461 - val_accuracy: 0.6948\n",
      "Epoch 1930/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6543 - accuracy: 0.7793 - val_loss: 1.0740 - val_accuracy: 0.6721\n",
      "Epoch 1931/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6917 - accuracy: 0.7682 - val_loss: 1.1113 - val_accuracy: 0.6494\n",
      "Epoch 1932/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6986 - accuracy: 0.7607 - val_loss: 1.1488 - val_accuracy: 0.6396\n",
      "Epoch 1933/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6173 - accuracy: 0.8128 - val_loss: 1.1615 - val_accuracy: 0.6429\n",
      "Epoch 1934/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6602 - accuracy: 0.7852 - val_loss: 1.1821 - val_accuracy: 0.6331\n",
      "Epoch 1935/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6489 - accuracy: 0.7900 - val_loss: 1.1949 - val_accuracy: 0.6234\n",
      "Epoch 1936/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6598 - accuracy: 0.7682 - val_loss: 1.1871 - val_accuracy: 0.6331\n",
      "Epoch 1937/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7069 - accuracy: 0.7676 - val_loss: 1.1832 - val_accuracy: 0.6331\n",
      "Epoch 1938/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6987 - accuracy: 0.7812 - val_loss: 1.1828 - val_accuracy: 0.6461\n",
      "Epoch 1939/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6231 - accuracy: 0.7905 - val_loss: 1.1630 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1940/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7395 - accuracy: 0.7510 - val_loss: 1.1602 - val_accuracy: 0.6429\n",
      "Epoch 1941/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6232 - accuracy: 0.7998 - val_loss: 1.1572 - val_accuracy: 0.6494\n",
      "Epoch 1942/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6328 - accuracy: 0.7939 - val_loss: 1.1527 - val_accuracy: 0.6494\n",
      "Epoch 1943/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6757 - accuracy: 0.7646 - val_loss: 1.1453 - val_accuracy: 0.6461\n",
      "Epoch 1944/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5724 - accuracy: 0.8086 - val_loss: 1.1403 - val_accuracy: 0.6526\n",
      "Epoch 1945/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6594 - accuracy: 0.7803 - val_loss: 1.1455 - val_accuracy: 0.6494\n",
      "Epoch 1946/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6217 - accuracy: 0.7891 - val_loss: 1.1517 - val_accuracy: 0.6526\n",
      "Epoch 1947/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6464 - accuracy: 0.7754 - val_loss: 1.1640 - val_accuracy: 0.6396\n",
      "Epoch 1948/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6871 - accuracy: 0.7764 - val_loss: 1.1942 - val_accuracy: 0.6299\n",
      "Epoch 1949/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6779 - accuracy: 0.7584 - val_loss: 1.2240 - val_accuracy: 0.6266\n",
      "Epoch 1950/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6820 - accuracy: 0.7881 - val_loss: 1.2273 - val_accuracy: 0.6266\n",
      "Epoch 1951/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6035 - accuracy: 0.7947 - val_loss: 1.2329 - val_accuracy: 0.6201\n",
      "Epoch 1952/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5917 - accuracy: 0.8066 - val_loss: 1.2336 - val_accuracy: 0.6169\n",
      "Epoch 1953/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6179 - accuracy: 0.7988 - val_loss: 1.2210 - val_accuracy: 0.6136\n",
      "Epoch 1954/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6101 - accuracy: 0.8073 - val_loss: 1.2081 - val_accuracy: 0.6169\n",
      "Epoch 1955/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6481 - accuracy: 0.7891 - val_loss: 1.2089 - val_accuracy: 0.6136\n",
      "Epoch 1956/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6627 - accuracy: 0.7881 - val_loss: 1.1913 - val_accuracy: 0.6201\n",
      "Epoch 1957/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6652 - accuracy: 0.7842 - val_loss: 1.1710 - val_accuracy: 0.6169\n",
      "Epoch 1958/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6175 - accuracy: 0.7863 - val_loss: 1.1545 - val_accuracy: 0.6299\n",
      "Epoch 1959/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6217 - accuracy: 0.7933 - val_loss: 1.1524 - val_accuracy: 0.6429\n",
      "Epoch 1960/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6257 - accuracy: 0.7891 - val_loss: 1.1474 - val_accuracy: 0.6396\n",
      "Epoch 1961/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6554 - accuracy: 0.7979 - val_loss: 1.1423 - val_accuracy: 0.6364\n",
      "Epoch 1962/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6416 - accuracy: 0.7668 - val_loss: 1.1472 - val_accuracy: 0.6266\n",
      "Epoch 1963/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6287 - accuracy: 0.7939 - val_loss: 1.1517 - val_accuracy: 0.6234\n",
      "Epoch 1964/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5994 - accuracy: 0.8027 - val_loss: 1.1666 - val_accuracy: 0.6364\n",
      "Epoch 1965/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6893 - accuracy: 0.7910 - val_loss: 1.1816 - val_accuracy: 0.6461\n",
      "Epoch 1966/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6534 - accuracy: 0.7905 - val_loss: 1.1787 - val_accuracy: 0.6364\n",
      "Epoch 1967/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6382 - accuracy: 0.7705 - val_loss: 1.1790 - val_accuracy: 0.6331\n",
      "Epoch 1968/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6545 - accuracy: 0.7871 - val_loss: 1.1607 - val_accuracy: 0.6169\n",
      "Epoch 1969/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6088 - accuracy: 0.7947 - val_loss: 1.1437 - val_accuracy: 0.6266\n",
      "Epoch 1970/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6370 - accuracy: 0.8008 - val_loss: 1.1270 - val_accuracy: 0.6266\n",
      "Epoch 1971/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6705 - accuracy: 0.7773 - val_loss: 1.1221 - val_accuracy: 0.6234\n",
      "Epoch 1972/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6279 - accuracy: 0.8045 - val_loss: 1.1158 - val_accuracy: 0.6234\n",
      "Epoch 1973/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6028 - accuracy: 0.8017 - val_loss: 1.1155 - val_accuracy: 0.6299\n",
      "Epoch 1974/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6125 - accuracy: 0.7900 - val_loss: 1.1159 - val_accuracy: 0.6331\n",
      "Epoch 1975/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6798 - accuracy: 0.7627 - val_loss: 1.1146 - val_accuracy: 0.6331\n",
      "Epoch 1976/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6322 - accuracy: 0.7905 - val_loss: 1.1175 - val_accuracy: 0.6331\n",
      "Epoch 1977/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6560 - accuracy: 0.7933 - val_loss: 1.1400 - val_accuracy: 0.6364\n",
      "Epoch 1978/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6434 - accuracy: 0.7961 - val_loss: 1.1725 - val_accuracy: 0.6331\n",
      "Epoch 1979/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5769 - accuracy: 0.8115 - val_loss: 1.1892 - val_accuracy: 0.6201\n",
      "Epoch 1980/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6305 - accuracy: 0.7754 - val_loss: 1.1873 - val_accuracy: 0.6234\n",
      "Epoch 1981/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7076 - accuracy: 0.7682 - val_loss: 1.1473 - val_accuracy: 0.6299\n",
      "Epoch 1982/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6490 - accuracy: 0.7696 - val_loss: 1.0964 - val_accuracy: 0.6461\n",
      "Epoch 1983/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6693 - accuracy: 0.7682 - val_loss: 1.0586 - val_accuracy: 0.6558\n",
      "Epoch 1984/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6478 - accuracy: 0.7803 - val_loss: 1.0479 - val_accuracy: 0.6558\n",
      "Epoch 1985/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6192 - accuracy: 0.7852 - val_loss: 1.0535 - val_accuracy: 0.6656\n",
      "Epoch 1986/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6029 - accuracy: 0.7939 - val_loss: 1.0640 - val_accuracy: 0.6753\n",
      "Epoch 1987/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6287 - accuracy: 0.7852 - val_loss: 1.0618 - val_accuracy: 0.6721\n",
      "Epoch 1988/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6110 - accuracy: 0.8128 - val_loss: 1.0600 - val_accuracy: 0.6721\n",
      "Epoch 1989/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6048 - accuracy: 0.7979 - val_loss: 1.0546 - val_accuracy: 0.6558\n",
      "Epoch 1990/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6308 - accuracy: 0.7910 - val_loss: 1.0655 - val_accuracy: 0.6526\n",
      "Epoch 1991/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6615 - accuracy: 0.7933 - val_loss: 1.0914 - val_accuracy: 0.6558\n",
      "Epoch 1992/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6639 - accuracy: 0.7852 - val_loss: 1.1368 - val_accuracy: 0.6526\n",
      "Epoch 1993/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6288 - accuracy: 0.7900 - val_loss: 1.1773 - val_accuracy: 0.6526\n",
      "Epoch 1994/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6048 - accuracy: 0.8008 - val_loss: 1.1807 - val_accuracy: 0.6461\n",
      "Epoch 1995/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6683 - accuracy: 0.7919 - val_loss: 1.1850 - val_accuracy: 0.6396\n",
      "Epoch 1996/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5729 - accuracy: 0.8037 - val_loss: 1.1765 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1997/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6222 - accuracy: 0.7877 - val_loss: 1.1461 - val_accuracy: 0.6429\n",
      "Epoch 1998/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6324 - accuracy: 0.7933 - val_loss: 1.1219 - val_accuracy: 0.6331\n",
      "Epoch 1999/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6257 - accuracy: 0.7961 - val_loss: 1.1188 - val_accuracy: 0.6331\n",
      "Epoch 2000/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5651 - accuracy: 0.8115 - val_loss: 1.1225 - val_accuracy: 0.6299\n",
      "Epoch 2001/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6723 - accuracy: 0.7807 - val_loss: 1.1259 - val_accuracy: 0.6429\n",
      "Epoch 2002/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6680 - accuracy: 0.7779 - val_loss: 1.1271 - val_accuracy: 0.6461\n",
      "Epoch 2003/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6443 - accuracy: 0.7793 - val_loss: 1.1401 - val_accuracy: 0.6299\n",
      "Epoch 2004/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5864 - accuracy: 0.8105 - val_loss: 1.1631 - val_accuracy: 0.6396\n",
      "Epoch 2005/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6030 - accuracy: 0.8105 - val_loss: 1.1809 - val_accuracy: 0.6364\n",
      "Epoch 2006/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6235 - accuracy: 0.7959 - val_loss: 1.1909 - val_accuracy: 0.6234\n",
      "Epoch 2007/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6023 - accuracy: 0.8076 - val_loss: 1.1860 - val_accuracy: 0.6266\n",
      "Epoch 2008/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5994 - accuracy: 0.8047 - val_loss: 1.1843 - val_accuracy: 0.6331\n",
      "Epoch 2009/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6277 - accuracy: 0.7910 - val_loss: 1.1783 - val_accuracy: 0.6364\n",
      "Epoch 2010/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6402 - accuracy: 0.7920 - val_loss: 1.1749 - val_accuracy: 0.6331\n",
      "Epoch 2011/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6113 - accuracy: 0.8087 - val_loss: 1.1727 - val_accuracy: 0.6299\n",
      "Epoch 2012/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6504 - accuracy: 0.7793 - val_loss: 1.1832 - val_accuracy: 0.6234\n",
      "Epoch 2013/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5629 - accuracy: 0.8045 - val_loss: 1.2039 - val_accuracy: 0.6429\n",
      "Epoch 2014/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6032 - accuracy: 0.7975 - val_loss: 1.2338 - val_accuracy: 0.6364\n",
      "Epoch 2015/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5652 - accuracy: 0.8226 - val_loss: 1.2647 - val_accuracy: 0.6201\n",
      "Epoch 2016/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6201 - accuracy: 0.8008 - val_loss: 1.2956 - val_accuracy: 0.6201\n",
      "Epoch 2017/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6327 - accuracy: 0.7877 - val_loss: 1.3209 - val_accuracy: 0.6266\n",
      "Epoch 2018/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6602 - accuracy: 0.7949 - val_loss: 1.2958 - val_accuracy: 0.6299\n",
      "Epoch 2019/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6537 - accuracy: 0.7881 - val_loss: 1.2479 - val_accuracy: 0.6429\n",
      "Epoch 2020/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5784 - accuracy: 0.8101 - val_loss: 1.1893 - val_accuracy: 0.6396\n",
      "Epoch 2021/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5936 - accuracy: 0.7988 - val_loss: 1.1567 - val_accuracy: 0.6364\n",
      "Epoch 2022/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6643 - accuracy: 0.7871 - val_loss: 1.1434 - val_accuracy: 0.6331\n",
      "Epoch 2023/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6057 - accuracy: 0.7939 - val_loss: 1.1362 - val_accuracy: 0.6461\n",
      "Epoch 2024/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6128 - accuracy: 0.8003 - val_loss: 1.1360 - val_accuracy: 0.6623\n",
      "Epoch 2025/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5995 - accuracy: 0.7961 - val_loss: 1.1280 - val_accuracy: 0.6656\n",
      "Epoch 2026/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6071 - accuracy: 0.8105 - val_loss: 1.1122 - val_accuracy: 0.6656\n",
      "Epoch 2027/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6441 - accuracy: 0.7835 - val_loss: 1.1058 - val_accuracy: 0.6656\n",
      "Epoch 2028/4000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6594 - accuracy: 0.7832 - val_loss: 1.1079 - val_accuracy: 0.6558\n",
      "Epoch 2029/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6269 - accuracy: 0.7959 - val_loss: 1.1164 - val_accuracy: 0.6526\n",
      "Epoch 2030/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6674 - accuracy: 0.7871 - val_loss: 1.1301 - val_accuracy: 0.6526\n",
      "Epoch 2031/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6243 - accuracy: 0.7863 - val_loss: 1.1160 - val_accuracy: 0.6591\n",
      "Epoch 2032/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6147 - accuracy: 0.7877 - val_loss: 1.0940 - val_accuracy: 0.6688\n",
      "Epoch 2033/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5932 - accuracy: 0.8066 - val_loss: 1.0883 - val_accuracy: 0.6623\n",
      "Epoch 2034/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6045 - accuracy: 0.7947 - val_loss: 1.0909 - val_accuracy: 0.6688\n",
      "Epoch 2035/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5878 - accuracy: 0.7988 - val_loss: 1.1063 - val_accuracy: 0.6721\n",
      "Epoch 2036/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6197 - accuracy: 0.8017 - val_loss: 1.1133 - val_accuracy: 0.6656\n",
      "Epoch 2037/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6653 - accuracy: 0.7877 - val_loss: 1.1108 - val_accuracy: 0.6688\n",
      "Epoch 2038/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6204 - accuracy: 0.8076 - val_loss: 1.0920 - val_accuracy: 0.6623\n",
      "Epoch 2039/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6522 - accuracy: 0.7900 - val_loss: 1.0725 - val_accuracy: 0.6656\n",
      "Epoch 2040/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5816 - accuracy: 0.7989 - val_loss: 1.0673 - val_accuracy: 0.6721\n",
      "Epoch 2041/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6534 - accuracy: 0.7891 - val_loss: 1.0671 - val_accuracy: 0.6721\n",
      "Epoch 2042/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6693 - accuracy: 0.7821 - val_loss: 1.0652 - val_accuracy: 0.6623\n",
      "Epoch 2043/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6878 - accuracy: 0.7807 - val_loss: 1.0847 - val_accuracy: 0.6461\n",
      "Epoch 2044/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6037 - accuracy: 0.8017 - val_loss: 1.1061 - val_accuracy: 0.6396\n",
      "Epoch 2045/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6200 - accuracy: 0.7947 - val_loss: 1.1308 - val_accuracy: 0.6429\n",
      "Epoch 2046/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6682 - accuracy: 0.7754 - val_loss: 1.1381 - val_accuracy: 0.6396\n",
      "Epoch 2047/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6006 - accuracy: 0.8027 - val_loss: 1.1354 - val_accuracy: 0.6234\n",
      "Epoch 2048/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6351 - accuracy: 0.8003 - val_loss: 1.1404 - val_accuracy: 0.6364\n",
      "Epoch 2049/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6214 - accuracy: 0.7988 - val_loss: 1.1302 - val_accuracy: 0.6429\n",
      "Epoch 2050/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6717 - accuracy: 0.7779 - val_loss: 1.1159 - val_accuracy: 0.6623\n",
      "Epoch 2051/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6414 - accuracy: 0.7835 - val_loss: 1.0964 - val_accuracy: 0.6656\n",
      "Epoch 2052/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6102 - accuracy: 0.7998 - val_loss: 1.0755 - val_accuracy: 0.6721\n",
      "Epoch 2053/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5958 - accuracy: 0.8087 - val_loss: 1.0691 - val_accuracy: 0.6688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2054/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6987 - accuracy: 0.7514 - val_loss: 1.0716 - val_accuracy: 0.6461\n",
      "Epoch 2055/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6891 - accuracy: 0.7696 - val_loss: 1.0890 - val_accuracy: 0.6494\n",
      "Epoch 2056/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6145 - accuracy: 0.7905 - val_loss: 1.1069 - val_accuracy: 0.6558\n",
      "Epoch 2057/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5975 - accuracy: 0.7849 - val_loss: 1.1056 - val_accuracy: 0.6526\n",
      "Epoch 2058/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6340 - accuracy: 0.7861 - val_loss: 1.0996 - val_accuracy: 0.6656\n",
      "Epoch 2059/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6576 - accuracy: 0.7751 - val_loss: 1.0952 - val_accuracy: 0.6623\n",
      "Epoch 2060/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5606 - accuracy: 0.8170 - val_loss: 1.0982 - val_accuracy: 0.6753\n",
      "Epoch 2061/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6483 - accuracy: 0.7852 - val_loss: 1.0909 - val_accuracy: 0.6721\n",
      "Epoch 2062/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6162 - accuracy: 0.7998 - val_loss: 1.0763 - val_accuracy: 0.6786\n",
      "Epoch 2063/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6719 - accuracy: 0.7905 - val_loss: 1.0824 - val_accuracy: 0.6753\n",
      "Epoch 2064/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5795 - accuracy: 0.8057 - val_loss: 1.1044 - val_accuracy: 0.6558\n",
      "Epoch 2065/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6227 - accuracy: 0.7734 - val_loss: 1.1454 - val_accuracy: 0.6429\n",
      "Epoch 2066/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5943 - accuracy: 0.8008 - val_loss: 1.1715 - val_accuracy: 0.6299\n",
      "Epoch 2067/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5975 - accuracy: 0.8003 - val_loss: 1.1944 - val_accuracy: 0.6266\n",
      "Epoch 2068/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5994 - accuracy: 0.7905 - val_loss: 1.2138 - val_accuracy: 0.6266\n",
      "Epoch 2069/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5620 - accuracy: 0.8198 - val_loss: 1.2244 - val_accuracy: 0.6234\n",
      "Epoch 2070/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6805 - accuracy: 0.7723 - val_loss: 1.2396 - val_accuracy: 0.6299\n",
      "Epoch 2071/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5598 - accuracy: 0.8125 - val_loss: 1.2700 - val_accuracy: 0.6169\n",
      "Epoch 2072/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5945 - accuracy: 0.8047 - val_loss: 1.3145 - val_accuracy: 0.6169\n",
      "Epoch 2073/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6329 - accuracy: 0.8226 - val_loss: 1.3378 - val_accuracy: 0.6039\n",
      "Epoch 2074/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6615 - accuracy: 0.7871 - val_loss: 1.3808 - val_accuracy: 0.5844\n",
      "Epoch 2075/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6256 - accuracy: 0.7849 - val_loss: 1.4080 - val_accuracy: 0.5747\n",
      "Epoch 2076/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6520 - accuracy: 0.7988 - val_loss: 1.3801 - val_accuracy: 0.5779\n",
      "Epoch 2077/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5749 - accuracy: 0.7979 - val_loss: 1.3269 - val_accuracy: 0.5844\n",
      "Epoch 2078/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5774 - accuracy: 0.8076 - val_loss: 1.2853 - val_accuracy: 0.5877\n",
      "Epoch 2079/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5575 - accuracy: 0.8226 - val_loss: 1.2648 - val_accuracy: 0.5942\n",
      "Epoch 2080/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6252 - accuracy: 0.7979 - val_loss: 1.2565 - val_accuracy: 0.5909\n",
      "Epoch 2081/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5754 - accuracy: 0.8125 - val_loss: 1.2303 - val_accuracy: 0.6006\n",
      "Epoch 2082/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5804 - accuracy: 0.8115 - val_loss: 1.2470 - val_accuracy: 0.6234\n",
      "Epoch 2083/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5383 - accuracy: 0.8359 - val_loss: 1.2612 - val_accuracy: 0.6299\n",
      "Epoch 2084/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5598 - accuracy: 0.8170 - val_loss: 1.2540 - val_accuracy: 0.6364\n",
      "Epoch 2085/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5953 - accuracy: 0.8045 - val_loss: 1.2520 - val_accuracy: 0.6364\n",
      "Epoch 2086/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6140 - accuracy: 0.7900 - val_loss: 1.2613 - val_accuracy: 0.6331\n",
      "Epoch 2087/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5880 - accuracy: 0.8115 - val_loss: 1.2436 - val_accuracy: 0.6396\n",
      "Epoch 2088/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5940 - accuracy: 0.8086 - val_loss: 1.2341 - val_accuracy: 0.6299\n",
      "Epoch 2089/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6021 - accuracy: 0.7933 - val_loss: 1.2348 - val_accuracy: 0.6266\n",
      "Epoch 2090/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6346 - accuracy: 0.7961 - val_loss: 1.2052 - val_accuracy: 0.6364\n",
      "Epoch 2091/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6025 - accuracy: 0.8018 - val_loss: 1.1907 - val_accuracy: 0.6234\n",
      "Epoch 2092/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6161 - accuracy: 0.7989 - val_loss: 1.1742 - val_accuracy: 0.6266\n",
      "Epoch 2093/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5749 - accuracy: 0.8059 - val_loss: 1.1584 - val_accuracy: 0.6364\n",
      "Epoch 2094/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5213 - accuracy: 0.8240 - val_loss: 1.1651 - val_accuracy: 0.6266\n",
      "Epoch 2095/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5700 - accuracy: 0.8338 - val_loss: 1.1608 - val_accuracy: 0.6266\n",
      "Epoch 2096/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6231 - accuracy: 0.7933 - val_loss: 1.1585 - val_accuracy: 0.6364\n",
      "Epoch 2097/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5703 - accuracy: 0.8066 - val_loss: 1.1602 - val_accuracy: 0.6364\n",
      "Epoch 2098/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5658 - accuracy: 0.8076 - val_loss: 1.1663 - val_accuracy: 0.6201\n",
      "Epoch 2099/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6547 - accuracy: 0.7930 - val_loss: 1.1778 - val_accuracy: 0.6136\n",
      "Epoch 2100/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6742 - accuracy: 0.7905 - val_loss: 1.1710 - val_accuracy: 0.6136\n",
      "Epoch 2101/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5608 - accuracy: 0.8045 - val_loss: 1.1304 - val_accuracy: 0.6201\n",
      "Epoch 2102/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5932 - accuracy: 0.8027 - val_loss: 1.0940 - val_accuracy: 0.6266\n",
      "Epoch 2103/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6060 - accuracy: 0.8184 - val_loss: 1.0714 - val_accuracy: 0.6461\n",
      "Epoch 2104/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5887 - accuracy: 0.7961 - val_loss: 1.0649 - val_accuracy: 0.6396\n",
      "Epoch 2105/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6256 - accuracy: 0.8073 - val_loss: 1.0724 - val_accuracy: 0.6526\n",
      "Epoch 2106/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5951 - accuracy: 0.8027 - val_loss: 1.0923 - val_accuracy: 0.6429\n",
      "Epoch 2107/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6011 - accuracy: 0.7988 - val_loss: 1.1178 - val_accuracy: 0.6364\n",
      "Epoch 2108/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5785 - accuracy: 0.8047 - val_loss: 1.1611 - val_accuracy: 0.6234\n",
      "Epoch 2109/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6631 - accuracy: 0.7744 - val_loss: 1.2271 - val_accuracy: 0.6169\n",
      "Epoch 2110/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6158 - accuracy: 0.7881 - val_loss: 1.2742 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2111/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5939 - accuracy: 0.8156 - val_loss: 1.2939 - val_accuracy: 0.6169\n",
      "Epoch 2112/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6493 - accuracy: 0.7920 - val_loss: 1.2474 - val_accuracy: 0.6234\n",
      "Epoch 2113/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5826 - accuracy: 0.8174 - val_loss: 1.2011 - val_accuracy: 0.6201\n",
      "Epoch 2114/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6505 - accuracy: 0.7919 - val_loss: 1.1880 - val_accuracy: 0.6364\n",
      "Epoch 2115/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6219 - accuracy: 0.7863 - val_loss: 1.1773 - val_accuracy: 0.6299\n",
      "Epoch 2116/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6493 - accuracy: 0.7988 - val_loss: 1.1483 - val_accuracy: 0.6364\n",
      "Epoch 2117/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5950 - accuracy: 0.8027 - val_loss: 1.1140 - val_accuracy: 0.6266\n",
      "Epoch 2118/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6012 - accuracy: 0.7905 - val_loss: 1.1073 - val_accuracy: 0.6331\n",
      "Epoch 2119/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6107 - accuracy: 0.7891 - val_loss: 1.0986 - val_accuracy: 0.6266\n",
      "Epoch 2120/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5847 - accuracy: 0.8128 - val_loss: 1.0985 - val_accuracy: 0.6331\n",
      "Epoch 2121/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6217 - accuracy: 0.7998 - val_loss: 1.1044 - val_accuracy: 0.6364\n",
      "Epoch 2122/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6023 - accuracy: 0.7910 - val_loss: 1.1268 - val_accuracy: 0.6331\n",
      "Epoch 2123/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6426 - accuracy: 0.8017 - val_loss: 1.1634 - val_accuracy: 0.6364\n",
      "Epoch 2124/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6005 - accuracy: 0.8008 - val_loss: 1.2293 - val_accuracy: 0.6201\n",
      "Epoch 2125/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6047 - accuracy: 0.8087 - val_loss: 1.3066 - val_accuracy: 0.6071\n",
      "Epoch 2126/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6312 - accuracy: 0.7961 - val_loss: 1.3422 - val_accuracy: 0.6071\n",
      "Epoch 2127/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5834 - accuracy: 0.8059 - val_loss: 1.3545 - val_accuracy: 0.5974\n",
      "Epoch 2128/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6113 - accuracy: 0.7939 - val_loss: 1.3393 - val_accuracy: 0.6104\n",
      "Epoch 2129/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5982 - accuracy: 0.8145 - val_loss: 1.3033 - val_accuracy: 0.6266\n",
      "Epoch 2130/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6045 - accuracy: 0.7989 - val_loss: 1.2729 - val_accuracy: 0.6104\n",
      "Epoch 2131/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5885 - accuracy: 0.8008 - val_loss: 1.2244 - val_accuracy: 0.6364\n",
      "Epoch 2132/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6045 - accuracy: 0.8105 - val_loss: 1.1893 - val_accuracy: 0.6364\n",
      "Epoch 2133/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5779 - accuracy: 0.8003 - val_loss: 1.1821 - val_accuracy: 0.6299\n",
      "Epoch 2134/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6138 - accuracy: 0.8101 - val_loss: 1.2082 - val_accuracy: 0.6299\n",
      "Epoch 2135/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5857 - accuracy: 0.7998 - val_loss: 1.2398 - val_accuracy: 0.6136\n",
      "Epoch 2136/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5977 - accuracy: 0.8045 - val_loss: 1.2934 - val_accuracy: 0.6169\n",
      "Epoch 2137/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5809 - accuracy: 0.8086 - val_loss: 1.3540 - val_accuracy: 0.6039\n",
      "Epoch 2138/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5960 - accuracy: 0.8154 - val_loss: 1.4205 - val_accuracy: 0.5877\n",
      "Epoch 2139/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6415 - accuracy: 0.7989 - val_loss: 1.4881 - val_accuracy: 0.5747\n",
      "Epoch 2140/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5531 - accuracy: 0.8320 - val_loss: 1.5249 - val_accuracy: 0.5714\n",
      "Epoch 2141/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5743 - accuracy: 0.8017 - val_loss: 1.5189 - val_accuracy: 0.5812\n",
      "Epoch 2142/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6282 - accuracy: 0.7849 - val_loss: 1.4935 - val_accuracy: 0.5909\n",
      "Epoch 2143/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5956 - accuracy: 0.8017 - val_loss: 1.4698 - val_accuracy: 0.6006\n",
      "Epoch 2144/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5687 - accuracy: 0.8291 - val_loss: 1.4186 - val_accuracy: 0.6104\n",
      "Epoch 2145/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5652 - accuracy: 0.8240 - val_loss: 1.3742 - val_accuracy: 0.5974\n",
      "Epoch 2146/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5710 - accuracy: 0.8115 - val_loss: 1.3366 - val_accuracy: 0.6006\n",
      "Epoch 2147/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6524 - accuracy: 0.7877 - val_loss: 1.2951 - val_accuracy: 0.6331\n",
      "Epoch 2148/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5227 - accuracy: 0.8242 - val_loss: 1.2822 - val_accuracy: 0.6299\n",
      "Epoch 2149/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6139 - accuracy: 0.8174 - val_loss: 1.2852 - val_accuracy: 0.6299\n",
      "Epoch 2150/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6164 - accuracy: 0.7905 - val_loss: 1.3050 - val_accuracy: 0.6169\n",
      "Epoch 2151/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6074 - accuracy: 0.8059 - val_loss: 1.3446 - val_accuracy: 0.6169\n",
      "Epoch 2152/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5975 - accuracy: 0.8101 - val_loss: 1.3746 - val_accuracy: 0.6266\n",
      "Epoch 2153/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6215 - accuracy: 0.7910 - val_loss: 1.3914 - val_accuracy: 0.6299\n",
      "Epoch 2154/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6038 - accuracy: 0.7905 - val_loss: 1.3549 - val_accuracy: 0.6234\n",
      "Epoch 2155/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5619 - accuracy: 0.8135 - val_loss: 1.3093 - val_accuracy: 0.6364\n",
      "Epoch 2156/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5903 - accuracy: 0.8086 - val_loss: 1.2815 - val_accuracy: 0.6266\n",
      "Epoch 2157/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5406 - accuracy: 0.8254 - val_loss: 1.2402 - val_accuracy: 0.6234\n",
      "Epoch 2158/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5867 - accuracy: 0.7835 - val_loss: 1.2156 - val_accuracy: 0.6299\n",
      "Epoch 2159/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5804 - accuracy: 0.8045 - val_loss: 1.2051 - val_accuracy: 0.6299\n",
      "Epoch 2160/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5845 - accuracy: 0.8154 - val_loss: 1.2089 - val_accuracy: 0.6396\n",
      "Epoch 2161/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6084 - accuracy: 0.7949 - val_loss: 1.2229 - val_accuracy: 0.6461\n",
      "Epoch 2162/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5747 - accuracy: 0.8047 - val_loss: 1.2411 - val_accuracy: 0.6526\n",
      "Epoch 2163/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6043 - accuracy: 0.8057 - val_loss: 1.2634 - val_accuracy: 0.6558\n",
      "Epoch 2164/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5659 - accuracy: 0.8128 - val_loss: 1.2724 - val_accuracy: 0.6526\n",
      "Epoch 2165/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6155 - accuracy: 0.8037 - val_loss: 1.3033 - val_accuracy: 0.6364\n",
      "Epoch 2166/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6488 - accuracy: 0.7849 - val_loss: 1.3414 - val_accuracy: 0.6104\n",
      "Epoch 2167/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5882 - accuracy: 0.8135 - val_loss: 1.3458 - val_accuracy: 0.6169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2168/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5220 - accuracy: 0.8352 - val_loss: 1.3075 - val_accuracy: 0.6136\n",
      "Epoch 2169/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6076 - accuracy: 0.7975 - val_loss: 1.2299 - val_accuracy: 0.6201\n",
      "Epoch 2170/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5848 - accuracy: 0.8087 - val_loss: 1.1578 - val_accuracy: 0.6201\n",
      "Epoch 2171/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6275 - accuracy: 0.8031 - val_loss: 1.1170 - val_accuracy: 0.6266\n",
      "Epoch 2172/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6047 - accuracy: 0.7989 - val_loss: 1.1024 - val_accuracy: 0.6429\n",
      "Epoch 2173/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5401 - accuracy: 0.8198 - val_loss: 1.1114 - val_accuracy: 0.6429\n",
      "Epoch 2174/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5502 - accuracy: 0.8174 - val_loss: 1.1282 - val_accuracy: 0.6429\n",
      "Epoch 2175/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6588 - accuracy: 0.7877 - val_loss: 1.1605 - val_accuracy: 0.6494\n",
      "Epoch 2176/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5638 - accuracy: 0.8115 - val_loss: 1.2051 - val_accuracy: 0.6396\n",
      "Epoch 2177/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5889 - accuracy: 0.8066 - val_loss: 1.2397 - val_accuracy: 0.6234\n",
      "Epoch 2178/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5501 - accuracy: 0.8203 - val_loss: 1.2812 - val_accuracy: 0.6104\n",
      "Epoch 2179/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6007 - accuracy: 0.8018 - val_loss: 1.3077 - val_accuracy: 0.6006\n",
      "Epoch 2180/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5703 - accuracy: 0.8128 - val_loss: 1.3172 - val_accuracy: 0.5974\n",
      "Epoch 2181/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5379 - accuracy: 0.8170 - val_loss: 1.2796 - val_accuracy: 0.6071\n",
      "Epoch 2182/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5308 - accuracy: 0.8296 - val_loss: 1.2358 - val_accuracy: 0.6104\n",
      "Epoch 2183/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5535 - accuracy: 0.8142 - val_loss: 1.2000 - val_accuracy: 0.6234\n",
      "Epoch 2184/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5664 - accuracy: 0.8170 - val_loss: 1.1791 - val_accuracy: 0.6461\n",
      "Epoch 2185/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5672 - accuracy: 0.8142 - val_loss: 1.1662 - val_accuracy: 0.6526\n",
      "Epoch 2186/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5489 - accuracy: 0.8271 - val_loss: 1.1547 - val_accuracy: 0.6526\n",
      "Epoch 2187/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5527 - accuracy: 0.8184 - val_loss: 1.1548 - val_accuracy: 0.6396\n",
      "Epoch 2188/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4816 - accuracy: 0.8492 - val_loss: 1.1574 - val_accuracy: 0.6396\n",
      "Epoch 2189/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5251 - accuracy: 0.8184 - val_loss: 1.1750 - val_accuracy: 0.6331\n",
      "Epoch 2190/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6566 - accuracy: 0.7783 - val_loss: 1.1951 - val_accuracy: 0.6461\n",
      "Epoch 2191/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5659 - accuracy: 0.8135 - val_loss: 1.2019 - val_accuracy: 0.6429\n",
      "Epoch 2192/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5798 - accuracy: 0.8045 - val_loss: 1.1902 - val_accuracy: 0.6429\n",
      "Epoch 2193/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6194 - accuracy: 0.8017 - val_loss: 1.1762 - val_accuracy: 0.6429\n",
      "Epoch 2194/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6435 - accuracy: 0.7919 - val_loss: 1.1629 - val_accuracy: 0.6429\n",
      "Epoch 2195/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5403 - accuracy: 0.8213 - val_loss: 1.1561 - val_accuracy: 0.6526\n",
      "Epoch 2196/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6026 - accuracy: 0.8125 - val_loss: 1.1646 - val_accuracy: 0.6558\n",
      "Epoch 2197/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5551 - accuracy: 0.8115 - val_loss: 1.1794 - val_accuracy: 0.6494\n",
      "Epoch 2198/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6114 - accuracy: 0.7949 - val_loss: 1.1878 - val_accuracy: 0.6494\n",
      "Epoch 2199/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5633 - accuracy: 0.7933 - val_loss: 1.2040 - val_accuracy: 0.6429\n",
      "Epoch 2200/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5806 - accuracy: 0.8156 - val_loss: 1.2403 - val_accuracy: 0.6201\n",
      "Epoch 2201/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5187 - accuracy: 0.8324 - val_loss: 1.2808 - val_accuracy: 0.6136\n",
      "Epoch 2202/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5258 - accuracy: 0.8125 - val_loss: 1.3076 - val_accuracy: 0.6006\n",
      "Epoch 2203/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5616 - accuracy: 0.8223 - val_loss: 1.3282 - val_accuracy: 0.6006\n",
      "Epoch 2204/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5527 - accuracy: 0.8105 - val_loss: 1.3487 - val_accuracy: 0.5812\n",
      "Epoch 2205/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5677 - accuracy: 0.8086 - val_loss: 1.3631 - val_accuracy: 0.5844\n",
      "Epoch 2206/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6053 - accuracy: 0.7959 - val_loss: 1.3446 - val_accuracy: 0.5812\n",
      "Epoch 2207/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5787 - accuracy: 0.8145 - val_loss: 1.3166 - val_accuracy: 0.5844\n",
      "Epoch 2208/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5841 - accuracy: 0.8198 - val_loss: 1.2742 - val_accuracy: 0.5844\n",
      "Epoch 2209/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6154 - accuracy: 0.7900 - val_loss: 1.2482 - val_accuracy: 0.5844\n",
      "Epoch 2210/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5960 - accuracy: 0.8037 - val_loss: 1.2459 - val_accuracy: 0.6039\n",
      "Epoch 2211/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5614 - accuracy: 0.8115 - val_loss: 1.2439 - val_accuracy: 0.6201\n",
      "Epoch 2212/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5583 - accuracy: 0.8017 - val_loss: 1.2581 - val_accuracy: 0.6331\n",
      "Epoch 2213/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5009 - accuracy: 0.8394 - val_loss: 1.2877 - val_accuracy: 0.6331\n",
      "Epoch 2214/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5549 - accuracy: 0.8045 - val_loss: 1.3119 - val_accuracy: 0.6201\n",
      "Epoch 2215/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5793 - accuracy: 0.8073 - val_loss: 1.3182 - val_accuracy: 0.6136\n",
      "Epoch 2216/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5926 - accuracy: 0.8037 - val_loss: 1.3024 - val_accuracy: 0.6169\n",
      "Epoch 2217/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6305 - accuracy: 0.7920 - val_loss: 1.2799 - val_accuracy: 0.6299\n",
      "Epoch 2218/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5754 - accuracy: 0.8128 - val_loss: 1.2435 - val_accuracy: 0.6494\n",
      "Epoch 2219/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5174 - accuracy: 0.8198 - val_loss: 1.2027 - val_accuracy: 0.6429\n",
      "Epoch 2220/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5504 - accuracy: 0.8115 - val_loss: 1.1834 - val_accuracy: 0.6396\n",
      "Epoch 2221/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6003 - accuracy: 0.8115 - val_loss: 1.1715 - val_accuracy: 0.6429\n",
      "Epoch 2222/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5549 - accuracy: 0.8198 - val_loss: 1.1663 - val_accuracy: 0.6364\n",
      "Epoch 2223/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5617 - accuracy: 0.8324 - val_loss: 1.1697 - val_accuracy: 0.6331\n",
      "Epoch 2224/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5642 - accuracy: 0.8170 - val_loss: 1.1920 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2225/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5101 - accuracy: 0.8142 - val_loss: 1.2499 - val_accuracy: 0.6136\n",
      "Epoch 2226/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4849 - accuracy: 0.8478 - val_loss: 1.2883 - val_accuracy: 0.6104\n",
      "Epoch 2227/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5387 - accuracy: 0.8232 - val_loss: 1.3385 - val_accuracy: 0.5974\n",
      "Epoch 2228/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5934 - accuracy: 0.8125 - val_loss: 1.3534 - val_accuracy: 0.5877\n",
      "Epoch 2229/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5838 - accuracy: 0.7989 - val_loss: 1.3188 - val_accuracy: 0.6071\n",
      "Epoch 2230/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5160 - accuracy: 0.8311 - val_loss: 1.2892 - val_accuracy: 0.6039\n",
      "Epoch 2231/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5489 - accuracy: 0.8223 - val_loss: 1.2573 - val_accuracy: 0.6104\n",
      "Epoch 2232/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5361 - accuracy: 0.8059 - val_loss: 1.2483 - val_accuracy: 0.6104\n",
      "Epoch 2233/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5142 - accuracy: 0.8464 - val_loss: 1.2332 - val_accuracy: 0.6266\n",
      "Epoch 2234/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5677 - accuracy: 0.8059 - val_loss: 1.2281 - val_accuracy: 0.6234\n",
      "Epoch 2235/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5238 - accuracy: 0.8268 - val_loss: 1.2219 - val_accuracy: 0.6364\n",
      "Epoch 2236/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5651 - accuracy: 0.8096 - val_loss: 1.2287 - val_accuracy: 0.6494\n",
      "Epoch 2237/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5487 - accuracy: 0.8115 - val_loss: 1.2586 - val_accuracy: 0.6331\n",
      "Epoch 2238/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5877 - accuracy: 0.8115 - val_loss: 1.3033 - val_accuracy: 0.6136\n",
      "Epoch 2239/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5614 - accuracy: 0.8193 - val_loss: 1.3210 - val_accuracy: 0.6136\n",
      "Epoch 2240/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5592 - accuracy: 0.8156 - val_loss: 1.2919 - val_accuracy: 0.6266\n",
      "Epoch 2241/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5638 - accuracy: 0.8115 - val_loss: 1.2663 - val_accuracy: 0.6331\n",
      "Epoch 2242/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5383 - accuracy: 0.8242 - val_loss: 1.2527 - val_accuracy: 0.6234\n",
      "Epoch 2243/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5296 - accuracy: 0.8282 - val_loss: 1.2636 - val_accuracy: 0.6331\n",
      "Epoch 2244/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4746 - accuracy: 0.8438 - val_loss: 1.2713 - val_accuracy: 0.6169\n",
      "Epoch 2245/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5534 - accuracy: 0.8203 - val_loss: 1.2977 - val_accuracy: 0.6006\n",
      "Epoch 2246/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5777 - accuracy: 0.8145 - val_loss: 1.3332 - val_accuracy: 0.5942\n",
      "Epoch 2247/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5429 - accuracy: 0.8115 - val_loss: 1.3837 - val_accuracy: 0.5877\n",
      "Epoch 2248/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5589 - accuracy: 0.8037 - val_loss: 1.4336 - val_accuracy: 0.5747\n",
      "Epoch 2249/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5300 - accuracy: 0.8203 - val_loss: 1.4628 - val_accuracy: 0.5682\n",
      "Epoch 2250/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5445 - accuracy: 0.8059 - val_loss: 1.4469 - val_accuracy: 0.5844\n",
      "Epoch 2251/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5233 - accuracy: 0.8436 - val_loss: 1.3995 - val_accuracy: 0.5974\n",
      "Epoch 2252/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5398 - accuracy: 0.8170 - val_loss: 1.3484 - val_accuracy: 0.6039\n",
      "Epoch 2253/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5227 - accuracy: 0.8203 - val_loss: 1.2810 - val_accuracy: 0.6071\n",
      "Epoch 2254/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5990 - accuracy: 0.8073 - val_loss: 1.2283 - val_accuracy: 0.6299\n",
      "Epoch 2255/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5975 - accuracy: 0.7949 - val_loss: 1.2116 - val_accuracy: 0.6364\n",
      "Epoch 2256/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5542 - accuracy: 0.8105 - val_loss: 1.2012 - val_accuracy: 0.6299\n",
      "Epoch 2257/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5588 - accuracy: 0.8045 - val_loss: 1.1931 - val_accuracy: 0.6331\n",
      "Epoch 2258/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5525 - accuracy: 0.8115 - val_loss: 1.1874 - val_accuracy: 0.6364\n",
      "Epoch 2259/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5695 - accuracy: 0.8135 - val_loss: 1.2114 - val_accuracy: 0.6201\n",
      "Epoch 2260/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5635 - accuracy: 0.8059 - val_loss: 1.2949 - val_accuracy: 0.6104\n",
      "Epoch 2261/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5344 - accuracy: 0.8301 - val_loss: 1.3870 - val_accuracy: 0.5877\n",
      "Epoch 2262/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5217 - accuracy: 0.8296 - val_loss: 1.4364 - val_accuracy: 0.5779\n",
      "Epoch 2263/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5318 - accuracy: 0.8213 - val_loss: 1.4836 - val_accuracy: 0.5682\n",
      "Epoch 2264/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5720 - accuracy: 0.8142 - val_loss: 1.5297 - val_accuracy: 0.5552\n",
      "Epoch 2265/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5144 - accuracy: 0.8174 - val_loss: 1.5133 - val_accuracy: 0.5584\n",
      "Epoch 2266/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5974 - accuracy: 0.8045 - val_loss: 1.4938 - val_accuracy: 0.5714\n",
      "Epoch 2267/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4397 - accuracy: 0.8436 - val_loss: 1.4696 - val_accuracy: 0.5714\n",
      "Epoch 2268/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5167 - accuracy: 0.8352 - val_loss: 1.4368 - val_accuracy: 0.5747\n",
      "Epoch 2269/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5125 - accuracy: 0.8310 - val_loss: 1.3738 - val_accuracy: 0.5974\n",
      "Epoch 2270/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5324 - accuracy: 0.8045 - val_loss: 1.3220 - val_accuracy: 0.6039\n",
      "Epoch 2271/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5519 - accuracy: 0.8240 - val_loss: 1.2609 - val_accuracy: 0.6234\n",
      "Epoch 2272/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6152 - accuracy: 0.8096 - val_loss: 1.2323 - val_accuracy: 0.6234\n",
      "Epoch 2273/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5556 - accuracy: 0.8135 - val_loss: 1.2370 - val_accuracy: 0.6364\n",
      "Epoch 2274/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5035 - accuracy: 0.8422 - val_loss: 1.2688 - val_accuracy: 0.6201\n",
      "Epoch 2275/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5335 - accuracy: 0.8436 - val_loss: 1.3274 - val_accuracy: 0.6006\n",
      "Epoch 2276/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5770 - accuracy: 0.8086 - val_loss: 1.4008 - val_accuracy: 0.5812\n",
      "Epoch 2277/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5850 - accuracy: 0.7949 - val_loss: 1.4926 - val_accuracy: 0.5747\n",
      "Epoch 2278/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5539 - accuracy: 0.8174 - val_loss: 1.5633 - val_accuracy: 0.5682\n",
      "Epoch 2279/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5396 - accuracy: 0.8101 - val_loss: 1.5949 - val_accuracy: 0.5617\n",
      "Epoch 2280/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5109 - accuracy: 0.8320 - val_loss: 1.6235 - val_accuracy: 0.5519\n",
      "Epoch 2281/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5735 - accuracy: 0.8142 - val_loss: 1.5813 - val_accuracy: 0.5617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2282/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5545 - accuracy: 0.8213 - val_loss: 1.5443 - val_accuracy: 0.5584\n",
      "Epoch 2283/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5384 - accuracy: 0.8213 - val_loss: 1.4767 - val_accuracy: 0.5682\n",
      "Epoch 2284/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5254 - accuracy: 0.8198 - val_loss: 1.4425 - val_accuracy: 0.5682\n",
      "Epoch 2285/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5209 - accuracy: 0.8320 - val_loss: 1.3988 - val_accuracy: 0.5714\n",
      "Epoch 2286/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5201 - accuracy: 0.8338 - val_loss: 1.3720 - val_accuracy: 0.5649\n",
      "Epoch 2287/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5206 - accuracy: 0.8262 - val_loss: 1.3398 - val_accuracy: 0.5779\n",
      "Epoch 2288/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5367 - accuracy: 0.8240 - val_loss: 1.3128 - val_accuracy: 0.5844\n",
      "Epoch 2289/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5924 - accuracy: 0.8115 - val_loss: 1.2809 - val_accuracy: 0.5974\n",
      "Epoch 2290/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6194 - accuracy: 0.7877 - val_loss: 1.2769 - val_accuracy: 0.5974\n",
      "Epoch 2291/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5178 - accuracy: 0.8379 - val_loss: 1.2853 - val_accuracy: 0.6136\n",
      "Epoch 2292/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5509 - accuracy: 0.8226 - val_loss: 1.3106 - val_accuracy: 0.5974\n",
      "Epoch 2293/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5438 - accuracy: 0.8281 - val_loss: 1.3080 - val_accuracy: 0.5909\n",
      "Epoch 2294/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5740 - accuracy: 0.7919 - val_loss: 1.3069 - val_accuracy: 0.5974\n",
      "Epoch 2295/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5304 - accuracy: 0.8252 - val_loss: 1.3015 - val_accuracy: 0.5974\n",
      "Epoch 2296/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5717 - accuracy: 0.8017 - val_loss: 1.2706 - val_accuracy: 0.6071\n",
      "Epoch 2297/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5391 - accuracy: 0.8198 - val_loss: 1.2558 - val_accuracy: 0.6136\n",
      "Epoch 2298/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5647 - accuracy: 0.8170 - val_loss: 1.2725 - val_accuracy: 0.6071\n",
      "Epoch 2299/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5556 - accuracy: 0.8135 - val_loss: 1.2880 - val_accuracy: 0.6006\n",
      "Epoch 2300/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5562 - accuracy: 0.8212 - val_loss: 1.2952 - val_accuracy: 0.5942\n",
      "Epoch 2301/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5707 - accuracy: 0.8184 - val_loss: 1.2881 - val_accuracy: 0.6006\n",
      "Epoch 2302/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5703 - accuracy: 0.8135 - val_loss: 1.3061 - val_accuracy: 0.5974\n",
      "Epoch 2303/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5808 - accuracy: 0.8115 - val_loss: 1.3380 - val_accuracy: 0.6071\n",
      "Epoch 2304/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5508 - accuracy: 0.8101 - val_loss: 1.3437 - val_accuracy: 0.6039\n",
      "Epoch 2305/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5598 - accuracy: 0.8076 - val_loss: 1.3029 - val_accuracy: 0.6104\n",
      "Epoch 2306/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5120 - accuracy: 0.8359 - val_loss: 1.2783 - val_accuracy: 0.6169\n",
      "Epoch 2307/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5819 - accuracy: 0.8076 - val_loss: 1.2761 - val_accuracy: 0.6136\n",
      "Epoch 2308/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4979 - accuracy: 0.8291 - val_loss: 1.2654 - val_accuracy: 0.6266\n",
      "Epoch 2309/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5241 - accuracy: 0.8198 - val_loss: 1.2682 - val_accuracy: 0.6364\n",
      "Epoch 2310/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5570 - accuracy: 0.8174 - val_loss: 1.2632 - val_accuracy: 0.6364\n",
      "Epoch 2311/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5790 - accuracy: 0.8115 - val_loss: 1.2664 - val_accuracy: 0.6266\n",
      "Epoch 2312/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5501 - accuracy: 0.8226 - val_loss: 1.2718 - val_accuracy: 0.6364\n",
      "Epoch 2313/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5240 - accuracy: 0.8268 - val_loss: 1.2628 - val_accuracy: 0.6104\n",
      "Epoch 2314/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5121 - accuracy: 0.8291 - val_loss: 1.2788 - val_accuracy: 0.6136\n",
      "Epoch 2315/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5037 - accuracy: 0.8282 - val_loss: 1.2820 - val_accuracy: 0.6169\n",
      "Epoch 2316/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5294 - accuracy: 0.8193 - val_loss: 1.2715 - val_accuracy: 0.6169\n",
      "Epoch 2317/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5462 - accuracy: 0.8311 - val_loss: 1.2379 - val_accuracy: 0.6169\n",
      "Epoch 2318/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5654 - accuracy: 0.8164 - val_loss: 1.2316 - val_accuracy: 0.6234\n",
      "Epoch 2319/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5402 - accuracy: 0.8242 - val_loss: 1.2243 - val_accuracy: 0.6331\n",
      "Epoch 2320/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5635 - accuracy: 0.8018 - val_loss: 1.2245 - val_accuracy: 0.6299\n",
      "Epoch 2321/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5390 - accuracy: 0.8291 - val_loss: 1.2125 - val_accuracy: 0.6364\n",
      "Epoch 2322/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5600 - accuracy: 0.8271 - val_loss: 1.2069 - val_accuracy: 0.6331\n",
      "Epoch 2323/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5285 - accuracy: 0.8389 - val_loss: 1.2177 - val_accuracy: 0.6299\n",
      "Epoch 2324/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5205 - accuracy: 0.8324 - val_loss: 1.2546 - val_accuracy: 0.6039\n",
      "Epoch 2325/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5283 - accuracy: 0.8330 - val_loss: 1.3403 - val_accuracy: 0.5682\n",
      "Epoch 2326/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5431 - accuracy: 0.8296 - val_loss: 1.4677 - val_accuracy: 0.5519\n",
      "Epoch 2327/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5233 - accuracy: 0.8268 - val_loss: 1.6472 - val_accuracy: 0.5292\n",
      "Epoch 2328/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5937 - accuracy: 0.8047 - val_loss: 1.7508 - val_accuracy: 0.5032\n",
      "Epoch 2329/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5608 - accuracy: 0.8105 - val_loss: 1.7802 - val_accuracy: 0.5032\n",
      "Epoch 2330/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5541 - accuracy: 0.8135 - val_loss: 1.7482 - val_accuracy: 0.5130\n",
      "Epoch 2331/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5646 - accuracy: 0.8170 - val_loss: 1.6372 - val_accuracy: 0.5260\n",
      "Epoch 2332/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5232 - accuracy: 0.8320 - val_loss: 1.5057 - val_accuracy: 0.5714\n",
      "Epoch 2333/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5629 - accuracy: 0.8184 - val_loss: 1.3989 - val_accuracy: 0.5942\n",
      "Epoch 2334/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4580 - accuracy: 0.8366 - val_loss: 1.3089 - val_accuracy: 0.6006\n",
      "Epoch 2335/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5037 - accuracy: 0.8492 - val_loss: 1.2647 - val_accuracy: 0.6071\n",
      "Epoch 2336/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5322 - accuracy: 0.8262 - val_loss: 1.2351 - val_accuracy: 0.6234\n",
      "Epoch 2337/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5262 - accuracy: 0.8193 - val_loss: 1.2175 - val_accuracy: 0.6266\n",
      "Epoch 2338/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5233 - accuracy: 0.8320 - val_loss: 1.1968 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2339/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5649 - accuracy: 0.8125 - val_loss: 1.1847 - val_accuracy: 0.6364\n",
      "Epoch 2340/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4812 - accuracy: 0.8324 - val_loss: 1.1695 - val_accuracy: 0.6494\n",
      "Epoch 2341/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4824 - accuracy: 0.8352 - val_loss: 1.1769 - val_accuracy: 0.6558\n",
      "Epoch 2342/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4664 - accuracy: 0.8350 - val_loss: 1.1943 - val_accuracy: 0.6591\n",
      "Epoch 2343/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5115 - accuracy: 0.8389 - val_loss: 1.2108 - val_accuracy: 0.6526\n",
      "Epoch 2344/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5138 - accuracy: 0.8422 - val_loss: 1.1980 - val_accuracy: 0.6461\n",
      "Epoch 2345/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5336 - accuracy: 0.8213 - val_loss: 1.1897 - val_accuracy: 0.6526\n",
      "Epoch 2346/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5212 - accuracy: 0.8156 - val_loss: 1.1842 - val_accuracy: 0.6494\n",
      "Epoch 2347/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5435 - accuracy: 0.8394 - val_loss: 1.1678 - val_accuracy: 0.6591\n",
      "Epoch 2348/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4533 - accuracy: 0.8575 - val_loss: 1.1630 - val_accuracy: 0.6558\n",
      "Epoch 2349/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5078 - accuracy: 0.8350 - val_loss: 1.1597 - val_accuracy: 0.6494\n",
      "Epoch 2350/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4895 - accuracy: 0.8467 - val_loss: 1.1699 - val_accuracy: 0.6494\n",
      "Epoch 2351/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5495 - accuracy: 0.8301 - val_loss: 1.1799 - val_accuracy: 0.6429\n",
      "Epoch 2352/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5114 - accuracy: 0.8340 - val_loss: 1.1971 - val_accuracy: 0.6266\n",
      "Epoch 2353/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5389 - accuracy: 0.8184 - val_loss: 1.2238 - val_accuracy: 0.6201\n",
      "Epoch 2354/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4849 - accuracy: 0.8359 - val_loss: 1.2473 - val_accuracy: 0.6201\n",
      "Epoch 2355/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4831 - accuracy: 0.8268 - val_loss: 1.2591 - val_accuracy: 0.6234\n",
      "Epoch 2356/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5479 - accuracy: 0.8226 - val_loss: 1.2362 - val_accuracy: 0.6234\n",
      "Epoch 2357/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5264 - accuracy: 0.8282 - val_loss: 1.1758 - val_accuracy: 0.6364\n",
      "Epoch 2358/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5238 - accuracy: 0.8359 - val_loss: 1.1285 - val_accuracy: 0.6526\n",
      "Epoch 2359/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5314 - accuracy: 0.8212 - val_loss: 1.1159 - val_accuracy: 0.6623\n",
      "Epoch 2360/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5333 - accuracy: 0.8170 - val_loss: 1.1189 - val_accuracy: 0.6558\n",
      "Epoch 2361/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5234 - accuracy: 0.8226 - val_loss: 1.1234 - val_accuracy: 0.6656\n",
      "Epoch 2362/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4845 - accuracy: 0.8589 - val_loss: 1.1191 - val_accuracy: 0.6688\n",
      "Epoch 2363/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5206 - accuracy: 0.8350 - val_loss: 1.1182 - val_accuracy: 0.6656\n",
      "Epoch 2364/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4897 - accuracy: 0.8369 - val_loss: 1.1206 - val_accuracy: 0.6753\n",
      "Epoch 2365/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5751 - accuracy: 0.8135 - val_loss: 1.1130 - val_accuracy: 0.6786\n",
      "Epoch 2366/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4907 - accuracy: 0.8506 - val_loss: 1.1069 - val_accuracy: 0.6753\n",
      "Epoch 2367/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5936 - accuracy: 0.8031 - val_loss: 1.1044 - val_accuracy: 0.6818\n",
      "Epoch 2368/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5381 - accuracy: 0.8125 - val_loss: 1.1104 - val_accuracy: 0.6688\n",
      "Epoch 2369/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5057 - accuracy: 0.8232 - val_loss: 1.1212 - val_accuracy: 0.6623\n",
      "Epoch 2370/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4705 - accuracy: 0.8492 - val_loss: 1.1495 - val_accuracy: 0.6526\n",
      "Epoch 2371/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5199 - accuracy: 0.8281 - val_loss: 1.1784 - val_accuracy: 0.6461\n",
      "Epoch 2372/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4884 - accuracy: 0.8320 - val_loss: 1.2173 - val_accuracy: 0.6396\n",
      "Epoch 2373/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5829 - accuracy: 0.7979 - val_loss: 1.2393 - val_accuracy: 0.6201\n",
      "Epoch 2374/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5386 - accuracy: 0.8282 - val_loss: 1.2638 - val_accuracy: 0.6006\n",
      "Epoch 2375/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5475 - accuracy: 0.8281 - val_loss: 1.3045 - val_accuracy: 0.6136\n",
      "Epoch 2376/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5001 - accuracy: 0.8320 - val_loss: 1.3290 - val_accuracy: 0.6104\n",
      "Epoch 2377/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4898 - accuracy: 0.8296 - val_loss: 1.3401 - val_accuracy: 0.6104\n",
      "Epoch 2378/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4971 - accuracy: 0.8418 - val_loss: 1.3288 - val_accuracy: 0.6006\n",
      "Epoch 2379/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4751 - accuracy: 0.8438 - val_loss: 1.3132 - val_accuracy: 0.6039\n",
      "Epoch 2380/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4812 - accuracy: 0.8310 - val_loss: 1.2898 - val_accuracy: 0.6299\n",
      "Epoch 2381/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5520 - accuracy: 0.8242 - val_loss: 1.2649 - val_accuracy: 0.6429\n",
      "Epoch 2382/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5063 - accuracy: 0.8240 - val_loss: 1.2274 - val_accuracy: 0.6623\n",
      "Epoch 2383/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6116 - accuracy: 0.8073 - val_loss: 1.1870 - val_accuracy: 0.6721\n",
      "Epoch 2384/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5083 - accuracy: 0.8128 - val_loss: 1.1559 - val_accuracy: 0.6721\n",
      "Epoch 2385/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5233 - accuracy: 0.8240 - val_loss: 1.1138 - val_accuracy: 0.6721\n",
      "Epoch 2386/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5104 - accuracy: 0.8428 - val_loss: 1.0952 - val_accuracy: 0.6818\n",
      "Epoch 2387/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5072 - accuracy: 0.8338 - val_loss: 1.0948 - val_accuracy: 0.6786\n",
      "Epoch 2388/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5341 - accuracy: 0.8164 - val_loss: 1.1116 - val_accuracy: 0.6688\n",
      "Epoch 2389/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4509 - accuracy: 0.8450 - val_loss: 1.1372 - val_accuracy: 0.6429\n",
      "Epoch 2390/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5338 - accuracy: 0.8184 - val_loss: 1.1710 - val_accuracy: 0.6396\n",
      "Epoch 2391/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4887 - accuracy: 0.8436 - val_loss: 1.2101 - val_accuracy: 0.6299\n",
      "Epoch 2392/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5486 - accuracy: 0.8135 - val_loss: 1.2174 - val_accuracy: 0.6234\n",
      "Epoch 2393/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5025 - accuracy: 0.8350 - val_loss: 1.2094 - val_accuracy: 0.6266\n",
      "Epoch 2394/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4916 - accuracy: 0.8301 - val_loss: 1.1871 - val_accuracy: 0.6364\n",
      "Epoch 2395/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6052 - accuracy: 0.7975 - val_loss: 1.1806 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2396/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5311 - accuracy: 0.8296 - val_loss: 1.1715 - val_accuracy: 0.6591\n",
      "Epoch 2397/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5233 - accuracy: 0.8324 - val_loss: 1.1927 - val_accuracy: 0.6396\n",
      "Epoch 2398/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5448 - accuracy: 0.8240 - val_loss: 1.2173 - val_accuracy: 0.6429\n",
      "Epoch 2399/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4967 - accuracy: 0.8252 - val_loss: 1.2370 - val_accuracy: 0.6299\n",
      "Epoch 2400/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5050 - accuracy: 0.8438 - val_loss: 1.2319 - val_accuracy: 0.6234\n",
      "Epoch 2401/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5676 - accuracy: 0.8164 - val_loss: 1.2334 - val_accuracy: 0.6299\n",
      "Epoch 2402/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5197 - accuracy: 0.8282 - val_loss: 1.2380 - val_accuracy: 0.6299\n",
      "Epoch 2403/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4910 - accuracy: 0.8359 - val_loss: 1.2270 - val_accuracy: 0.6396\n",
      "Epoch 2404/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4821 - accuracy: 0.8324 - val_loss: 1.2175 - val_accuracy: 0.6429\n",
      "Epoch 2405/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5221 - accuracy: 0.8350 - val_loss: 1.2054 - val_accuracy: 0.6429\n",
      "Epoch 2406/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4651 - accuracy: 0.8398 - val_loss: 1.1985 - val_accuracy: 0.6461\n",
      "Epoch 2407/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5633 - accuracy: 0.8145 - val_loss: 1.1882 - val_accuracy: 0.6331\n",
      "Epoch 2408/4000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4792 - accuracy: 0.8268 - val_loss: 1.1761 - val_accuracy: 0.6364\n",
      "Epoch 2409/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4957 - accuracy: 0.8380 - val_loss: 1.1752 - val_accuracy: 0.6461\n",
      "Epoch 2410/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5051 - accuracy: 0.8268 - val_loss: 1.1779 - val_accuracy: 0.6396\n",
      "Epoch 2411/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4857 - accuracy: 0.8252 - val_loss: 1.1845 - val_accuracy: 0.6396\n",
      "Epoch 2412/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4914 - accuracy: 0.8282 - val_loss: 1.1921 - val_accuracy: 0.6429\n",
      "Epoch 2413/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4944 - accuracy: 0.8271 - val_loss: 1.2096 - val_accuracy: 0.6461\n",
      "Epoch 2414/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5374 - accuracy: 0.8184 - val_loss: 1.2063 - val_accuracy: 0.6591\n",
      "Epoch 2415/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4565 - accuracy: 0.8478 - val_loss: 1.2076 - val_accuracy: 0.6494\n",
      "Epoch 2416/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5217 - accuracy: 0.8422 - val_loss: 1.2135 - val_accuracy: 0.6526\n",
      "Epoch 2417/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5172 - accuracy: 0.8394 - val_loss: 1.2293 - val_accuracy: 0.6429\n",
      "Epoch 2418/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4970 - accuracy: 0.8301 - val_loss: 1.2430 - val_accuracy: 0.6494\n",
      "Epoch 2419/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4214 - accuracy: 0.8575 - val_loss: 1.2516 - val_accuracy: 0.6494\n",
      "Epoch 2420/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5589 - accuracy: 0.8101 - val_loss: 1.2564 - val_accuracy: 0.6396\n",
      "Epoch 2421/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5428 - accuracy: 0.8156 - val_loss: 1.2519 - val_accuracy: 0.6396\n",
      "Epoch 2422/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4691 - accuracy: 0.8545 - val_loss: 1.2731 - val_accuracy: 0.6136\n",
      "Epoch 2423/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4869 - accuracy: 0.8379 - val_loss: 1.2767 - val_accuracy: 0.6104\n",
      "Epoch 2424/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4755 - accuracy: 0.8467 - val_loss: 1.2787 - val_accuracy: 0.6169\n",
      "Epoch 2425/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5126 - accuracy: 0.8324 - val_loss: 1.2905 - val_accuracy: 0.6039\n",
      "Epoch 2426/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5258 - accuracy: 0.8320 - val_loss: 1.2778 - val_accuracy: 0.6234\n",
      "Epoch 2427/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5755 - accuracy: 0.8184 - val_loss: 1.2562 - val_accuracy: 0.6201\n",
      "Epoch 2428/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5274 - accuracy: 0.8320 - val_loss: 1.2344 - val_accuracy: 0.6234\n",
      "Epoch 2429/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4281 - accuracy: 0.8561 - val_loss: 1.2156 - val_accuracy: 0.6429\n",
      "Epoch 2430/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5313 - accuracy: 0.8170 - val_loss: 1.2075 - val_accuracy: 0.6623\n",
      "Epoch 2431/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4562 - accuracy: 0.8408 - val_loss: 1.2043 - val_accuracy: 0.6558\n",
      "Epoch 2432/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4661 - accuracy: 0.8340 - val_loss: 1.2013 - val_accuracy: 0.6623\n",
      "Epoch 2433/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5005 - accuracy: 0.8428 - val_loss: 1.2094 - val_accuracy: 0.6558\n",
      "Epoch 2434/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5171 - accuracy: 0.8450 - val_loss: 1.2329 - val_accuracy: 0.6364\n",
      "Epoch 2435/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4678 - accuracy: 0.8254 - val_loss: 1.2523 - val_accuracy: 0.6494\n",
      "Epoch 2436/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5159 - accuracy: 0.8156 - val_loss: 1.2646 - val_accuracy: 0.6461\n",
      "Epoch 2437/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4901 - accuracy: 0.8492 - val_loss: 1.2640 - val_accuracy: 0.6494\n",
      "Epoch 2438/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5243 - accuracy: 0.8311 - val_loss: 1.2582 - val_accuracy: 0.6558\n",
      "Epoch 2439/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5281 - accuracy: 0.8242 - val_loss: 1.2461 - val_accuracy: 0.6558\n",
      "Epoch 2440/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4471 - accuracy: 0.8673 - val_loss: 1.2506 - val_accuracy: 0.6558\n",
      "Epoch 2441/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5212 - accuracy: 0.8291 - val_loss: 1.2597 - val_accuracy: 0.6591\n",
      "Epoch 2442/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5046 - accuracy: 0.8436 - val_loss: 1.2794 - val_accuracy: 0.6526\n",
      "Epoch 2443/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4892 - accuracy: 0.8408 - val_loss: 1.2735 - val_accuracy: 0.6656\n",
      "Epoch 2444/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5105 - accuracy: 0.8338 - val_loss: 1.2690 - val_accuracy: 0.6656\n",
      "Epoch 2445/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5298 - accuracy: 0.8408 - val_loss: 1.2543 - val_accuracy: 0.6721\n",
      "Epoch 2446/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5018 - accuracy: 0.8281 - val_loss: 1.2380 - val_accuracy: 0.6721\n",
      "Epoch 2447/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4956 - accuracy: 0.8447 - val_loss: 1.2337 - val_accuracy: 0.6688\n",
      "Epoch 2448/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5146 - accuracy: 0.8380 - val_loss: 1.2318 - val_accuracy: 0.6623\n",
      "Epoch 2449/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5282 - accuracy: 0.8226 - val_loss: 1.2313 - val_accuracy: 0.6623\n",
      "Epoch 2450/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5452 - accuracy: 0.8338 - val_loss: 1.2286 - val_accuracy: 0.6623\n",
      "Epoch 2451/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4778 - accuracy: 0.8366 - val_loss: 1.2278 - val_accuracy: 0.6461\n",
      "Epoch 2452/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5337 - accuracy: 0.8380 - val_loss: 1.2286 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2453/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4962 - accuracy: 0.8380 - val_loss: 1.2363 - val_accuracy: 0.6396\n",
      "Epoch 2454/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4797 - accuracy: 0.8467 - val_loss: 1.2368 - val_accuracy: 0.6396\n",
      "Epoch 2455/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5115 - accuracy: 0.8311 - val_loss: 1.2243 - val_accuracy: 0.6429\n",
      "Epoch 2456/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5463 - accuracy: 0.8184 - val_loss: 1.2128 - val_accuracy: 0.6396\n",
      "Epoch 2457/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4623 - accuracy: 0.8477 - val_loss: 1.1953 - val_accuracy: 0.6364\n",
      "Epoch 2458/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4458 - accuracy: 0.8575 - val_loss: 1.1829 - val_accuracy: 0.6461\n",
      "Epoch 2459/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4904 - accuracy: 0.8340 - val_loss: 1.1830 - val_accuracy: 0.6396\n",
      "Epoch 2460/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4999 - accuracy: 0.8394 - val_loss: 1.1816 - val_accuracy: 0.6396\n",
      "Epoch 2461/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4943 - accuracy: 0.8324 - val_loss: 1.1772 - val_accuracy: 0.6461\n",
      "Epoch 2462/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5044 - accuracy: 0.8369 - val_loss: 1.1767 - val_accuracy: 0.6494\n",
      "Epoch 2463/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5397 - accuracy: 0.8212 - val_loss: 1.1842 - val_accuracy: 0.6591\n",
      "Epoch 2464/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4916 - accuracy: 0.8408 - val_loss: 1.1990 - val_accuracy: 0.6623\n",
      "Epoch 2465/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4668 - accuracy: 0.8589 - val_loss: 1.2105 - val_accuracy: 0.6461\n",
      "Epoch 2466/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4906 - accuracy: 0.8296 - val_loss: 1.2184 - val_accuracy: 0.6461\n",
      "Epoch 2467/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5377 - accuracy: 0.8301 - val_loss: 1.2266 - val_accuracy: 0.6494\n",
      "Epoch 2468/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4585 - accuracy: 0.8561 - val_loss: 1.2560 - val_accuracy: 0.6331\n",
      "Epoch 2469/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4956 - accuracy: 0.8340 - val_loss: 1.3103 - val_accuracy: 0.6234\n",
      "Epoch 2470/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4524 - accuracy: 0.8464 - val_loss: 1.3787 - val_accuracy: 0.6169\n",
      "Epoch 2471/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4768 - accuracy: 0.8408 - val_loss: 1.4372 - val_accuracy: 0.5942\n",
      "Epoch 2472/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4995 - accuracy: 0.8486 - val_loss: 1.4666 - val_accuracy: 0.5779\n",
      "Epoch 2473/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5151 - accuracy: 0.8226 - val_loss: 1.4780 - val_accuracy: 0.5682\n",
      "Epoch 2474/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4615 - accuracy: 0.8324 - val_loss: 1.4507 - val_accuracy: 0.5747\n",
      "Epoch 2475/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5125 - accuracy: 0.8193 - val_loss: 1.4143 - val_accuracy: 0.5877\n",
      "Epoch 2476/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4908 - accuracy: 0.8380 - val_loss: 1.3757 - val_accuracy: 0.6039\n",
      "Epoch 2477/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4490 - accuracy: 0.8603 - val_loss: 1.3399 - val_accuracy: 0.6299\n",
      "Epoch 2478/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4601 - accuracy: 0.8478 - val_loss: 1.3089 - val_accuracy: 0.6429\n",
      "Epoch 2479/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4635 - accuracy: 0.8547 - val_loss: 1.2819 - val_accuracy: 0.6558\n",
      "Epoch 2480/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4842 - accuracy: 0.8330 - val_loss: 1.2581 - val_accuracy: 0.6396\n",
      "Epoch 2481/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4873 - accuracy: 0.8447 - val_loss: 1.2438 - val_accuracy: 0.6494\n",
      "Epoch 2482/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4734 - accuracy: 0.8457 - val_loss: 1.2275 - val_accuracy: 0.6591\n",
      "Epoch 2483/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4497 - accuracy: 0.8408 - val_loss: 1.2228 - val_accuracy: 0.6591\n",
      "Epoch 2484/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4603 - accuracy: 0.8422 - val_loss: 1.2325 - val_accuracy: 0.6558\n",
      "Epoch 2485/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5265 - accuracy: 0.8212 - val_loss: 1.2555 - val_accuracy: 0.6623\n",
      "Epoch 2486/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4740 - accuracy: 0.8301 - val_loss: 1.2808 - val_accuracy: 0.6494\n",
      "Epoch 2487/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4742 - accuracy: 0.8496 - val_loss: 1.3002 - val_accuracy: 0.6331\n",
      "Epoch 2488/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4797 - accuracy: 0.8330 - val_loss: 1.3104 - val_accuracy: 0.6169\n",
      "Epoch 2489/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4832 - accuracy: 0.8478 - val_loss: 1.3027 - val_accuracy: 0.6136\n",
      "Epoch 2490/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5308 - accuracy: 0.8408 - val_loss: 1.2725 - val_accuracy: 0.6299\n",
      "Epoch 2491/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4916 - accuracy: 0.8436 - val_loss: 1.2437 - val_accuracy: 0.6461\n",
      "Epoch 2492/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4911 - accuracy: 0.8252 - val_loss: 1.2210 - val_accuracy: 0.6494\n",
      "Epoch 2493/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4800 - accuracy: 0.8350 - val_loss: 1.2053 - val_accuracy: 0.6396\n",
      "Epoch 2494/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4947 - accuracy: 0.8359 - val_loss: 1.1958 - val_accuracy: 0.6461\n",
      "Epoch 2495/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5141 - accuracy: 0.8193 - val_loss: 1.1940 - val_accuracy: 0.6526\n",
      "Epoch 2496/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4848 - accuracy: 0.8240 - val_loss: 1.2098 - val_accuracy: 0.6494\n",
      "Epoch 2497/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4782 - accuracy: 0.8436 - val_loss: 1.2408 - val_accuracy: 0.6461\n",
      "Epoch 2498/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4381 - accuracy: 0.8589 - val_loss: 1.2880 - val_accuracy: 0.6331\n",
      "Epoch 2499/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5364 - accuracy: 0.8262 - val_loss: 1.3212 - val_accuracy: 0.6266\n",
      "Epoch 2500/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4772 - accuracy: 0.8547 - val_loss: 1.3315 - val_accuracy: 0.6331\n",
      "Epoch 2501/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4979 - accuracy: 0.8359 - val_loss: 1.3203 - val_accuracy: 0.6364\n",
      "Epoch 2502/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4779 - accuracy: 0.8310 - val_loss: 1.3058 - val_accuracy: 0.6396\n",
      "Epoch 2503/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4516 - accuracy: 0.8603 - val_loss: 1.2706 - val_accuracy: 0.6331\n",
      "Epoch 2504/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4838 - accuracy: 0.8350 - val_loss: 1.2330 - val_accuracy: 0.6429\n",
      "Epoch 2505/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4929 - accuracy: 0.8436 - val_loss: 1.2110 - val_accuracy: 0.6526\n",
      "Epoch 2506/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4384 - accuracy: 0.8575 - val_loss: 1.2129 - val_accuracy: 0.6526\n",
      "Epoch 2507/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4436 - accuracy: 0.8457 - val_loss: 1.2099 - val_accuracy: 0.6591\n",
      "Epoch 2508/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4832 - accuracy: 0.8282 - val_loss: 1.2160 - val_accuracy: 0.6623\n",
      "Epoch 2509/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4506 - accuracy: 0.8506 - val_loss: 1.2261 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2510/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5327 - accuracy: 0.8128 - val_loss: 1.2322 - val_accuracy: 0.6396\n",
      "Epoch 2511/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4756 - accuracy: 0.8436 - val_loss: 1.2480 - val_accuracy: 0.6396\n",
      "Epoch 2512/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4665 - accuracy: 0.8525 - val_loss: 1.2743 - val_accuracy: 0.6266\n",
      "Epoch 2513/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5438 - accuracy: 0.8240 - val_loss: 1.3103 - val_accuracy: 0.6039\n",
      "Epoch 2514/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5096 - accuracy: 0.8436 - val_loss: 1.3330 - val_accuracy: 0.5779\n",
      "Epoch 2515/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5176 - accuracy: 0.8156 - val_loss: 1.3176 - val_accuracy: 0.5942\n",
      "Epoch 2516/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4791 - accuracy: 0.8447 - val_loss: 1.2685 - val_accuracy: 0.6136\n",
      "Epoch 2517/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5262 - accuracy: 0.8324 - val_loss: 1.2310 - val_accuracy: 0.6461\n",
      "Epoch 2518/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4481 - accuracy: 0.8520 - val_loss: 1.2081 - val_accuracy: 0.6591\n",
      "Epoch 2519/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4300 - accuracy: 0.8652 - val_loss: 1.2009 - val_accuracy: 0.6721\n",
      "Epoch 2520/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4768 - accuracy: 0.8436 - val_loss: 1.2079 - val_accuracy: 0.6753\n",
      "Epoch 2521/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5008 - accuracy: 0.8428 - val_loss: 1.2324 - val_accuracy: 0.6623\n",
      "Epoch 2522/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4398 - accuracy: 0.8525 - val_loss: 1.2585 - val_accuracy: 0.6494\n",
      "Epoch 2523/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4771 - accuracy: 0.8389 - val_loss: 1.2955 - val_accuracy: 0.6169\n",
      "Epoch 2524/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4462 - accuracy: 0.8555 - val_loss: 1.3292 - val_accuracy: 0.6071\n",
      "Epoch 2525/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4914 - accuracy: 0.8418 - val_loss: 1.3828 - val_accuracy: 0.6006\n",
      "Epoch 2526/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4592 - accuracy: 0.8643 - val_loss: 1.4224 - val_accuracy: 0.6006\n",
      "Epoch 2527/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4662 - accuracy: 0.8394 - val_loss: 1.4638 - val_accuracy: 0.5877\n",
      "Epoch 2528/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4780 - accuracy: 0.8352 - val_loss: 1.4715 - val_accuracy: 0.5974\n",
      "Epoch 2529/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5093 - accuracy: 0.8359 - val_loss: 1.4490 - val_accuracy: 0.5942\n",
      "Epoch 2530/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4793 - accuracy: 0.8438 - val_loss: 1.4214 - val_accuracy: 0.6039\n",
      "Epoch 2531/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4499 - accuracy: 0.8467 - val_loss: 1.3828 - val_accuracy: 0.6104\n",
      "Epoch 2532/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4985 - accuracy: 0.8447 - val_loss: 1.3240 - val_accuracy: 0.6201\n",
      "Epoch 2533/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4654 - accuracy: 0.8436 - val_loss: 1.2891 - val_accuracy: 0.6299\n",
      "Epoch 2534/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4468 - accuracy: 0.8525 - val_loss: 1.2797 - val_accuracy: 0.6461\n",
      "Epoch 2535/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4231 - accuracy: 0.8715 - val_loss: 1.2913 - val_accuracy: 0.6429\n",
      "Epoch 2536/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5060 - accuracy: 0.8516 - val_loss: 1.3261 - val_accuracy: 0.6136\n",
      "Epoch 2537/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4617 - accuracy: 0.8457 - val_loss: 1.3883 - val_accuracy: 0.5942\n",
      "Epoch 2538/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4799 - accuracy: 0.8408 - val_loss: 1.4463 - val_accuracy: 0.5779\n",
      "Epoch 2539/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4985 - accuracy: 0.8366 - val_loss: 1.4809 - val_accuracy: 0.5714\n",
      "Epoch 2540/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4365 - accuracy: 0.8672 - val_loss: 1.4637 - val_accuracy: 0.5812\n",
      "Epoch 2541/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4845 - accuracy: 0.8394 - val_loss: 1.4392 - val_accuracy: 0.5877\n",
      "Epoch 2542/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5385 - accuracy: 0.8320 - val_loss: 1.4016 - val_accuracy: 0.5942\n",
      "Epoch 2543/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4030 - accuracy: 0.8673 - val_loss: 1.3688 - val_accuracy: 0.6039\n",
      "Epoch 2544/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5031 - accuracy: 0.8338 - val_loss: 1.3287 - val_accuracy: 0.6039\n",
      "Epoch 2545/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4762 - accuracy: 0.8428 - val_loss: 1.3124 - val_accuracy: 0.6201\n",
      "Epoch 2546/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5078 - accuracy: 0.8352 - val_loss: 1.3075 - val_accuracy: 0.6234\n",
      "Epoch 2547/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4541 - accuracy: 0.8492 - val_loss: 1.3121 - val_accuracy: 0.6169\n",
      "Epoch 2548/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4613 - accuracy: 0.8594 - val_loss: 1.3006 - val_accuracy: 0.6169\n",
      "Epoch 2549/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4928 - accuracy: 0.8520 - val_loss: 1.3052 - val_accuracy: 0.5974\n",
      "Epoch 2550/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4985 - accuracy: 0.8366 - val_loss: 1.3146 - val_accuracy: 0.5942\n",
      "Epoch 2551/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4433 - accuracy: 0.8555 - val_loss: 1.3336 - val_accuracy: 0.5714\n",
      "Epoch 2552/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5122 - accuracy: 0.8296 - val_loss: 1.3635 - val_accuracy: 0.5714\n",
      "Epoch 2553/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5078 - accuracy: 0.8330 - val_loss: 1.4170 - val_accuracy: 0.5617\n",
      "Epoch 2554/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4779 - accuracy: 0.8464 - val_loss: 1.4857 - val_accuracy: 0.5584\n",
      "Epoch 2555/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4996 - accuracy: 0.8492 - val_loss: 1.5389 - val_accuracy: 0.5487\n",
      "Epoch 2556/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5036 - accuracy: 0.8422 - val_loss: 1.5939 - val_accuracy: 0.5584\n",
      "Epoch 2557/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5601 - accuracy: 0.8156 - val_loss: 1.6384 - val_accuracy: 0.5455\n",
      "Epoch 2558/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4788 - accuracy: 0.8464 - val_loss: 1.6323 - val_accuracy: 0.5487\n",
      "Epoch 2559/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4607 - accuracy: 0.8438 - val_loss: 1.5879 - val_accuracy: 0.5649\n",
      "Epoch 2560/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4759 - accuracy: 0.8496 - val_loss: 1.5198 - val_accuracy: 0.5519\n",
      "Epoch 2561/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4829 - accuracy: 0.8418 - val_loss: 1.4451 - val_accuracy: 0.5877\n",
      "Epoch 2562/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4666 - accuracy: 0.8478 - val_loss: 1.3999 - val_accuracy: 0.6071\n",
      "Epoch 2563/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4676 - accuracy: 0.8438 - val_loss: 1.3841 - val_accuracy: 0.6136\n",
      "Epoch 2564/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5107 - accuracy: 0.8340 - val_loss: 1.4025 - val_accuracy: 0.6169\n",
      "Epoch 2565/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4333 - accuracy: 0.8682 - val_loss: 1.4195 - val_accuracy: 0.6201\n",
      "Epoch 2566/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4513 - accuracy: 0.8547 - val_loss: 1.4449 - val_accuracy: 0.6006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2567/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5136 - accuracy: 0.8492 - val_loss: 1.4693 - val_accuracy: 0.6006\n",
      "Epoch 2568/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5034 - accuracy: 0.8408 - val_loss: 1.4816 - val_accuracy: 0.6071\n",
      "Epoch 2569/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4898 - accuracy: 0.8478 - val_loss: 1.4620 - val_accuracy: 0.6039\n",
      "Epoch 2570/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5032 - accuracy: 0.8408 - val_loss: 1.4235 - val_accuracy: 0.6266\n",
      "Epoch 2571/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5141 - accuracy: 0.8254 - val_loss: 1.3780 - val_accuracy: 0.6364\n",
      "Epoch 2572/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4457 - accuracy: 0.8520 - val_loss: 1.3485 - val_accuracy: 0.6364\n",
      "Epoch 2573/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4963 - accuracy: 0.8240 - val_loss: 1.3261 - val_accuracy: 0.6494\n",
      "Epoch 2574/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4770 - accuracy: 0.8516 - val_loss: 1.3042 - val_accuracy: 0.6558\n",
      "Epoch 2575/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4511 - accuracy: 0.8535 - val_loss: 1.2875 - val_accuracy: 0.6591\n",
      "Epoch 2576/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4425 - accuracy: 0.8613 - val_loss: 1.2833 - val_accuracy: 0.6591\n",
      "Epoch 2577/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5148 - accuracy: 0.8394 - val_loss: 1.2939 - val_accuracy: 0.6429\n",
      "Epoch 2578/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4732 - accuracy: 0.8398 - val_loss: 1.3275 - val_accuracy: 0.6169\n",
      "Epoch 2579/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5133 - accuracy: 0.8398 - val_loss: 1.3507 - val_accuracy: 0.6234\n",
      "Epoch 2580/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4786 - accuracy: 0.8291 - val_loss: 1.3644 - val_accuracy: 0.6071\n",
      "Epoch 2581/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4787 - accuracy: 0.8478 - val_loss: 1.3870 - val_accuracy: 0.6006\n",
      "Epoch 2582/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4779 - accuracy: 0.8545 - val_loss: 1.4225 - val_accuracy: 0.5974\n",
      "Epoch 2583/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4944 - accuracy: 0.8394 - val_loss: 1.4722 - val_accuracy: 0.5942\n",
      "Epoch 2584/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4081 - accuracy: 0.8633 - val_loss: 1.5003 - val_accuracy: 0.6104\n",
      "Epoch 2585/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4564 - accuracy: 0.8555 - val_loss: 1.4962 - val_accuracy: 0.6104\n",
      "Epoch 2586/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4249 - accuracy: 0.8574 - val_loss: 1.4773 - val_accuracy: 0.6169\n",
      "Epoch 2587/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4930 - accuracy: 0.8350 - val_loss: 1.4487 - val_accuracy: 0.6136\n",
      "Epoch 2588/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4460 - accuracy: 0.8535 - val_loss: 1.4047 - val_accuracy: 0.6234\n",
      "Epoch 2589/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4583 - accuracy: 0.8525 - val_loss: 1.3885 - val_accuracy: 0.6234\n",
      "Epoch 2590/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4158 - accuracy: 0.8643 - val_loss: 1.3756 - val_accuracy: 0.6201\n",
      "Epoch 2591/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4594 - accuracy: 0.8506 - val_loss: 1.3507 - val_accuracy: 0.6266\n",
      "Epoch 2592/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4569 - accuracy: 0.8535 - val_loss: 1.3356 - val_accuracy: 0.6266\n",
      "Epoch 2593/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4670 - accuracy: 0.8428 - val_loss: 1.3236 - val_accuracy: 0.6299\n",
      "Epoch 2594/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4949 - accuracy: 0.8450 - val_loss: 1.3491 - val_accuracy: 0.6331\n",
      "Epoch 2595/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4611 - accuracy: 0.8478 - val_loss: 1.3812 - val_accuracy: 0.6201\n",
      "Epoch 2596/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4720 - accuracy: 0.8324 - val_loss: 1.3869 - val_accuracy: 0.6136\n",
      "Epoch 2597/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4913 - accuracy: 0.8398 - val_loss: 1.3687 - val_accuracy: 0.6104\n",
      "Epoch 2598/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4272 - accuracy: 0.8604 - val_loss: 1.3287 - val_accuracy: 0.6201\n",
      "Epoch 2599/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5124 - accuracy: 0.8352 - val_loss: 1.2831 - val_accuracy: 0.6526\n",
      "Epoch 2600/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4810 - accuracy: 0.8320 - val_loss: 1.2552 - val_accuracy: 0.6494\n",
      "Epoch 2601/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4574 - accuracy: 0.8422 - val_loss: 1.2348 - val_accuracy: 0.6623\n",
      "Epoch 2602/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4844 - accuracy: 0.8464 - val_loss: 1.2351 - val_accuracy: 0.6591\n",
      "Epoch 2603/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3979 - accuracy: 0.8617 - val_loss: 1.2551 - val_accuracy: 0.6429\n",
      "Epoch 2604/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4853 - accuracy: 0.8296 - val_loss: 1.2866 - val_accuracy: 0.6234\n",
      "Epoch 2605/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4333 - accuracy: 0.8594 - val_loss: 1.3216 - val_accuracy: 0.6201\n",
      "Epoch 2606/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5185 - accuracy: 0.8389 - val_loss: 1.3444 - val_accuracy: 0.6136\n",
      "Epoch 2607/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4820 - accuracy: 0.8398 - val_loss: 1.3505 - val_accuracy: 0.6169\n",
      "Epoch 2608/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4837 - accuracy: 0.8457 - val_loss: 1.3719 - val_accuracy: 0.6169\n",
      "Epoch 2609/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4206 - accuracy: 0.8721 - val_loss: 1.3685 - val_accuracy: 0.6169\n",
      "Epoch 2610/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4232 - accuracy: 0.8721 - val_loss: 1.3501 - val_accuracy: 0.6234\n",
      "Epoch 2611/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4576 - accuracy: 0.8492 - val_loss: 1.3044 - val_accuracy: 0.6364\n",
      "Epoch 2612/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4419 - accuracy: 0.8617 - val_loss: 1.2900 - val_accuracy: 0.6364\n",
      "Epoch 2613/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4688 - accuracy: 0.8394 - val_loss: 1.2720 - val_accuracy: 0.6331\n",
      "Epoch 2614/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4710 - accuracy: 0.8408 - val_loss: 1.2756 - val_accuracy: 0.6169\n",
      "Epoch 2615/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4791 - accuracy: 0.8575 - val_loss: 1.2797 - val_accuracy: 0.6234\n",
      "Epoch 2616/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4851 - accuracy: 0.8447 - val_loss: 1.2818 - val_accuracy: 0.6331\n",
      "Epoch 2617/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4834 - accuracy: 0.8380 - val_loss: 1.2846 - val_accuracy: 0.6299\n",
      "Epoch 2618/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4646 - accuracy: 0.8478 - val_loss: 1.2806 - val_accuracy: 0.6331\n",
      "Epoch 2619/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4138 - accuracy: 0.8701 - val_loss: 1.2715 - val_accuracy: 0.6461\n",
      "Epoch 2620/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4138 - accuracy: 0.8631 - val_loss: 1.2567 - val_accuracy: 0.6494\n",
      "Epoch 2621/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4665 - accuracy: 0.8486 - val_loss: 1.2502 - val_accuracy: 0.6526\n",
      "Epoch 2622/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4611 - accuracy: 0.8584 - val_loss: 1.2525 - val_accuracy: 0.6656\n",
      "Epoch 2623/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4161 - accuracy: 0.8589 - val_loss: 1.2616 - val_accuracy: 0.6753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2624/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4405 - accuracy: 0.8486 - val_loss: 1.2774 - val_accuracy: 0.6753\n",
      "Epoch 2625/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4086 - accuracy: 0.8770 - val_loss: 1.2923 - val_accuracy: 0.6688\n",
      "Epoch 2626/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4414 - accuracy: 0.8535 - val_loss: 1.3004 - val_accuracy: 0.6656\n",
      "Epoch 2627/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5258 - accuracy: 0.8291 - val_loss: 1.3138 - val_accuracy: 0.6623\n",
      "Epoch 2628/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4615 - accuracy: 0.8408 - val_loss: 1.3342 - val_accuracy: 0.6494\n",
      "Epoch 2629/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4396 - accuracy: 0.8545 - val_loss: 1.3577 - val_accuracy: 0.6201\n",
      "Epoch 2630/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4172 - accuracy: 0.8575 - val_loss: 1.3810 - val_accuracy: 0.6266\n",
      "Epoch 2631/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4459 - accuracy: 0.8575 - val_loss: 1.3693 - val_accuracy: 0.6429\n",
      "Epoch 2632/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4419 - accuracy: 0.8492 - val_loss: 1.3581 - val_accuracy: 0.6461\n",
      "Epoch 2633/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4444 - accuracy: 0.8603 - val_loss: 1.3537 - val_accuracy: 0.6494\n",
      "Epoch 2634/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4536 - accuracy: 0.8464 - val_loss: 1.3531 - val_accuracy: 0.6364\n",
      "Epoch 2635/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4867 - accuracy: 0.8394 - val_loss: 1.3427 - val_accuracy: 0.6429\n",
      "Epoch 2636/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4638 - accuracy: 0.8506 - val_loss: 1.3300 - val_accuracy: 0.6364\n",
      "Epoch 2637/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4497 - accuracy: 0.8673 - val_loss: 1.3175 - val_accuracy: 0.6461\n",
      "Epoch 2638/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4647 - accuracy: 0.8438 - val_loss: 1.3094 - val_accuracy: 0.6429\n",
      "Epoch 2639/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4705 - accuracy: 0.8450 - val_loss: 1.2981 - val_accuracy: 0.6461\n",
      "Epoch 2640/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5400 - accuracy: 0.8240 - val_loss: 1.2958 - val_accuracy: 0.6461\n",
      "Epoch 2641/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4361 - accuracy: 0.8659 - val_loss: 1.2851 - val_accuracy: 0.6364\n",
      "Epoch 2642/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4395 - accuracy: 0.8428 - val_loss: 1.2734 - val_accuracy: 0.6461\n",
      "Epoch 2643/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4748 - accuracy: 0.8350 - val_loss: 1.2675 - val_accuracy: 0.6526\n",
      "Epoch 2644/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5057 - accuracy: 0.8226 - val_loss: 1.2744 - val_accuracy: 0.6558\n",
      "Epoch 2645/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4558 - accuracy: 0.8438 - val_loss: 1.2783 - val_accuracy: 0.6526\n",
      "Epoch 2646/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4585 - accuracy: 0.8516 - val_loss: 1.2835 - val_accuracy: 0.6461\n",
      "Epoch 2647/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4465 - accuracy: 0.8574 - val_loss: 1.2837 - val_accuracy: 0.6526\n",
      "Epoch 2648/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5160 - accuracy: 0.8389 - val_loss: 1.2807 - val_accuracy: 0.6591\n",
      "Epoch 2649/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4924 - accuracy: 0.8296 - val_loss: 1.2848 - val_accuracy: 0.6558\n",
      "Epoch 2650/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4624 - accuracy: 0.8564 - val_loss: 1.2895 - val_accuracy: 0.6494\n",
      "Epoch 2651/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5112 - accuracy: 0.8310 - val_loss: 1.2974 - val_accuracy: 0.6429\n",
      "Epoch 2652/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4190 - accuracy: 0.8687 - val_loss: 1.3077 - val_accuracy: 0.6299\n",
      "Epoch 2653/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5386 - accuracy: 0.8242 - val_loss: 1.3154 - val_accuracy: 0.6234\n",
      "Epoch 2654/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4393 - accuracy: 0.8631 - val_loss: 1.3107 - val_accuracy: 0.6201\n",
      "Epoch 2655/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4236 - accuracy: 0.8701 - val_loss: 1.2984 - val_accuracy: 0.6234\n",
      "Epoch 2656/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4424 - accuracy: 0.8477 - val_loss: 1.2885 - val_accuracy: 0.6266\n",
      "Epoch 2657/4000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4240 - accuracy: 0.8617 - val_loss: 1.2984 - val_accuracy: 0.6299\n",
      "Epoch 2658/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4786 - accuracy: 0.8478 - val_loss: 1.3030 - val_accuracy: 0.6169\n",
      "Epoch 2659/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4109 - accuracy: 0.8740 - val_loss: 1.2980 - val_accuracy: 0.6201\n",
      "Epoch 2660/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4520 - accuracy: 0.8535 - val_loss: 1.3030 - val_accuracy: 0.6104\n",
      "Epoch 2661/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4940 - accuracy: 0.8281 - val_loss: 1.3090 - val_accuracy: 0.6071\n",
      "Epoch 2662/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4613 - accuracy: 0.8428 - val_loss: 1.3025 - val_accuracy: 0.6136\n",
      "Epoch 2663/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4733 - accuracy: 0.8408 - val_loss: 1.3136 - val_accuracy: 0.6104\n",
      "Epoch 2664/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4656 - accuracy: 0.8555 - val_loss: 1.3252 - val_accuracy: 0.6136\n",
      "Epoch 2665/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4351 - accuracy: 0.8594 - val_loss: 1.3223 - val_accuracy: 0.6169\n",
      "Epoch 2666/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4938 - accuracy: 0.8310 - val_loss: 1.3615 - val_accuracy: 0.6039\n",
      "Epoch 2667/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4439 - accuracy: 0.8701 - val_loss: 1.3586 - val_accuracy: 0.6136\n",
      "Epoch 2668/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5048 - accuracy: 0.8422 - val_loss: 1.3486 - val_accuracy: 0.6234\n",
      "Epoch 2669/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4685 - accuracy: 0.8408 - val_loss: 1.3513 - val_accuracy: 0.6169\n",
      "Epoch 2670/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4827 - accuracy: 0.8422 - val_loss: 1.3437 - val_accuracy: 0.6201\n",
      "Epoch 2671/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4180 - accuracy: 0.8545 - val_loss: 1.3519 - val_accuracy: 0.6169\n",
      "Epoch 2672/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4444 - accuracy: 0.8516 - val_loss: 1.3818 - val_accuracy: 0.6006\n",
      "Epoch 2673/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4561 - accuracy: 0.8418 - val_loss: 1.4271 - val_accuracy: 0.5812\n",
      "Epoch 2674/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5270 - accuracy: 0.8226 - val_loss: 1.4650 - val_accuracy: 0.5812\n",
      "Epoch 2675/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4754 - accuracy: 0.8408 - val_loss: 1.5007 - val_accuracy: 0.5779\n",
      "Epoch 2676/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4379 - accuracy: 0.8478 - val_loss: 1.4927 - val_accuracy: 0.5779\n",
      "Epoch 2677/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5035 - accuracy: 0.8389 - val_loss: 1.4451 - val_accuracy: 0.5812\n",
      "Epoch 2678/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5311 - accuracy: 0.8366 - val_loss: 1.3678 - val_accuracy: 0.5844\n",
      "Epoch 2679/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4405 - accuracy: 0.8575 - val_loss: 1.3217 - val_accuracy: 0.6136\n",
      "Epoch 2680/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4309 - accuracy: 0.8643 - val_loss: 1.2986 - val_accuracy: 0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2681/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4631 - accuracy: 0.8574 - val_loss: 1.3020 - val_accuracy: 0.6364\n",
      "Epoch 2682/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4683 - accuracy: 0.8436 - val_loss: 1.2952 - val_accuracy: 0.6364\n",
      "Epoch 2683/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5166 - accuracy: 0.8213 - val_loss: 1.2943 - val_accuracy: 0.6396\n",
      "Epoch 2684/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4849 - accuracy: 0.8447 - val_loss: 1.3079 - val_accuracy: 0.6364\n",
      "Epoch 2685/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4972 - accuracy: 0.8436 - val_loss: 1.3271 - val_accuracy: 0.6331\n",
      "Epoch 2686/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4042 - accuracy: 0.8730 - val_loss: 1.3454 - val_accuracy: 0.6299\n",
      "Epoch 2687/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4021 - accuracy: 0.8547 - val_loss: 1.3426 - val_accuracy: 0.6266\n",
      "Epoch 2688/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4713 - accuracy: 0.8398 - val_loss: 1.3399 - val_accuracy: 0.6201\n",
      "Epoch 2689/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4608 - accuracy: 0.8520 - val_loss: 1.3303 - val_accuracy: 0.6201\n",
      "Epoch 2690/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4899 - accuracy: 0.8477 - val_loss: 1.3389 - val_accuracy: 0.6201\n",
      "Epoch 2691/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4372 - accuracy: 0.8555 - val_loss: 1.3661 - val_accuracy: 0.6071\n",
      "Epoch 2692/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4664 - accuracy: 0.8422 - val_loss: 1.4041 - val_accuracy: 0.5877\n",
      "Epoch 2693/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4501 - accuracy: 0.8534 - val_loss: 1.4104 - val_accuracy: 0.5942\n",
      "Epoch 2694/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4438 - accuracy: 0.8617 - val_loss: 1.4087 - val_accuracy: 0.5877\n",
      "Epoch 2695/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4610 - accuracy: 0.8301 - val_loss: 1.4030 - val_accuracy: 0.5877\n",
      "Epoch 2696/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4225 - accuracy: 0.8604 - val_loss: 1.4121 - val_accuracy: 0.5974\n",
      "Epoch 2697/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4374 - accuracy: 0.8492 - val_loss: 1.4193 - val_accuracy: 0.6039\n",
      "Epoch 2698/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4133 - accuracy: 0.8691 - val_loss: 1.4433 - val_accuracy: 0.6039\n",
      "Epoch 2699/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3561 - accuracy: 0.8771 - val_loss: 1.4677 - val_accuracy: 0.6006\n",
      "Epoch 2700/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3696 - accuracy: 0.8771 - val_loss: 1.4748 - val_accuracy: 0.6104\n",
      "Epoch 2701/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4517 - accuracy: 0.8604 - val_loss: 1.4409 - val_accuracy: 0.6104\n",
      "Epoch 2702/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4383 - accuracy: 0.8477 - val_loss: 1.4229 - val_accuracy: 0.6201\n",
      "Epoch 2703/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4444 - accuracy: 0.8447 - val_loss: 1.3891 - val_accuracy: 0.6266\n",
      "Epoch 2704/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4238 - accuracy: 0.8564 - val_loss: 1.3565 - val_accuracy: 0.6266\n",
      "Epoch 2705/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4870 - accuracy: 0.8436 - val_loss: 1.3529 - val_accuracy: 0.6234\n",
      "Epoch 2706/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5044 - accuracy: 0.8478 - val_loss: 1.3414 - val_accuracy: 0.6266\n",
      "Epoch 2707/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4833 - accuracy: 0.8547 - val_loss: 1.3361 - val_accuracy: 0.6331\n",
      "Epoch 2708/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4289 - accuracy: 0.8534 - val_loss: 1.3240 - val_accuracy: 0.6461\n",
      "Epoch 2709/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5129 - accuracy: 0.8268 - val_loss: 1.3037 - val_accuracy: 0.6558\n",
      "Epoch 2710/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4048 - accuracy: 0.8604 - val_loss: 1.3065 - val_accuracy: 0.6331\n",
      "Epoch 2711/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4053 - accuracy: 0.8594 - val_loss: 1.3146 - val_accuracy: 0.6266\n",
      "Epoch 2712/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3880 - accuracy: 0.8743 - val_loss: 1.3114 - val_accuracy: 0.6136\n",
      "Epoch 2713/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4423 - accuracy: 0.8516 - val_loss: 1.3173 - val_accuracy: 0.6039\n",
      "Epoch 2714/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4410 - accuracy: 0.8631 - val_loss: 1.3271 - val_accuracy: 0.6104\n",
      "Epoch 2715/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4581 - accuracy: 0.8645 - val_loss: 1.3375 - val_accuracy: 0.6234\n",
      "Epoch 2716/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4240 - accuracy: 0.8652 - val_loss: 1.3381 - val_accuracy: 0.6266\n",
      "Epoch 2717/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4389 - accuracy: 0.8496 - val_loss: 1.3561 - val_accuracy: 0.6266\n",
      "Epoch 2718/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4698 - accuracy: 0.8525 - val_loss: 1.3796 - val_accuracy: 0.6136\n",
      "Epoch 2719/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4105 - accuracy: 0.8617 - val_loss: 1.3887 - val_accuracy: 0.6071\n",
      "Epoch 2720/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4138 - accuracy: 0.8631 - val_loss: 1.3992 - val_accuracy: 0.6039\n",
      "Epoch 2721/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4635 - accuracy: 0.8574 - val_loss: 1.4069 - val_accuracy: 0.6039\n",
      "Epoch 2722/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4541 - accuracy: 0.8477 - val_loss: 1.4044 - val_accuracy: 0.6071\n",
      "Epoch 2723/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4852 - accuracy: 0.8447 - val_loss: 1.3978 - val_accuracy: 0.6071\n",
      "Epoch 2724/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4496 - accuracy: 0.8496 - val_loss: 1.3936 - val_accuracy: 0.6136\n",
      "Epoch 2725/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4537 - accuracy: 0.8478 - val_loss: 1.3935 - val_accuracy: 0.6071\n",
      "Epoch 2726/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4077 - accuracy: 0.8743 - val_loss: 1.3856 - val_accuracy: 0.6169\n",
      "Epoch 2727/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4631 - accuracy: 0.8428 - val_loss: 1.3805 - val_accuracy: 0.6201\n",
      "Epoch 2728/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4464 - accuracy: 0.8561 - val_loss: 1.3790 - val_accuracy: 0.6169\n",
      "Epoch 2729/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4458 - accuracy: 0.8467 - val_loss: 1.3819 - val_accuracy: 0.6169\n",
      "Epoch 2730/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4476 - accuracy: 0.8555 - val_loss: 1.3748 - val_accuracy: 0.6039\n",
      "Epoch 2731/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4989 - accuracy: 0.8464 - val_loss: 1.3369 - val_accuracy: 0.6039\n",
      "Epoch 2732/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4768 - accuracy: 0.8438 - val_loss: 1.3132 - val_accuracy: 0.6201\n",
      "Epoch 2733/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4619 - accuracy: 0.8478 - val_loss: 1.3074 - val_accuracy: 0.6266\n",
      "Epoch 2734/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4759 - accuracy: 0.8394 - val_loss: 1.3140 - val_accuracy: 0.6136\n",
      "Epoch 2735/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4640 - accuracy: 0.8525 - val_loss: 1.3410 - val_accuracy: 0.6266\n",
      "Epoch 2736/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4674 - accuracy: 0.8330 - val_loss: 1.3489 - val_accuracy: 0.6234\n",
      "Epoch 2737/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4438 - accuracy: 0.8631 - val_loss: 1.3832 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2738/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4682 - accuracy: 0.8398 - val_loss: 1.4121 - val_accuracy: 0.5942\n",
      "Epoch 2739/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4117 - accuracy: 0.8659 - val_loss: 1.4427 - val_accuracy: 0.5779\n",
      "Epoch 2740/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4766 - accuracy: 0.8516 - val_loss: 1.4931 - val_accuracy: 0.5714\n",
      "Epoch 2741/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4373 - accuracy: 0.8525 - val_loss: 1.5273 - val_accuracy: 0.5844\n",
      "Epoch 2742/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4449 - accuracy: 0.8506 - val_loss: 1.5313 - val_accuracy: 0.5844\n",
      "Epoch 2743/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4155 - accuracy: 0.8750 - val_loss: 1.5134 - val_accuracy: 0.5812\n",
      "Epoch 2744/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4541 - accuracy: 0.8310 - val_loss: 1.4885 - val_accuracy: 0.5747\n",
      "Epoch 2745/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4520 - accuracy: 0.8506 - val_loss: 1.4987 - val_accuracy: 0.6006\n",
      "Epoch 2746/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4618 - accuracy: 0.8520 - val_loss: 1.5274 - val_accuracy: 0.6136\n",
      "Epoch 2747/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4611 - accuracy: 0.8520 - val_loss: 1.5777 - val_accuracy: 0.6169\n",
      "Epoch 2748/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4911 - accuracy: 0.8492 - val_loss: 1.5442 - val_accuracy: 0.5974\n",
      "Epoch 2749/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4247 - accuracy: 0.8561 - val_loss: 1.4824 - val_accuracy: 0.6104\n",
      "Epoch 2750/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4236 - accuracy: 0.8652 - val_loss: 1.4270 - val_accuracy: 0.6136\n",
      "Epoch 2751/4000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4195 - accuracy: 0.8643 - val_loss: 1.3904 - val_accuracy: 0.6136\n",
      "Epoch 2752/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4594 - accuracy: 0.8561 - val_loss: 1.3568 - val_accuracy: 0.6266\n",
      "Epoch 2753/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4387 - accuracy: 0.8603 - val_loss: 1.3279 - val_accuracy: 0.6071\n",
      "Epoch 2754/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4569 - accuracy: 0.8492 - val_loss: 1.3131 - val_accuracy: 0.6266\n",
      "Epoch 2755/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4487 - accuracy: 0.8506 - val_loss: 1.2619 - val_accuracy: 0.6364\n",
      "Epoch 2756/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4196 - accuracy: 0.8547 - val_loss: 1.2272 - val_accuracy: 0.6656\n",
      "Epoch 2757/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4086 - accuracy: 0.8631 - val_loss: 1.2388 - val_accuracy: 0.6494\n",
      "Epoch 2758/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4391 - accuracy: 0.8408 - val_loss: 1.2745 - val_accuracy: 0.6396\n",
      "Epoch 2759/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4159 - accuracy: 0.8715 - val_loss: 1.3087 - val_accuracy: 0.6331\n",
      "Epoch 2760/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4233 - accuracy: 0.8603 - val_loss: 1.3340 - val_accuracy: 0.6331\n",
      "Epoch 2761/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4546 - accuracy: 0.8545 - val_loss: 1.3523 - val_accuracy: 0.6364\n",
      "Epoch 2762/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4123 - accuracy: 0.8603 - val_loss: 1.3523 - val_accuracy: 0.6299\n",
      "Epoch 2763/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4128 - accuracy: 0.8534 - val_loss: 1.3562 - val_accuracy: 0.6169\n",
      "Epoch 2764/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4232 - accuracy: 0.8584 - val_loss: 1.3496 - val_accuracy: 0.6104\n",
      "Epoch 2765/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4396 - accuracy: 0.8486 - val_loss: 1.3411 - val_accuracy: 0.6136\n",
      "Epoch 2766/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4650 - accuracy: 0.8547 - val_loss: 1.3257 - val_accuracy: 0.6266\n",
      "Epoch 2767/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4605 - accuracy: 0.8564 - val_loss: 1.3137 - val_accuracy: 0.6136\n",
      "Epoch 2768/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4485 - accuracy: 0.8477 - val_loss: 1.2931 - val_accuracy: 0.6201\n",
      "Epoch 2769/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4537 - accuracy: 0.8418 - val_loss: 1.2823 - val_accuracy: 0.6364\n",
      "Epoch 2770/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5020 - accuracy: 0.8311 - val_loss: 1.2950 - val_accuracy: 0.6299\n",
      "Epoch 2771/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4492 - accuracy: 0.8520 - val_loss: 1.2975 - val_accuracy: 0.6201\n",
      "Epoch 2772/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4569 - accuracy: 0.8492 - val_loss: 1.2992 - val_accuracy: 0.6299\n",
      "Epoch 2773/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4257 - accuracy: 0.8574 - val_loss: 1.3025 - val_accuracy: 0.6364\n",
      "Epoch 2774/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5048 - accuracy: 0.8350 - val_loss: 1.3084 - val_accuracy: 0.6169\n",
      "Epoch 2775/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4393 - accuracy: 0.8589 - val_loss: 1.3209 - val_accuracy: 0.6136\n",
      "Epoch 2776/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4644 - accuracy: 0.8525 - val_loss: 1.3339 - val_accuracy: 0.6104\n",
      "Epoch 2777/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4266 - accuracy: 0.8584 - val_loss: 1.3232 - val_accuracy: 0.6169\n",
      "Epoch 2778/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4158 - accuracy: 0.8408 - val_loss: 1.3089 - val_accuracy: 0.6299\n",
      "Epoch 2779/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4329 - accuracy: 0.8574 - val_loss: 1.2895 - val_accuracy: 0.6461\n",
      "Epoch 2780/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3722 - accuracy: 0.8701 - val_loss: 1.2869 - val_accuracy: 0.6494\n",
      "Epoch 2781/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4604 - accuracy: 0.8457 - val_loss: 1.2842 - val_accuracy: 0.6591\n",
      "Epoch 2782/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4573 - accuracy: 0.8464 - val_loss: 1.2886 - val_accuracy: 0.6461\n",
      "Epoch 2783/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4081 - accuracy: 0.8604 - val_loss: 1.2911 - val_accuracy: 0.6331\n",
      "Epoch 2784/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4444 - accuracy: 0.8535 - val_loss: 1.2961 - val_accuracy: 0.6331\n",
      "Epoch 2785/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4393 - accuracy: 0.8535 - val_loss: 1.3045 - val_accuracy: 0.6234\n",
      "Epoch 2786/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4202 - accuracy: 0.8584 - val_loss: 1.3018 - val_accuracy: 0.6396\n",
      "Epoch 2787/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4244 - accuracy: 0.8687 - val_loss: 1.3164 - val_accuracy: 0.6429\n",
      "Epoch 2788/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4789 - accuracy: 0.8369 - val_loss: 1.3481 - val_accuracy: 0.6266\n",
      "Epoch 2789/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4324 - accuracy: 0.8594 - val_loss: 1.4055 - val_accuracy: 0.6169\n",
      "Epoch 2790/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4442 - accuracy: 0.8672 - val_loss: 1.5056 - val_accuracy: 0.5747\n",
      "Epoch 2791/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4058 - accuracy: 0.8701 - val_loss: 1.5967 - val_accuracy: 0.5617\n",
      "Epoch 2792/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3942 - accuracy: 0.8771 - val_loss: 1.6847 - val_accuracy: 0.5487\n",
      "Epoch 2793/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4211 - accuracy: 0.8631 - val_loss: 1.7298 - val_accuracy: 0.5455\n",
      "Epoch 2794/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4228 - accuracy: 0.8687 - val_loss: 1.7478 - val_accuracy: 0.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2795/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3802 - accuracy: 0.8799 - val_loss: 1.7329 - val_accuracy: 0.5519\n",
      "Epoch 2796/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3708 - accuracy: 0.8757 - val_loss: 1.6743 - val_accuracy: 0.5584\n",
      "Epoch 2797/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4517 - accuracy: 0.8555 - val_loss: 1.6047 - val_accuracy: 0.5649\n",
      "Epoch 2798/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4244 - accuracy: 0.8652 - val_loss: 1.5397 - val_accuracy: 0.5747\n",
      "Epoch 2799/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4864 - accuracy: 0.8350 - val_loss: 1.5082 - val_accuracy: 0.5747\n",
      "Epoch 2800/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4495 - accuracy: 0.8457 - val_loss: 1.4762 - val_accuracy: 0.5942\n",
      "Epoch 2801/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4200 - accuracy: 0.8450 - val_loss: 1.4521 - val_accuracy: 0.5942\n",
      "Epoch 2802/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4123 - accuracy: 0.8760 - val_loss: 1.4331 - val_accuracy: 0.5942\n",
      "Epoch 2803/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4991 - accuracy: 0.8464 - val_loss: 1.4127 - val_accuracy: 0.5974\n",
      "Epoch 2804/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4058 - accuracy: 0.8652 - val_loss: 1.4030 - val_accuracy: 0.5877\n",
      "Epoch 2805/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4685 - accuracy: 0.8547 - val_loss: 1.4087 - val_accuracy: 0.5942\n",
      "Epoch 2806/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4196 - accuracy: 0.8525 - val_loss: 1.4098 - val_accuracy: 0.5942\n",
      "Epoch 2807/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3769 - accuracy: 0.8750 - val_loss: 1.4020 - val_accuracy: 0.5942\n",
      "Epoch 2808/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5258 - accuracy: 0.8408 - val_loss: 1.3888 - val_accuracy: 0.6071\n",
      "Epoch 2809/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4392 - accuracy: 0.8545 - val_loss: 1.3562 - val_accuracy: 0.6201\n",
      "Epoch 2810/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4326 - accuracy: 0.8574 - val_loss: 1.3243 - val_accuracy: 0.6266\n",
      "Epoch 2811/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4264 - accuracy: 0.8467 - val_loss: 1.2873 - val_accuracy: 0.6429\n",
      "Epoch 2812/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4325 - accuracy: 0.8631 - val_loss: 1.2594 - val_accuracy: 0.6429\n",
      "Epoch 2813/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4214 - accuracy: 0.8682 - val_loss: 1.2439 - val_accuracy: 0.6526\n",
      "Epoch 2814/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4263 - accuracy: 0.8547 - val_loss: 1.2348 - val_accuracy: 0.6591\n",
      "Epoch 2815/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4157 - accuracy: 0.8613 - val_loss: 1.2293 - val_accuracy: 0.6591\n",
      "Epoch 2816/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4707 - accuracy: 0.8422 - val_loss: 1.2286 - val_accuracy: 0.6591\n",
      "Epoch 2817/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4499 - accuracy: 0.8525 - val_loss: 1.2406 - val_accuracy: 0.6558\n",
      "Epoch 2818/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4180 - accuracy: 0.8757 - val_loss: 1.2490 - val_accuracy: 0.6461\n",
      "Epoch 2819/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4723 - accuracy: 0.8561 - val_loss: 1.2675 - val_accuracy: 0.6461\n",
      "Epoch 2820/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3818 - accuracy: 0.8623 - val_loss: 1.2867 - val_accuracy: 0.6299\n",
      "Epoch 2821/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4571 - accuracy: 0.8506 - val_loss: 1.2917 - val_accuracy: 0.6266\n",
      "Epoch 2822/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4471 - accuracy: 0.8438 - val_loss: 1.2957 - val_accuracy: 0.6234\n",
      "Epoch 2823/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4477 - accuracy: 0.8659 - val_loss: 1.2870 - val_accuracy: 0.6201\n",
      "Epoch 2824/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4184 - accuracy: 0.8701 - val_loss: 1.2980 - val_accuracy: 0.6169\n",
      "Epoch 2825/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4038 - accuracy: 0.8691 - val_loss: 1.3079 - val_accuracy: 0.6169\n",
      "Epoch 2826/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4265 - accuracy: 0.8604 - val_loss: 1.3008 - val_accuracy: 0.6266\n",
      "Epoch 2827/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3786 - accuracy: 0.8603 - val_loss: 1.2931 - val_accuracy: 0.6266\n",
      "Epoch 2828/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3971 - accuracy: 0.8711 - val_loss: 1.2795 - val_accuracy: 0.6201\n",
      "Epoch 2829/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4895 - accuracy: 0.8398 - val_loss: 1.2914 - val_accuracy: 0.6201\n",
      "Epoch 2830/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4145 - accuracy: 0.8691 - val_loss: 1.3133 - val_accuracy: 0.6201\n",
      "Epoch 2831/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4389 - accuracy: 0.8520 - val_loss: 1.3260 - val_accuracy: 0.6234\n",
      "Epoch 2832/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4545 - accuracy: 0.8564 - val_loss: 1.3415 - val_accuracy: 0.6104\n",
      "Epoch 2833/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4109 - accuracy: 0.8799 - val_loss: 1.3612 - val_accuracy: 0.6104\n",
      "Epoch 2834/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4049 - accuracy: 0.8603 - val_loss: 1.3879 - val_accuracy: 0.6104\n",
      "Epoch 2835/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4331 - accuracy: 0.8478 - val_loss: 1.4179 - val_accuracy: 0.5974\n",
      "Epoch 2836/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4658 - accuracy: 0.8547 - val_loss: 1.4219 - val_accuracy: 0.6071\n",
      "Epoch 2837/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4292 - accuracy: 0.8682 - val_loss: 1.4149 - val_accuracy: 0.6039\n",
      "Epoch 2838/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4484 - accuracy: 0.8534 - val_loss: 1.4174 - val_accuracy: 0.6071\n",
      "Epoch 2839/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3932 - accuracy: 0.8564 - val_loss: 1.4245 - val_accuracy: 0.6169\n",
      "Epoch 2840/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4612 - accuracy: 0.8575 - val_loss: 1.4249 - val_accuracy: 0.6104\n",
      "Epoch 2841/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4266 - accuracy: 0.8534 - val_loss: 1.4196 - val_accuracy: 0.6136\n",
      "Epoch 2842/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4049 - accuracy: 0.8574 - val_loss: 1.4160 - val_accuracy: 0.6104\n",
      "Epoch 2843/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4229 - accuracy: 0.8672 - val_loss: 1.3779 - val_accuracy: 0.6169\n",
      "Epoch 2844/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4637 - accuracy: 0.8520 - val_loss: 1.3278 - val_accuracy: 0.6299\n",
      "Epoch 2845/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4610 - accuracy: 0.8506 - val_loss: 1.2829 - val_accuracy: 0.6429\n",
      "Epoch 2846/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4204 - accuracy: 0.8534 - val_loss: 1.2668 - val_accuracy: 0.6461\n",
      "Epoch 2847/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4339 - accuracy: 0.8564 - val_loss: 1.2506 - val_accuracy: 0.6461\n",
      "Epoch 2848/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4199 - accuracy: 0.8673 - val_loss: 1.2553 - val_accuracy: 0.6429\n",
      "Epoch 2849/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3874 - accuracy: 0.8715 - val_loss: 1.2900 - val_accuracy: 0.6201\n",
      "Epoch 2850/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3983 - accuracy: 0.8721 - val_loss: 1.3386 - val_accuracy: 0.6006\n",
      "Epoch 2851/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4543 - accuracy: 0.8545 - val_loss: 1.3732 - val_accuracy: 0.5942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2852/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4229 - accuracy: 0.8555 - val_loss: 1.3804 - val_accuracy: 0.5877\n",
      "Epoch 2853/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4040 - accuracy: 0.8740 - val_loss: 1.3517 - val_accuracy: 0.5909\n",
      "Epoch 2854/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4845 - accuracy: 0.8506 - val_loss: 1.3132 - val_accuracy: 0.6234\n",
      "Epoch 2855/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4399 - accuracy: 0.8506 - val_loss: 1.2710 - val_accuracy: 0.6364\n",
      "Epoch 2856/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3589 - accuracy: 0.8771 - val_loss: 1.2379 - val_accuracy: 0.6461\n",
      "Epoch 2857/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4189 - accuracy: 0.8575 - val_loss: 1.2350 - val_accuracy: 0.6461\n",
      "Epoch 2858/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4014 - accuracy: 0.8589 - val_loss: 1.2566 - val_accuracy: 0.6429\n",
      "Epoch 2859/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4456 - accuracy: 0.8594 - val_loss: 1.2995 - val_accuracy: 0.6331\n",
      "Epoch 2860/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4360 - accuracy: 0.8603 - val_loss: 1.3511 - val_accuracy: 0.6104\n",
      "Epoch 2861/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4439 - accuracy: 0.8545 - val_loss: 1.4010 - val_accuracy: 0.6039\n",
      "Epoch 2862/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4833 - accuracy: 0.8496 - val_loss: 1.4557 - val_accuracy: 0.5942\n",
      "Epoch 2863/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4084 - accuracy: 0.8589 - val_loss: 1.5060 - val_accuracy: 0.5877\n",
      "Epoch 2864/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4234 - accuracy: 0.8623 - val_loss: 1.5711 - val_accuracy: 0.5812\n",
      "Epoch 2865/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4207 - accuracy: 0.8662 - val_loss: 1.6725 - val_accuracy: 0.5552\n",
      "Epoch 2866/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4076 - accuracy: 0.8575 - val_loss: 1.7522 - val_accuracy: 0.5390\n",
      "Epoch 2867/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4178 - accuracy: 0.8575 - val_loss: 1.7925 - val_accuracy: 0.5325\n",
      "Epoch 2868/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4500 - accuracy: 0.8555 - val_loss: 1.7820 - val_accuracy: 0.5195\n",
      "Epoch 2869/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4683 - accuracy: 0.8506 - val_loss: 1.7472 - val_accuracy: 0.5390\n",
      "Epoch 2870/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3844 - accuracy: 0.8799 - val_loss: 1.6875 - val_accuracy: 0.5292\n",
      "Epoch 2871/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4297 - accuracy: 0.8673 - val_loss: 1.6174 - val_accuracy: 0.5422\n",
      "Epoch 2872/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4437 - accuracy: 0.8545 - val_loss: 1.5677 - val_accuracy: 0.5617\n",
      "Epoch 2873/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3900 - accuracy: 0.8779 - val_loss: 1.5191 - val_accuracy: 0.5714\n",
      "Epoch 2874/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3946 - accuracy: 0.8721 - val_loss: 1.4777 - val_accuracy: 0.5747\n",
      "Epoch 2875/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4019 - accuracy: 0.8740 - val_loss: 1.4692 - val_accuracy: 0.5747\n",
      "Epoch 2876/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4549 - accuracy: 0.8574 - val_loss: 1.4986 - val_accuracy: 0.5844\n",
      "Epoch 2877/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4559 - accuracy: 0.8594 - val_loss: 1.5370 - val_accuracy: 0.5909\n",
      "Epoch 2878/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4415 - accuracy: 0.8645 - val_loss: 1.5520 - val_accuracy: 0.5844\n",
      "Epoch 2879/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4260 - accuracy: 0.8545 - val_loss: 1.5291 - val_accuracy: 0.5844\n",
      "Epoch 2880/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3996 - accuracy: 0.8682 - val_loss: 1.4947 - val_accuracy: 0.5877\n",
      "Epoch 2881/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4279 - accuracy: 0.8617 - val_loss: 1.4502 - val_accuracy: 0.5909\n",
      "Epoch 2882/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4161 - accuracy: 0.8673 - val_loss: 1.3887 - val_accuracy: 0.6136\n",
      "Epoch 2883/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4109 - accuracy: 0.8701 - val_loss: 1.3311 - val_accuracy: 0.6299\n",
      "Epoch 2884/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4460 - accuracy: 0.8547 - val_loss: 1.2859 - val_accuracy: 0.6364\n",
      "Epoch 2885/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3576 - accuracy: 0.8809 - val_loss: 1.2665 - val_accuracy: 0.6299\n",
      "Epoch 2886/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4449 - accuracy: 0.8478 - val_loss: 1.2632 - val_accuracy: 0.6494\n",
      "Epoch 2887/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3974 - accuracy: 0.8701 - val_loss: 1.2657 - val_accuracy: 0.6526\n",
      "Epoch 2888/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3904 - accuracy: 0.8715 - val_loss: 1.2658 - val_accuracy: 0.6558\n",
      "Epoch 2889/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4062 - accuracy: 0.8701 - val_loss: 1.2790 - val_accuracy: 0.6721\n",
      "Epoch 2890/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4430 - accuracy: 0.8547 - val_loss: 1.3059 - val_accuracy: 0.6526\n",
      "Epoch 2891/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3865 - accuracy: 0.8659 - val_loss: 1.3174 - val_accuracy: 0.6429\n",
      "Epoch 2892/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3775 - accuracy: 0.8809 - val_loss: 1.3200 - val_accuracy: 0.6494\n",
      "Epoch 2893/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4129 - accuracy: 0.8687 - val_loss: 1.3140 - val_accuracy: 0.6396\n",
      "Epoch 2894/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3767 - accuracy: 0.8750 - val_loss: 1.2997 - val_accuracy: 0.6299\n",
      "Epoch 2895/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3911 - accuracy: 0.8662 - val_loss: 1.2907 - val_accuracy: 0.6494\n",
      "Epoch 2896/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4118 - accuracy: 0.8662 - val_loss: 1.2794 - val_accuracy: 0.6461\n",
      "Epoch 2897/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3866 - accuracy: 0.8652 - val_loss: 1.2755 - val_accuracy: 0.6396\n",
      "Epoch 2898/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4226 - accuracy: 0.8617 - val_loss: 1.2811 - val_accuracy: 0.6429\n",
      "Epoch 2899/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4293 - accuracy: 0.8478 - val_loss: 1.2796 - val_accuracy: 0.6461\n",
      "Epoch 2900/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4270 - accuracy: 0.8561 - val_loss: 1.2823 - val_accuracy: 0.6461\n",
      "Epoch 2901/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4152 - accuracy: 0.8771 - val_loss: 1.2760 - val_accuracy: 0.6494\n",
      "Epoch 2902/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4205 - accuracy: 0.8687 - val_loss: 1.2884 - val_accuracy: 0.6526\n",
      "Epoch 2903/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4077 - accuracy: 0.8623 - val_loss: 1.3027 - val_accuracy: 0.6494\n",
      "Epoch 2904/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4026 - accuracy: 0.8672 - val_loss: 1.3086 - val_accuracy: 0.6429\n",
      "Epoch 2905/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3860 - accuracy: 0.8730 - val_loss: 1.3096 - val_accuracy: 0.6331\n",
      "Epoch 2906/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3741 - accuracy: 0.8682 - val_loss: 1.3166 - val_accuracy: 0.6299\n",
      "Epoch 2907/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4206 - accuracy: 0.8711 - val_loss: 1.3387 - val_accuracy: 0.6396\n",
      "Epoch 2908/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3886 - accuracy: 0.8603 - val_loss: 1.3597 - val_accuracy: 0.6234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2909/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4280 - accuracy: 0.8672 - val_loss: 1.3869 - val_accuracy: 0.6234\n",
      "Epoch 2910/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3724 - accuracy: 0.8953 - val_loss: 1.4244 - val_accuracy: 0.6136\n",
      "Epoch 2911/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3650 - accuracy: 0.8848 - val_loss: 1.4462 - val_accuracy: 0.6071\n",
      "Epoch 2912/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3955 - accuracy: 0.8687 - val_loss: 1.4702 - val_accuracy: 0.6006\n",
      "Epoch 2913/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4176 - accuracy: 0.8547 - val_loss: 1.4939 - val_accuracy: 0.5974\n",
      "Epoch 2914/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4232 - accuracy: 0.8760 - val_loss: 1.5037 - val_accuracy: 0.5974\n",
      "Epoch 2915/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3857 - accuracy: 0.8743 - val_loss: 1.5005 - val_accuracy: 0.5844\n",
      "Epoch 2916/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4259 - accuracy: 0.8564 - val_loss: 1.4525 - val_accuracy: 0.5844\n",
      "Epoch 2917/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4143 - accuracy: 0.8659 - val_loss: 1.3930 - val_accuracy: 0.6071\n",
      "Epoch 2918/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3884 - accuracy: 0.8757 - val_loss: 1.3374 - val_accuracy: 0.6104\n",
      "Epoch 2919/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3828 - accuracy: 0.8838 - val_loss: 1.2989 - val_accuracy: 0.6299\n",
      "Epoch 2920/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4473 - accuracy: 0.8672 - val_loss: 1.2671 - val_accuracy: 0.6396\n",
      "Epoch 2921/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4156 - accuracy: 0.8594 - val_loss: 1.2588 - val_accuracy: 0.6396\n",
      "Epoch 2922/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3954 - accuracy: 0.8574 - val_loss: 1.2556 - val_accuracy: 0.6364\n",
      "Epoch 2923/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4093 - accuracy: 0.8701 - val_loss: 1.2731 - val_accuracy: 0.6364\n",
      "Epoch 2924/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3994 - accuracy: 0.8711 - val_loss: 1.2734 - val_accuracy: 0.6396\n",
      "Epoch 2925/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4023 - accuracy: 0.8711 - val_loss: 1.2729 - val_accuracy: 0.6461\n",
      "Epoch 2926/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3820 - accuracy: 0.8770 - val_loss: 1.2686 - val_accuracy: 0.6526\n",
      "Epoch 2927/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4266 - accuracy: 0.8652 - val_loss: 1.2661 - val_accuracy: 0.6526\n",
      "Epoch 2928/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4433 - accuracy: 0.8617 - val_loss: 1.2788 - val_accuracy: 0.6526\n",
      "Epoch 2929/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4454 - accuracy: 0.8659 - val_loss: 1.3002 - val_accuracy: 0.6331\n",
      "Epoch 2930/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4653 - accuracy: 0.8477 - val_loss: 1.3437 - val_accuracy: 0.6234\n",
      "Epoch 2931/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3946 - accuracy: 0.8715 - val_loss: 1.3426 - val_accuracy: 0.6266\n",
      "Epoch 2932/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4327 - accuracy: 0.8631 - val_loss: 1.3210 - val_accuracy: 0.6331\n",
      "Epoch 2933/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4220 - accuracy: 0.8589 - val_loss: 1.2914 - val_accuracy: 0.6364\n",
      "Epoch 2934/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4020 - accuracy: 0.8757 - val_loss: 1.2588 - val_accuracy: 0.6494\n",
      "Epoch 2935/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4610 - accuracy: 0.8492 - val_loss: 1.2374 - val_accuracy: 0.6623\n",
      "Epoch 2936/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3835 - accuracy: 0.8883 - val_loss: 1.2259 - val_accuracy: 0.6623\n",
      "Epoch 2937/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3713 - accuracy: 0.8828 - val_loss: 1.2225 - val_accuracy: 0.6688\n",
      "Epoch 2938/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3706 - accuracy: 0.8789 - val_loss: 1.2157 - val_accuracy: 0.6786\n",
      "Epoch 2939/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4226 - accuracy: 0.8687 - val_loss: 1.2211 - val_accuracy: 0.6753\n",
      "Epoch 2940/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4271 - accuracy: 0.8645 - val_loss: 1.2280 - val_accuracy: 0.6753\n",
      "Epoch 2941/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4316 - accuracy: 0.8617 - val_loss: 1.2388 - val_accuracy: 0.6721\n",
      "Epoch 2942/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3902 - accuracy: 0.8730 - val_loss: 1.2464 - val_accuracy: 0.6656\n",
      "Epoch 2943/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4009 - accuracy: 0.8750 - val_loss: 1.2589 - val_accuracy: 0.6558\n",
      "Epoch 2944/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3830 - accuracy: 0.8682 - val_loss: 1.2773 - val_accuracy: 0.6558\n",
      "Epoch 2945/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3768 - accuracy: 0.8785 - val_loss: 1.2916 - val_accuracy: 0.6461\n",
      "Epoch 2946/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4086 - accuracy: 0.8729 - val_loss: 1.3047 - val_accuracy: 0.6396\n",
      "Epoch 2947/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4110 - accuracy: 0.8673 - val_loss: 1.3037 - val_accuracy: 0.6364\n",
      "Epoch 2948/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4480 - accuracy: 0.8506 - val_loss: 1.3046 - val_accuracy: 0.6396\n",
      "Epoch 2949/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4223 - accuracy: 0.8589 - val_loss: 1.3254 - val_accuracy: 0.6429\n",
      "Epoch 2950/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3826 - accuracy: 0.8673 - val_loss: 1.3252 - val_accuracy: 0.6429\n",
      "Epoch 2951/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3689 - accuracy: 0.8740 - val_loss: 1.3330 - val_accuracy: 0.6461\n",
      "Epoch 2952/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3998 - accuracy: 0.8771 - val_loss: 1.3261 - val_accuracy: 0.6396\n",
      "Epoch 2953/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4044 - accuracy: 0.8617 - val_loss: 1.3070 - val_accuracy: 0.6396\n",
      "Epoch 2954/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3997 - accuracy: 0.8729 - val_loss: 1.2889 - val_accuracy: 0.6526\n",
      "Epoch 2955/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4150 - accuracy: 0.8575 - val_loss: 1.2761 - val_accuracy: 0.6461\n",
      "Epoch 2956/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3929 - accuracy: 0.8617 - val_loss: 1.2728 - val_accuracy: 0.6591\n",
      "Epoch 2957/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4349 - accuracy: 0.8574 - val_loss: 1.2705 - val_accuracy: 0.6558\n",
      "Epoch 2958/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4342 - accuracy: 0.8715 - val_loss: 1.2734 - val_accuracy: 0.6558\n",
      "Epoch 2959/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3517 - accuracy: 0.8730 - val_loss: 1.2817 - val_accuracy: 0.6558\n",
      "Epoch 2960/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3832 - accuracy: 0.8711 - val_loss: 1.3060 - val_accuracy: 0.6461\n",
      "Epoch 2961/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4475 - accuracy: 0.8645 - val_loss: 1.3158 - val_accuracy: 0.6461\n",
      "Epoch 2962/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3601 - accuracy: 0.8896 - val_loss: 1.3269 - val_accuracy: 0.6526\n",
      "Epoch 2963/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3885 - accuracy: 0.8652 - val_loss: 1.3391 - val_accuracy: 0.6429\n",
      "Epoch 2964/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4113 - accuracy: 0.8633 - val_loss: 1.3455 - val_accuracy: 0.6429\n",
      "Epoch 2965/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4636 - accuracy: 0.8450 - val_loss: 1.3453 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2966/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4110 - accuracy: 0.8623 - val_loss: 1.3279 - val_accuracy: 0.6266\n",
      "Epoch 2967/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3519 - accuracy: 0.8827 - val_loss: 1.3105 - val_accuracy: 0.6331\n",
      "Epoch 2968/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3516 - accuracy: 0.8841 - val_loss: 1.3018 - val_accuracy: 0.6429\n",
      "Epoch 2969/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4041 - accuracy: 0.8743 - val_loss: 1.2862 - val_accuracy: 0.6591\n",
      "Epoch 2970/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4416 - accuracy: 0.8589 - val_loss: 1.2760 - val_accuracy: 0.6494\n",
      "Epoch 2971/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3694 - accuracy: 0.8701 - val_loss: 1.2634 - val_accuracy: 0.6656\n",
      "Epoch 2972/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4091 - accuracy: 0.8631 - val_loss: 1.2644 - val_accuracy: 0.6656\n",
      "Epoch 2973/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3955 - accuracy: 0.8623 - val_loss: 1.2739 - val_accuracy: 0.6656\n",
      "Epoch 2974/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4491 - accuracy: 0.8687 - val_loss: 1.2877 - val_accuracy: 0.6526\n",
      "Epoch 2975/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4014 - accuracy: 0.8682 - val_loss: 1.3155 - val_accuracy: 0.6591\n",
      "Epoch 2976/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3928 - accuracy: 0.8673 - val_loss: 1.3501 - val_accuracy: 0.6396\n",
      "Epoch 2977/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3723 - accuracy: 0.8828 - val_loss: 1.3870 - val_accuracy: 0.6364\n",
      "Epoch 2978/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4011 - accuracy: 0.8643 - val_loss: 1.4150 - val_accuracy: 0.6299\n",
      "Epoch 2979/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3825 - accuracy: 0.8779 - val_loss: 1.4320 - val_accuracy: 0.6396\n",
      "Epoch 2980/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4337 - accuracy: 0.8525 - val_loss: 1.4405 - val_accuracy: 0.6331\n",
      "Epoch 2981/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4330 - accuracy: 0.8574 - val_loss: 1.4386 - val_accuracy: 0.6169\n",
      "Epoch 2982/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3800 - accuracy: 0.8740 - val_loss: 1.4083 - val_accuracy: 0.6104\n",
      "Epoch 2983/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3999 - accuracy: 0.8729 - val_loss: 1.3698 - val_accuracy: 0.6071\n",
      "Epoch 2984/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4230 - accuracy: 0.8603 - val_loss: 1.3383 - val_accuracy: 0.6201\n",
      "Epoch 2985/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3824 - accuracy: 0.8855 - val_loss: 1.3115 - val_accuracy: 0.6266\n",
      "Epoch 2986/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3641 - accuracy: 0.8813 - val_loss: 1.2961 - val_accuracy: 0.6396\n",
      "Epoch 2987/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3512 - accuracy: 0.8828 - val_loss: 1.2890 - val_accuracy: 0.6558\n",
      "Epoch 2988/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3772 - accuracy: 0.8715 - val_loss: 1.2931 - val_accuracy: 0.6558\n",
      "Epoch 2989/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3804 - accuracy: 0.8584 - val_loss: 1.3040 - val_accuracy: 0.6429\n",
      "Epoch 2990/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3900 - accuracy: 0.8687 - val_loss: 1.3181 - val_accuracy: 0.6461\n",
      "Epoch 2991/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4626 - accuracy: 0.8506 - val_loss: 1.3105 - val_accuracy: 0.6364\n",
      "Epoch 2992/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4086 - accuracy: 0.8623 - val_loss: 1.3048 - val_accuracy: 0.6364\n",
      "Epoch 2993/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4171 - accuracy: 0.8691 - val_loss: 1.3159 - val_accuracy: 0.6266\n",
      "Epoch 2994/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3853 - accuracy: 0.8633 - val_loss: 1.3116 - val_accuracy: 0.6364\n",
      "Epoch 2995/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4059 - accuracy: 0.8547 - val_loss: 1.2946 - val_accuracy: 0.6623\n",
      "Epoch 2996/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3576 - accuracy: 0.8809 - val_loss: 1.2779 - val_accuracy: 0.6623\n",
      "Epoch 2997/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4187 - accuracy: 0.8561 - val_loss: 1.2677 - val_accuracy: 0.6786\n",
      "Epoch 2998/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3775 - accuracy: 0.8980 - val_loss: 1.2671 - val_accuracy: 0.6786\n",
      "Epoch 2999/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3802 - accuracy: 0.8789 - val_loss: 1.2722 - val_accuracy: 0.6623\n",
      "Epoch 3000/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3850 - accuracy: 0.8643 - val_loss: 1.2994 - val_accuracy: 0.6429\n",
      "Epoch 3001/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3419 - accuracy: 0.8857 - val_loss: 1.3464 - val_accuracy: 0.6461\n",
      "Epoch 3002/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3917 - accuracy: 0.8757 - val_loss: 1.3990 - val_accuracy: 0.6364\n",
      "Epoch 3003/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3466 - accuracy: 0.8799 - val_loss: 1.4336 - val_accuracy: 0.6201\n",
      "Epoch 3004/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4114 - accuracy: 0.8743 - val_loss: 1.4544 - val_accuracy: 0.6104\n",
      "Epoch 3005/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3629 - accuracy: 0.8916 - val_loss: 1.4653 - val_accuracy: 0.6071\n",
      "Epoch 3006/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4212 - accuracy: 0.8643 - val_loss: 1.4482 - val_accuracy: 0.6006\n",
      "Epoch 3007/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3524 - accuracy: 0.8877 - val_loss: 1.4132 - val_accuracy: 0.6136\n",
      "Epoch 3008/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3171 - accuracy: 0.8939 - val_loss: 1.3706 - val_accuracy: 0.6169\n",
      "Epoch 3009/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4320 - accuracy: 0.8687 - val_loss: 1.3281 - val_accuracy: 0.6299\n",
      "Epoch 3010/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4262 - accuracy: 0.8682 - val_loss: 1.3133 - val_accuracy: 0.6591\n",
      "Epoch 3011/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3548 - accuracy: 0.8841 - val_loss: 1.3071 - val_accuracy: 0.6656\n",
      "Epoch 3012/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4037 - accuracy: 0.8645 - val_loss: 1.3036 - val_accuracy: 0.6494\n",
      "Epoch 3013/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3305 - accuracy: 0.8925 - val_loss: 1.3003 - val_accuracy: 0.6526\n",
      "Epoch 3014/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3551 - accuracy: 0.8779 - val_loss: 1.2941 - val_accuracy: 0.6753\n",
      "Epoch 3015/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4106 - accuracy: 0.8662 - val_loss: 1.2932 - val_accuracy: 0.6656\n",
      "Epoch 3016/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3924 - accuracy: 0.8750 - val_loss: 1.2893 - val_accuracy: 0.6721\n",
      "Epoch 3017/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3635 - accuracy: 0.8687 - val_loss: 1.2947 - val_accuracy: 0.6591\n",
      "Epoch 3018/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4068 - accuracy: 0.8687 - val_loss: 1.3214 - val_accuracy: 0.6591\n",
      "Epoch 3019/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3685 - accuracy: 0.8721 - val_loss: 1.3520 - val_accuracy: 0.6494\n",
      "Epoch 3020/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4139 - accuracy: 0.8659 - val_loss: 1.3762 - val_accuracy: 0.6201\n",
      "Epoch 3021/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3765 - accuracy: 0.8673 - val_loss: 1.4243 - val_accuracy: 0.6169\n",
      "Epoch 3022/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4191 - accuracy: 0.8506 - val_loss: 1.4736 - val_accuracy: 0.5909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3023/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4645 - accuracy: 0.8477 - val_loss: 1.5167 - val_accuracy: 0.5877\n",
      "Epoch 3024/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3779 - accuracy: 0.8730 - val_loss: 1.5251 - val_accuracy: 0.5779\n",
      "Epoch 3025/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3795 - accuracy: 0.8631 - val_loss: 1.5139 - val_accuracy: 0.5747\n",
      "Epoch 3026/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4142 - accuracy: 0.8643 - val_loss: 1.4867 - val_accuracy: 0.5812\n",
      "Epoch 3027/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4829 - accuracy: 0.8506 - val_loss: 1.4425 - val_accuracy: 0.5877\n",
      "Epoch 3028/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4304 - accuracy: 0.8631 - val_loss: 1.4085 - val_accuracy: 0.5974\n",
      "Epoch 3029/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3466 - accuracy: 0.8869 - val_loss: 1.3721 - val_accuracy: 0.6169\n",
      "Epoch 3030/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3868 - accuracy: 0.8760 - val_loss: 1.3571 - val_accuracy: 0.6201\n",
      "Epoch 3031/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4114 - accuracy: 0.8687 - val_loss: 1.3582 - val_accuracy: 0.6136\n",
      "Epoch 3032/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3496 - accuracy: 0.8809 - val_loss: 1.3923 - val_accuracy: 0.5974\n",
      "Epoch 3033/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3588 - accuracy: 0.8838 - val_loss: 1.4239 - val_accuracy: 0.5909\n",
      "Epoch 3034/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4419 - accuracy: 0.8574 - val_loss: 1.4626 - val_accuracy: 0.5877\n",
      "Epoch 3035/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3549 - accuracy: 0.8867 - val_loss: 1.5141 - val_accuracy: 0.5779\n",
      "Epoch 3036/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4025 - accuracy: 0.8687 - val_loss: 1.5719 - val_accuracy: 0.5649\n",
      "Epoch 3037/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3937 - accuracy: 0.8659 - val_loss: 1.5934 - val_accuracy: 0.5584\n",
      "Epoch 3038/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3674 - accuracy: 0.8771 - val_loss: 1.6017 - val_accuracy: 0.5487\n",
      "Epoch 3039/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3840 - accuracy: 0.8779 - val_loss: 1.5521 - val_accuracy: 0.5682\n",
      "Epoch 3040/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3439 - accuracy: 0.8896 - val_loss: 1.4813 - val_accuracy: 0.5909\n",
      "Epoch 3041/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3503 - accuracy: 0.8911 - val_loss: 1.4105 - val_accuracy: 0.6104\n",
      "Epoch 3042/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3657 - accuracy: 0.8867 - val_loss: 1.3328 - val_accuracy: 0.6396\n",
      "Epoch 3043/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3652 - accuracy: 0.8869 - val_loss: 1.2804 - val_accuracy: 0.6558\n",
      "Epoch 3044/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4067 - accuracy: 0.8643 - val_loss: 1.2381 - val_accuracy: 0.6688\n",
      "Epoch 3045/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3950 - accuracy: 0.8760 - val_loss: 1.2207 - val_accuracy: 0.6656\n",
      "Epoch 3046/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4868 - accuracy: 0.8506 - val_loss: 1.2155 - val_accuracy: 0.6623\n",
      "Epoch 3047/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3466 - accuracy: 0.8687 - val_loss: 1.2154 - val_accuracy: 0.6721\n",
      "Epoch 3048/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3733 - accuracy: 0.8701 - val_loss: 1.2144 - val_accuracy: 0.6688\n",
      "Epoch 3049/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3682 - accuracy: 0.8813 - val_loss: 1.2259 - val_accuracy: 0.6623\n",
      "Epoch 3050/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3584 - accuracy: 0.8869 - val_loss: 1.2422 - val_accuracy: 0.6558\n",
      "Epoch 3051/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4055 - accuracy: 0.8604 - val_loss: 1.2572 - val_accuracy: 0.6396\n",
      "Epoch 3052/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4064 - accuracy: 0.8799 - val_loss: 1.2747 - val_accuracy: 0.6429\n",
      "Epoch 3053/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3962 - accuracy: 0.8760 - val_loss: 1.3164 - val_accuracy: 0.6396\n",
      "Epoch 3054/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3701 - accuracy: 0.8682 - val_loss: 1.3491 - val_accuracy: 0.6234\n",
      "Epoch 3055/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4202 - accuracy: 0.8617 - val_loss: 1.3497 - val_accuracy: 0.6136\n",
      "Epoch 3056/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4088 - accuracy: 0.8652 - val_loss: 1.3502 - val_accuracy: 0.6201\n",
      "Epoch 3057/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3863 - accuracy: 0.8771 - val_loss: 1.3393 - val_accuracy: 0.6169\n",
      "Epoch 3058/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3507 - accuracy: 0.8813 - val_loss: 1.3331 - val_accuracy: 0.6234\n",
      "Epoch 3059/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3448 - accuracy: 0.8841 - val_loss: 1.3295 - val_accuracy: 0.6299\n",
      "Epoch 3060/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3838 - accuracy: 0.8813 - val_loss: 1.3205 - val_accuracy: 0.6364\n",
      "Epoch 3061/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3993 - accuracy: 0.8813 - val_loss: 1.3327 - val_accuracy: 0.6364\n",
      "Epoch 3062/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4079 - accuracy: 0.8757 - val_loss: 1.3821 - val_accuracy: 0.6234\n",
      "Epoch 3063/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3804 - accuracy: 0.8887 - val_loss: 1.4438 - val_accuracy: 0.6071\n",
      "Epoch 3064/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3619 - accuracy: 0.8809 - val_loss: 1.5164 - val_accuracy: 0.5942\n",
      "Epoch 3065/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4216 - accuracy: 0.8589 - val_loss: 1.6022 - val_accuracy: 0.5844\n",
      "Epoch 3066/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3769 - accuracy: 0.8818 - val_loss: 1.6926 - val_accuracy: 0.5682\n",
      "Epoch 3067/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3966 - accuracy: 0.8721 - val_loss: 1.7337 - val_accuracy: 0.5714\n",
      "Epoch 3068/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3846 - accuracy: 0.8740 - val_loss: 1.7359 - val_accuracy: 0.5747\n",
      "Epoch 3069/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3896 - accuracy: 0.8743 - val_loss: 1.6865 - val_accuracy: 0.5812\n",
      "Epoch 3070/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4045 - accuracy: 0.8534 - val_loss: 1.5789 - val_accuracy: 0.5974\n",
      "Epoch 3071/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3780 - accuracy: 0.8779 - val_loss: 1.4904 - val_accuracy: 0.6006\n",
      "Epoch 3072/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3721 - accuracy: 0.8715 - val_loss: 1.4252 - val_accuracy: 0.6104\n",
      "Epoch 3073/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4152 - accuracy: 0.8672 - val_loss: 1.3850 - val_accuracy: 0.6039\n",
      "Epoch 3074/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3990 - accuracy: 0.8743 - val_loss: 1.3704 - val_accuracy: 0.6071\n",
      "Epoch 3075/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3958 - accuracy: 0.8672 - val_loss: 1.3570 - val_accuracy: 0.6266\n",
      "Epoch 3076/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3899 - accuracy: 0.8750 - val_loss: 1.3531 - val_accuracy: 0.6364\n",
      "Epoch 3077/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3941 - accuracy: 0.8789 - val_loss: 1.3660 - val_accuracy: 0.6364\n",
      "Epoch 3078/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3557 - accuracy: 0.8838 - val_loss: 1.3774 - val_accuracy: 0.6396\n",
      "Epoch 3079/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3878 - accuracy: 0.8711 - val_loss: 1.4037 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3080/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3447 - accuracy: 0.8877 - val_loss: 1.4214 - val_accuracy: 0.6331\n",
      "Epoch 3081/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4036 - accuracy: 0.8631 - val_loss: 1.4438 - val_accuracy: 0.6201\n",
      "Epoch 3082/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3864 - accuracy: 0.8771 - val_loss: 1.4694 - val_accuracy: 0.6039\n",
      "Epoch 3083/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3994 - accuracy: 0.8659 - val_loss: 1.4803 - val_accuracy: 0.5974\n",
      "Epoch 3084/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3989 - accuracy: 0.8729 - val_loss: 1.4888 - val_accuracy: 0.6039\n",
      "Epoch 3085/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4013 - accuracy: 0.8633 - val_loss: 1.4807 - val_accuracy: 0.6039\n",
      "Epoch 3086/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4238 - accuracy: 0.8701 - val_loss: 1.4588 - val_accuracy: 0.5974\n",
      "Epoch 3087/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4632 - accuracy: 0.8436 - val_loss: 1.4497 - val_accuracy: 0.6104\n",
      "Epoch 3088/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3976 - accuracy: 0.8740 - val_loss: 1.4416 - val_accuracy: 0.6234\n",
      "Epoch 3089/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4026 - accuracy: 0.8673 - val_loss: 1.4164 - val_accuracy: 0.6396\n",
      "Epoch 3090/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4030 - accuracy: 0.8771 - val_loss: 1.3884 - val_accuracy: 0.6526\n",
      "Epoch 3091/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3613 - accuracy: 0.8841 - val_loss: 1.3653 - val_accuracy: 0.6558\n",
      "Epoch 3092/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3829 - accuracy: 0.8701 - val_loss: 1.3373 - val_accuracy: 0.6526\n",
      "Epoch 3093/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4091 - accuracy: 0.8631 - val_loss: 1.3149 - val_accuracy: 0.6688\n",
      "Epoch 3094/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4441 - accuracy: 0.8631 - val_loss: 1.3041 - val_accuracy: 0.6656\n",
      "Epoch 3095/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3826 - accuracy: 0.8672 - val_loss: 1.2908 - val_accuracy: 0.6656\n",
      "Epoch 3096/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3307 - accuracy: 0.8869 - val_loss: 1.2965 - val_accuracy: 0.6688\n",
      "Epoch 3097/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3654 - accuracy: 0.8779 - val_loss: 1.2997 - val_accuracy: 0.6721\n",
      "Epoch 3098/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3888 - accuracy: 0.8730 - val_loss: 1.3007 - val_accuracy: 0.6688\n",
      "Epoch 3099/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3817 - accuracy: 0.8701 - val_loss: 1.2981 - val_accuracy: 0.6591\n",
      "Epoch 3100/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3551 - accuracy: 0.8869 - val_loss: 1.2981 - val_accuracy: 0.6526\n",
      "Epoch 3101/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3854 - accuracy: 0.8701 - val_loss: 1.2793 - val_accuracy: 0.6461\n",
      "Epoch 3102/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3056 - accuracy: 0.8925 - val_loss: 1.2654 - val_accuracy: 0.6558\n",
      "Epoch 3103/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3191 - accuracy: 0.8925 - val_loss: 1.2618 - val_accuracy: 0.6558\n",
      "Epoch 3104/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3334 - accuracy: 0.8925 - val_loss: 1.2648 - val_accuracy: 0.6656\n",
      "Epoch 3105/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4216 - accuracy: 0.8729 - val_loss: 1.2662 - val_accuracy: 0.6558\n",
      "Epoch 3106/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3879 - accuracy: 0.8673 - val_loss: 1.2714 - val_accuracy: 0.6591\n",
      "Epoch 3107/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4161 - accuracy: 0.8617 - val_loss: 1.2822 - val_accuracy: 0.6623\n",
      "Epoch 3108/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3572 - accuracy: 0.8848 - val_loss: 1.2977 - val_accuracy: 0.6656\n",
      "Epoch 3109/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3055 - accuracy: 0.8994 - val_loss: 1.3033 - val_accuracy: 0.6623\n",
      "Epoch 3110/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3562 - accuracy: 0.8841 - val_loss: 1.3081 - val_accuracy: 0.6623\n",
      "Epoch 3111/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3915 - accuracy: 0.8779 - val_loss: 1.3104 - val_accuracy: 0.6721\n",
      "Epoch 3112/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3507 - accuracy: 0.8965 - val_loss: 1.3098 - val_accuracy: 0.6688\n",
      "Epoch 3113/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3980 - accuracy: 0.8701 - val_loss: 1.3160 - val_accuracy: 0.6591\n",
      "Epoch 3114/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3566 - accuracy: 0.8785 - val_loss: 1.3326 - val_accuracy: 0.6526\n",
      "Epoch 3115/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3626 - accuracy: 0.8779 - val_loss: 1.3500 - val_accuracy: 0.6461\n",
      "Epoch 3116/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4270 - accuracy: 0.8603 - val_loss: 1.3437 - val_accuracy: 0.6494\n",
      "Epoch 3117/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3909 - accuracy: 0.8520 - val_loss: 1.3362 - val_accuracy: 0.6396\n",
      "Epoch 3118/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3217 - accuracy: 0.8916 - val_loss: 1.3304 - val_accuracy: 0.6429\n",
      "Epoch 3119/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3639 - accuracy: 0.8818 - val_loss: 1.3227 - val_accuracy: 0.6461\n",
      "Epoch 3120/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4323 - accuracy: 0.8589 - val_loss: 1.3159 - val_accuracy: 0.6429\n",
      "Epoch 3121/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4179 - accuracy: 0.8617 - val_loss: 1.3175 - val_accuracy: 0.6591\n",
      "Epoch 3122/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3259 - accuracy: 0.8916 - val_loss: 1.3214 - val_accuracy: 0.6558\n",
      "Epoch 3123/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3400 - accuracy: 0.8841 - val_loss: 1.3280 - val_accuracy: 0.6558\n",
      "Epoch 3124/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3938 - accuracy: 0.8659 - val_loss: 1.3289 - val_accuracy: 0.6591\n",
      "Epoch 3125/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4044 - accuracy: 0.8701 - val_loss: 1.3233 - val_accuracy: 0.6591\n",
      "Epoch 3126/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4146 - accuracy: 0.8813 - val_loss: 1.3206 - val_accuracy: 0.6623\n",
      "Epoch 3127/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3495 - accuracy: 0.8883 - val_loss: 1.3189 - val_accuracy: 0.6623\n",
      "Epoch 3128/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3856 - accuracy: 0.8813 - val_loss: 1.3235 - val_accuracy: 0.6526\n",
      "Epoch 3129/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3782 - accuracy: 0.8715 - val_loss: 1.3307 - val_accuracy: 0.6461\n",
      "Epoch 3130/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3331 - accuracy: 0.8955 - val_loss: 1.3729 - val_accuracy: 0.6396\n",
      "Epoch 3131/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4004 - accuracy: 0.8785 - val_loss: 1.4216 - val_accuracy: 0.6104\n",
      "Epoch 3132/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3786 - accuracy: 0.8770 - val_loss: 1.4629 - val_accuracy: 0.6039\n",
      "Epoch 3133/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4080 - accuracy: 0.8673 - val_loss: 1.5047 - val_accuracy: 0.5877\n",
      "Epoch 3134/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4055 - accuracy: 0.8691 - val_loss: 1.5124 - val_accuracy: 0.5812\n",
      "Epoch 3135/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3829 - accuracy: 0.8813 - val_loss: 1.4910 - val_accuracy: 0.5877\n",
      "Epoch 3136/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4083 - accuracy: 0.8701 - val_loss: 1.4573 - val_accuracy: 0.5877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3137/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4130 - accuracy: 0.8730 - val_loss: 1.3968 - val_accuracy: 0.6039\n",
      "Epoch 3138/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4101 - accuracy: 0.8645 - val_loss: 1.3443 - val_accuracy: 0.6331\n",
      "Epoch 3139/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3759 - accuracy: 0.8841 - val_loss: 1.3137 - val_accuracy: 0.6494\n",
      "Epoch 3140/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3953 - accuracy: 0.8730 - val_loss: 1.3006 - val_accuracy: 0.6494\n",
      "Epoch 3141/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4191 - accuracy: 0.8659 - val_loss: 1.3008 - val_accuracy: 0.6591\n",
      "Epoch 3142/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3900 - accuracy: 0.8691 - val_loss: 1.2969 - val_accuracy: 0.6656\n",
      "Epoch 3143/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3651 - accuracy: 0.8906 - val_loss: 1.2839 - val_accuracy: 0.6656\n",
      "Epoch 3144/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3543 - accuracy: 0.8757 - val_loss: 1.2690 - val_accuracy: 0.6591\n",
      "Epoch 3145/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4051 - accuracy: 0.8613 - val_loss: 1.2590 - val_accuracy: 0.6494\n",
      "Epoch 3146/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4062 - accuracy: 0.8617 - val_loss: 1.2545 - val_accuracy: 0.6688\n",
      "Epoch 3147/4000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3589 - accuracy: 0.8838 - val_loss: 1.2526 - val_accuracy: 0.6721\n",
      "Epoch 3148/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3632 - accuracy: 0.8617 - val_loss: 1.2588 - val_accuracy: 0.6721\n",
      "Epoch 3149/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3474 - accuracy: 0.8945 - val_loss: 1.2671 - val_accuracy: 0.6688\n",
      "Epoch 3150/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3965 - accuracy: 0.8771 - val_loss: 1.2586 - val_accuracy: 0.6623\n",
      "Epoch 3151/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3653 - accuracy: 0.8730 - val_loss: 1.2570 - val_accuracy: 0.6656\n",
      "Epoch 3152/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4169 - accuracy: 0.8662 - val_loss: 1.2590 - val_accuracy: 0.6558\n",
      "Epoch 3153/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3662 - accuracy: 0.8867 - val_loss: 1.2558 - val_accuracy: 0.6558\n",
      "Epoch 3154/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3255 - accuracy: 0.8953 - val_loss: 1.2486 - val_accuracy: 0.6494\n",
      "Epoch 3155/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3735 - accuracy: 0.8757 - val_loss: 1.2504 - val_accuracy: 0.6526\n",
      "Epoch 3156/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3994 - accuracy: 0.8662 - val_loss: 1.2521 - val_accuracy: 0.6591\n",
      "Epoch 3157/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3657 - accuracy: 0.8857 - val_loss: 1.2589 - val_accuracy: 0.6558\n",
      "Epoch 3158/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3694 - accuracy: 0.8672 - val_loss: 1.2703 - val_accuracy: 0.6558\n",
      "Epoch 3159/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4053 - accuracy: 0.8789 - val_loss: 1.2858 - val_accuracy: 0.6461\n",
      "Epoch 3160/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3589 - accuracy: 0.8799 - val_loss: 1.3050 - val_accuracy: 0.6526\n",
      "Epoch 3161/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3832 - accuracy: 0.8721 - val_loss: 1.3195 - val_accuracy: 0.6461\n",
      "Epoch 3162/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3655 - accuracy: 0.8785 - val_loss: 1.3210 - val_accuracy: 0.6623\n",
      "Epoch 3163/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3801 - accuracy: 0.8701 - val_loss: 1.3246 - val_accuracy: 0.6526\n",
      "Epoch 3164/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4168 - accuracy: 0.8687 - val_loss: 1.3315 - val_accuracy: 0.6429\n",
      "Epoch 3165/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3701 - accuracy: 0.8827 - val_loss: 1.3339 - val_accuracy: 0.6331\n",
      "Epoch 3166/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3801 - accuracy: 0.8750 - val_loss: 1.3422 - val_accuracy: 0.6364\n",
      "Epoch 3167/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3925 - accuracy: 0.8715 - val_loss: 1.3538 - val_accuracy: 0.6299\n",
      "Epoch 3168/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3642 - accuracy: 0.8789 - val_loss: 1.3553 - val_accuracy: 0.6201\n",
      "Epoch 3169/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4339 - accuracy: 0.8574 - val_loss: 1.3524 - val_accuracy: 0.6006\n",
      "Epoch 3170/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4253 - accuracy: 0.8574 - val_loss: 1.3503 - val_accuracy: 0.6104\n",
      "Epoch 3171/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3875 - accuracy: 0.8729 - val_loss: 1.3410 - val_accuracy: 0.6266\n",
      "Epoch 3172/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3790 - accuracy: 0.8743 - val_loss: 1.3312 - val_accuracy: 0.6234\n",
      "Epoch 3173/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3843 - accuracy: 0.8757 - val_loss: 1.3159 - val_accuracy: 0.6266\n",
      "Epoch 3174/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3519 - accuracy: 0.8857 - val_loss: 1.2951 - val_accuracy: 0.6364\n",
      "Epoch 3175/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3806 - accuracy: 0.8785 - val_loss: 1.2879 - val_accuracy: 0.6266\n",
      "Epoch 3176/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3806 - accuracy: 0.8809 - val_loss: 1.2942 - val_accuracy: 0.6396\n",
      "Epoch 3177/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3494 - accuracy: 0.8785 - val_loss: 1.3080 - val_accuracy: 0.6396\n",
      "Epoch 3178/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3888 - accuracy: 0.8645 - val_loss: 1.3166 - val_accuracy: 0.6461\n",
      "Epoch 3179/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3803 - accuracy: 0.8673 - val_loss: 1.3220 - val_accuracy: 0.6299\n",
      "Epoch 3180/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4267 - accuracy: 0.8673 - val_loss: 1.3314 - val_accuracy: 0.6331\n",
      "Epoch 3181/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3626 - accuracy: 0.8813 - val_loss: 1.3395 - val_accuracy: 0.6331\n",
      "Epoch 3182/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2939 - accuracy: 0.9050 - val_loss: 1.3462 - val_accuracy: 0.6396\n",
      "Epoch 3183/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4042 - accuracy: 0.8682 - val_loss: 1.3353 - val_accuracy: 0.6429\n",
      "Epoch 3184/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3857 - accuracy: 0.8730 - val_loss: 1.3096 - val_accuracy: 0.6461\n",
      "Epoch 3185/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3651 - accuracy: 0.8779 - val_loss: 1.2824 - val_accuracy: 0.6526\n",
      "Epoch 3186/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4119 - accuracy: 0.8760 - val_loss: 1.2652 - val_accuracy: 0.6591\n",
      "Epoch 3187/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3943 - accuracy: 0.8506 - val_loss: 1.2477 - val_accuracy: 0.6656\n",
      "Epoch 3188/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3418 - accuracy: 0.8855 - val_loss: 1.2438 - val_accuracy: 0.6721\n",
      "Epoch 3189/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4199 - accuracy: 0.8603 - val_loss: 1.2574 - val_accuracy: 0.6753\n",
      "Epoch 3190/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4399 - accuracy: 0.8645 - val_loss: 1.2556 - val_accuracy: 0.6753\n",
      "Epoch 3191/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3818 - accuracy: 0.8897 - val_loss: 1.2486 - val_accuracy: 0.6753\n",
      "Epoch 3192/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4048 - accuracy: 0.8561 - val_loss: 1.2381 - val_accuracy: 0.6818\n",
      "Epoch 3193/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3902 - accuracy: 0.8771 - val_loss: 1.2338 - val_accuracy: 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3194/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3880 - accuracy: 0.8687 - val_loss: 1.2385 - val_accuracy: 0.6656\n",
      "Epoch 3195/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3722 - accuracy: 0.8857 - val_loss: 1.2492 - val_accuracy: 0.6656\n",
      "Epoch 3196/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3688 - accuracy: 0.8771 - val_loss: 1.2575 - val_accuracy: 0.6688\n",
      "Epoch 3197/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3867 - accuracy: 0.8757 - val_loss: 1.2396 - val_accuracy: 0.6753\n",
      "Epoch 3198/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3212 - accuracy: 0.9022 - val_loss: 1.2214 - val_accuracy: 0.6786\n",
      "Epoch 3199/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3929 - accuracy: 0.8721 - val_loss: 1.2139 - val_accuracy: 0.6721\n",
      "Epoch 3200/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3487 - accuracy: 0.8896 - val_loss: 1.2130 - val_accuracy: 0.6688\n",
      "Epoch 3201/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3477 - accuracy: 0.8828 - val_loss: 1.2165 - val_accuracy: 0.6721\n",
      "Epoch 3202/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3985 - accuracy: 0.8701 - val_loss: 1.2199 - val_accuracy: 0.6688\n",
      "Epoch 3203/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3244 - accuracy: 0.8966 - val_loss: 1.2228 - val_accuracy: 0.6688\n",
      "Epoch 3204/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3791 - accuracy: 0.8687 - val_loss: 1.2242 - val_accuracy: 0.6656\n",
      "Epoch 3205/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4342 - accuracy: 0.8673 - val_loss: 1.2256 - val_accuracy: 0.6591\n",
      "Epoch 3206/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3992 - accuracy: 0.8757 - val_loss: 1.2187 - val_accuracy: 0.6558\n",
      "Epoch 3207/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3684 - accuracy: 0.8818 - val_loss: 1.2133 - val_accuracy: 0.6558\n",
      "Epoch 3208/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3900 - accuracy: 0.8789 - val_loss: 1.2128 - val_accuracy: 0.6558\n",
      "Epoch 3209/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3448 - accuracy: 0.8883 - val_loss: 1.2201 - val_accuracy: 0.6526\n",
      "Epoch 3210/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3726 - accuracy: 0.8799 - val_loss: 1.2252 - val_accuracy: 0.6494\n",
      "Epoch 3211/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3786 - accuracy: 0.8682 - val_loss: 1.2306 - val_accuracy: 0.6558\n",
      "Epoch 3212/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3624 - accuracy: 0.8730 - val_loss: 1.2412 - val_accuracy: 0.6623\n",
      "Epoch 3213/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3416 - accuracy: 0.8955 - val_loss: 1.2543 - val_accuracy: 0.6558\n",
      "Epoch 3214/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3518 - accuracy: 0.8828 - val_loss: 1.2581 - val_accuracy: 0.6429\n",
      "Epoch 3215/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3391 - accuracy: 0.8841 - val_loss: 1.2584 - val_accuracy: 0.6558\n",
      "Epoch 3216/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3751 - accuracy: 0.8730 - val_loss: 1.2674 - val_accuracy: 0.6558\n",
      "Epoch 3217/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3188 - accuracy: 0.8855 - val_loss: 1.2739 - val_accuracy: 0.6591\n",
      "Epoch 3218/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3964 - accuracy: 0.8740 - val_loss: 1.2818 - val_accuracy: 0.6558\n",
      "Epoch 3219/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3635 - accuracy: 0.8770 - val_loss: 1.2884 - val_accuracy: 0.6558\n",
      "Epoch 3220/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4151 - accuracy: 0.8740 - val_loss: 1.2899 - val_accuracy: 0.6591\n",
      "Epoch 3221/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4144 - accuracy: 0.8584 - val_loss: 1.2932 - val_accuracy: 0.6688\n",
      "Epoch 3222/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4222 - accuracy: 0.8643 - val_loss: 1.2916 - val_accuracy: 0.6656\n",
      "Epoch 3223/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3480 - accuracy: 0.9050 - val_loss: 1.3003 - val_accuracy: 0.6558\n",
      "Epoch 3224/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4226 - accuracy: 0.8682 - val_loss: 1.3099 - val_accuracy: 0.6494\n",
      "Epoch 3225/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3813 - accuracy: 0.8828 - val_loss: 1.3193 - val_accuracy: 0.6494\n",
      "Epoch 3226/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3436 - accuracy: 0.8813 - val_loss: 1.3291 - val_accuracy: 0.6494\n",
      "Epoch 3227/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4018 - accuracy: 0.8631 - val_loss: 1.3398 - val_accuracy: 0.6623\n",
      "Epoch 3228/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3468 - accuracy: 0.8936 - val_loss: 1.3453 - val_accuracy: 0.6494\n",
      "Epoch 3229/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3757 - accuracy: 0.8770 - val_loss: 1.3515 - val_accuracy: 0.6558\n",
      "Epoch 3230/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4255 - accuracy: 0.8652 - val_loss: 1.3576 - val_accuracy: 0.6558\n",
      "Epoch 3231/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3892 - accuracy: 0.8740 - val_loss: 1.3683 - val_accuracy: 0.6461\n",
      "Epoch 3232/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3314 - accuracy: 0.8789 - val_loss: 1.3739 - val_accuracy: 0.6461\n",
      "Epoch 3233/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3209 - accuracy: 0.8945 - val_loss: 1.3806 - val_accuracy: 0.6429\n",
      "Epoch 3234/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3713 - accuracy: 0.8701 - val_loss: 1.3836 - val_accuracy: 0.6396\n",
      "Epoch 3235/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3206 - accuracy: 0.8877 - val_loss: 1.3902 - val_accuracy: 0.6396\n",
      "Epoch 3236/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3179 - accuracy: 0.8896 - val_loss: 1.3997 - val_accuracy: 0.6331\n",
      "Epoch 3237/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3465 - accuracy: 0.8911 - val_loss: 1.4065 - val_accuracy: 0.6299\n",
      "Epoch 3238/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3331 - accuracy: 0.8906 - val_loss: 1.4094 - val_accuracy: 0.6169\n",
      "Epoch 3239/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3848 - accuracy: 0.8750 - val_loss: 1.4087 - val_accuracy: 0.6104\n",
      "Epoch 3240/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3275 - accuracy: 0.8743 - val_loss: 1.3968 - val_accuracy: 0.6169\n",
      "Epoch 3241/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3831 - accuracy: 0.8827 - val_loss: 1.3855 - val_accuracy: 0.6136\n",
      "Epoch 3242/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3559 - accuracy: 0.8945 - val_loss: 1.3775 - val_accuracy: 0.6266\n",
      "Epoch 3243/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4081 - accuracy: 0.8760 - val_loss: 1.3740 - val_accuracy: 0.6364\n",
      "Epoch 3244/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4028 - accuracy: 0.8779 - val_loss: 1.3718 - val_accuracy: 0.6364\n",
      "Epoch 3245/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3396 - accuracy: 0.9008 - val_loss: 1.3750 - val_accuracy: 0.6331\n",
      "Epoch 3246/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3547 - accuracy: 0.8867 - val_loss: 1.3736 - val_accuracy: 0.6364\n",
      "Epoch 3247/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3404 - accuracy: 0.8857 - val_loss: 1.3538 - val_accuracy: 0.6429\n",
      "Epoch 3248/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3627 - accuracy: 0.8729 - val_loss: 1.3297 - val_accuracy: 0.6526\n",
      "Epoch 3249/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3672 - accuracy: 0.8770 - val_loss: 1.3145 - val_accuracy: 0.6461\n",
      "Epoch 3250/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4184 - accuracy: 0.8645 - val_loss: 1.2977 - val_accuracy: 0.6558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3251/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3023 - accuracy: 0.8955 - val_loss: 1.2896 - val_accuracy: 0.6656\n",
      "Epoch 3252/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3396 - accuracy: 0.8945 - val_loss: 1.2794 - val_accuracy: 0.6753\n",
      "Epoch 3253/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2475 - accuracy: 0.9162 - val_loss: 1.2735 - val_accuracy: 0.6818\n",
      "Epoch 3254/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3586 - accuracy: 0.8841 - val_loss: 1.2826 - val_accuracy: 0.6656\n",
      "Epoch 3255/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4156 - accuracy: 0.8645 - val_loss: 1.2955 - val_accuracy: 0.6494\n",
      "Epoch 3256/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3562 - accuracy: 0.8848 - val_loss: 1.3287 - val_accuracy: 0.6331\n",
      "Epoch 3257/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4006 - accuracy: 0.8750 - val_loss: 1.3619 - val_accuracy: 0.6136\n",
      "Epoch 3258/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3551 - accuracy: 0.8799 - val_loss: 1.3838 - val_accuracy: 0.6136\n",
      "Epoch 3259/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3447 - accuracy: 0.8936 - val_loss: 1.3985 - val_accuracy: 0.6071\n",
      "Epoch 3260/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3701 - accuracy: 0.8813 - val_loss: 1.4017 - val_accuracy: 0.6104\n",
      "Epoch 3261/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3962 - accuracy: 0.8869 - val_loss: 1.3965 - val_accuracy: 0.6104\n",
      "Epoch 3262/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3734 - accuracy: 0.8813 - val_loss: 1.3630 - val_accuracy: 0.6201\n",
      "Epoch 3263/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3379 - accuracy: 0.8770 - val_loss: 1.3327 - val_accuracy: 0.6039\n",
      "Epoch 3264/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3495 - accuracy: 0.8877 - val_loss: 1.3215 - val_accuracy: 0.6104\n",
      "Epoch 3265/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3881 - accuracy: 0.8673 - val_loss: 1.3190 - val_accuracy: 0.6169\n",
      "Epoch 3266/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3816 - accuracy: 0.8743 - val_loss: 1.3249 - val_accuracy: 0.6136\n",
      "Epoch 3267/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3734 - accuracy: 0.8743 - val_loss: 1.3369 - val_accuracy: 0.6104\n",
      "Epoch 3268/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3294 - accuracy: 0.8883 - val_loss: 1.3720 - val_accuracy: 0.6071\n",
      "Epoch 3269/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4105 - accuracy: 0.8770 - val_loss: 1.4287 - val_accuracy: 0.6039\n",
      "Epoch 3270/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3673 - accuracy: 0.8682 - val_loss: 1.4812 - val_accuracy: 0.5909\n",
      "Epoch 3271/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3420 - accuracy: 0.8906 - val_loss: 1.5179 - val_accuracy: 0.5877\n",
      "Epoch 3272/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3576 - accuracy: 0.8911 - val_loss: 1.5244 - val_accuracy: 0.5844\n",
      "Epoch 3273/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4256 - accuracy: 0.8631 - val_loss: 1.5249 - val_accuracy: 0.5747\n",
      "Epoch 3274/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3581 - accuracy: 0.8906 - val_loss: 1.4964 - val_accuracy: 0.6006\n",
      "Epoch 3275/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3675 - accuracy: 0.8799 - val_loss: 1.4719 - val_accuracy: 0.6039\n",
      "Epoch 3276/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4095 - accuracy: 0.8534 - val_loss: 1.4782 - val_accuracy: 0.5942\n",
      "Epoch 3277/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3075 - accuracy: 0.8877 - val_loss: 1.4748 - val_accuracy: 0.5844\n",
      "Epoch 3278/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3735 - accuracy: 0.8877 - val_loss: 1.4640 - val_accuracy: 0.5909\n",
      "Epoch 3279/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3848 - accuracy: 0.8799 - val_loss: 1.4565 - val_accuracy: 0.6104\n",
      "Epoch 3280/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3055 - accuracy: 0.9148 - val_loss: 1.4772 - val_accuracy: 0.6039\n",
      "Epoch 3281/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3506 - accuracy: 0.8925 - val_loss: 1.4838 - val_accuracy: 0.6104\n",
      "Epoch 3282/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3562 - accuracy: 0.8848 - val_loss: 1.4979 - val_accuracy: 0.6039\n",
      "Epoch 3283/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3442 - accuracy: 0.8838 - val_loss: 1.5118 - val_accuracy: 0.6071\n",
      "Epoch 3284/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3828 - accuracy: 0.8729 - val_loss: 1.5260 - val_accuracy: 0.6071\n",
      "Epoch 3285/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3700 - accuracy: 0.8691 - val_loss: 1.5400 - val_accuracy: 0.6006\n",
      "Epoch 3286/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3847 - accuracy: 0.8799 - val_loss: 1.5692 - val_accuracy: 0.5942\n",
      "Epoch 3287/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3434 - accuracy: 0.8827 - val_loss: 1.5943 - val_accuracy: 0.5844\n",
      "Epoch 3288/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3508 - accuracy: 0.8715 - val_loss: 1.6092 - val_accuracy: 0.5649\n",
      "Epoch 3289/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3316 - accuracy: 0.8771 - val_loss: 1.6186 - val_accuracy: 0.5617\n",
      "Epoch 3290/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3125 - accuracy: 0.8911 - val_loss: 1.5951 - val_accuracy: 0.5649\n",
      "Epoch 3291/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3338 - accuracy: 0.8953 - val_loss: 1.5559 - val_accuracy: 0.5714\n",
      "Epoch 3292/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3361 - accuracy: 0.9064 - val_loss: 1.5201 - val_accuracy: 0.5877\n",
      "Epoch 3293/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3387 - accuracy: 0.8809 - val_loss: 1.4984 - val_accuracy: 0.5942\n",
      "Epoch 3294/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3460 - accuracy: 0.8911 - val_loss: 1.5008 - val_accuracy: 0.5942\n",
      "Epoch 3295/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3319 - accuracy: 0.9033 - val_loss: 1.5163 - val_accuracy: 0.5909\n",
      "Epoch 3296/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3559 - accuracy: 0.8841 - val_loss: 1.5237 - val_accuracy: 0.5942\n",
      "Epoch 3297/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3580 - accuracy: 0.8867 - val_loss: 1.5196 - val_accuracy: 0.5942\n",
      "Epoch 3298/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3932 - accuracy: 0.8701 - val_loss: 1.5123 - val_accuracy: 0.6039\n",
      "Epoch 3299/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3442 - accuracy: 0.8799 - val_loss: 1.4981 - val_accuracy: 0.6071\n",
      "Epoch 3300/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3021 - accuracy: 0.8965 - val_loss: 1.4775 - val_accuracy: 0.6201\n",
      "Epoch 3301/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3426 - accuracy: 0.8799 - val_loss: 1.4533 - val_accuracy: 0.6201\n",
      "Epoch 3302/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3306 - accuracy: 0.8966 - val_loss: 1.4506 - val_accuracy: 0.6234\n",
      "Epoch 3303/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3204 - accuracy: 0.8936 - val_loss: 1.4534 - val_accuracy: 0.6299\n",
      "Epoch 3304/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3199 - accuracy: 0.9043 - val_loss: 1.4538 - val_accuracy: 0.6201\n",
      "Epoch 3305/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3682 - accuracy: 0.8818 - val_loss: 1.4526 - val_accuracy: 0.6201\n",
      "Epoch 3306/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3528 - accuracy: 0.8869 - val_loss: 1.4568 - val_accuracy: 0.6104\n",
      "Epoch 3307/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3708 - accuracy: 0.8721 - val_loss: 1.4774 - val_accuracy: 0.6039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3308/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3115 - accuracy: 0.8841 - val_loss: 1.4935 - val_accuracy: 0.6039\n",
      "Epoch 3309/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3402 - accuracy: 0.8869 - val_loss: 1.5001 - val_accuracy: 0.5974\n",
      "Epoch 3310/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3352 - accuracy: 0.8799 - val_loss: 1.4909 - val_accuracy: 0.5942\n",
      "Epoch 3311/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3906 - accuracy: 0.8757 - val_loss: 1.4666 - val_accuracy: 0.6039\n",
      "Epoch 3312/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3545 - accuracy: 0.8841 - val_loss: 1.4229 - val_accuracy: 0.6299\n",
      "Epoch 3313/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3687 - accuracy: 0.8813 - val_loss: 1.4062 - val_accuracy: 0.6429\n",
      "Epoch 3314/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3562 - accuracy: 0.8857 - val_loss: 1.4008 - val_accuracy: 0.6364\n",
      "Epoch 3315/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3484 - accuracy: 0.8838 - val_loss: 1.4074 - val_accuracy: 0.6364\n",
      "Epoch 3316/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4069 - accuracy: 0.8799 - val_loss: 1.4078 - val_accuracy: 0.6526\n",
      "Epoch 3317/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3694 - accuracy: 0.8750 - val_loss: 1.4116 - val_accuracy: 0.6429\n",
      "Epoch 3318/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3013 - accuracy: 0.8936 - val_loss: 1.4123 - val_accuracy: 0.6364\n",
      "Epoch 3319/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3510 - accuracy: 0.8897 - val_loss: 1.4151 - val_accuracy: 0.6396\n",
      "Epoch 3320/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3436 - accuracy: 0.8828 - val_loss: 1.4105 - val_accuracy: 0.6429\n",
      "Epoch 3321/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3151 - accuracy: 0.8945 - val_loss: 1.4050 - val_accuracy: 0.6429\n",
      "Epoch 3322/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4240 - accuracy: 0.8643 - val_loss: 1.3887 - val_accuracy: 0.6526\n",
      "Epoch 3323/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3457 - accuracy: 0.8953 - val_loss: 1.3708 - val_accuracy: 0.6494\n",
      "Epoch 3324/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4139 - accuracy: 0.8740 - val_loss: 1.3515 - val_accuracy: 0.6494\n",
      "Epoch 3325/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3321 - accuracy: 0.8687 - val_loss: 1.3349 - val_accuracy: 0.6526\n",
      "Epoch 3326/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3907 - accuracy: 0.8673 - val_loss: 1.3267 - val_accuracy: 0.6494\n",
      "Epoch 3327/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3485 - accuracy: 0.8906 - val_loss: 1.3169 - val_accuracy: 0.6461\n",
      "Epoch 3328/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3319 - accuracy: 0.8916 - val_loss: 1.3136 - val_accuracy: 0.6396\n",
      "Epoch 3329/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3143 - accuracy: 0.8896 - val_loss: 1.3135 - val_accuracy: 0.6461\n",
      "Epoch 3330/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3600 - accuracy: 0.8827 - val_loss: 1.3196 - val_accuracy: 0.6494\n",
      "Epoch 3331/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3689 - accuracy: 0.8799 - val_loss: 1.3214 - val_accuracy: 0.6558\n",
      "Epoch 3332/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4428 - accuracy: 0.8687 - val_loss: 1.3365 - val_accuracy: 0.6623\n",
      "Epoch 3333/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2992 - accuracy: 0.8911 - val_loss: 1.3705 - val_accuracy: 0.6623\n",
      "Epoch 3334/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3443 - accuracy: 0.8869 - val_loss: 1.3934 - val_accuracy: 0.6721\n",
      "Epoch 3335/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3351 - accuracy: 0.8887 - val_loss: 1.4084 - val_accuracy: 0.6753\n",
      "Epoch 3336/4000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3720 - accuracy: 0.8701 - val_loss: 1.4091 - val_accuracy: 0.6688\n",
      "Epoch 3337/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3640 - accuracy: 0.8809 - val_loss: 1.4051 - val_accuracy: 0.6656\n",
      "Epoch 3338/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3579 - accuracy: 0.8911 - val_loss: 1.3963 - val_accuracy: 0.6429\n",
      "Epoch 3339/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3540 - accuracy: 0.8818 - val_loss: 1.3964 - val_accuracy: 0.6494\n",
      "Epoch 3340/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3444 - accuracy: 0.8939 - val_loss: 1.4050 - val_accuracy: 0.6494\n",
      "Epoch 3341/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3389 - accuracy: 0.8994 - val_loss: 1.4196 - val_accuracy: 0.6591\n",
      "Epoch 3342/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3443 - accuracy: 0.8887 - val_loss: 1.4439 - val_accuracy: 0.6558\n",
      "Epoch 3343/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3620 - accuracy: 0.8848 - val_loss: 1.4980 - val_accuracy: 0.6266\n",
      "Epoch 3344/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3083 - accuracy: 0.8877 - val_loss: 1.5577 - val_accuracy: 0.6006\n",
      "Epoch 3345/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3640 - accuracy: 0.8691 - val_loss: 1.6231 - val_accuracy: 0.5909\n",
      "Epoch 3346/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3792 - accuracy: 0.8813 - val_loss: 1.6493 - val_accuracy: 0.5779\n",
      "Epoch 3347/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3270 - accuracy: 0.8867 - val_loss: 1.6309 - val_accuracy: 0.5844\n",
      "Epoch 3348/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3206 - accuracy: 0.9023 - val_loss: 1.5876 - val_accuracy: 0.6006\n",
      "Epoch 3349/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3393 - accuracy: 0.8916 - val_loss: 1.5558 - val_accuracy: 0.6136\n",
      "Epoch 3350/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3801 - accuracy: 0.8743 - val_loss: 1.5292 - val_accuracy: 0.6201\n",
      "Epoch 3351/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3462 - accuracy: 0.8867 - val_loss: 1.5242 - val_accuracy: 0.6266\n",
      "Epoch 3352/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3265 - accuracy: 0.8965 - val_loss: 1.5275 - val_accuracy: 0.6201\n",
      "Epoch 3353/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3081 - accuracy: 0.9008 - val_loss: 1.5332 - val_accuracy: 0.6201\n",
      "Epoch 3354/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3312 - accuracy: 0.8953 - val_loss: 1.5367 - val_accuracy: 0.6104\n",
      "Epoch 3355/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3817 - accuracy: 0.8757 - val_loss: 1.5213 - val_accuracy: 0.6136\n",
      "Epoch 3356/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3239 - accuracy: 0.9062 - val_loss: 1.5128 - val_accuracy: 0.6071\n",
      "Epoch 3357/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3723 - accuracy: 0.8848 - val_loss: 1.5082 - val_accuracy: 0.6104\n",
      "Epoch 3358/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3350 - accuracy: 0.8980 - val_loss: 1.5179 - val_accuracy: 0.6234\n",
      "Epoch 3359/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3229 - accuracy: 0.8883 - val_loss: 1.5171 - val_accuracy: 0.6201\n",
      "Epoch 3360/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3437 - accuracy: 0.8729 - val_loss: 1.5166 - val_accuracy: 0.6169\n",
      "Epoch 3361/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3262 - accuracy: 0.8980 - val_loss: 1.5086 - val_accuracy: 0.6169\n",
      "Epoch 3362/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4185 - accuracy: 0.8715 - val_loss: 1.5294 - val_accuracy: 0.6104\n",
      "Epoch 3363/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3732 - accuracy: 0.8785 - val_loss: 1.5487 - val_accuracy: 0.6039\n",
      "Epoch 3364/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3554 - accuracy: 0.8877 - val_loss: 1.5704 - val_accuracy: 0.5877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3365/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3855 - accuracy: 0.8757 - val_loss: 1.6028 - val_accuracy: 0.5909\n",
      "Epoch 3366/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3364 - accuracy: 0.8813 - val_loss: 1.6377 - val_accuracy: 0.5812\n",
      "Epoch 3367/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3679 - accuracy: 0.8799 - val_loss: 1.6663 - val_accuracy: 0.5844\n",
      "Epoch 3368/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3745 - accuracy: 0.8906 - val_loss: 1.6905 - val_accuracy: 0.5779\n",
      "Epoch 3369/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3704 - accuracy: 0.8897 - val_loss: 1.7260 - val_accuracy: 0.5714\n",
      "Epoch 3370/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2913 - accuracy: 0.9072 - val_loss: 1.7637 - val_accuracy: 0.5584\n",
      "Epoch 3371/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3195 - accuracy: 0.8936 - val_loss: 1.7769 - val_accuracy: 0.5682\n",
      "Epoch 3372/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3350 - accuracy: 0.8906 - val_loss: 1.7921 - val_accuracy: 0.5487\n",
      "Epoch 3373/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3462 - accuracy: 0.8939 - val_loss: 1.7769 - val_accuracy: 0.5617\n",
      "Epoch 3374/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3611 - accuracy: 0.8916 - val_loss: 1.7321 - val_accuracy: 0.5844\n",
      "Epoch 3375/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3424 - accuracy: 0.9064 - val_loss: 1.6745 - val_accuracy: 0.5942\n",
      "Epoch 3376/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3510 - accuracy: 0.8883 - val_loss: 1.5667 - val_accuracy: 0.6136\n",
      "Epoch 3377/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3163 - accuracy: 0.8906 - val_loss: 1.5103 - val_accuracy: 0.6331\n",
      "Epoch 3378/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3346 - accuracy: 0.8883 - val_loss: 1.4714 - val_accuracy: 0.6461\n",
      "Epoch 3379/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2953 - accuracy: 0.8939 - val_loss: 1.4613 - val_accuracy: 0.6526\n",
      "Epoch 3380/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3744 - accuracy: 0.8809 - val_loss: 1.4667 - val_accuracy: 0.6558\n",
      "Epoch 3381/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3584 - accuracy: 0.8857 - val_loss: 1.4635 - val_accuracy: 0.6494\n",
      "Epoch 3382/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2958 - accuracy: 0.9082 - val_loss: 1.4595 - val_accuracy: 0.6461\n",
      "Epoch 3383/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3401 - accuracy: 0.8906 - val_loss: 1.4480 - val_accuracy: 0.6396\n",
      "Epoch 3384/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3267 - accuracy: 0.9036 - val_loss: 1.4357 - val_accuracy: 0.6364\n",
      "Epoch 3385/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3511 - accuracy: 0.8887 - val_loss: 1.4315 - val_accuracy: 0.6364\n",
      "Epoch 3386/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3549 - accuracy: 0.8789 - val_loss: 1.4312 - val_accuracy: 0.6364\n",
      "Epoch 3387/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3554 - accuracy: 0.8799 - val_loss: 1.4341 - val_accuracy: 0.6331\n",
      "Epoch 3388/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3496 - accuracy: 0.8785 - val_loss: 1.4535 - val_accuracy: 0.6266\n",
      "Epoch 3389/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3614 - accuracy: 0.8855 - val_loss: 1.4755 - val_accuracy: 0.6201\n",
      "Epoch 3390/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3255 - accuracy: 0.8867 - val_loss: 1.4802 - val_accuracy: 0.6169\n",
      "Epoch 3391/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3728 - accuracy: 0.8770 - val_loss: 1.4705 - val_accuracy: 0.6169\n",
      "Epoch 3392/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3784 - accuracy: 0.8785 - val_loss: 1.4436 - val_accuracy: 0.6234\n",
      "Epoch 3393/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3349 - accuracy: 0.8896 - val_loss: 1.4027 - val_accuracy: 0.6429\n",
      "Epoch 3394/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3406 - accuracy: 0.8827 - val_loss: 1.3766 - val_accuracy: 0.6429\n",
      "Epoch 3395/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3288 - accuracy: 0.8980 - val_loss: 1.3623 - val_accuracy: 0.6331\n",
      "Epoch 3396/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3119 - accuracy: 0.9004 - val_loss: 1.3577 - val_accuracy: 0.6299\n",
      "Epoch 3397/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3959 - accuracy: 0.8659 - val_loss: 1.3522 - val_accuracy: 0.6331\n",
      "Epoch 3398/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3713 - accuracy: 0.8743 - val_loss: 1.3438 - val_accuracy: 0.6396\n",
      "Epoch 3399/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3375 - accuracy: 0.8682 - val_loss: 1.3361 - val_accuracy: 0.6494\n",
      "Epoch 3400/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3097 - accuracy: 0.8925 - val_loss: 1.3371 - val_accuracy: 0.6526\n",
      "Epoch 3401/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2950 - accuracy: 0.8911 - val_loss: 1.3451 - val_accuracy: 0.6591\n",
      "Epoch 3402/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3803 - accuracy: 0.8799 - val_loss: 1.3680 - val_accuracy: 0.6526\n",
      "Epoch 3403/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3429 - accuracy: 0.8939 - val_loss: 1.3867 - val_accuracy: 0.6331\n",
      "Epoch 3404/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3336 - accuracy: 0.8925 - val_loss: 1.4079 - val_accuracy: 0.6299\n",
      "Epoch 3405/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3742 - accuracy: 0.8848 - val_loss: 1.4292 - val_accuracy: 0.6396\n",
      "Epoch 3406/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4136 - accuracy: 0.8729 - val_loss: 1.4541 - val_accuracy: 0.6331\n",
      "Epoch 3407/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3270 - accuracy: 0.8936 - val_loss: 1.4792 - val_accuracy: 0.6266\n",
      "Epoch 3408/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4008 - accuracy: 0.8662 - val_loss: 1.5142 - val_accuracy: 0.6266\n",
      "Epoch 3409/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3060 - accuracy: 0.8994 - val_loss: 1.5544 - val_accuracy: 0.6234\n",
      "Epoch 3410/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3260 - accuracy: 0.8911 - val_loss: 1.6107 - val_accuracy: 0.5909\n",
      "Epoch 3411/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3367 - accuracy: 0.8729 - val_loss: 1.6822 - val_accuracy: 0.5779\n",
      "Epoch 3412/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4086 - accuracy: 0.8813 - val_loss: 1.7352 - val_accuracy: 0.5779\n",
      "Epoch 3413/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3471 - accuracy: 0.8809 - val_loss: 1.7512 - val_accuracy: 0.5519\n",
      "Epoch 3414/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3810 - accuracy: 0.8770 - val_loss: 1.7685 - val_accuracy: 0.5617\n",
      "Epoch 3415/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3123 - accuracy: 0.9078 - val_loss: 1.7764 - val_accuracy: 0.5649\n",
      "Epoch 3416/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3197 - accuracy: 0.8869 - val_loss: 1.7683 - val_accuracy: 0.5519\n",
      "Epoch 3417/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2795 - accuracy: 0.9064 - val_loss: 1.7322 - val_accuracy: 0.5649\n",
      "Epoch 3418/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3444 - accuracy: 0.8966 - val_loss: 1.7113 - val_accuracy: 0.5747\n",
      "Epoch 3419/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3117 - accuracy: 0.8867 - val_loss: 1.6752 - val_accuracy: 0.5844\n",
      "Epoch 3420/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3670 - accuracy: 0.8980 - val_loss: 1.6213 - val_accuracy: 0.5877\n",
      "Epoch 3421/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3834 - accuracy: 0.8770 - val_loss: 1.5768 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3422/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3691 - accuracy: 0.8828 - val_loss: 1.5660 - val_accuracy: 0.6104\n",
      "Epoch 3423/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3565 - accuracy: 0.8857 - val_loss: 1.5627 - val_accuracy: 0.6104\n",
      "Epoch 3424/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3330 - accuracy: 0.8966 - val_loss: 1.5472 - val_accuracy: 0.6201\n",
      "Epoch 3425/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3269 - accuracy: 0.9033 - val_loss: 1.5432 - val_accuracy: 0.6136\n",
      "Epoch 3426/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3339 - accuracy: 0.8925 - val_loss: 1.5350 - val_accuracy: 0.6071\n",
      "Epoch 3427/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3335 - accuracy: 0.8916 - val_loss: 1.5400 - val_accuracy: 0.5974\n",
      "Epoch 3428/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3345 - accuracy: 0.8966 - val_loss: 1.5286 - val_accuracy: 0.5974\n",
      "Epoch 3429/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3650 - accuracy: 0.8848 - val_loss: 1.5195 - val_accuracy: 0.5844\n",
      "Epoch 3430/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3223 - accuracy: 0.8925 - val_loss: 1.5421 - val_accuracy: 0.5812\n",
      "Epoch 3431/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3556 - accuracy: 0.8779 - val_loss: 1.5797 - val_accuracy: 0.5909\n",
      "Epoch 3432/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3213 - accuracy: 0.9036 - val_loss: 1.6185 - val_accuracy: 0.5779\n",
      "Epoch 3433/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3111 - accuracy: 0.9022 - val_loss: 1.6407 - val_accuracy: 0.5844\n",
      "Epoch 3434/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4220 - accuracy: 0.8743 - val_loss: 1.6271 - val_accuracy: 0.5844\n",
      "Epoch 3435/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3486 - accuracy: 0.8897 - val_loss: 1.6004 - val_accuracy: 0.5877\n",
      "Epoch 3436/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3953 - accuracy: 0.8750 - val_loss: 1.5563 - val_accuracy: 0.6169\n",
      "Epoch 3437/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3536 - accuracy: 0.8897 - val_loss: 1.5207 - val_accuracy: 0.6364\n",
      "Epoch 3438/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3344 - accuracy: 0.8994 - val_loss: 1.4920 - val_accuracy: 0.6396\n",
      "Epoch 3439/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2895 - accuracy: 0.9064 - val_loss: 1.4643 - val_accuracy: 0.6364\n",
      "Epoch 3440/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3426 - accuracy: 0.8883 - val_loss: 1.4307 - val_accuracy: 0.6494\n",
      "Epoch 3441/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3716 - accuracy: 0.8673 - val_loss: 1.4193 - val_accuracy: 0.6429\n",
      "Epoch 3442/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3609 - accuracy: 0.8883 - val_loss: 1.4193 - val_accuracy: 0.6558\n",
      "Epoch 3443/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3441 - accuracy: 0.8887 - val_loss: 1.4211 - val_accuracy: 0.6591\n",
      "Epoch 3444/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3620 - accuracy: 0.8721 - val_loss: 1.4381 - val_accuracy: 0.6623\n",
      "Epoch 3445/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3553 - accuracy: 0.8813 - val_loss: 1.4641 - val_accuracy: 0.6526\n",
      "Epoch 3446/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3859 - accuracy: 0.8757 - val_loss: 1.4824 - val_accuracy: 0.6299\n",
      "Epoch 3447/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3073 - accuracy: 0.8936 - val_loss: 1.5031 - val_accuracy: 0.6299\n",
      "Epoch 3448/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3610 - accuracy: 0.8939 - val_loss: 1.5039 - val_accuracy: 0.6169\n",
      "Epoch 3449/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3201 - accuracy: 0.9004 - val_loss: 1.4981 - val_accuracy: 0.6071\n",
      "Epoch 3450/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3160 - accuracy: 0.8911 - val_loss: 1.4980 - val_accuracy: 0.6104\n",
      "Epoch 3451/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3435 - accuracy: 0.8897 - val_loss: 1.5410 - val_accuracy: 0.5812\n",
      "Epoch 3452/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3381 - accuracy: 0.8848 - val_loss: 1.5705 - val_accuracy: 0.5812\n",
      "Epoch 3453/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3618 - accuracy: 0.8855 - val_loss: 1.5915 - val_accuracy: 0.5779\n",
      "Epoch 3454/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3595 - accuracy: 0.8897 - val_loss: 1.5903 - val_accuracy: 0.5779\n",
      "Epoch 3455/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3135 - accuracy: 0.8994 - val_loss: 1.6342 - val_accuracy: 0.5682\n",
      "Epoch 3456/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3416 - accuracy: 0.8855 - val_loss: 1.6752 - val_accuracy: 0.5617\n",
      "Epoch 3457/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3411 - accuracy: 0.8916 - val_loss: 1.6922 - val_accuracy: 0.5552\n",
      "Epoch 3458/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3401 - accuracy: 0.8841 - val_loss: 1.7004 - val_accuracy: 0.5552\n",
      "Epoch 3459/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3101 - accuracy: 0.9078 - val_loss: 1.6672 - val_accuracy: 0.5747\n",
      "Epoch 3460/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3813 - accuracy: 0.8771 - val_loss: 1.6440 - val_accuracy: 0.5812\n",
      "Epoch 3461/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3325 - accuracy: 0.8926 - val_loss: 1.6178 - val_accuracy: 0.5812\n",
      "Epoch 3462/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3379 - accuracy: 0.9023 - val_loss: 1.5906 - val_accuracy: 0.5779\n",
      "Epoch 3463/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3018 - accuracy: 0.8966 - val_loss: 1.5723 - val_accuracy: 0.5812\n",
      "Epoch 3464/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3558 - accuracy: 0.8916 - val_loss: 1.5355 - val_accuracy: 0.5877\n",
      "Epoch 3465/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3253 - accuracy: 0.8867 - val_loss: 1.4949 - val_accuracy: 0.6006\n",
      "Epoch 3466/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3111 - accuracy: 0.9008 - val_loss: 1.4847 - val_accuracy: 0.5942\n",
      "Epoch 3467/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3717 - accuracy: 0.8721 - val_loss: 1.4608 - val_accuracy: 0.6006\n",
      "Epoch 3468/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2933 - accuracy: 0.9062 - val_loss: 1.4485 - val_accuracy: 0.6136\n",
      "Epoch 3469/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3311 - accuracy: 0.8897 - val_loss: 1.4333 - val_accuracy: 0.6136\n",
      "Epoch 3470/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3094 - accuracy: 0.8925 - val_loss: 1.4109 - val_accuracy: 0.6234\n",
      "Epoch 3471/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3076 - accuracy: 0.9008 - val_loss: 1.3886 - val_accuracy: 0.6266\n",
      "Epoch 3472/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2991 - accuracy: 0.8955 - val_loss: 1.3684 - val_accuracy: 0.6266\n",
      "Epoch 3473/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3739 - accuracy: 0.8672 - val_loss: 1.3493 - val_accuracy: 0.6396\n",
      "Epoch 3474/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3673 - accuracy: 0.8828 - val_loss: 1.3416 - val_accuracy: 0.6461\n",
      "Epoch 3475/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3265 - accuracy: 0.8869 - val_loss: 1.3315 - val_accuracy: 0.6526\n",
      "Epoch 3476/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2793 - accuracy: 0.9189 - val_loss: 1.3275 - val_accuracy: 0.6558\n",
      "Epoch 3477/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3383 - accuracy: 0.8877 - val_loss: 1.3229 - val_accuracy: 0.6526\n",
      "Epoch 3478/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2928 - accuracy: 0.8966 - val_loss: 1.3250 - val_accuracy: 0.6526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3479/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3267 - accuracy: 0.8936 - val_loss: 1.3348 - val_accuracy: 0.6429\n",
      "Epoch 3480/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3459 - accuracy: 0.8779 - val_loss: 1.3609 - val_accuracy: 0.6396\n",
      "Epoch 3481/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3418 - accuracy: 0.8906 - val_loss: 1.3891 - val_accuracy: 0.6299\n",
      "Epoch 3482/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3428 - accuracy: 0.8916 - val_loss: 1.4194 - val_accuracy: 0.6266\n",
      "Epoch 3483/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3922 - accuracy: 0.8687 - val_loss: 1.4488 - val_accuracy: 0.6266\n",
      "Epoch 3484/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3407 - accuracy: 0.8867 - val_loss: 1.4849 - val_accuracy: 0.6169\n",
      "Epoch 3485/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3162 - accuracy: 0.8911 - val_loss: 1.5150 - val_accuracy: 0.6104\n",
      "Epoch 3486/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3097 - accuracy: 0.9008 - val_loss: 1.5253 - val_accuracy: 0.6071\n",
      "Epoch 3487/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3503 - accuracy: 0.8771 - val_loss: 1.4947 - val_accuracy: 0.6071\n",
      "Epoch 3488/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2901 - accuracy: 0.9148 - val_loss: 1.4681 - val_accuracy: 0.6234\n",
      "Epoch 3489/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3297 - accuracy: 0.8926 - val_loss: 1.4550 - val_accuracy: 0.6104\n",
      "Epoch 3490/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3718 - accuracy: 0.8828 - val_loss: 1.4531 - val_accuracy: 0.6104\n",
      "Epoch 3491/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3208 - accuracy: 0.8877 - val_loss: 1.4569 - val_accuracy: 0.6104\n",
      "Epoch 3492/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3263 - accuracy: 0.8906 - val_loss: 1.4531 - val_accuracy: 0.6136\n",
      "Epoch 3493/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3579 - accuracy: 0.8828 - val_loss: 1.4361 - val_accuracy: 0.6136\n",
      "Epoch 3494/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2910 - accuracy: 0.9008 - val_loss: 1.4161 - val_accuracy: 0.6201\n",
      "Epoch 3495/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3372 - accuracy: 0.8994 - val_loss: 1.4075 - val_accuracy: 0.6331\n",
      "Epoch 3496/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3523 - accuracy: 0.8897 - val_loss: 1.4082 - val_accuracy: 0.6299\n",
      "Epoch 3497/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3528 - accuracy: 0.8818 - val_loss: 1.4059 - val_accuracy: 0.6331\n",
      "Epoch 3498/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3263 - accuracy: 0.8953 - val_loss: 1.3995 - val_accuracy: 0.6299\n",
      "Epoch 3499/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3099 - accuracy: 0.8896 - val_loss: 1.4027 - val_accuracy: 0.6299\n",
      "Epoch 3500/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3525 - accuracy: 0.8799 - val_loss: 1.4176 - val_accuracy: 0.6266\n",
      "Epoch 3501/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3224 - accuracy: 0.8869 - val_loss: 1.4401 - val_accuracy: 0.6299\n",
      "Epoch 3502/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2984 - accuracy: 0.9050 - val_loss: 1.4742 - val_accuracy: 0.6169\n",
      "Epoch 3503/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3323 - accuracy: 0.8926 - val_loss: 1.4917 - val_accuracy: 0.5974\n",
      "Epoch 3504/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3268 - accuracy: 0.8945 - val_loss: 1.5049 - val_accuracy: 0.5974\n",
      "Epoch 3505/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3094 - accuracy: 0.8813 - val_loss: 1.5097 - val_accuracy: 0.5909\n",
      "Epoch 3506/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2889 - accuracy: 0.8939 - val_loss: 1.5387 - val_accuracy: 0.5942\n",
      "Epoch 3507/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3524 - accuracy: 0.8887 - val_loss: 1.5374 - val_accuracy: 0.5974\n",
      "Epoch 3508/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3421 - accuracy: 0.8925 - val_loss: 1.5754 - val_accuracy: 0.5779\n",
      "Epoch 3509/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3860 - accuracy: 0.8779 - val_loss: 1.6057 - val_accuracy: 0.5682\n",
      "Epoch 3510/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3570 - accuracy: 0.8809 - val_loss: 1.6308 - val_accuracy: 0.5779\n",
      "Epoch 3511/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3439 - accuracy: 0.8887 - val_loss: 1.6360 - val_accuracy: 0.5844\n",
      "Epoch 3512/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3356 - accuracy: 0.8994 - val_loss: 1.6604 - val_accuracy: 0.5779\n",
      "Epoch 3513/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2984 - accuracy: 0.9050 - val_loss: 1.6746 - val_accuracy: 0.5779\n",
      "Epoch 3514/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3406 - accuracy: 0.8883 - val_loss: 1.6540 - val_accuracy: 0.5909\n",
      "Epoch 3515/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3915 - accuracy: 0.8701 - val_loss: 1.6169 - val_accuracy: 0.6006\n",
      "Epoch 3516/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3138 - accuracy: 0.8911 - val_loss: 1.5823 - val_accuracy: 0.6039\n",
      "Epoch 3517/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2825 - accuracy: 0.9050 - val_loss: 1.5330 - val_accuracy: 0.6104\n",
      "Epoch 3518/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3062 - accuracy: 0.9023 - val_loss: 1.4800 - val_accuracy: 0.6396\n",
      "Epoch 3519/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3369 - accuracy: 0.8945 - val_loss: 1.4493 - val_accuracy: 0.6396\n",
      "Epoch 3520/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3626 - accuracy: 0.8896 - val_loss: 1.4183 - val_accuracy: 0.6461\n",
      "Epoch 3521/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3305 - accuracy: 0.8925 - val_loss: 1.3889 - val_accuracy: 0.6461\n",
      "Epoch 3522/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3033 - accuracy: 0.9022 - val_loss: 1.3747 - val_accuracy: 0.6494\n",
      "Epoch 3523/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3122 - accuracy: 0.8966 - val_loss: 1.3676 - val_accuracy: 0.6591\n",
      "Epoch 3524/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3170 - accuracy: 0.8953 - val_loss: 1.3748 - val_accuracy: 0.6558\n",
      "Epoch 3525/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3303 - accuracy: 0.8945 - val_loss: 1.4013 - val_accuracy: 0.6429\n",
      "Epoch 3526/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3279 - accuracy: 0.8953 - val_loss: 1.4364 - val_accuracy: 0.6396\n",
      "Epoch 3527/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3178 - accuracy: 0.8887 - val_loss: 1.4499 - val_accuracy: 0.6364\n",
      "Epoch 3528/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3331 - accuracy: 0.8953 - val_loss: 1.4718 - val_accuracy: 0.6396\n",
      "Epoch 3529/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3349 - accuracy: 0.8818 - val_loss: 1.4695 - val_accuracy: 0.6494\n",
      "Epoch 3530/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3146 - accuracy: 0.8818 - val_loss: 1.4666 - val_accuracy: 0.6364\n",
      "Epoch 3531/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3009 - accuracy: 0.9092 - val_loss: 1.4586 - val_accuracy: 0.6331\n",
      "Epoch 3532/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3107 - accuracy: 0.8883 - val_loss: 1.4590 - val_accuracy: 0.6331\n",
      "Epoch 3533/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3494 - accuracy: 0.8911 - val_loss: 1.4613 - val_accuracy: 0.6396\n",
      "Epoch 3534/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3715 - accuracy: 0.8869 - val_loss: 1.4661 - val_accuracy: 0.6331\n",
      "Epoch 3535/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3184 - accuracy: 0.8887 - val_loss: 1.4629 - val_accuracy: 0.6331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3536/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3390 - accuracy: 0.8906 - val_loss: 1.4586 - val_accuracy: 0.6299\n",
      "Epoch 3537/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2816 - accuracy: 0.9072 - val_loss: 1.4419 - val_accuracy: 0.6396\n",
      "Epoch 3538/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3169 - accuracy: 0.8906 - val_loss: 1.4334 - val_accuracy: 0.6364\n",
      "Epoch 3539/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3382 - accuracy: 0.8848 - val_loss: 1.4197 - val_accuracy: 0.6429\n",
      "Epoch 3540/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3168 - accuracy: 0.9014 - val_loss: 1.4154 - val_accuracy: 0.6429\n",
      "Epoch 3541/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3379 - accuracy: 0.8939 - val_loss: 1.3926 - val_accuracy: 0.6494\n",
      "Epoch 3542/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3647 - accuracy: 0.8818 - val_loss: 1.3957 - val_accuracy: 0.6429\n",
      "Epoch 3543/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3336 - accuracy: 0.8760 - val_loss: 1.3953 - val_accuracy: 0.6461\n",
      "Epoch 3544/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3061 - accuracy: 0.8945 - val_loss: 1.4023 - val_accuracy: 0.6429\n",
      "Epoch 3545/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3592 - accuracy: 0.8779 - val_loss: 1.4108 - val_accuracy: 0.6429\n",
      "Epoch 3546/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3626 - accuracy: 0.8916 - val_loss: 1.4173 - val_accuracy: 0.6331\n",
      "Epoch 3547/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2872 - accuracy: 0.9162 - val_loss: 1.4296 - val_accuracy: 0.6429\n",
      "Epoch 3548/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3339 - accuracy: 0.8926 - val_loss: 1.4339 - val_accuracy: 0.6396\n",
      "Epoch 3549/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3665 - accuracy: 0.8911 - val_loss: 1.4314 - val_accuracy: 0.6461\n",
      "Epoch 3550/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3400 - accuracy: 0.8857 - val_loss: 1.4386 - val_accuracy: 0.6494\n",
      "Epoch 3551/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3241 - accuracy: 0.8841 - val_loss: 1.4431 - val_accuracy: 0.6656\n",
      "Epoch 3552/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3215 - accuracy: 0.8953 - val_loss: 1.4561 - val_accuracy: 0.6591\n",
      "Epoch 3553/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3414 - accuracy: 0.8867 - val_loss: 1.4642 - val_accuracy: 0.6558\n",
      "Epoch 3554/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2655 - accuracy: 0.9150 - val_loss: 1.4683 - val_accuracy: 0.6558\n",
      "Epoch 3555/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2963 - accuracy: 0.9064 - val_loss: 1.4661 - val_accuracy: 0.6656\n",
      "Epoch 3556/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3277 - accuracy: 0.8975 - val_loss: 1.4561 - val_accuracy: 0.6656\n",
      "Epoch 3557/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3509 - accuracy: 0.8838 - val_loss: 1.4433 - val_accuracy: 0.6721\n",
      "Epoch 3558/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2795 - accuracy: 0.9036 - val_loss: 1.4199 - val_accuracy: 0.6721\n",
      "Epoch 3559/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3394 - accuracy: 0.8828 - val_loss: 1.4109 - val_accuracy: 0.6753\n",
      "Epoch 3560/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3284 - accuracy: 0.8975 - val_loss: 1.4037 - val_accuracy: 0.6753\n",
      "Epoch 3561/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3232 - accuracy: 0.9036 - val_loss: 1.4032 - val_accuracy: 0.6786\n",
      "Epoch 3562/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3029 - accuracy: 0.8994 - val_loss: 1.4142 - val_accuracy: 0.6656\n",
      "Epoch 3563/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3002 - accuracy: 0.8945 - val_loss: 1.4215 - val_accuracy: 0.6753\n",
      "Epoch 3564/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3112 - accuracy: 0.8925 - val_loss: 1.4241 - val_accuracy: 0.6656\n",
      "Epoch 3565/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3334 - accuracy: 0.8966 - val_loss: 1.4214 - val_accuracy: 0.6656\n",
      "Epoch 3566/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2802 - accuracy: 0.8984 - val_loss: 1.4290 - val_accuracy: 0.6591\n",
      "Epoch 3567/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3042 - accuracy: 0.9082 - val_loss: 1.4226 - val_accuracy: 0.6526\n",
      "Epoch 3568/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3161 - accuracy: 0.8936 - val_loss: 1.4341 - val_accuracy: 0.6526\n",
      "Epoch 3569/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3235 - accuracy: 0.8906 - val_loss: 1.4306 - val_accuracy: 0.6461\n",
      "Epoch 3570/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2844 - accuracy: 0.8953 - val_loss: 1.4366 - val_accuracy: 0.6558\n",
      "Epoch 3571/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3133 - accuracy: 0.9036 - val_loss: 1.4390 - val_accuracy: 0.6526\n",
      "Epoch 3572/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3287 - accuracy: 0.8994 - val_loss: 1.4481 - val_accuracy: 0.6526\n",
      "Epoch 3573/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3332 - accuracy: 0.8818 - val_loss: 1.4754 - val_accuracy: 0.6429\n",
      "Epoch 3574/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3637 - accuracy: 0.8799 - val_loss: 1.4984 - val_accuracy: 0.6429\n",
      "Epoch 3575/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2931 - accuracy: 0.9033 - val_loss: 1.5235 - val_accuracy: 0.6396\n",
      "Epoch 3576/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3015 - accuracy: 0.8984 - val_loss: 1.5387 - val_accuracy: 0.6494\n",
      "Epoch 3577/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3840 - accuracy: 0.8760 - val_loss: 1.5588 - val_accuracy: 0.6429\n",
      "Epoch 3578/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3443 - accuracy: 0.8897 - val_loss: 1.5773 - val_accuracy: 0.6169\n",
      "Epoch 3579/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3360 - accuracy: 0.8887 - val_loss: 1.5941 - val_accuracy: 0.6006\n",
      "Epoch 3580/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3382 - accuracy: 0.8887 - val_loss: 1.5942 - val_accuracy: 0.6104\n",
      "Epoch 3581/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3280 - accuracy: 0.8916 - val_loss: 1.5679 - val_accuracy: 0.6136\n",
      "Epoch 3582/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3302 - accuracy: 0.8926 - val_loss: 1.5412 - val_accuracy: 0.6169\n",
      "Epoch 3583/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3391 - accuracy: 0.8897 - val_loss: 1.5189 - val_accuracy: 0.6234\n",
      "Epoch 3584/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2992 - accuracy: 0.9092 - val_loss: 1.4965 - val_accuracy: 0.6429\n",
      "Epoch 3585/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2696 - accuracy: 0.9023 - val_loss: 1.4751 - val_accuracy: 0.6429\n",
      "Epoch 3586/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3058 - accuracy: 0.9033 - val_loss: 1.4637 - val_accuracy: 0.6461\n",
      "Epoch 3587/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3072 - accuracy: 0.9023 - val_loss: 1.4585 - val_accuracy: 0.6494\n",
      "Epoch 3588/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2970 - accuracy: 0.9008 - val_loss: 1.4619 - val_accuracy: 0.6494\n",
      "Epoch 3589/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2934 - accuracy: 0.8906 - val_loss: 1.4797 - val_accuracy: 0.6429\n",
      "Epoch 3590/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3528 - accuracy: 0.8813 - val_loss: 1.4945 - val_accuracy: 0.6331\n",
      "Epoch 3591/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2866 - accuracy: 0.9131 - val_loss: 1.5109 - val_accuracy: 0.6266\n",
      "Epoch 3592/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2975 - accuracy: 0.8939 - val_loss: 1.5334 - val_accuracy: 0.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3593/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3327 - accuracy: 0.8936 - val_loss: 1.5527 - val_accuracy: 0.6331\n",
      "Epoch 3594/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3352 - accuracy: 0.9008 - val_loss: 1.5803 - val_accuracy: 0.6169\n",
      "Epoch 3595/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3346 - accuracy: 0.8980 - val_loss: 1.5980 - val_accuracy: 0.6201\n",
      "Epoch 3596/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3490 - accuracy: 0.8789 - val_loss: 1.6323 - val_accuracy: 0.5909\n",
      "Epoch 3597/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3341 - accuracy: 0.8883 - val_loss: 1.6789 - val_accuracy: 0.5877\n",
      "Epoch 3598/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2777 - accuracy: 0.8966 - val_loss: 1.7347 - val_accuracy: 0.5812\n",
      "Epoch 3599/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3171 - accuracy: 0.8984 - val_loss: 1.7703 - val_accuracy: 0.5812\n",
      "Epoch 3600/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3579 - accuracy: 0.8848 - val_loss: 1.7885 - val_accuracy: 0.5617\n",
      "Epoch 3601/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2980 - accuracy: 0.9008 - val_loss: 1.8007 - val_accuracy: 0.5714\n",
      "Epoch 3602/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3540 - accuracy: 0.8841 - val_loss: 1.7841 - val_accuracy: 0.5649\n",
      "Epoch 3603/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2991 - accuracy: 0.9064 - val_loss: 1.7466 - val_accuracy: 0.5682\n",
      "Epoch 3604/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3292 - accuracy: 0.8841 - val_loss: 1.7058 - val_accuracy: 0.5747\n",
      "Epoch 3605/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3295 - accuracy: 0.8911 - val_loss: 1.6886 - val_accuracy: 0.5779\n",
      "Epoch 3606/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3870 - accuracy: 0.8855 - val_loss: 1.6743 - val_accuracy: 0.5877\n",
      "Epoch 3607/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3510 - accuracy: 0.8729 - val_loss: 1.6634 - val_accuracy: 0.5844\n",
      "Epoch 3608/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2933 - accuracy: 0.9120 - val_loss: 1.6531 - val_accuracy: 0.5942\n",
      "Epoch 3609/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3324 - accuracy: 0.8883 - val_loss: 1.6451 - val_accuracy: 0.5909\n",
      "Epoch 3610/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3465 - accuracy: 0.8887 - val_loss: 1.6317 - val_accuracy: 0.6006\n",
      "Epoch 3611/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3160 - accuracy: 0.8799 - val_loss: 1.5967 - val_accuracy: 0.6039\n",
      "Epoch 3612/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2948 - accuracy: 0.9014 - val_loss: 1.5664 - val_accuracy: 0.6104\n",
      "Epoch 3613/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3125 - accuracy: 0.8813 - val_loss: 1.5455 - val_accuracy: 0.6169\n",
      "Epoch 3614/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2675 - accuracy: 0.9078 - val_loss: 1.5519 - val_accuracy: 0.6104\n",
      "Epoch 3615/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3570 - accuracy: 0.8818 - val_loss: 1.5698 - val_accuracy: 0.6039\n",
      "Epoch 3616/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2726 - accuracy: 0.9120 - val_loss: 1.5699 - val_accuracy: 0.6006\n",
      "Epoch 3617/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2939 - accuracy: 0.9022 - val_loss: 1.5993 - val_accuracy: 0.5877\n",
      "Epoch 3618/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3463 - accuracy: 0.8953 - val_loss: 1.6139 - val_accuracy: 0.5942\n",
      "Epoch 3619/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2966 - accuracy: 0.9064 - val_loss: 1.6130 - val_accuracy: 0.5942\n",
      "Epoch 3620/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3444 - accuracy: 0.8896 - val_loss: 1.6059 - val_accuracy: 0.6006\n",
      "Epoch 3621/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3278 - accuracy: 0.8897 - val_loss: 1.5910 - val_accuracy: 0.6039\n",
      "Epoch 3622/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2605 - accuracy: 0.9246 - val_loss: 1.5772 - val_accuracy: 0.6039\n",
      "Epoch 3623/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3564 - accuracy: 0.8828 - val_loss: 1.5615 - val_accuracy: 0.6136\n",
      "Epoch 3624/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2851 - accuracy: 0.9078 - val_loss: 1.5528 - val_accuracy: 0.6169\n",
      "Epoch 3625/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3185 - accuracy: 0.8953 - val_loss: 1.5501 - val_accuracy: 0.6234\n",
      "Epoch 3626/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3373 - accuracy: 0.8926 - val_loss: 1.5508 - val_accuracy: 0.6299\n",
      "Epoch 3627/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3023 - accuracy: 0.8966 - val_loss: 1.5778 - val_accuracy: 0.6266\n",
      "Epoch 3628/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3399 - accuracy: 0.8906 - val_loss: 1.6094 - val_accuracy: 0.6006\n",
      "Epoch 3629/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3421 - accuracy: 0.8838 - val_loss: 1.6339 - val_accuracy: 0.5909\n",
      "Epoch 3630/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3546 - accuracy: 0.8848 - val_loss: 1.6779 - val_accuracy: 0.5844\n",
      "Epoch 3631/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3222 - accuracy: 0.9072 - val_loss: 1.7333 - val_accuracy: 0.5812\n",
      "Epoch 3632/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3092 - accuracy: 0.9050 - val_loss: 1.7952 - val_accuracy: 0.5649\n",
      "Epoch 3633/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3122 - accuracy: 0.8906 - val_loss: 1.8412 - val_accuracy: 0.5649\n",
      "Epoch 3634/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2993 - accuracy: 0.9082 - val_loss: 1.8702 - val_accuracy: 0.5519\n",
      "Epoch 3635/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3036 - accuracy: 0.9014 - val_loss: 1.8943 - val_accuracy: 0.5390\n",
      "Epoch 3636/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2568 - accuracy: 0.9120 - val_loss: 1.8924 - val_accuracy: 0.5455\n",
      "Epoch 3637/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3558 - accuracy: 0.8867 - val_loss: 1.8576 - val_accuracy: 0.5584\n",
      "Epoch 3638/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3620 - accuracy: 0.8827 - val_loss: 1.8183 - val_accuracy: 0.5617\n",
      "Epoch 3639/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3093 - accuracy: 0.9008 - val_loss: 1.7651 - val_accuracy: 0.5747\n",
      "Epoch 3640/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3411 - accuracy: 0.8887 - val_loss: 1.7066 - val_accuracy: 0.5877\n",
      "Epoch 3641/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3465 - accuracy: 0.8955 - val_loss: 1.6954 - val_accuracy: 0.5974\n",
      "Epoch 3642/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3248 - accuracy: 0.8911 - val_loss: 1.6845 - val_accuracy: 0.5974\n",
      "Epoch 3643/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2751 - accuracy: 0.9106 - val_loss: 1.6589 - val_accuracy: 0.6071\n",
      "Epoch 3644/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3024 - accuracy: 0.9120 - val_loss: 1.6477 - val_accuracy: 0.5942\n",
      "Epoch 3645/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3241 - accuracy: 0.8965 - val_loss: 1.6289 - val_accuracy: 0.6006\n",
      "Epoch 3646/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3312 - accuracy: 0.9004 - val_loss: 1.6106 - val_accuracy: 0.6071\n",
      "Epoch 3647/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3405 - accuracy: 0.8975 - val_loss: 1.6130 - val_accuracy: 0.6104\n",
      "Epoch 3648/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2971 - accuracy: 0.8925 - val_loss: 1.6107 - val_accuracy: 0.6071\n",
      "Epoch 3649/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3208 - accuracy: 0.9036 - val_loss: 1.6396 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3650/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3662 - accuracy: 0.8740 - val_loss: 1.6838 - val_accuracy: 0.5844\n",
      "Epoch 3651/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3461 - accuracy: 0.8906 - val_loss: 1.7256 - val_accuracy: 0.5747\n",
      "Epoch 3652/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3273 - accuracy: 0.8965 - val_loss: 1.7552 - val_accuracy: 0.5617\n",
      "Epoch 3653/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3054 - accuracy: 0.8925 - val_loss: 1.7665 - val_accuracy: 0.5682\n",
      "Epoch 3654/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3082 - accuracy: 0.9008 - val_loss: 1.7403 - val_accuracy: 0.5747\n",
      "Epoch 3655/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2814 - accuracy: 0.9082 - val_loss: 1.6927 - val_accuracy: 0.5974\n",
      "Epoch 3656/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3135 - accuracy: 0.8955 - val_loss: 1.6219 - val_accuracy: 0.6071\n",
      "Epoch 3657/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3634 - accuracy: 0.8855 - val_loss: 1.5823 - val_accuracy: 0.6136\n",
      "Epoch 3658/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2737 - accuracy: 0.9111 - val_loss: 1.5522 - val_accuracy: 0.6234\n",
      "Epoch 3659/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3542 - accuracy: 0.8897 - val_loss: 1.5449 - val_accuracy: 0.6396\n",
      "Epoch 3660/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3467 - accuracy: 0.8848 - val_loss: 1.5516 - val_accuracy: 0.6331\n",
      "Epoch 3661/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3009 - accuracy: 0.9036 - val_loss: 1.5684 - val_accuracy: 0.6331\n",
      "Epoch 3662/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3112 - accuracy: 0.9008 - val_loss: 1.5737 - val_accuracy: 0.6396\n",
      "Epoch 3663/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3117 - accuracy: 0.9062 - val_loss: 1.5841 - val_accuracy: 0.6396\n",
      "Epoch 3664/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3087 - accuracy: 0.8994 - val_loss: 1.5786 - val_accuracy: 0.6364\n",
      "Epoch 3665/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3061 - accuracy: 0.8994 - val_loss: 1.5503 - val_accuracy: 0.6429\n",
      "Epoch 3666/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3366 - accuracy: 0.8869 - val_loss: 1.5357 - val_accuracy: 0.6266\n",
      "Epoch 3667/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2998 - accuracy: 0.9023 - val_loss: 1.5205 - val_accuracy: 0.6266\n",
      "Epoch 3668/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3431 - accuracy: 0.8770 - val_loss: 1.4996 - val_accuracy: 0.6201\n",
      "Epoch 3669/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3217 - accuracy: 0.8897 - val_loss: 1.4749 - val_accuracy: 0.6266\n",
      "Epoch 3670/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3278 - accuracy: 0.9014 - val_loss: 1.4575 - val_accuracy: 0.6461\n",
      "Epoch 3671/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2847 - accuracy: 0.9141 - val_loss: 1.4602 - val_accuracy: 0.6558\n",
      "Epoch 3672/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3372 - accuracy: 0.8955 - val_loss: 1.4675 - val_accuracy: 0.6494\n",
      "Epoch 3673/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3009 - accuracy: 0.9004 - val_loss: 1.4898 - val_accuracy: 0.6429\n",
      "Epoch 3674/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3148 - accuracy: 0.8906 - val_loss: 1.5105 - val_accuracy: 0.6266\n",
      "Epoch 3675/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3810 - accuracy: 0.8827 - val_loss: 1.5722 - val_accuracy: 0.6234\n",
      "Epoch 3676/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3034 - accuracy: 0.9062 - val_loss: 1.6004 - val_accuracy: 0.6169\n",
      "Epoch 3677/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2916 - accuracy: 0.8984 - val_loss: 1.6376 - val_accuracy: 0.5974\n",
      "Epoch 3678/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2912 - accuracy: 0.9023 - val_loss: 1.6557 - val_accuracy: 0.5909\n",
      "Epoch 3679/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3167 - accuracy: 0.9036 - val_loss: 1.6638 - val_accuracy: 0.5779\n",
      "Epoch 3680/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3265 - accuracy: 0.8994 - val_loss: 1.6844 - val_accuracy: 0.5747\n",
      "Epoch 3681/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3581 - accuracy: 0.8789 - val_loss: 1.6740 - val_accuracy: 0.5812\n",
      "Epoch 3682/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2894 - accuracy: 0.9131 - val_loss: 1.6314 - val_accuracy: 0.5942\n",
      "Epoch 3683/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3444 - accuracy: 0.8818 - val_loss: 1.5567 - val_accuracy: 0.6169\n",
      "Epoch 3684/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3158 - accuracy: 0.8984 - val_loss: 1.5144 - val_accuracy: 0.6136\n",
      "Epoch 3685/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2889 - accuracy: 0.8994 - val_loss: 1.4903 - val_accuracy: 0.6234\n",
      "Epoch 3686/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3211 - accuracy: 0.9078 - val_loss: 1.4782 - val_accuracy: 0.6331\n",
      "Epoch 3687/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3146 - accuracy: 0.8955 - val_loss: 1.4777 - val_accuracy: 0.6331\n",
      "Epoch 3688/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2995 - accuracy: 0.9050 - val_loss: 1.4666 - val_accuracy: 0.6494\n",
      "Epoch 3689/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3050 - accuracy: 0.9022 - val_loss: 1.4656 - val_accuracy: 0.6558\n",
      "Epoch 3690/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3317 - accuracy: 0.8945 - val_loss: 1.4739 - val_accuracy: 0.6526\n",
      "Epoch 3691/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3522 - accuracy: 0.8857 - val_loss: 1.4994 - val_accuracy: 0.6429\n",
      "Epoch 3692/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2644 - accuracy: 0.9092 - val_loss: 1.5301 - val_accuracy: 0.6331\n",
      "Epoch 3693/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2991 - accuracy: 0.9121 - val_loss: 1.5388 - val_accuracy: 0.6201\n",
      "Epoch 3694/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2660 - accuracy: 0.9092 - val_loss: 1.5431 - val_accuracy: 0.6201\n",
      "Epoch 3695/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2777 - accuracy: 0.9150 - val_loss: 1.5499 - val_accuracy: 0.6201\n",
      "Epoch 3696/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3340 - accuracy: 0.8867 - val_loss: 1.5494 - val_accuracy: 0.6071\n",
      "Epoch 3697/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3482 - accuracy: 0.9022 - val_loss: 1.5260 - val_accuracy: 0.6169\n",
      "Epoch 3698/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2652 - accuracy: 0.9148 - val_loss: 1.5031 - val_accuracy: 0.6136\n",
      "Epoch 3699/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3127 - accuracy: 0.8965 - val_loss: 1.5130 - val_accuracy: 0.6266\n",
      "Epoch 3700/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3812 - accuracy: 0.8757 - val_loss: 1.5180 - val_accuracy: 0.6169\n",
      "Epoch 3701/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2901 - accuracy: 0.9078 - val_loss: 1.5139 - val_accuracy: 0.6234\n",
      "Epoch 3702/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3721 - accuracy: 0.8855 - val_loss: 1.5279 - val_accuracy: 0.6299\n",
      "Epoch 3703/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3153 - accuracy: 0.8994 - val_loss: 1.5518 - val_accuracy: 0.6169\n",
      "Epoch 3704/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3102 - accuracy: 0.9064 - val_loss: 1.5910 - val_accuracy: 0.5974\n",
      "Epoch 3705/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3243 - accuracy: 0.8906 - val_loss: 1.6392 - val_accuracy: 0.5877\n",
      "Epoch 3706/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3158 - accuracy: 0.8911 - val_loss: 1.6995 - val_accuracy: 0.5747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3707/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3371 - accuracy: 0.8936 - val_loss: 1.7426 - val_accuracy: 0.5682\n",
      "Epoch 3708/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3534 - accuracy: 0.8799 - val_loss: 1.7594 - val_accuracy: 0.5747\n",
      "Epoch 3709/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2720 - accuracy: 0.9180 - val_loss: 1.7353 - val_accuracy: 0.5779\n",
      "Epoch 3710/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3410 - accuracy: 0.9036 - val_loss: 1.6834 - val_accuracy: 0.5877\n",
      "Epoch 3711/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2432 - accuracy: 0.9189 - val_loss: 1.6406 - val_accuracy: 0.5877\n",
      "Epoch 3712/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3269 - accuracy: 0.9053 - val_loss: 1.6154 - val_accuracy: 0.5877\n",
      "Epoch 3713/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3531 - accuracy: 0.8827 - val_loss: 1.6001 - val_accuracy: 0.5942\n",
      "Epoch 3714/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3074 - accuracy: 0.9014 - val_loss: 1.5794 - val_accuracy: 0.5974\n",
      "Epoch 3715/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3740 - accuracy: 0.8740 - val_loss: 1.5717 - val_accuracy: 0.6039\n",
      "Epoch 3716/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3172 - accuracy: 0.8945 - val_loss: 1.5636 - val_accuracy: 0.6104\n",
      "Epoch 3717/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3402 - accuracy: 0.8848 - val_loss: 1.5769 - val_accuracy: 0.6234\n",
      "Epoch 3718/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2559 - accuracy: 0.9162 - val_loss: 1.5994 - val_accuracy: 0.6039\n",
      "Epoch 3719/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3179 - accuracy: 0.8925 - val_loss: 1.6022 - val_accuracy: 0.6006\n",
      "Epoch 3720/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3787 - accuracy: 0.8799 - val_loss: 1.5821 - val_accuracy: 0.6104\n",
      "Epoch 3721/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3079 - accuracy: 0.9050 - val_loss: 1.5611 - val_accuracy: 0.6234\n",
      "Epoch 3722/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3253 - accuracy: 0.8953 - val_loss: 1.5481 - val_accuracy: 0.6299\n",
      "Epoch 3723/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3394 - accuracy: 0.8936 - val_loss: 1.5289 - val_accuracy: 0.6331\n",
      "Epoch 3724/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2854 - accuracy: 0.9008 - val_loss: 1.5148 - val_accuracy: 0.6266\n",
      "Epoch 3725/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3009 - accuracy: 0.9050 - val_loss: 1.4979 - val_accuracy: 0.6234\n",
      "Epoch 3726/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3340 - accuracy: 0.8945 - val_loss: 1.4964 - val_accuracy: 0.6169\n",
      "Epoch 3727/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3244 - accuracy: 0.8994 - val_loss: 1.5088 - val_accuracy: 0.6201\n",
      "Epoch 3728/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3132 - accuracy: 0.9022 - val_loss: 1.5173 - val_accuracy: 0.6039\n",
      "Epoch 3729/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2591 - accuracy: 0.9160 - val_loss: 1.5412 - val_accuracy: 0.6071\n",
      "Epoch 3730/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3322 - accuracy: 0.8838 - val_loss: 1.5675 - val_accuracy: 0.6071\n",
      "Epoch 3731/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3140 - accuracy: 0.8994 - val_loss: 1.5822 - val_accuracy: 0.6006\n",
      "Epoch 3732/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3310 - accuracy: 0.8965 - val_loss: 1.5844 - val_accuracy: 0.6006\n",
      "Epoch 3733/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3212 - accuracy: 0.8994 - val_loss: 1.5843 - val_accuracy: 0.6136\n",
      "Epoch 3734/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2940 - accuracy: 0.9078 - val_loss: 1.5793 - val_accuracy: 0.6201\n",
      "Epoch 3735/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2915 - accuracy: 0.9043 - val_loss: 1.5628 - val_accuracy: 0.6169\n",
      "Epoch 3736/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3168 - accuracy: 0.8936 - val_loss: 1.5453 - val_accuracy: 0.6006\n",
      "Epoch 3737/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3549 - accuracy: 0.8841 - val_loss: 1.5306 - val_accuracy: 0.6071\n",
      "Epoch 3738/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3134 - accuracy: 0.8966 - val_loss: 1.5180 - val_accuracy: 0.6136\n",
      "Epoch 3739/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2505 - accuracy: 0.9092 - val_loss: 1.5029 - val_accuracy: 0.6136\n",
      "Epoch 3740/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3697 - accuracy: 0.8828 - val_loss: 1.4859 - val_accuracy: 0.6234\n",
      "Epoch 3741/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3074 - accuracy: 0.9008 - val_loss: 1.4809 - val_accuracy: 0.6234\n",
      "Epoch 3742/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3028 - accuracy: 0.9036 - val_loss: 1.4733 - val_accuracy: 0.6364\n",
      "Epoch 3743/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3931 - accuracy: 0.8743 - val_loss: 1.4724 - val_accuracy: 0.6396\n",
      "Epoch 3744/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3414 - accuracy: 0.9022 - val_loss: 1.4720 - val_accuracy: 0.6396\n",
      "Epoch 3745/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2873 - accuracy: 0.9092 - val_loss: 1.4640 - val_accuracy: 0.6494\n",
      "Epoch 3746/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2568 - accuracy: 0.9121 - val_loss: 1.4587 - val_accuracy: 0.6429\n",
      "Epoch 3747/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2757 - accuracy: 0.9033 - val_loss: 1.4519 - val_accuracy: 0.6494\n",
      "Epoch 3748/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2974 - accuracy: 0.9121 - val_loss: 1.4498 - val_accuracy: 0.6429\n",
      "Epoch 3749/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3011 - accuracy: 0.9064 - val_loss: 1.4425 - val_accuracy: 0.6429\n",
      "Epoch 3750/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2963 - accuracy: 0.9199 - val_loss: 1.4387 - val_accuracy: 0.6396\n",
      "Epoch 3751/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3065 - accuracy: 0.8965 - val_loss: 1.4526 - val_accuracy: 0.6396\n",
      "Epoch 3752/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3357 - accuracy: 0.8911 - val_loss: 1.4448 - val_accuracy: 0.6364\n",
      "Epoch 3753/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2775 - accuracy: 0.8966 - val_loss: 1.4365 - val_accuracy: 0.6364\n",
      "Epoch 3754/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2988 - accuracy: 0.8926 - val_loss: 1.4365 - val_accuracy: 0.6494\n",
      "Epoch 3755/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2482 - accuracy: 0.9078 - val_loss: 1.4374 - val_accuracy: 0.6526\n",
      "Epoch 3756/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3208 - accuracy: 0.8926 - val_loss: 1.4475 - val_accuracy: 0.6526\n",
      "Epoch 3757/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2715 - accuracy: 0.9062 - val_loss: 1.4659 - val_accuracy: 0.6591\n",
      "Epoch 3758/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3374 - accuracy: 0.8848 - val_loss: 1.4906 - val_accuracy: 0.6558\n",
      "Epoch 3759/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2498 - accuracy: 0.9160 - val_loss: 1.5187 - val_accuracy: 0.6494\n",
      "Epoch 3760/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2970 - accuracy: 0.8911 - val_loss: 1.5464 - val_accuracy: 0.6494\n",
      "Epoch 3761/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2608 - accuracy: 0.9078 - val_loss: 1.5805 - val_accuracy: 0.6429\n",
      "Epoch 3762/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3416 - accuracy: 0.8897 - val_loss: 1.6101 - val_accuracy: 0.6331\n",
      "Epoch 3763/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3147 - accuracy: 0.9036 - val_loss: 1.6325 - val_accuracy: 0.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3764/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3244 - accuracy: 0.8925 - val_loss: 1.6518 - val_accuracy: 0.6169\n",
      "Epoch 3765/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3124 - accuracy: 0.9043 - val_loss: 1.6625 - val_accuracy: 0.6136\n",
      "Epoch 3766/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3054 - accuracy: 0.9023 - val_loss: 1.6709 - val_accuracy: 0.6136\n",
      "Epoch 3767/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2934 - accuracy: 0.9050 - val_loss: 1.6593 - val_accuracy: 0.6006\n",
      "Epoch 3768/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3210 - accuracy: 0.8869 - val_loss: 1.6452 - val_accuracy: 0.5974\n",
      "Epoch 3769/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3077 - accuracy: 0.9023 - val_loss: 1.6347 - val_accuracy: 0.5974\n",
      "Epoch 3770/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3429 - accuracy: 0.8897 - val_loss: 1.6462 - val_accuracy: 0.5877\n",
      "Epoch 3771/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2751 - accuracy: 0.9232 - val_loss: 1.6347 - val_accuracy: 0.5942\n",
      "Epoch 3772/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2870 - accuracy: 0.9141 - val_loss: 1.6267 - val_accuracy: 0.5812\n",
      "Epoch 3773/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2979 - accuracy: 0.8980 - val_loss: 1.6188 - val_accuracy: 0.5812\n",
      "Epoch 3774/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3207 - accuracy: 0.9050 - val_loss: 1.6219 - val_accuracy: 0.5877\n",
      "Epoch 3775/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3219 - accuracy: 0.8926 - val_loss: 1.6408 - val_accuracy: 0.5942\n",
      "Epoch 3776/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3049 - accuracy: 0.9072 - val_loss: 1.6580 - val_accuracy: 0.5909\n",
      "Epoch 3777/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3145 - accuracy: 0.8945 - val_loss: 1.6785 - val_accuracy: 0.5877\n",
      "Epoch 3778/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3179 - accuracy: 0.9008 - val_loss: 1.6756 - val_accuracy: 0.6006\n",
      "Epoch 3779/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2736 - accuracy: 0.9036 - val_loss: 1.6794 - val_accuracy: 0.6071\n",
      "Epoch 3780/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2985 - accuracy: 0.9106 - val_loss: 1.6768 - val_accuracy: 0.6039\n",
      "Epoch 3781/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2768 - accuracy: 0.9102 - val_loss: 1.6476 - val_accuracy: 0.6071\n",
      "Epoch 3782/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3190 - accuracy: 0.9148 - val_loss: 1.6024 - val_accuracy: 0.6169\n",
      "Epoch 3783/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2879 - accuracy: 0.9043 - val_loss: 1.5601 - val_accuracy: 0.6234\n",
      "Epoch 3784/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2952 - accuracy: 0.9043 - val_loss: 1.5298 - val_accuracy: 0.6266\n",
      "Epoch 3785/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2842 - accuracy: 0.9082 - val_loss: 1.5076 - val_accuracy: 0.6299\n",
      "Epoch 3786/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3322 - accuracy: 0.8953 - val_loss: 1.4950 - val_accuracy: 0.6299\n",
      "Epoch 3787/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3589 - accuracy: 0.8877 - val_loss: 1.4851 - val_accuracy: 0.6201\n",
      "Epoch 3788/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3079 - accuracy: 0.8953 - val_loss: 1.4703 - val_accuracy: 0.6234\n",
      "Epoch 3789/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2596 - accuracy: 0.9162 - val_loss: 1.4671 - val_accuracy: 0.6266\n",
      "Epoch 3790/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3144 - accuracy: 0.9004 - val_loss: 1.4690 - val_accuracy: 0.6201\n",
      "Epoch 3791/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2702 - accuracy: 0.9092 - val_loss: 1.4691 - val_accuracy: 0.6299\n",
      "Epoch 3792/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3056 - accuracy: 0.8994 - val_loss: 1.4661 - val_accuracy: 0.6266\n",
      "Epoch 3793/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2918 - accuracy: 0.8939 - val_loss: 1.4720 - val_accuracy: 0.6331\n",
      "Epoch 3794/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2848 - accuracy: 0.8994 - val_loss: 1.4727 - val_accuracy: 0.6331\n",
      "Epoch 3795/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3076 - accuracy: 0.8975 - val_loss: 1.4708 - val_accuracy: 0.6169\n",
      "Epoch 3796/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3170 - accuracy: 0.8980 - val_loss: 1.4676 - val_accuracy: 0.6169\n",
      "Epoch 3797/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3323 - accuracy: 0.8906 - val_loss: 1.4572 - val_accuracy: 0.6331\n",
      "Epoch 3798/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2596 - accuracy: 0.9274 - val_loss: 1.4474 - val_accuracy: 0.6396\n",
      "Epoch 3799/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3038 - accuracy: 0.8994 - val_loss: 1.4358 - val_accuracy: 0.6494\n",
      "Epoch 3800/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2975 - accuracy: 0.9033 - val_loss: 1.4319 - val_accuracy: 0.6494\n",
      "Epoch 3801/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3162 - accuracy: 0.9008 - val_loss: 1.4295 - val_accuracy: 0.6494\n",
      "Epoch 3802/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2813 - accuracy: 0.9106 - val_loss: 1.4306 - val_accuracy: 0.6494\n",
      "Epoch 3803/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2899 - accuracy: 0.9176 - val_loss: 1.4310 - val_accuracy: 0.6429\n",
      "Epoch 3804/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3425 - accuracy: 0.8855 - val_loss: 1.4380 - val_accuracy: 0.6429\n",
      "Epoch 3805/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2804 - accuracy: 0.9150 - val_loss: 1.4551 - val_accuracy: 0.6494\n",
      "Epoch 3806/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2874 - accuracy: 0.9180 - val_loss: 1.4920 - val_accuracy: 0.6461\n",
      "Epoch 3807/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2901 - accuracy: 0.9111 - val_loss: 1.5490 - val_accuracy: 0.6461\n",
      "Epoch 3808/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3066 - accuracy: 0.9053 - val_loss: 1.5936 - val_accuracy: 0.6364\n",
      "Epoch 3809/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2948 - accuracy: 0.9106 - val_loss: 1.6084 - val_accuracy: 0.6299\n",
      "Epoch 3810/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3366 - accuracy: 0.8869 - val_loss: 1.5957 - val_accuracy: 0.6299\n",
      "Epoch 3811/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3239 - accuracy: 0.8966 - val_loss: 1.5633 - val_accuracy: 0.6364\n",
      "Epoch 3812/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2539 - accuracy: 0.9180 - val_loss: 1.5540 - val_accuracy: 0.6299\n",
      "Epoch 3813/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2797 - accuracy: 0.9106 - val_loss: 1.5593 - val_accuracy: 0.6429\n",
      "Epoch 3814/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2969 - accuracy: 0.8994 - val_loss: 1.5642 - val_accuracy: 0.6396\n",
      "Epoch 3815/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2733 - accuracy: 0.9218 - val_loss: 1.5592 - val_accuracy: 0.6364\n",
      "Epoch 3816/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2548 - accuracy: 0.9111 - val_loss: 1.5583 - val_accuracy: 0.6299\n",
      "Epoch 3817/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3025 - accuracy: 0.8980 - val_loss: 1.5661 - val_accuracy: 0.6364\n",
      "Epoch 3818/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3000 - accuracy: 0.8975 - val_loss: 1.5811 - val_accuracy: 0.6331\n",
      "Epoch 3819/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3198 - accuracy: 0.8926 - val_loss: 1.5763 - val_accuracy: 0.6396\n",
      "Epoch 3820/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2544 - accuracy: 0.9176 - val_loss: 1.5656 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3821/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3121 - accuracy: 0.8965 - val_loss: 1.5521 - val_accuracy: 0.6364\n",
      "Epoch 3822/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2791 - accuracy: 0.9092 - val_loss: 1.5406 - val_accuracy: 0.6396\n",
      "Epoch 3823/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2903 - accuracy: 0.9092 - val_loss: 1.5432 - val_accuracy: 0.6429\n",
      "Epoch 3824/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2944 - accuracy: 0.9148 - val_loss: 1.5430 - val_accuracy: 0.6396\n",
      "Epoch 3825/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2721 - accuracy: 0.9150 - val_loss: 1.5455 - val_accuracy: 0.6364\n",
      "Epoch 3826/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3202 - accuracy: 0.8953 - val_loss: 1.5407 - val_accuracy: 0.6396\n",
      "Epoch 3827/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3433 - accuracy: 0.9064 - val_loss: 1.5405 - val_accuracy: 0.6234\n",
      "Epoch 3828/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2645 - accuracy: 0.9134 - val_loss: 1.5314 - val_accuracy: 0.6234\n",
      "Epoch 3829/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2461 - accuracy: 0.9148 - val_loss: 1.5225 - val_accuracy: 0.6266\n",
      "Epoch 3830/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3101 - accuracy: 0.9004 - val_loss: 1.5217 - val_accuracy: 0.6266\n",
      "Epoch 3831/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3200 - accuracy: 0.8925 - val_loss: 1.5393 - val_accuracy: 0.6331\n",
      "Epoch 3832/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2962 - accuracy: 0.8994 - val_loss: 1.5802 - val_accuracy: 0.6396\n",
      "Epoch 3833/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3197 - accuracy: 0.8906 - val_loss: 1.6357 - val_accuracy: 0.6201\n",
      "Epoch 3834/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3342 - accuracy: 0.8916 - val_loss: 1.6836 - val_accuracy: 0.6136\n",
      "Epoch 3835/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2638 - accuracy: 0.9190 - val_loss: 1.7355 - val_accuracy: 0.6039\n",
      "Epoch 3836/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2741 - accuracy: 0.9082 - val_loss: 1.7705 - val_accuracy: 0.6006\n",
      "Epoch 3837/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2938 - accuracy: 0.9082 - val_loss: 1.8018 - val_accuracy: 0.5942\n",
      "Epoch 3838/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3267 - accuracy: 0.8994 - val_loss: 1.8125 - val_accuracy: 0.6006\n",
      "Epoch 3839/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3659 - accuracy: 0.8789 - val_loss: 1.7826 - val_accuracy: 0.6039\n",
      "Epoch 3840/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2874 - accuracy: 0.9078 - val_loss: 1.7416 - val_accuracy: 0.5942\n",
      "Epoch 3841/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2779 - accuracy: 0.9014 - val_loss: 1.7040 - val_accuracy: 0.5942\n",
      "Epoch 3842/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2932 - accuracy: 0.9053 - val_loss: 1.6691 - val_accuracy: 0.6169\n",
      "Epoch 3843/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2642 - accuracy: 0.9148 - val_loss: 1.6466 - val_accuracy: 0.6201\n",
      "Epoch 3844/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2799 - accuracy: 0.9053 - val_loss: 1.6318 - val_accuracy: 0.6331\n",
      "Epoch 3845/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3106 - accuracy: 0.8965 - val_loss: 1.6253 - val_accuracy: 0.6299\n",
      "Epoch 3846/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3209 - accuracy: 0.9033 - val_loss: 1.6188 - val_accuracy: 0.6266\n",
      "Epoch 3847/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2629 - accuracy: 0.9078 - val_loss: 1.6256 - val_accuracy: 0.6201\n",
      "Epoch 3848/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2652 - accuracy: 0.9082 - val_loss: 1.6381 - val_accuracy: 0.6201\n",
      "Epoch 3849/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2909 - accuracy: 0.9022 - val_loss: 1.6623 - val_accuracy: 0.6201\n",
      "Epoch 3850/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2837 - accuracy: 0.9062 - val_loss: 1.6901 - val_accuracy: 0.6006\n",
      "Epoch 3851/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3021 - accuracy: 0.8939 - val_loss: 1.7222 - val_accuracy: 0.5942\n",
      "Epoch 3852/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2634 - accuracy: 0.9120 - val_loss: 1.7647 - val_accuracy: 0.5974\n",
      "Epoch 3853/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2419 - accuracy: 0.9162 - val_loss: 1.7998 - val_accuracy: 0.5812\n",
      "Epoch 3854/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3017 - accuracy: 0.9082 - val_loss: 1.8101 - val_accuracy: 0.5779\n",
      "Epoch 3855/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2806 - accuracy: 0.9106 - val_loss: 1.7931 - val_accuracy: 0.5812\n",
      "Epoch 3856/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3024 - accuracy: 0.8980 - val_loss: 1.7537 - val_accuracy: 0.5877\n",
      "Epoch 3857/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2594 - accuracy: 0.9131 - val_loss: 1.6828 - val_accuracy: 0.6006\n",
      "Epoch 3858/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2856 - accuracy: 0.9004 - val_loss: 1.6037 - val_accuracy: 0.6136\n",
      "Epoch 3859/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2763 - accuracy: 0.9160 - val_loss: 1.5406 - val_accuracy: 0.6201\n",
      "Epoch 3860/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2684 - accuracy: 0.9170 - val_loss: 1.5055 - val_accuracy: 0.6331\n",
      "Epoch 3861/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2684 - accuracy: 0.9260 - val_loss: 1.4807 - val_accuracy: 0.6429\n",
      "Epoch 3862/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2683 - accuracy: 0.9131 - val_loss: 1.4602 - val_accuracy: 0.6494\n",
      "Epoch 3863/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3457 - accuracy: 0.8936 - val_loss: 1.4540 - val_accuracy: 0.6688\n",
      "Epoch 3864/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2921 - accuracy: 0.8966 - val_loss: 1.4521 - val_accuracy: 0.6721\n",
      "Epoch 3865/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2981 - accuracy: 0.9008 - val_loss: 1.4569 - val_accuracy: 0.6688\n",
      "Epoch 3866/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2945 - accuracy: 0.9036 - val_loss: 1.4651 - val_accuracy: 0.6591\n",
      "Epoch 3867/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2957 - accuracy: 0.8994 - val_loss: 1.4566 - val_accuracy: 0.6429\n",
      "Epoch 3868/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3285 - accuracy: 0.8896 - val_loss: 1.4457 - val_accuracy: 0.6558\n",
      "Epoch 3869/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2937 - accuracy: 0.9082 - val_loss: 1.4427 - val_accuracy: 0.6526\n",
      "Epoch 3870/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3364 - accuracy: 0.8953 - val_loss: 1.4577 - val_accuracy: 0.6526\n",
      "Epoch 3871/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2757 - accuracy: 0.9050 - val_loss: 1.4583 - val_accuracy: 0.6558\n",
      "Epoch 3872/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2838 - accuracy: 0.9062 - val_loss: 1.4612 - val_accuracy: 0.6526\n",
      "Epoch 3873/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2689 - accuracy: 0.9134 - val_loss: 1.4778 - val_accuracy: 0.6526\n",
      "Epoch 3874/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2613 - accuracy: 0.9170 - val_loss: 1.4895 - val_accuracy: 0.6461\n",
      "Epoch 3875/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3080 - accuracy: 0.8939 - val_loss: 1.5141 - val_accuracy: 0.6299\n",
      "Epoch 3876/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2799 - accuracy: 0.9004 - val_loss: 1.5442 - val_accuracy: 0.6396\n",
      "Epoch 3877/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2910 - accuracy: 0.9043 - val_loss: 1.5724 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3878/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2757 - accuracy: 0.9232 - val_loss: 1.6070 - val_accuracy: 0.6136\n",
      "Epoch 3879/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2391 - accuracy: 0.9344 - val_loss: 1.6208 - val_accuracy: 0.6104\n",
      "Epoch 3880/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3007 - accuracy: 0.9072 - val_loss: 1.6203 - val_accuracy: 0.6136\n",
      "Epoch 3881/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2739 - accuracy: 0.9111 - val_loss: 1.5833 - val_accuracy: 0.6201\n",
      "Epoch 3882/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2572 - accuracy: 0.9176 - val_loss: 1.5560 - val_accuracy: 0.6201\n",
      "Epoch 3883/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3092 - accuracy: 0.8877 - val_loss: 1.5217 - val_accuracy: 0.6169\n",
      "Epoch 3884/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2977 - accuracy: 0.9022 - val_loss: 1.4708 - val_accuracy: 0.6396\n",
      "Epoch 3885/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3180 - accuracy: 0.8906 - val_loss: 1.4248 - val_accuracy: 0.6558\n",
      "Epoch 3886/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2604 - accuracy: 0.9141 - val_loss: 1.4213 - val_accuracy: 0.6591\n",
      "Epoch 3887/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2611 - accuracy: 0.9148 - val_loss: 1.4151 - val_accuracy: 0.6656\n",
      "Epoch 3888/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4002 - accuracy: 0.8955 - val_loss: 1.4089 - val_accuracy: 0.6721\n",
      "Epoch 3889/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2882 - accuracy: 0.9111 - val_loss: 1.4315 - val_accuracy: 0.6656\n",
      "Epoch 3890/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3144 - accuracy: 0.9008 - val_loss: 1.4573 - val_accuracy: 0.6656\n",
      "Epoch 3891/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3051 - accuracy: 0.8994 - val_loss: 1.4977 - val_accuracy: 0.6526\n",
      "Epoch 3892/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2819 - accuracy: 0.9053 - val_loss: 1.5334 - val_accuracy: 0.6494\n",
      "Epoch 3893/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2658 - accuracy: 0.9219 - val_loss: 1.5625 - val_accuracy: 0.6429\n",
      "Epoch 3894/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3059 - accuracy: 0.8975 - val_loss: 1.5885 - val_accuracy: 0.6396\n",
      "Epoch 3895/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3106 - accuracy: 0.9004 - val_loss: 1.6057 - val_accuracy: 0.6364\n",
      "Epoch 3896/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3077 - accuracy: 0.9120 - val_loss: 1.6258 - val_accuracy: 0.6201\n",
      "Epoch 3897/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2856 - accuracy: 0.9078 - val_loss: 1.6275 - val_accuracy: 0.6039\n",
      "Epoch 3898/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2932 - accuracy: 0.9014 - val_loss: 1.6321 - val_accuracy: 0.6039\n",
      "Epoch 3899/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3000 - accuracy: 0.9092 - val_loss: 1.6375 - val_accuracy: 0.6169\n",
      "Epoch 3900/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2819 - accuracy: 0.9023 - val_loss: 1.6719 - val_accuracy: 0.6136\n",
      "Epoch 3901/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2801 - accuracy: 0.9064 - val_loss: 1.7098 - val_accuracy: 0.6039\n",
      "Epoch 3902/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2904 - accuracy: 0.9053 - val_loss: 1.7266 - val_accuracy: 0.6006\n",
      "Epoch 3903/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2900 - accuracy: 0.9078 - val_loss: 1.7443 - val_accuracy: 0.6104\n",
      "Epoch 3904/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3012 - accuracy: 0.9141 - val_loss: 1.7554 - val_accuracy: 0.6071\n",
      "Epoch 3905/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2728 - accuracy: 0.9148 - val_loss: 1.7630 - val_accuracy: 0.6039\n",
      "Epoch 3906/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2571 - accuracy: 0.9131 - val_loss: 1.7497 - val_accuracy: 0.6071\n",
      "Epoch 3907/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3237 - accuracy: 0.9064 - val_loss: 1.7002 - val_accuracy: 0.5974\n",
      "Epoch 3908/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3115 - accuracy: 0.8965 - val_loss: 1.6803 - val_accuracy: 0.6006\n",
      "Epoch 3909/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2999 - accuracy: 0.9004 - val_loss: 1.6459 - val_accuracy: 0.6136\n",
      "Epoch 3910/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2997 - accuracy: 0.9111 - val_loss: 1.6092 - val_accuracy: 0.6234\n",
      "Epoch 3911/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2765 - accuracy: 0.9092 - val_loss: 1.5959 - val_accuracy: 0.6266\n",
      "Epoch 3912/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2873 - accuracy: 0.9033 - val_loss: 1.5847 - val_accuracy: 0.6234\n",
      "Epoch 3913/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3136 - accuracy: 0.9008 - val_loss: 1.5696 - val_accuracy: 0.6234\n",
      "Epoch 3914/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3084 - accuracy: 0.9064 - val_loss: 1.5569 - val_accuracy: 0.6331\n",
      "Epoch 3915/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2884 - accuracy: 0.9148 - val_loss: 1.5393 - val_accuracy: 0.6299\n",
      "Epoch 3916/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3004 - accuracy: 0.9053 - val_loss: 1.5300 - val_accuracy: 0.6396\n",
      "Epoch 3917/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2716 - accuracy: 0.9092 - val_loss: 1.5286 - val_accuracy: 0.6364\n",
      "Epoch 3918/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3149 - accuracy: 0.9043 - val_loss: 1.5331 - val_accuracy: 0.6396\n",
      "Epoch 3919/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2837 - accuracy: 0.9150 - val_loss: 1.5368 - val_accuracy: 0.6396\n",
      "Epoch 3920/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2799 - accuracy: 0.9053 - val_loss: 1.5447 - val_accuracy: 0.6429\n",
      "Epoch 3921/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2710 - accuracy: 0.8994 - val_loss: 1.5453 - val_accuracy: 0.6429\n",
      "Epoch 3922/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3024 - accuracy: 0.9008 - val_loss: 1.5340 - val_accuracy: 0.6494\n",
      "Epoch 3923/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2930 - accuracy: 0.9062 - val_loss: 1.5247 - val_accuracy: 0.6364\n",
      "Epoch 3924/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2636 - accuracy: 0.9134 - val_loss: 1.5253 - val_accuracy: 0.6364\n",
      "Epoch 3925/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2687 - accuracy: 0.9131 - val_loss: 1.5359 - val_accuracy: 0.6364\n",
      "Epoch 3926/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2534 - accuracy: 0.9232 - val_loss: 1.5401 - val_accuracy: 0.6396\n",
      "Epoch 3927/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2812 - accuracy: 0.9064 - val_loss: 1.5336 - val_accuracy: 0.6461\n",
      "Epoch 3928/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2881 - accuracy: 0.9141 - val_loss: 1.5277 - val_accuracy: 0.6429\n",
      "Epoch 3929/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3074 - accuracy: 0.9062 - val_loss: 1.5248 - val_accuracy: 0.6429\n",
      "Epoch 3930/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3051 - accuracy: 0.8939 - val_loss: 1.5210 - val_accuracy: 0.6526\n",
      "Epoch 3931/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2716 - accuracy: 0.9176 - val_loss: 1.5231 - val_accuracy: 0.6526\n",
      "Epoch 3932/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2360 - accuracy: 0.9232 - val_loss: 1.5284 - val_accuracy: 0.6494\n",
      "Epoch 3933/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3783 - accuracy: 0.8841 - val_loss: 1.5213 - val_accuracy: 0.6429\n",
      "Epoch 3934/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3144 - accuracy: 0.8848 - val_loss: 1.5188 - val_accuracy: 0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3935/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2906 - accuracy: 0.9064 - val_loss: 1.5131 - val_accuracy: 0.6234\n",
      "Epoch 3936/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2726 - accuracy: 0.9102 - val_loss: 1.5055 - val_accuracy: 0.6169\n",
      "Epoch 3937/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2850 - accuracy: 0.9053 - val_loss: 1.4993 - val_accuracy: 0.6234\n",
      "Epoch 3938/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3350 - accuracy: 0.8896 - val_loss: 1.4905 - val_accuracy: 0.6234\n",
      "Epoch 3939/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2695 - accuracy: 0.9043 - val_loss: 1.4837 - val_accuracy: 0.6299\n",
      "Epoch 3940/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2886 - accuracy: 0.9033 - val_loss: 1.4828 - val_accuracy: 0.6364\n",
      "Epoch 3941/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3073 - accuracy: 0.9036 - val_loss: 1.4953 - val_accuracy: 0.6266\n",
      "Epoch 3942/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2696 - accuracy: 0.9134 - val_loss: 1.5196 - val_accuracy: 0.6299\n",
      "Epoch 3943/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2760 - accuracy: 0.9082 - val_loss: 1.5473 - val_accuracy: 0.6234\n",
      "Epoch 3944/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3256 - accuracy: 0.8897 - val_loss: 1.5748 - val_accuracy: 0.6299\n",
      "Epoch 3945/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2804 - accuracy: 0.9120 - val_loss: 1.5920 - val_accuracy: 0.6201\n",
      "Epoch 3946/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2425 - accuracy: 0.9268 - val_loss: 1.6058 - val_accuracy: 0.6136\n",
      "Epoch 3947/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2954 - accuracy: 0.9120 - val_loss: 1.5904 - val_accuracy: 0.6136\n",
      "Epoch 3948/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2937 - accuracy: 0.9092 - val_loss: 1.5540 - val_accuracy: 0.6071\n",
      "Epoch 3949/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2899 - accuracy: 0.9064 - val_loss: 1.4987 - val_accuracy: 0.6071\n",
      "Epoch 3950/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2622 - accuracy: 0.9141 - val_loss: 1.4554 - val_accuracy: 0.6136\n",
      "Epoch 3951/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2960 - accuracy: 0.8984 - val_loss: 1.4143 - val_accuracy: 0.6494\n",
      "Epoch 3952/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2897 - accuracy: 0.9148 - val_loss: 1.3876 - val_accuracy: 0.6591\n",
      "Epoch 3953/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3229 - accuracy: 0.8994 - val_loss: 1.3769 - val_accuracy: 0.6591\n",
      "Epoch 3954/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3430 - accuracy: 0.9023 - val_loss: 1.3792 - val_accuracy: 0.6623\n",
      "Epoch 3955/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2830 - accuracy: 0.9082 - val_loss: 1.3935 - val_accuracy: 0.6721\n",
      "Epoch 3956/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3180 - accuracy: 0.9053 - val_loss: 1.4060 - val_accuracy: 0.6558\n",
      "Epoch 3957/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3088 - accuracy: 0.9082 - val_loss: 1.4277 - val_accuracy: 0.6526\n",
      "Epoch 3958/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2469 - accuracy: 0.9176 - val_loss: 1.4578 - val_accuracy: 0.6461\n",
      "Epoch 3959/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2936 - accuracy: 0.9092 - val_loss: 1.4967 - val_accuracy: 0.6364\n",
      "Epoch 3960/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3159 - accuracy: 0.8966 - val_loss: 1.5348 - val_accuracy: 0.6364\n",
      "Epoch 3961/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2682 - accuracy: 0.9043 - val_loss: 1.5408 - val_accuracy: 0.6299\n",
      "Epoch 3962/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3000 - accuracy: 0.9022 - val_loss: 1.5088 - val_accuracy: 0.6429\n",
      "Epoch 3963/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2833 - accuracy: 0.9190 - val_loss: 1.4796 - val_accuracy: 0.6396\n",
      "Epoch 3964/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3324 - accuracy: 0.9023 - val_loss: 1.4538 - val_accuracy: 0.6461\n",
      "Epoch 3965/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2823 - accuracy: 0.8984 - val_loss: 1.4254 - val_accuracy: 0.6591\n",
      "Epoch 3966/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3568 - accuracy: 0.8939 - val_loss: 1.4041 - val_accuracy: 0.6688\n",
      "Epoch 3967/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3118 - accuracy: 0.9022 - val_loss: 1.3909 - val_accuracy: 0.6558\n",
      "Epoch 3968/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2297 - accuracy: 0.9204 - val_loss: 1.3966 - val_accuracy: 0.6494\n",
      "Epoch 3969/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2923 - accuracy: 0.9120 - val_loss: 1.3985 - val_accuracy: 0.6494\n",
      "Epoch 3970/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2442 - accuracy: 0.9072 - val_loss: 1.4040 - val_accuracy: 0.6623\n",
      "Epoch 3971/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2876 - accuracy: 0.9092 - val_loss: 1.4157 - val_accuracy: 0.6526\n",
      "Epoch 3972/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2761 - accuracy: 0.9199 - val_loss: 1.4322 - val_accuracy: 0.6526\n",
      "Epoch 3973/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3295 - accuracy: 0.8939 - val_loss: 1.4724 - val_accuracy: 0.6364\n",
      "Epoch 3974/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2679 - accuracy: 0.9199 - val_loss: 1.5312 - val_accuracy: 0.6266\n",
      "Epoch 3975/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2817 - accuracy: 0.9078 - val_loss: 1.5949 - val_accuracy: 0.6201\n",
      "Epoch 3976/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2829 - accuracy: 0.8984 - val_loss: 1.6126 - val_accuracy: 0.6136\n",
      "Epoch 3977/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3392 - accuracy: 0.8925 - val_loss: 1.5675 - val_accuracy: 0.6169\n",
      "Epoch 3978/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3241 - accuracy: 0.8939 - val_loss: 1.5063 - val_accuracy: 0.6299\n",
      "Epoch 3979/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3297 - accuracy: 0.8953 - val_loss: 1.4734 - val_accuracy: 0.6331\n",
      "Epoch 3980/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3077 - accuracy: 0.8945 - val_loss: 1.4473 - val_accuracy: 0.6299\n",
      "Epoch 3981/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3349 - accuracy: 0.8867 - val_loss: 1.4392 - val_accuracy: 0.6234\n",
      "Epoch 3982/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3042 - accuracy: 0.8955 - val_loss: 1.4419 - val_accuracy: 0.6364\n",
      "Epoch 3983/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2948 - accuracy: 0.9014 - val_loss: 1.4430 - val_accuracy: 0.6396\n",
      "Epoch 3984/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2881 - accuracy: 0.9064 - val_loss: 1.4547 - val_accuracy: 0.6299\n",
      "Epoch 3985/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3025 - accuracy: 0.9092 - val_loss: 1.4668 - val_accuracy: 0.6234\n",
      "Epoch 3986/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2792 - accuracy: 0.9092 - val_loss: 1.4728 - val_accuracy: 0.6396\n",
      "Epoch 3987/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2669 - accuracy: 0.9120 - val_loss: 1.4875 - val_accuracy: 0.6364\n",
      "Epoch 3988/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2657 - accuracy: 0.9111 - val_loss: 1.5096 - val_accuracy: 0.6299\n",
      "Epoch 3989/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3062 - accuracy: 0.9004 - val_loss: 1.5220 - val_accuracy: 0.6234\n",
      "Epoch 3990/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2755 - accuracy: 0.9106 - val_loss: 1.5149 - val_accuracy: 0.6331\n",
      "Epoch 3991/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2722 - accuracy: 0.9199 - val_loss: 1.5279 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3992/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2761 - accuracy: 0.9033 - val_loss: 1.5566 - val_accuracy: 0.6169\n",
      "Epoch 3993/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2464 - accuracy: 0.9036 - val_loss: 1.5567 - val_accuracy: 0.6169\n",
      "Epoch 3994/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3355 - accuracy: 0.8925 - val_loss: 1.5282 - val_accuracy: 0.6136\n",
      "Epoch 3995/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2507 - accuracy: 0.9218 - val_loss: 1.5136 - val_accuracy: 0.6201\n",
      "Epoch 3996/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3037 - accuracy: 0.8994 - val_loss: 1.5035 - val_accuracy: 0.6234\n",
      "Epoch 3997/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2772 - accuracy: 0.9218 - val_loss: 1.4810 - val_accuracy: 0.6299\n",
      "Epoch 3998/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2962 - accuracy: 0.9014 - val_loss: 1.4771 - val_accuracy: 0.6461\n",
      "Epoch 3999/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2784 - accuracy: 0.8994 - val_loss: 1.4792 - val_accuracy: 0.6429\n",
      "Epoch 4000/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2982 - accuracy: 0.9078 - val_loss: 1.4857 - val_accuracy: 0.6461\n",
      "CNN: Epochs=4000, Train accuracy=0.93436, Validation accuracy=0.69805\n"
     ]
    }
   ],
   "source": [
    "epochs = 4000\n",
    "batch_size = 1024\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold로 훈련시키기\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "epochs = 800\n",
    "batch_size = 512\n",
    "\n",
    "for k_train_index, k_valid_index in kf.split(X, y):\n",
    "    history = model.fit(\n",
    "    datagen.flow(X[k_train_index,:], y[k_train_index,:], batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=X[k_train_index,:].shape[0]//batch_size,\n",
    "    validation_data=(X[k_valid_index,:], y[k_valid_index,:]),\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2603262,
     "status": "ok",
     "timestamp": 1598167802346,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "9bcd067b-5514-491c-8c63-db77d4fc6967"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####relu 대신 leaky relu 써보자########\n",
    "#####Adam보단 RMSprop이 좋은 듯도?######\n",
    "#####후에 early stopping도 추가 ########\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1598177058256,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "pHMuMFz1DsU2"
   },
   "outputs": [],
   "source": [
    "#model_10\n",
    "from tensorflow import keras\n",
    "#model_9-3 9-2에서 optimizer만 RMSprop로 바꿔봄\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), Adagrad(lr=0.01, epsilon=None, decay=0.0), adadelta, adam\n",
    "    model.compile(optimizer=RMSprop(lr=0.001, rho=0.95, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1598177058258,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "Lmn384nZDysV",
    "outputId": "5f3b3b04-604f-410c-ac92-0ec2f300de42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1201 (Conv2D)         (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1157 (Ba (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_630 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1202 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1158 (Ba (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_631 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1203 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1159 (Ba (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_632 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1204 (Conv2D)         (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1160 (Ba (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_633 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1205 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1161 (Ba (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_634 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1206 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1162 (Ba (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_635 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1207 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1163 (Ba (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_636 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1208 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1164 (Ba (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_637 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1209 (Conv2D)         (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1165 (Ba (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_638 (LeakyReLU)  (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_31  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_639 (LeakyReLU)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 125,392\n",
      "Trainable params: 124,720\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1598177058642,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yVsg_v1KD4rr"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.975 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 858204,
     "status": "ok",
     "timestamp": 1598177916752,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "_YuoyhnFD7qj",
    "outputId": "9a9e2baa-b85e-405f-d605-310f7ff15302",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 2.4998 - accuracy: 0.1276 - val_loss: 2.2552 - val_accuracy: 0.1526\n",
      "Epoch 2/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.2659 - accuracy: 0.1593 - val_loss: 2.1527 - val_accuracy: 0.2273\n",
      "Epoch 3/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.1901 - accuracy: 0.1868 - val_loss: 2.3029 - val_accuracy: 0.1201\n",
      "Epoch 4/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.1149 - accuracy: 0.2330 - val_loss: 2.4806 - val_accuracy: 0.1039\n",
      "Epoch 5/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.0548 - accuracy: 0.2617 - val_loss: 3.0083 - val_accuracy: 0.1039\n",
      "Epoch 6/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.9871 - accuracy: 0.2875 - val_loss: 2.8759 - val_accuracy: 0.1039\n",
      "Epoch 7/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.8967 - accuracy: 0.3226 - val_loss: 2.7598 - val_accuracy: 0.1169\n",
      "Epoch 8/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.8031 - accuracy: 0.3618 - val_loss: 3.1314 - val_accuracy: 0.1234\n",
      "Epoch 9/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.7294 - accuracy: 0.3852 - val_loss: 1.8271 - val_accuracy: 0.4221\n",
      "Epoch 10/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.6769 - accuracy: 0.3958 - val_loss: 1.2876 - val_accuracy: 0.6234\n",
      "Epoch 11/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.5821 - accuracy: 0.4420 - val_loss: 1.3205 - val_accuracy: 0.5877\n",
      "Epoch 12/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.5320 - accuracy: 0.4693 - val_loss: 1.2170 - val_accuracy: 0.6136\n",
      "Epoch 13/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.4765 - accuracy: 0.4795 - val_loss: 1.2912 - val_accuracy: 0.5877\n",
      "Epoch 14/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.4124 - accuracy: 0.5146 - val_loss: 1.2951 - val_accuracy: 0.5714\n",
      "Epoch 15/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.3823 - accuracy: 0.5187 - val_loss: 1.4694 - val_accuracy: 0.5065\n",
      "Epoch 16/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.3816 - accuracy: 0.5018 - val_loss: 1.0159 - val_accuracy: 0.6688\n",
      "Epoch 17/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.2975 - accuracy: 0.5527 - val_loss: 1.0708 - val_accuracy: 0.6429\n",
      "Epoch 18/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.2263 - accuracy: 0.5796 - val_loss: 0.9438 - val_accuracy: 0.6818\n",
      "Epoch 19/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.2246 - accuracy: 0.5790 - val_loss: 1.0757 - val_accuracy: 0.6429\n",
      "Epoch 20/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.1714 - accuracy: 0.6060 - val_loss: 0.8871 - val_accuracy: 0.6883\n",
      "Epoch 21/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.1384 - accuracy: 0.6189 - val_loss: 0.8942 - val_accuracy: 0.6883\n",
      "Epoch 22/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.1424 - accuracy: 0.6171 - val_loss: 0.8996 - val_accuracy: 0.6851\n",
      "Epoch 23/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.0789 - accuracy: 0.6352 - val_loss: 0.7822 - val_accuracy: 0.7338\n",
      "Epoch 24/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.0897 - accuracy: 0.6306 - val_loss: 0.7925 - val_accuracy: 0.7338\n",
      "Epoch 25/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.0528 - accuracy: 0.6411 - val_loss: 0.7672 - val_accuracy: 0.7338\n",
      "Epoch 26/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9782 - accuracy: 0.6569 - val_loss: 0.6813 - val_accuracy: 0.7727\n",
      "Epoch 27/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9853 - accuracy: 0.6692 - val_loss: 0.7866 - val_accuracy: 0.7370\n",
      "Epoch 28/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9913 - accuracy: 0.6628 - val_loss: 0.8792 - val_accuracy: 0.7013\n",
      "Epoch 29/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9389 - accuracy: 0.6797 - val_loss: 0.7541 - val_accuracy: 0.7403\n",
      "Epoch 30/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9157 - accuracy: 0.6821 - val_loss: 0.9700 - val_accuracy: 0.6688\n",
      "Epoch 31/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9173 - accuracy: 0.6944 - val_loss: 0.6722 - val_accuracy: 0.7695\n",
      "Epoch 32/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9178 - accuracy: 0.6909 - val_loss: 0.7221 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8738 - accuracy: 0.6915 - val_loss: 0.7235 - val_accuracy: 0.7597\n",
      "Epoch 34/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8717 - accuracy: 0.7067 - val_loss: 0.6963 - val_accuracy: 0.7727\n",
      "Epoch 35/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8594 - accuracy: 0.7190 - val_loss: 0.8186 - val_accuracy: 0.7175\n",
      "Epoch 36/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8376 - accuracy: 0.7149 - val_loss: 0.6815 - val_accuracy: 0.7825\n",
      "Epoch 37/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8354 - accuracy: 0.7084 - val_loss: 0.8090 - val_accuracy: 0.7305\n",
      "Epoch 38/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8459 - accuracy: 0.7137 - val_loss: 0.6092 - val_accuracy: 0.7955\n",
      "Epoch 39/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8059 - accuracy: 0.7336 - val_loss: 0.7836 - val_accuracy: 0.7338\n",
      "Epoch 40/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8178 - accuracy: 0.7219 - val_loss: 0.6750 - val_accuracy: 0.7597\n",
      "Epoch 41/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7811 - accuracy: 0.7254 - val_loss: 0.6522 - val_accuracy: 0.7630\n",
      "Epoch 42/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7963 - accuracy: 0.7365 - val_loss: 0.7445 - val_accuracy: 0.7435\n",
      "Epoch 43/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8059 - accuracy: 0.7196 - val_loss: 0.6496 - val_accuracy: 0.7857\n",
      "Epoch 44/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8114 - accuracy: 0.7149 - val_loss: 0.7443 - val_accuracy: 0.7305\n",
      "Epoch 45/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7662 - accuracy: 0.7500 - val_loss: 0.6249 - val_accuracy: 0.7792\n",
      "Epoch 46/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7500 - accuracy: 0.7383 - val_loss: 0.6272 - val_accuracy: 0.7890\n",
      "Epoch 47/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7456 - accuracy: 0.7447 - val_loss: 0.7600 - val_accuracy: 0.7468\n",
      "Epoch 48/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7262 - accuracy: 0.7488 - val_loss: 0.5925 - val_accuracy: 0.7987\n",
      "Epoch 49/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7260 - accuracy: 0.7412 - val_loss: 0.6221 - val_accuracy: 0.8019\n",
      "Epoch 50/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7505 - accuracy: 0.7559 - val_loss: 0.7101 - val_accuracy: 0.7435\n",
      "Epoch 51/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7277 - accuracy: 0.7535 - val_loss: 0.6287 - val_accuracy: 0.7857\n",
      "Epoch 52/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7258 - accuracy: 0.7465 - val_loss: 0.5989 - val_accuracy: 0.8052\n",
      "Epoch 53/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.6988 - accuracy: 0.7652 - val_loss: 0.6240 - val_accuracy: 0.7825\n",
      "Epoch 54/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7062 - accuracy: 0.7541 - val_loss: 0.6481 - val_accuracy: 0.8019\n",
      "Epoch 55/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6977 - accuracy: 0.7711 - val_loss: 0.6163 - val_accuracy: 0.7987\n",
      "Epoch 56/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6929 - accuracy: 0.7570 - val_loss: 0.6802 - val_accuracy: 0.7792\n",
      "Epoch 57/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7194 - accuracy: 0.7529 - val_loss: 0.6242 - val_accuracy: 0.7890\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6953 - accuracy: 0.7605 - val_loss: 0.6067 - val_accuracy: 0.8019\n",
      "Epoch 59/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6613 - accuracy: 0.7758 - val_loss: 0.6572 - val_accuracy: 0.7760\n",
      "Epoch 60/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6696 - accuracy: 0.7681 - val_loss: 0.8487 - val_accuracy: 0.7273\n",
      "Epoch 61/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6757 - accuracy: 0.7646 - val_loss: 0.7014 - val_accuracy: 0.7662\n",
      "Epoch 62/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6608 - accuracy: 0.7670 - val_loss: 0.6366 - val_accuracy: 0.7857\n",
      "Epoch 63/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6320 - accuracy: 0.7881 - val_loss: 0.7097 - val_accuracy: 0.7695\n",
      "Epoch 64/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6651 - accuracy: 0.7693 - val_loss: 0.6045 - val_accuracy: 0.7987\n",
      "Epoch 65/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6655 - accuracy: 0.7641 - val_loss: 0.6040 - val_accuracy: 0.7987\n",
      "Epoch 66/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6524 - accuracy: 0.7664 - val_loss: 0.6303 - val_accuracy: 0.8052\n",
      "Epoch 67/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6729 - accuracy: 0.7810 - val_loss: 0.6506 - val_accuracy: 0.7890\n",
      "Epoch 68/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6340 - accuracy: 0.7951 - val_loss: 0.6675 - val_accuracy: 0.7565\n",
      "Epoch 69/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6644 - accuracy: 0.7752 - val_loss: 0.5886 - val_accuracy: 0.8182\n",
      "Epoch 70/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6400 - accuracy: 0.7804 - val_loss: 0.5669 - val_accuracy: 0.7955\n",
      "Epoch 71/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6376 - accuracy: 0.7822 - val_loss: 0.5742 - val_accuracy: 0.8117\n",
      "Epoch 72/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6627 - accuracy: 0.7863 - val_loss: 0.6134 - val_accuracy: 0.8182\n",
      "Epoch 73/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6027 - accuracy: 0.7986 - val_loss: 0.6403 - val_accuracy: 0.7987\n",
      "Epoch 74/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6432 - accuracy: 0.7910 - val_loss: 0.6138 - val_accuracy: 0.7922\n",
      "Epoch 75/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6152 - accuracy: 0.7957 - val_loss: 0.5987 - val_accuracy: 0.8084\n",
      "Epoch 76/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6078 - accuracy: 0.7904 - val_loss: 0.6446 - val_accuracy: 0.7857\n",
      "Epoch 77/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6203 - accuracy: 0.7810 - val_loss: 0.6096 - val_accuracy: 0.7922\n",
      "Epoch 78/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6308 - accuracy: 0.7828 - val_loss: 0.6246 - val_accuracy: 0.7987\n",
      "Epoch 79/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6240 - accuracy: 0.7822 - val_loss: 0.6460 - val_accuracy: 0.7857\n",
      "Epoch 80/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6232 - accuracy: 0.7851 - val_loss: 0.6637 - val_accuracy: 0.7825\n",
      "Epoch 81/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6052 - accuracy: 0.7945 - val_loss: 0.7033 - val_accuracy: 0.7630\n",
      "Epoch 82/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6134 - accuracy: 0.7881 - val_loss: 0.5900 - val_accuracy: 0.7792\n",
      "Epoch 83/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6014 - accuracy: 0.7910 - val_loss: 0.6836 - val_accuracy: 0.7760\n",
      "Epoch 84/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5992 - accuracy: 0.7986 - val_loss: 0.6291 - val_accuracy: 0.7955\n",
      "Epoch 85/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5965 - accuracy: 0.8015 - val_loss: 0.6344 - val_accuracy: 0.7922\n",
      "Epoch 86/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6191 - accuracy: 0.7886 - val_loss: 0.6093 - val_accuracy: 0.7890\n",
      "Epoch 87/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6049 - accuracy: 0.7933 - val_loss: 0.6477 - val_accuracy: 0.7825\n",
      "Epoch 88/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5972 - accuracy: 0.7951 - val_loss: 0.5780 - val_accuracy: 0.8182\n",
      "Epoch 89/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6217 - accuracy: 0.7904 - val_loss: 0.5783 - val_accuracy: 0.8117\n",
      "Epoch 90/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6283 - accuracy: 0.7886 - val_loss: 0.6178 - val_accuracy: 0.8019\n",
      "Epoch 91/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5556 - accuracy: 0.8085 - val_loss: 0.5905 - val_accuracy: 0.8084\n",
      "Epoch 92/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5792 - accuracy: 0.8085 - val_loss: 0.6331 - val_accuracy: 0.8019\n",
      "Epoch 93/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5812 - accuracy: 0.7904 - val_loss: 0.6477 - val_accuracy: 0.7825\n",
      "Epoch 94/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5970 - accuracy: 0.7945 - val_loss: 0.6084 - val_accuracy: 0.8019\n",
      "Epoch 95/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5827 - accuracy: 0.7998 - val_loss: 0.6296 - val_accuracy: 0.7760\n",
      "Epoch 96/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5704 - accuracy: 0.8103 - val_loss: 0.5769 - val_accuracy: 0.8052\n",
      "Epoch 97/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5970 - accuracy: 0.7904 - val_loss: 0.6054 - val_accuracy: 0.7955\n",
      "Epoch 98/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5966 - accuracy: 0.7998 - val_loss: 0.5896 - val_accuracy: 0.8019\n",
      "Epoch 99/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5565 - accuracy: 0.8050 - val_loss: 0.6189 - val_accuracy: 0.7922\n",
      "Epoch 100/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5815 - accuracy: 0.8142 - val_loss: 0.6427 - val_accuracy: 0.7890\n",
      "Epoch 101/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5558 - accuracy: 0.8091 - val_loss: 0.6597 - val_accuracy: 0.7695\n",
      "Epoch 102/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5649 - accuracy: 0.8208 - val_loss: 0.6526 - val_accuracy: 0.7760\n",
      "Epoch 103/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5582 - accuracy: 0.8080 - val_loss: 0.6199 - val_accuracy: 0.7792\n",
      "Epoch 104/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5485 - accuracy: 0.8004 - val_loss: 0.6102 - val_accuracy: 0.8052\n",
      "Epoch 105/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5762 - accuracy: 0.7992 - val_loss: 0.6148 - val_accuracy: 0.8019\n",
      "Epoch 106/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5449 - accuracy: 0.8109 - val_loss: 0.5861 - val_accuracy: 0.7987\n",
      "Epoch 107/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5728 - accuracy: 0.8068 - val_loss: 0.5534 - val_accuracy: 0.8084\n",
      "Epoch 108/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5739 - accuracy: 0.8039 - val_loss: 0.6319 - val_accuracy: 0.7825\n",
      "Epoch 109/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5926 - accuracy: 0.7968 - val_loss: 0.6230 - val_accuracy: 0.7825\n",
      "Epoch 110/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5398 - accuracy: 0.8156 - val_loss: 0.6177 - val_accuracy: 0.7922\n",
      "Epoch 111/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5507 - accuracy: 0.8121 - val_loss: 0.5872 - val_accuracy: 0.7987\n",
      "Epoch 112/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5678 - accuracy: 0.8074 - val_loss: 0.5963 - val_accuracy: 0.7955\n",
      "Epoch 113/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5877 - accuracy: 0.7869 - val_loss: 0.5938 - val_accuracy: 0.7987\n",
      "Epoch 114/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5390 - accuracy: 0.8144 - val_loss: 0.6080 - val_accuracy: 0.7922\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5488 - accuracy: 0.8021 - val_loss: 0.5931 - val_accuracy: 0.7890\n",
      "Epoch 116/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5346 - accuracy: 0.8197 - val_loss: 0.6279 - val_accuracy: 0.7955\n",
      "Epoch 117/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5494 - accuracy: 0.8138 - val_loss: 0.6057 - val_accuracy: 0.7922\n",
      "Epoch 118/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5358 - accuracy: 0.8208 - val_loss: 0.6448 - val_accuracy: 0.7857\n",
      "Epoch 119/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5234 - accuracy: 0.8185 - val_loss: 0.6424 - val_accuracy: 0.7792\n",
      "Epoch 120/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8197 - val_loss: 0.6297 - val_accuracy: 0.7825\n",
      "Epoch 121/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5419 - accuracy: 0.8050 - val_loss: 0.6185 - val_accuracy: 0.7890\n",
      "Epoch 122/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5313 - accuracy: 0.8132 - val_loss: 0.6142 - val_accuracy: 0.7922\n",
      "Epoch 123/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5291 - accuracy: 0.8074 - val_loss: 0.6259 - val_accuracy: 0.7857\n",
      "Epoch 124/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5717 - accuracy: 0.8109 - val_loss: 0.6011 - val_accuracy: 0.7955\n",
      "Epoch 125/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5470 - accuracy: 0.8068 - val_loss: 0.5836 - val_accuracy: 0.8084\n",
      "Epoch 126/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8056 - val_loss: 0.6075 - val_accuracy: 0.8019\n",
      "Epoch 127/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5169 - accuracy: 0.8279 - val_loss: 0.6067 - val_accuracy: 0.7890\n",
      "Epoch 128/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5248 - accuracy: 0.8290 - val_loss: 0.6456 - val_accuracy: 0.7825\n",
      "Epoch 129/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5331 - accuracy: 0.8214 - val_loss: 0.5859 - val_accuracy: 0.8019\n",
      "Epoch 130/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5741 - accuracy: 0.8091 - val_loss: 0.5804 - val_accuracy: 0.8214\n",
      "Epoch 131/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5071 - accuracy: 0.8349 - val_loss: 0.6237 - val_accuracy: 0.7857\n",
      "Epoch 132/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5542 - accuracy: 0.8050 - val_loss: 0.5969 - val_accuracy: 0.8052\n",
      "Epoch 133/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5382 - accuracy: 0.8138 - val_loss: 0.6054 - val_accuracy: 0.8019\n",
      "Epoch 134/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8121 - val_loss: 0.6200 - val_accuracy: 0.7922\n",
      "Epoch 135/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5653 - accuracy: 0.8103 - val_loss: 0.5936 - val_accuracy: 0.7987\n",
      "Epoch 136/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5032 - accuracy: 0.8167 - val_loss: 0.6319 - val_accuracy: 0.7857\n",
      "Epoch 137/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5513 - accuracy: 0.8115 - val_loss: 0.6192 - val_accuracy: 0.7922\n",
      "Epoch 138/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5346 - accuracy: 0.8097 - val_loss: 0.6215 - val_accuracy: 0.7955\n",
      "Epoch 139/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5496 - accuracy: 0.8144 - val_loss: 0.6068 - val_accuracy: 0.7922\n",
      "Epoch 140/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.4722 - accuracy: 0.8367 - val_loss: 0.6097 - val_accuracy: 0.7890\n",
      "Epoch 141/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5471 - accuracy: 0.8138 - val_loss: 0.6330 - val_accuracy: 0.7760\n",
      "Epoch 142/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5260 - accuracy: 0.8273 - val_loss: 0.6185 - val_accuracy: 0.7825\n",
      "Epoch 143/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5475 - accuracy: 0.8068 - val_loss: 0.6198 - val_accuracy: 0.7987\n",
      "Epoch 144/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.4780 - accuracy: 0.8367 - val_loss: 0.6033 - val_accuracy: 0.7987\n",
      "Epoch 145/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5080 - accuracy: 0.8208 - val_loss: 0.6197 - val_accuracy: 0.7890\n",
      "Epoch 146/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5259 - accuracy: 0.8132 - val_loss: 0.6196 - val_accuracy: 0.7922\n",
      "Epoch 147/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5112 - accuracy: 0.8343 - val_loss: 0.5957 - val_accuracy: 0.7987\n",
      "Epoch 148/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5390 - accuracy: 0.8285 - val_loss: 0.6055 - val_accuracy: 0.7987\n",
      "Epoch 149/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5543 - accuracy: 0.8156 - val_loss: 0.6071 - val_accuracy: 0.7922\n",
      "Epoch 150/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5114 - accuracy: 0.8249 - val_loss: 0.6284 - val_accuracy: 0.7825\n",
      "CNN: Epochs=150, Train accuracy=0.83665, Validation accuracy=0.82143\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 847482,
     "status": "ok",
     "timestamp": 1598177917190,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "ztjVtlqWD_Nb",
    "outputId": "5b0440a7-235f-4ee6-dc8a-20925a204bb5"
   },
   "outputs": [],
   "source": [
    "#9까지는 콘볼루션 층 9개에 맥스풀링과 FC 첨가해서 필터 수나 러닝 레이트만 조절해봄\n",
    "#이번 model_10은 LeNet 참고하여 비슷한 구조로 얕게 층 쌓음 - 훈련 모델에 대한 오버피팅 심함\n",
    "\n",
    "#conv 층과 maxpooling 층에 strides=2 추가해서 해봄\n",
    "\n",
    "#randomsearch로 learning rate 등 하이퍼 파라미터 조절해보기\n",
    "#차라리 learning rate 줄이고 많이 시도? 진동하는 경향이 좀 보임 epoch 75부터 계~~~~속 0.7대 유지 - epoch 161 아직도 탈출 못함\n",
    "#0.003으로 했을 때 진동하는 듯 해서 0.001로 다시 돌아옴 - 근데 학습률이 낮아도 마찬가지로 local 최적에 빠지지 않을까? - global 최적 찾을 방법은??\n",
    "#이것도 진동에 빠진다면 0.002로 시도해보기\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 167612,
     "status": "aborted",
     "timestamp": 1598169622005,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "PD-P4Jt4MoI7"
   },
   "outputs": [],
   "source": [
    "#model_11 - 모델 10에서 Leaky ReLU나 PReLU나 Maxout 시도해보기\n",
    "#아무튼 적당한 활성화 함수 찾은 후 RandomSearch로 하이퍼파라미터 최적화\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, PReLU, \n",
    "    Add, Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1597999558839,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "RkVofda0MsDp",
    "outputId": "303bc178-314a-4b69-a342-b6fb04ffc8c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1174 (Conv2D)         (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_600 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1175 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_601 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1176 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_602 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1177 (Conv2D)         (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_603 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1178 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_604 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1179 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_605 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1180 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_606 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1181 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_607 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1182 (Conv2D)         (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_608 (LeakyReLU)  (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_28  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_609 (LeakyReLU)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 124,048\n",
      "Trainable params: 124,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UJzxDuhMvcE"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.975 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "ByQCa6DAMyRv",
    "outputId": "456de1d2-61df-46d0-b582-20df15e6a5c6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 230\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11108,
     "status": "ok",
     "timestamp": 1597818952144,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "j8AWxmI1RF-1",
    "outputId": "401d75f1-e73c-47b2-9c70-e54ec1c63627"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(valid_X, valid_y, verbose=2)\n",
    "print('테스트 손실함수:', test_loss, '\\n테스트 정확도:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vr35rvIqPNUu"
   },
   "source": [
    "시도해볼 것: maxout은 dropout과 함께 쓰면 효과가 좋은 활성화함수라고 함\n",
    "    - maxout 적용 예제 / 코드 찾아서 직접 사용해보기\n",
    "    - maxout의 단점은 파라미터의 수가 두배가 된다는 점\n",
    "             maxpooling만 쓰지 말고 각 방법의 장단점 파악 후 새롭게 적용해보기\n",
    "\n",
    "Summary\n",
    "Stanford의 CS231n 강의에서는 다음과 같은 순서로 Activation function을 시도해볼 것을 권한다.\n",
    "\n",
    "(1) ReLU를 사용하자.\n",
    "\n",
    "(2) 성능이 만족스럽지 않다면, LeakyReLU, Maxout, ELU를 사용하라.\n",
    "\n",
    "(3) 그래도 만족스럽지 않다면, tanh를 사용하라. 하지만 많은 기대는 하지말자.\n",
    "\n",
    "(4) 그러나 Sigmoid는 사용하지 말라.\n",
    "\n",
    "실무적으로는 ReLU를 가장 많이 사용하며, LeakyReLU/Maxout/ELU도 좋은 선택지가 될 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XskrI2jTrcn"
   },
   "source": [
    "learning rate 점점 감소 시켰을 때: 0.7941\n",
    "\n",
    "그냥 없이 했을 때: 0.8284\n",
    "\n",
    "model_5: train - 0.87, valid - 0.82\n",
    "\n",
    "model_6: Train accuracy=0.89975, Validation accuracy=0.82195\n",
    "\n",
    "강아지 품종 분류 cnn, 데이터 부풀리기 비교 예제\n",
    "\n",
    "# https://lsjsj92.tistory.com/387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_GEq195_R9L"
   },
   "source": [
    "cnn\n",
    "# https://m.blog.naver.com/laonple/221212462034\n",
    "\n",
    "https://m.blog.naver.com/laonple/220808903260\n",
    "\n",
    "# https://buomsoo-kim.github.io/keras/2018/05/05/Easy-deep-learning-with-Keras-11.md/\n",
    "\n",
    "https://machine-geon.tistory.com/46\n",
    "\n",
    "https://excelsior-cjh.tistory.com/152\n",
    "\n",
    "cnn 정확도 높이기\n",
    "\n",
    "https://manofconcrete.blogspot.com/2019/12/mnist-hands-on-3.html\n",
    "\n",
    "randpm search vs grid search\n",
    "\n",
    "https://shwksl101.github.io/ml/dl/2019/01/30/Hyper_parameter_optimization.html\n",
    "\n",
    "케라스 튜너\n",
    "# https://github.com/keras-team/keras-tuner\n",
    "https://tykimos.github.io/2019/05/10/KerasTuner/\n",
    "\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Md1ua95yr-J"
   },
   "outputs": [],
   "source": [
    "'''def model_fn():\n",
    "    LR = Choice('learning_rate', [0.001, 0.0005, 0.0001], group='optimizer')\n",
    "    DROPOUT_RATE = Linear('dropout_rate', 0.0, 0.5, 5, group='dense')\n",
    "    NUM_DIMS = Range('num_dims', 8, 32, 8, group='dense')\n",
    "    NUM_LAYERS = Range('num_layers', 1, 3, group='dense')\n",
    "    L2_NUM_FILTERS = Range('l2_num_filters', 8, 64, 8, group='cnn')\n",
    "    L1_NUM_FILTERS = Range('l1_num_filters', 8, 64, 8, group='cnn')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(L1_NUM_FILTERS, kernel_size=(3, 3), activation='relu'), input_shape = train_X.shape[1:])\n",
    "    model.add(Conv2D(L2_NUM_FILTERS, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    for _ in range(NUM_LAYERS):\n",
    "        model.add(Dense(NUM_DIMS, activation='relu'))\n",
    "        model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(LR), metrics=['accuracy'])\n",
    "\n",
    "    return model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6uEnvE_8RF-3"
   },
   "outputs": [],
   "source": [
    "'''def create_cnn_model(train_x):\n",
    "    inputs = tf.keras.layers.Input(train_x.shape[1:])\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    conv = tf.keras.layers.Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu')(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2,2))(conv)\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(pool)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2,2))(conv)\n",
    "    \n",
    "    flatten = tf.keras.layers.Flatten()(pool)\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(flatten)\n",
    "    dense = tf.keras.layers.Dense(1000, activation='relu')(bn)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(dense)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(bn)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvsh_fosRF-5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''model = create_cnn_model(train_X)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=20)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cEvNqqJeRF-8"
   },
   "outputs": [],
   "source": [
    "'''test_loss, test_acc = model.evaluate(valid_X, valid_y, verbose=2)\n",
    "print('테스트 손실함수:', test_loss, '\\n테스트 정확도:', test_acc)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcIjWCcoRF-_"
   },
   "source": [
    "https://excelsior-cjh.tistory.com/152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8lDYw1oRF-_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "train = pd.read_csv('./data/cvision/train.csv')\n",
    "train_x = train.iloc[:,3:].values.reshape(-1,28,28)\n",
    "data = train_x[0]\n",
    "data.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZiVdnh4RF_C"
   },
   "outputs": [],
   "source": [
    "'''#상하좌우 이동\n",
    "samples = np.expand_dims(data, 0)\n",
    "\n",
    "#Generator 생성\n",
    "#range를 설정해 얼마나 움직일지 정해줌\n",
    "gen = ImageDataGenerator(width_shift_range=[-10,10])\n",
    "\n",
    "#figure 생성\n",
    "fig = plt.figure(figsize=(28,28))\n",
    "\n",
    "#it\n",
    "it = gen.flow(samples, batch_size=1)\n",
    "\n",
    "#9개 이미지 생성\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    \n",
    "    batch = it.next()\n",
    "    img = batch[0].astype('uint8')\n",
    "    \n",
    "    #plot raw pixel data\n",
    "    plt.imshow(img)\n",
    "    \n",
    "#show the figure\n",
    "plt.title('moving')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P75WrD3Zkzfb"
   },
   "outputs": [],
   "source": [
    "#ResNet - Residual Block\n",
    "\n",
    "'''\n",
    "from keras import layers\n",
    "\n",
    "def residual_block(x, filters_in, filters_out, k_size):\n",
    "    shortcut = x\n",
    "    x = layers.Conv2D(filters_in, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters_in, kernel_size=(k_size, k_size), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)    \n",
    "    \n",
    "    x = layers.Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    shortcut_channel = x.shape.as_list()[-1]\n",
    "    \n",
    "    if shortcut_channel != filters_out:\n",
    "        shortcut = layers.Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(shortcut)\n",
    "        \n",
    "    x = layers.Add()([x, shortcut])\n",
    "    return layers.LeakyReLU()(x)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
