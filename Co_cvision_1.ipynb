{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    " \n",
    " \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16828,
     "status": "ok",
     "timestamp": 1598155136621,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "4J-uM_NYZaui",
    "outputId": "edfdb337-fb39-4a12-94d8-400fea4f7313"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6394,
     "status": "ok",
     "timestamp": 1598155139625,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "9GCffZJIRF-O",
    "outputId": "b9d185b6-94e8-44e1-bd2c-70125bbd6f78"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('/content/drive/My Drive/cvision_1/train.csv')\n",
    "test = pd.read_csv('/content/drive/My Drive/cvision_1/test.csv')\n",
    "submission = pd.read_csv('/content/drive/My Drive/cvision_1/submission.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "      <th>letter</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>2044</td>\n",
       "      <td>6</td>\n",
       "      <td>V</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>2045</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>2046</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>2047</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2048</td>\n",
       "      <td>5</td>\n",
       "      <td>Z</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows × 787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  digit letter  0  1  2  3  4  5  6  ...  774  775  776  777  778  \\\n",
       "0        1      5      L  1  1  1  4  3  0  0  ...    2    1    0    1    2   \n",
       "1        2      0      B  0  4  0  0  4  1  1  ...    0    3    0    1    4   \n",
       "2        3      4      L  1  1  2  2  1  1  1  ...    3    3    3    0    2   \n",
       "3        4      9      D  1  2  0  2  0  4  0  ...    3    3    2    0    1   \n",
       "4        5      6      A  3  0  2  4  0  3  0  ...    4    4    3    2    1   \n",
       "...    ...    ...    ... .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...   \n",
       "2043  2044      6      V  2  4  3  4  2  4  4  ...    0    2    2    0    0   \n",
       "2044  2045      1      L  3  2  2  1  1  4  0  ...    2    3    4    2    1   \n",
       "2045  2046      9      A  4  0  4  0  2  4  4  ...    2    3    1    1    3   \n",
       "2046  2047      0      Z  2  3  3  0  3  0  4  ...    2    3    1    1    0   \n",
       "2047  2048      5      Z  4  2  2  1  3  0  0  ...    4    2    4    0    4   \n",
       "\n",
       "      779  780  781  782  783  \n",
       "0       4    4    4    3    4  \n",
       "1       1    4    2    1    2  \n",
       "2       0    3    0    2    2  \n",
       "3       4    0    0    1    1  \n",
       "4       3    4    3    1    2  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "2043    1    3    1    4    0  \n",
       "2044    2    3    4    1    1  \n",
       "2045    4    2    2    0    0  \n",
       "2046    4    1    4    3    1  \n",
       "2047    3    2    4    3    4  \n",
       "\n",
       "[2048 rows x 787 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#local 연결 전용\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('data/cvision/train.csv')\n",
    "test = pd.read_csv('data/cvision/test.csv')\n",
    "submission = pd.read_csv('data/cvision/submission.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5632,
     "status": "ok",
     "timestamp": 1598155139628,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "1zwkSGXiRF-S"
   },
   "outputs": [],
   "source": [
    "#X와 y 분리\n",
    "X = train.drop(['id','digit','letter'], axis=1).values\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "X = X/255.\n",
    "\n",
    "y = train['digit']\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5688,
     "status": "ok",
     "timestamp": 1598155140257,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "XrcmgXVBRF-V"
   },
   "outputs": [],
   "source": [
    "#train과 valid로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5350,
     "status": "ok",
     "timestamp": 1597982635917,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "gaxhVV6TRF-X",
    "outputId": "084bfeec-31ae-4b76-bad3-80c9c3797202",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#그림 시각화\n",
    "data = np.where(train_X >= 150/255., train_X, 0)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(train_X[i].reshape(28,28))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(data[i,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('number ' + str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec4UH2IrRF-c"
   },
   "outputs": [],
   "source": [
    "#숫자 있는 부분만 추출 (이걸로만 딥러닝해보니 성과 매우 안 좋음,\n",
    "#이 방식 적용할 거면 train, valid, test 모두 이런 형식으로 변형한 후 해야할 듯)\n",
    "\n",
    "#train_X = np.where(train_X >= 150/255., train_X, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1597801710042,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yqeCSgUDRF-f",
    "outputId": "deb594a8-d67a-48bc-e508-2a63e492992e"
   },
   "outputs": [],
   "source": [
    "#별 거 아님 kernel 예시\n",
    "from scipy.signal import correlate2d\n",
    "\n",
    "kernel = np.array(\n",
    "[\n",
    "    [0, -100, 0],\n",
    "    [0, 255, 0],\n",
    "    [0,-100,0]\n",
    "])\n",
    "plt.imshow(correlate2d(train_X[0].reshape(28,28), kernel, mode='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fd66eFzY4Mj3"
   },
   "outputs": [],
   "source": [
    "#model_4: 0.8284\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout, MaxPool2D,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.10, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=3, activation='relu', input_shape = train_X.shape[1:]))\n",
    "    model.add(Conv2D(32,kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(32,kernel_size=3, strides=2, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64,kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(64,kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(64,kernel_size=3, strides=2, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128,kernel_size=4, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRduAyEEAZ9F"
   },
   "outputs": [],
   "source": [
    "#model_5\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.10, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1597815169880,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "wDOUiuAiRF-p",
    "outputId": "7e701e81-6a8c-44d2-d13f-61ce1fd01abb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPbJftOsRF-s"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.975 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 571595,
     "status": "ok",
     "timestamp": 1597815744083,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "vJymm1W6RF-u",
    "outputId": "99976e7d-f05b-4bd4-ac9c-f63a9b111f30",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 120\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    "    #callbacks=[annealer],\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XF1MPFKyRF-w"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'/content/drive/My Drive/cvision_1/params_5.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'/content/drive/My Drive/cvision_1/model_5.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fjm7D-7jRF-z"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict(test_X)\n",
    "\n",
    "#submission 파일 생성\n",
    "for i in range(len(res)):\n",
    "    submission.digit[i] = int(res[i].argmax())\n",
    "submission.to_csv('/content/drive/My Drive/cvision_1/my_subm_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9V1sl_PZkAw"
   },
   "outputs": [],
   "source": [
    "#model_6\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.10, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2J4dDK7WcMjX"
   },
   "outputs": [],
   "source": [
    "#model_6\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.1, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1597828789914,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "bG2wRBFqSufq",
    "outputId": "f6766304-bc50-4e52-e751-289fafc95502"
   },
   "outputs": [],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q73HFCn7TfqS"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 690159,
     "status": "ok",
     "timestamp": 1597829479885,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "WjESPwIkTb3s",
    "outputId": "a89b9895-8416-4155-b03c-88500199cd8f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    "    #callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 688963,
     "status": "ok",
     "timestamp": 1597829480386,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "Ppp3z5-lXawC",
    "outputId": "29fc344b-1b47-4573-cc29-ed86cb5c3f91"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTtpmPijTjmk"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'/content/drive/My Drive/cvision_1/params_6.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'/content/drive/My Drive/cvision_1/model_6.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFSBLgQKTmM2"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('/content/drive/My Drive/cvision_1/my_subm_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qcD4AYCGQ9Np"
   },
   "outputs": [],
   "source": [
    "#model_8인데 데이터 부풀리기 x, 학습률 감소 x\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "'''\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.1, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "'''\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnWl2qzoURfw"
   },
   "outputs": [],
   "source": [
    "#model_8인데 데이터 부풀리기 x, 학습률 감소 x\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "'''\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.1, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "'''\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1597987417365,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "pO2aXT2wRIxn",
    "outputId": "844cd092-1f77-4b2f-ec82-a73fd3218df2"
   },
   "outputs": [],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 398869,
     "status": "error",
     "timestamp": 1597987815537,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "nS8BcL7CRNa7",
    "outputId": "5df7083b-3e1b-4666-b8bc-7dd13f53d38c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    "    #callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 604665,
     "status": "ok",
     "timestamp": 1597904733003,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "bseu0T8lRl3X",
    "outputId": "d803d7b7-14d2-42c9-8068-86e0d941c10c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2moYVE1jTLc"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'/content/drive/My Drive/cvision_1/params_9.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'/content/drive/My Drive/cvision_1/model_9.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12146,
     "status": "ok",
     "timestamp": 1597904941423,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "HDMU0LnTjiwo",
    "outputId": "7704ff38-1a02-49b2-80a3-f263ac8fcf35"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('/content/drive/My Drive/cvision_1/my_subm_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1598178326978,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "sTKcFoyikcjV"
   },
   "outputs": [],
   "source": [
    "#model_9-3 9-2에서 optimizer만 RMSprop로 바꿔봄\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), Adagrad(lr=0.01, epsilon=None, decay=0.0), adadelta, adam\n",
    "    model.compile(optimizer=RMSprop(lr=0.001, rho=0.95, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1598178327240,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "ySu34IFkkhNe",
    "outputId": "35e5e9cf-6ace-4666-d8f8-9a78010b08ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1130 (Conv2D)         (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1131 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_1132 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1133 (Conv2D)         (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_1134 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_1135 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1136 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_1137 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_1138 (Conv2D)         (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 133,648\n",
      "Trainable params: 133,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1598165198924,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "tPFielyJ5yMH"
   },
   "outputs": [],
   "source": [
    "'''#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** x)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19652,
     "status": "error",
     "timestamp": 1598178350080,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "cb892981-08ed-4ba9-af29-c492b265fb8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/230\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 2.3177 - accuracy: 0.1124 - val_loss: 2.3050 - val_accuracy: 0.1234\n",
      "Epoch 2/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.2986 - accuracy: 0.1224 - val_loss: 2.2818 - val_accuracy: 0.1364\n",
      "Epoch 3/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.2723 - accuracy: 0.1475 - val_loss: 2.2041 - val_accuracy: 0.2403\n",
      "Epoch 4/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.2194 - accuracy: 0.1698 - val_loss: 2.1775 - val_accuracy: 0.3084\n",
      "Epoch 5/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.1228 - accuracy: 0.2289 - val_loss: 1.9912 - val_accuracy: 0.3052\n",
      "Epoch 6/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.0449 - accuracy: 0.2600 - val_loss: 1.8695 - val_accuracy: 0.4383\n",
      "Epoch 7/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 2.0128 - accuracy: 0.2810 - val_loss: 1.8475 - val_accuracy: 0.4221\n",
      "Epoch 8/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.9614 - accuracy: 0.2945 - val_loss: 1.8433 - val_accuracy: 0.4156\n",
      "Epoch 9/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.9551 - accuracy: 0.2910 - val_loss: 1.9247 - val_accuracy: 0.4188\n",
      "Epoch 10/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.8949 - accuracy: 0.3296 - val_loss: 1.7544 - val_accuracy: 0.3766\n",
      "Epoch 11/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.8602 - accuracy: 0.3460 - val_loss: 1.5965 - val_accuracy: 0.4903\n",
      "Epoch 12/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.7710 - accuracy: 0.3700 - val_loss: 1.7271 - val_accuracy: 0.4481\n",
      "Epoch 13/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.7467 - accuracy: 0.3917 - val_loss: 1.8237 - val_accuracy: 0.3474\n",
      "Epoch 14/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.6872 - accuracy: 0.4227 - val_loss: 1.4903 - val_accuracy: 0.5325\n",
      "Epoch 15/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.6345 - accuracy: 0.4444 - val_loss: 1.5117 - val_accuracy: 0.5682\n",
      "Epoch 16/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.5943 - accuracy: 0.4496 - val_loss: 1.8145 - val_accuracy: 0.3766\n",
      "Epoch 17/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.5349 - accuracy: 0.4649 - val_loss: 1.5299 - val_accuracy: 0.5390\n",
      "Epoch 18/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.5205 - accuracy: 0.4778 - val_loss: 1.2588 - val_accuracy: 0.5974\n",
      "Epoch 19/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.4652 - accuracy: 0.5000 - val_loss: 1.2626 - val_accuracy: 0.6201\n",
      "Epoch 20/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.4198 - accuracy: 0.5105 - val_loss: 1.1165 - val_accuracy: 0.6656\n",
      "Epoch 21/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3907 - accuracy: 0.5181 - val_loss: 1.1452 - val_accuracy: 0.6234\n",
      "Epoch 22/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3534 - accuracy: 0.5322 - val_loss: 1.0149 - val_accuracy: 0.6916\n",
      "Epoch 23/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3238 - accuracy: 0.5632 - val_loss: 1.0673 - val_accuracy: 0.6948\n",
      "Epoch 24/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.3346 - accuracy: 0.5404 - val_loss: 0.8865 - val_accuracy: 0.7143\n",
      "Epoch 25/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2577 - accuracy: 0.5761 - val_loss: 1.0915 - val_accuracy: 0.6558\n",
      "Epoch 26/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2388 - accuracy: 0.5714 - val_loss: 0.9715 - val_accuracy: 0.7013\n",
      "Epoch 27/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.2483 - accuracy: 0.5755 - val_loss: 0.9189 - val_accuracy: 0.7110\n",
      "Epoch 28/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1921 - accuracy: 0.5925 - val_loss: 0.8702 - val_accuracy: 0.7403\n",
      "Epoch 29/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1864 - accuracy: 0.5954 - val_loss: 0.8952 - val_accuracy: 0.7175\n",
      "Epoch 30/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1314 - accuracy: 0.6241 - val_loss: 0.9693 - val_accuracy: 0.6948\n",
      "Epoch 31/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1450 - accuracy: 0.6025 - val_loss: 0.8525 - val_accuracy: 0.7240\n",
      "Epoch 32/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1039 - accuracy: 0.6183 - val_loss: 0.9708 - val_accuracy: 0.6721\n",
      "Epoch 33/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.1173 - accuracy: 0.6189 - val_loss: 0.8858 - val_accuracy: 0.7175\n",
      "Epoch 34/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0926 - accuracy: 0.6235 - val_loss: 0.8311 - val_accuracy: 0.7305\n",
      "Epoch 35/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0195 - accuracy: 0.6399 - val_loss: 0.7765 - val_accuracy: 0.7760\n",
      "Epoch 36/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9932 - accuracy: 0.6710 - val_loss: 0.7761 - val_accuracy: 0.7695\n",
      "Epoch 37/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.0452 - accuracy: 0.6475 - val_loss: 0.7581 - val_accuracy: 0.7760\n",
      "Epoch 38/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 1.0113 - accuracy: 0.6458 - val_loss: 0.7927 - val_accuracy: 0.7468\n",
      "Epoch 39/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9987 - accuracy: 0.6669 - val_loss: 0.7346 - val_accuracy: 0.7630\n",
      "Epoch 40/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 1.0015 - accuracy: 0.6622 - val_loss: 0.7314 - val_accuracy: 0.7727\n",
      "Epoch 41/230\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9653 - accuracy: 0.67 - 1s 11ms/step - loss: 0.9715 - accuracy: 0.6686 - val_loss: 0.6716 - val_accuracy: 0.7987\n",
      "Epoch 42/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9481 - accuracy: 0.6862 - val_loss: 0.7151 - val_accuracy: 0.7760\n",
      "Epoch 43/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9331 - accuracy: 0.6827 - val_loss: 0.8850 - val_accuracy: 0.6753\n",
      "Epoch 44/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9241 - accuracy: 0.6891 - val_loss: 0.6987 - val_accuracy: 0.7727\n",
      "Epoch 45/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8992 - accuracy: 0.6815 - val_loss: 0.6598 - val_accuracy: 0.7597\n",
      "Epoch 46/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8768 - accuracy: 0.7043 - val_loss: 0.8030 - val_accuracy: 0.7078\n",
      "Epoch 47/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9533 - accuracy: 0.6811 - val_loss: 0.6511 - val_accuracy: 0.7857\n",
      "Epoch 48/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8595 - accuracy: 0.6956 - val_loss: 0.5535 - val_accuracy: 0.8052\n",
      "Epoch 49/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.9123 - accuracy: 0.6885 - val_loss: 0.6170 - val_accuracy: 0.8019\n",
      "Epoch 50/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.8473 - accuracy: 0.7143 - val_loss: 0.5661 - val_accuracy: 0.8019\n",
      "Epoch 51/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8663 - accuracy: 0.6967 - val_loss: 0.5684 - val_accuracy: 0.8247\n",
      "Epoch 52/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8399 - accuracy: 0.7149 - val_loss: 0.6037 - val_accuracy: 0.8214\n",
      "Epoch 53/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8163 - accuracy: 0.7160 - val_loss: 0.6094 - val_accuracy: 0.7987\n",
      "Epoch 54/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8425 - accuracy: 0.7049 - val_loss: 0.5611 - val_accuracy: 0.7955\n",
      "Epoch 55/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8168 - accuracy: 0.7090 - val_loss: 0.6181 - val_accuracy: 0.7857\n",
      "Epoch 56/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7773 - accuracy: 0.7313 - val_loss: 0.6119 - val_accuracy: 0.7955\n",
      "Epoch 57/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.8248 - accuracy: 0.7242 - val_loss: 0.6019 - val_accuracy: 0.8149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7739 - accuracy: 0.7348 - val_loss: 0.6018 - val_accuracy: 0.7922\n",
      "Epoch 59/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7909 - accuracy: 0.7336 - val_loss: 0.6387 - val_accuracy: 0.7695\n",
      "Epoch 60/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7693 - accuracy: 0.7459 - val_loss: 0.6013 - val_accuracy: 0.8052\n",
      "Epoch 61/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7673 - accuracy: 0.7365 - val_loss: 0.5130 - val_accuracy: 0.8344\n",
      "Epoch 62/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7447 - accuracy: 0.7518 - val_loss: 0.6460 - val_accuracy: 0.8084\n",
      "Epoch 63/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7523 - accuracy: 0.7518 - val_loss: 0.5000 - val_accuracy: 0.8409\n",
      "Epoch 64/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7247 - accuracy: 0.7506 - val_loss: 0.6095 - val_accuracy: 0.7955\n",
      "Epoch 65/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7170 - accuracy: 0.7518 - val_loss: 0.5885 - val_accuracy: 0.7955\n",
      "Epoch 66/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7369 - accuracy: 0.7512 - val_loss: 0.6119 - val_accuracy: 0.7695\n",
      "Epoch 67/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7083 - accuracy: 0.7594 - val_loss: 0.4885 - val_accuracy: 0.8344\n",
      "Epoch 68/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7254 - accuracy: 0.7523 - val_loss: 0.4787 - val_accuracy: 0.8377\n",
      "Epoch 69/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.7286 - accuracy: 0.7576 - val_loss: 0.5186 - val_accuracy: 0.8377\n",
      "Epoch 70/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6793 - accuracy: 0.7646 - val_loss: 0.5703 - val_accuracy: 0.8149\n",
      "Epoch 71/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6988 - accuracy: 0.7605 - val_loss: 0.5299 - val_accuracy: 0.8149\n",
      "Epoch 72/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6631 - accuracy: 0.7758 - val_loss: 0.6274 - val_accuracy: 0.7825\n",
      "Epoch 73/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6650 - accuracy: 0.7641 - val_loss: 0.5105 - val_accuracy: 0.8247\n",
      "Epoch 74/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6457 - accuracy: 0.7769 - val_loss: 0.5771 - val_accuracy: 0.7987\n",
      "Epoch 75/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6977 - accuracy: 0.7594 - val_loss: 0.4793 - val_accuracy: 0.8279\n",
      "Epoch 76/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6522 - accuracy: 0.7763 - val_loss: 0.5858 - val_accuracy: 0.8149\n",
      "Epoch 77/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6635 - accuracy: 0.7641 - val_loss: 0.5228 - val_accuracy: 0.8117\n",
      "Epoch 78/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6658 - accuracy: 0.7799 - val_loss: 0.5041 - val_accuracy: 0.8442\n",
      "Epoch 79/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6588 - accuracy: 0.7875 - val_loss: 0.6038 - val_accuracy: 0.8019\n",
      "Epoch 80/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6423 - accuracy: 0.7810 - val_loss: 0.4605 - val_accuracy: 0.8506\n",
      "Epoch 81/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6312 - accuracy: 0.7828 - val_loss: 0.4990 - val_accuracy: 0.8506\n",
      "Epoch 82/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6483 - accuracy: 0.7769 - val_loss: 0.4782 - val_accuracy: 0.8474\n",
      "Epoch 83/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6581 - accuracy: 0.7676 - val_loss: 0.5275 - val_accuracy: 0.8312\n",
      "Epoch 84/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6654 - accuracy: 0.7746 - val_loss: 0.4795 - val_accuracy: 0.8377\n",
      "Epoch 85/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6280 - accuracy: 0.7922 - val_loss: 0.4741 - val_accuracy: 0.8571\n",
      "Epoch 86/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5763 - accuracy: 0.7992 - val_loss: 0.4233 - val_accuracy: 0.8669\n",
      "Epoch 87/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5899 - accuracy: 0.7992 - val_loss: 0.4360 - val_accuracy: 0.8734\n",
      "Epoch 88/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6025 - accuracy: 0.8050 - val_loss: 0.4724 - val_accuracy: 0.8377\n",
      "Epoch 89/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6041 - accuracy: 0.7998 - val_loss: 0.4556 - val_accuracy: 0.8506\n",
      "Epoch 90/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5971 - accuracy: 0.7992 - val_loss: 0.5826 - val_accuracy: 0.7955\n",
      "Epoch 91/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5931 - accuracy: 0.7945 - val_loss: 0.5675 - val_accuracy: 0.8247\n",
      "Epoch 92/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5908 - accuracy: 0.7875 - val_loss: 0.4997 - val_accuracy: 0.8442\n",
      "Epoch 93/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6145 - accuracy: 0.7922 - val_loss: 0.5062 - val_accuracy: 0.8149\n",
      "Epoch 94/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5989 - accuracy: 0.7951 - val_loss: 0.4525 - val_accuracy: 0.8506\n",
      "Epoch 95/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5821 - accuracy: 0.7998 - val_loss: 0.4634 - val_accuracy: 0.8474\n",
      "Epoch 96/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5883 - accuracy: 0.7986 - val_loss: 0.4475 - val_accuracy: 0.8279\n",
      "Epoch 97/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5777 - accuracy: 0.8056 - val_loss: 0.4844 - val_accuracy: 0.8312\n",
      "Epoch 98/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5971 - accuracy: 0.7927 - val_loss: 0.4933 - val_accuracy: 0.8312\n",
      "Epoch 99/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5654 - accuracy: 0.8074 - val_loss: 0.4268 - val_accuracy: 0.8604\n",
      "Epoch 100/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5543 - accuracy: 0.8056 - val_loss: 0.4702 - val_accuracy: 0.8279\n",
      "Epoch 101/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5759 - accuracy: 0.8050 - val_loss: 0.4207 - val_accuracy: 0.8539\n",
      "Epoch 102/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5605 - accuracy: 0.8033 - val_loss: 0.4433 - val_accuracy: 0.8539\n",
      "Epoch 103/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5445 - accuracy: 0.8203 - val_loss: 0.4404 - val_accuracy: 0.8442\n",
      "Epoch 104/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5624 - accuracy: 0.8103 - val_loss: 0.4165 - val_accuracy: 0.8604\n",
      "Epoch 105/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5452 - accuracy: 0.8144 - val_loss: 0.4152 - val_accuracy: 0.8604\n",
      "Epoch 106/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5701 - accuracy: 0.8074 - val_loss: 0.4217 - val_accuracy: 0.8636\n",
      "Epoch 107/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5230 - accuracy: 0.8296 - val_loss: 0.6655 - val_accuracy: 0.7922\n",
      "Epoch 108/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5247 - accuracy: 0.8208 - val_loss: 0.4336 - val_accuracy: 0.8571\n",
      "Epoch 109/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5333 - accuracy: 0.8185 - val_loss: 0.4924 - val_accuracy: 0.8279\n",
      "Epoch 110/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5110 - accuracy: 0.8273 - val_loss: 0.4556 - val_accuracy: 0.8409\n",
      "Epoch 111/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5310 - accuracy: 0.8091 - val_loss: 0.4325 - val_accuracy: 0.8506\n",
      "Epoch 112/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5458 - accuracy: 0.8132 - val_loss: 0.4134 - val_accuracy: 0.8571\n",
      "Epoch 113/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5328 - accuracy: 0.8191 - val_loss: 0.4153 - val_accuracy: 0.8571\n",
      "Epoch 114/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5189 - accuracy: 0.8197 - val_loss: 0.4529 - val_accuracy: 0.8377\n",
      "Epoch 115/230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5223 - accuracy: 0.8232 - val_loss: 0.4189 - val_accuracy: 0.8571\n",
      "Epoch 116/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5050 - accuracy: 0.8232 - val_loss: 0.3767 - val_accuracy: 0.8766\n",
      "Epoch 117/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.4927 - accuracy: 0.8244 - val_loss: 0.3828 - val_accuracy: 0.8636\n",
      "Epoch 118/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4960 - accuracy: 0.8191 - val_loss: 0.4566 - val_accuracy: 0.8442\n",
      "Epoch 119/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4953 - accuracy: 0.8367 - val_loss: 0.4092 - val_accuracy: 0.8701\n",
      "Epoch 120/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5260 - accuracy: 0.8109 - val_loss: 0.5021 - val_accuracy: 0.8344\n",
      "Epoch 121/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5075 - accuracy: 0.8255 - val_loss: 0.3741 - val_accuracy: 0.8799\n",
      "Epoch 122/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4718 - accuracy: 0.8349 - val_loss: 0.4149 - val_accuracy: 0.8636\n",
      "Epoch 123/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4893 - accuracy: 0.8285 - val_loss: 0.3955 - val_accuracy: 0.8734\n",
      "Epoch 124/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4911 - accuracy: 0.8308 - val_loss: 0.4521 - val_accuracy: 0.8506\n",
      "Epoch 125/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5092 - accuracy: 0.8308 - val_loss: 0.4509 - val_accuracy: 0.8506\n",
      "Epoch 126/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4643 - accuracy: 0.8396 - val_loss: 0.4137 - val_accuracy: 0.8506\n",
      "Epoch 127/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4980 - accuracy: 0.8314 - val_loss: 0.3651 - val_accuracy: 0.8734\n",
      "Epoch 128/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5201 - accuracy: 0.8273 - val_loss: 0.4537 - val_accuracy: 0.8571\n",
      "Epoch 129/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5283 - accuracy: 0.8162 - val_loss: 0.4360 - val_accuracy: 0.8442\n",
      "Epoch 130/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4743 - accuracy: 0.8402 - val_loss: 0.3794 - val_accuracy: 0.8506\n",
      "Epoch 131/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4995 - accuracy: 0.8296 - val_loss: 0.3629 - val_accuracy: 0.8734\n",
      "Epoch 132/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4887 - accuracy: 0.8214 - val_loss: 0.3670 - val_accuracy: 0.8734\n",
      "Epoch 133/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4913 - accuracy: 0.8337 - val_loss: 0.4355 - val_accuracy: 0.8377\n",
      "Epoch 134/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4631 - accuracy: 0.8331 - val_loss: 0.4081 - val_accuracy: 0.8409\n",
      "Epoch 135/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4617 - accuracy: 0.8448 - val_loss: 0.4126 - val_accuracy: 0.8571\n",
      "Epoch 136/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4250 - accuracy: 0.8571 - val_loss: 0.4091 - val_accuracy: 0.8506\n",
      "Epoch 137/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4703 - accuracy: 0.8355 - val_loss: 0.4157 - val_accuracy: 0.8442\n",
      "Epoch 138/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4312 - accuracy: 0.8536 - val_loss: 0.6881 - val_accuracy: 0.7792\n",
      "Epoch 139/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4571 - accuracy: 0.8443 - val_loss: 0.4421 - val_accuracy: 0.8539\n",
      "Epoch 140/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4565 - accuracy: 0.8431 - val_loss: 0.3743 - val_accuracy: 0.8734\n",
      "Epoch 141/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4972 - accuracy: 0.8267 - val_loss: 0.4497 - val_accuracy: 0.8571\n",
      "Epoch 142/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4625 - accuracy: 0.8349 - val_loss: 0.4282 - val_accuracy: 0.8571\n",
      "Epoch 143/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4723 - accuracy: 0.8337 - val_loss: 0.4391 - val_accuracy: 0.8377\n",
      "Epoch 144/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4243 - accuracy: 0.8548 - val_loss: 0.4713 - val_accuracy: 0.8442\n",
      "Epoch 145/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4324 - accuracy: 0.8536 - val_loss: 0.4646 - val_accuracy: 0.8474\n",
      "Epoch 146/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4689 - accuracy: 0.8367 - val_loss: 0.4995 - val_accuracy: 0.8214\n",
      "Epoch 147/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4394 - accuracy: 0.8413 - val_loss: 0.4976 - val_accuracy: 0.8312\n",
      "Epoch 148/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4387 - accuracy: 0.8407 - val_loss: 0.5034 - val_accuracy: 0.8312\n",
      "Epoch 149/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4473 - accuracy: 0.8390 - val_loss: 0.4072 - val_accuracy: 0.8442\n",
      "Epoch 150/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4536 - accuracy: 0.8443 - val_loss: 0.5050 - val_accuracy: 0.8182\n",
      "Epoch 151/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4197 - accuracy: 0.8607 - val_loss: 0.4946 - val_accuracy: 0.8409\n",
      "Epoch 152/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4526 - accuracy: 0.8507 - val_loss: 0.4987 - val_accuracy: 0.8149\n",
      "Epoch 153/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4534 - accuracy: 0.8460 - val_loss: 0.4463 - val_accuracy: 0.8506\n",
      "Epoch 154/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3870 - accuracy: 0.8706 - val_loss: 0.4379 - val_accuracy: 0.8539\n",
      "Epoch 155/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3913 - accuracy: 0.8642 - val_loss: 0.4166 - val_accuracy: 0.8377\n",
      "Epoch 156/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4195 - accuracy: 0.8548 - val_loss: 0.4562 - val_accuracy: 0.8442\n",
      "Epoch 157/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4318 - accuracy: 0.8443 - val_loss: 0.4946 - val_accuracy: 0.8214\n",
      "Epoch 158/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4403 - accuracy: 0.8448 - val_loss: 0.4147 - val_accuracy: 0.8539\n",
      "Epoch 159/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4061 - accuracy: 0.8612 - val_loss: 0.4974 - val_accuracy: 0.8247\n",
      "Epoch 160/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4252 - accuracy: 0.8560 - val_loss: 0.4254 - val_accuracy: 0.8636\n",
      "Epoch 161/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4234 - accuracy: 0.8495 - val_loss: 0.4465 - val_accuracy: 0.8474\n",
      "Epoch 162/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4072 - accuracy: 0.8560 - val_loss: 0.4465 - val_accuracy: 0.8279\n",
      "Epoch 163/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.4340 - accuracy: 0.8583 - val_loss: 0.4420 - val_accuracy: 0.8474\n",
      "Epoch 164/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4064 - accuracy: 0.8560 - val_loss: 0.5297 - val_accuracy: 0.8279\n",
      "Epoch 165/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4226 - accuracy: 0.8648 - val_loss: 0.4863 - val_accuracy: 0.8442\n",
      "Epoch 166/230\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.4153 - accuracy: 0.8560 - val_loss: 0.5444 - val_accuracy: 0.8052\n",
      "Epoch 167/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4555 - accuracy: 0.8448 - val_loss: 0.4393 - val_accuracy: 0.8344\n",
      "Epoch 168/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4088 - accuracy: 0.8595 - val_loss: 0.4376 - val_accuracy: 0.8539\n",
      "Epoch 169/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4198 - accuracy: 0.8560 - val_loss: 0.3890 - val_accuracy: 0.8669\n",
      "Epoch 170/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3958 - accuracy: 0.8683 - val_loss: 0.4161 - val_accuracy: 0.8636\n",
      "Epoch 171/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4086 - accuracy: 0.8548 - val_loss: 0.4671 - val_accuracy: 0.8377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4291 - accuracy: 0.8560 - val_loss: 0.4311 - val_accuracy: 0.8474\n",
      "Epoch 173/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3975 - accuracy: 0.8576 - val_loss: 0.4103 - val_accuracy: 0.8636\n",
      "Epoch 174/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4285 - accuracy: 0.8402 - val_loss: 0.4310 - val_accuracy: 0.8377\n",
      "Epoch 175/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3950 - accuracy: 0.8636 - val_loss: 0.4220 - val_accuracy: 0.8474\n",
      "Epoch 176/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3994 - accuracy: 0.8648 - val_loss: 0.4846 - val_accuracy: 0.8474\n",
      "Epoch 177/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3839 - accuracy: 0.8694 - val_loss: 0.4736 - val_accuracy: 0.8442\n",
      "Epoch 178/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4061 - accuracy: 0.8519 - val_loss: 0.5389 - val_accuracy: 0.8247\n",
      "Epoch 179/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3863 - accuracy: 0.8612 - val_loss: 0.5457 - val_accuracy: 0.8214\n",
      "Epoch 180/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3981 - accuracy: 0.8583 - val_loss: 0.4691 - val_accuracy: 0.8344\n",
      "Epoch 181/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3810 - accuracy: 0.8694 - val_loss: 0.4457 - val_accuracy: 0.8279\n",
      "Epoch 182/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3850 - accuracy: 0.8677 - val_loss: 0.4385 - val_accuracy: 0.8571\n",
      "Epoch 183/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4253 - accuracy: 0.8554 - val_loss: 0.5025 - val_accuracy: 0.8214\n",
      "Epoch 184/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3706 - accuracy: 0.8665 - val_loss: 0.3846 - val_accuracy: 0.8701\n",
      "Epoch 185/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3790 - accuracy: 0.8741 - val_loss: 0.4790 - val_accuracy: 0.8344\n",
      "Epoch 186/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3681 - accuracy: 0.8794 - val_loss: 0.4729 - val_accuracy: 0.8474\n",
      "Epoch 187/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3876 - accuracy: 0.8542 - val_loss: 0.4467 - val_accuracy: 0.8344\n",
      "Epoch 188/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3742 - accuracy: 0.8800 - val_loss: 0.3792 - val_accuracy: 0.8474\n",
      "Epoch 189/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3827 - accuracy: 0.8648 - val_loss: 0.4290 - val_accuracy: 0.8539\n",
      "Epoch 190/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3916 - accuracy: 0.8683 - val_loss: 0.4215 - val_accuracy: 0.8799\n",
      "Epoch 191/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3487 - accuracy: 0.8882 - val_loss: 0.4928 - val_accuracy: 0.8506\n",
      "Epoch 192/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3745 - accuracy: 0.8724 - val_loss: 0.5175 - val_accuracy: 0.8474\n",
      "Epoch 193/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3748 - accuracy: 0.8718 - val_loss: 0.5581 - val_accuracy: 0.8312\n",
      "Epoch 194/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3782 - accuracy: 0.8735 - val_loss: 0.4059 - val_accuracy: 0.8669\n",
      "Epoch 195/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3545 - accuracy: 0.8712 - val_loss: 0.3541 - val_accuracy: 0.8734\n",
      "Epoch 196/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3611 - accuracy: 0.8724 - val_loss: 0.3838 - val_accuracy: 0.8734\n",
      "Epoch 197/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3749 - accuracy: 0.8712 - val_loss: 0.6359 - val_accuracy: 0.8084\n",
      "Epoch 198/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3695 - accuracy: 0.8724 - val_loss: 0.4578 - val_accuracy: 0.8442\n",
      "Epoch 199/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3629 - accuracy: 0.8724 - val_loss: 0.5002 - val_accuracy: 0.8442\n",
      "Epoch 200/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3633 - accuracy: 0.8706 - val_loss: 0.4444 - val_accuracy: 0.8571\n",
      "Epoch 201/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3782 - accuracy: 0.8659 - val_loss: 0.4254 - val_accuracy: 0.8571\n",
      "Epoch 202/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3767 - accuracy: 0.8741 - val_loss: 0.4837 - val_accuracy: 0.8604\n",
      "Epoch 203/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3518 - accuracy: 0.8788 - val_loss: 0.4573 - val_accuracy: 0.8734\n",
      "Epoch 204/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3766 - accuracy: 0.8706 - val_loss: 0.4982 - val_accuracy: 0.8247\n",
      "Epoch 205/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3636 - accuracy: 0.8765 - val_loss: 0.3941 - val_accuracy: 0.8701\n",
      "Epoch 206/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3497 - accuracy: 0.8811 - val_loss: 0.4522 - val_accuracy: 0.8506\n",
      "Epoch 207/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3548 - accuracy: 0.8811 - val_loss: 0.5362 - val_accuracy: 0.8312\n",
      "Epoch 208/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3487 - accuracy: 0.8770 - val_loss: 0.4145 - val_accuracy: 0.8539\n",
      "Epoch 209/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3634 - accuracy: 0.8677 - val_loss: 0.4408 - val_accuracy: 0.8539\n",
      "Epoch 210/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3459 - accuracy: 0.8770 - val_loss: 0.4904 - val_accuracy: 0.8506\n",
      "Epoch 211/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3691 - accuracy: 0.8765 - val_loss: 0.4206 - val_accuracy: 0.8669\n",
      "Epoch 212/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3908 - accuracy: 0.8653 - val_loss: 0.4671 - val_accuracy: 0.8539\n",
      "Epoch 213/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3358 - accuracy: 0.8905 - val_loss: 0.4185 - val_accuracy: 0.8571\n",
      "Epoch 214/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3511 - accuracy: 0.8776 - val_loss: 0.4852 - val_accuracy: 0.8279\n",
      "Epoch 215/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3556 - accuracy: 0.8847 - val_loss: 0.3874 - val_accuracy: 0.8539\n",
      "Epoch 216/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3498 - accuracy: 0.8829 - val_loss: 0.5400 - val_accuracy: 0.8084\n",
      "Epoch 217/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3556 - accuracy: 0.8642 - val_loss: 0.4585 - val_accuracy: 0.8442\n",
      "Epoch 218/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3088 - accuracy: 0.8882 - val_loss: 0.4359 - val_accuracy: 0.8571\n",
      "Epoch 219/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3340 - accuracy: 0.8800 - val_loss: 0.4459 - val_accuracy: 0.8377\n",
      "Epoch 220/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3729 - accuracy: 0.8747 - val_loss: 0.4500 - val_accuracy: 0.8539\n",
      "Epoch 221/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3403 - accuracy: 0.8794 - val_loss: 0.5028 - val_accuracy: 0.8474\n",
      "Epoch 222/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3498 - accuracy: 0.8788 - val_loss: 0.4942 - val_accuracy: 0.8312\n",
      "Epoch 223/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3498 - accuracy: 0.8776 - val_loss: 0.3842 - val_accuracy: 0.8604\n",
      "Epoch 224/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3797 - accuracy: 0.8712 - val_loss: 0.5189 - val_accuracy: 0.8247\n",
      "Epoch 225/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3441 - accuracy: 0.8841 - val_loss: 0.4179 - val_accuracy: 0.8377\n",
      "Epoch 226/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3360 - accuracy: 0.8829 - val_loss: 0.4308 - val_accuracy: 0.8442\n",
      "Epoch 227/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3666 - accuracy: 0.8712 - val_loss: 0.4503 - val_accuracy: 0.8247\n",
      "Epoch 228/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3213 - accuracy: 0.8870 - val_loss: 0.3917 - val_accuracy: 0.8506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3175 - accuracy: 0.8841 - val_loss: 0.4069 - val_accuracy: 0.8701\n",
      "Epoch 230/230\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3304 - accuracy: 0.8841 - val_loss: 0.4257 - val_accuracy: 0.8701\n",
      "CNN: Epochs=230, Train accuracy=0.89052, Validation accuracy=0.87987\n"
     ]
    }
   ],
   "source": [
    "epochs = 230\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1#, callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2603262,
     "status": "ok",
     "timestamp": 1598167802346,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "9bcd067b-5514-491c-8c63-db77d4fc6967"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#맥스풀링 마지막에만 하고 FC두번 거쳐서 하니 느리지만 꾸준히 정확도 증가 80에서 거의 멈춤 - 해결 방안?\n",
    "#epoch 180정도로 한 결과 = model_9\n",
    "#model_9는 0.89166, 0.87805\n",
    "#model_9-2를 eopch 230, relu 대신 leaky relu\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EQCvPGZks9v"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'data/cvision/params_9.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'data/cvision/model_9.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12146,
     "status": "ok",
     "timestamp": 1597904941423,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "Y-8nb5jokyny",
    "outputId": "7704ff38-1a02-49b2-80a3-f263ac8fcf35"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('data/cvision/my_subm_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1598178326978,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "sTKcFoyikcjV"
   },
   "outputs": [],
   "source": [
    "#model_9-4\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop, Adagrad\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.10, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    #층을 2,3,4,6,3장처럼 더 쌓아보기 (resnet처럼)\n",
    "    model.add(Conv2D(8, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Conv2D(8, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides=2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides=2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(52, kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), adadelta, adam\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1598178327240,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "ySu34IFkkhNe",
    "outputId": "35e5e9cf-6ace-4666-d8f8-9a78010b08ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1230 (Conv2D)         (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_662 (LeakyReLU)  (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1231 (Conv2D)         (None, 28, 28, 8)         584       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_663 (LeakyReLU)  (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1232 (Conv2D)         (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_664 (LeakyReLU)  (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1233 (Conv2D)         (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_665 (LeakyReLU)  (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1234 (Conv2D)         (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_666 (LeakyReLU)  (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1235 (Conv2D)         (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_667 (LeakyReLU)  (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1236 (Conv2D)         (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_668 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1237 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_669 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_34  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 52)                3380      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_670 (LeakyReLU)  (None, 52)                0         \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 52)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                530       \n",
      "=================================================================\n",
      "Total params: 77,374\n",
      "Trainable params: 77,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19652,
     "status": "error",
     "timestamp": 1598178350080,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "cb892981-08ed-4ba9-af29-c492b265fb8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 3.2711 - accuracy: 0.0928 - val_loss: 2.3076 - val_accuracy: 0.1234\n",
      "Epoch 2/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.3704 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1006\n",
      "Epoch 3/1500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 2.3351 - accuracy: 0.0790 - val_loss: 2.3041 - val_accuracy: 0.0909\n",
      "Epoch 4/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.3142 - accuracy: 0.0888 - val_loss: 2.3054 - val_accuracy: 0.0617\n",
      "Epoch 5/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.3100 - accuracy: 0.1055 - val_loss: 2.3051 - val_accuracy: 0.0617\n",
      "Epoch 6/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.3014 - accuracy: 0.1107 - val_loss: 2.3049 - val_accuracy: 0.0617\n",
      "Epoch 7/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.3048 - accuracy: 0.0990 - val_loss: 2.3044 - val_accuracy: 0.0649\n",
      "Epoch 8/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.3053 - accuracy: 0.0888 - val_loss: 2.3036 - val_accuracy: 0.0942\n",
      "Epoch 9/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.3006 - accuracy: 0.1042 - val_loss: 2.3028 - val_accuracy: 0.1006\n",
      "Epoch 10/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2989 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1006\n",
      "Epoch 11/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.3012 - accuracy: 0.1107 - val_loss: 2.3019 - val_accuracy: 0.1006\n",
      "Epoch 12/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.3016 - accuracy: 0.1034 - val_loss: 2.3017 - val_accuracy: 0.1006\n",
      "Epoch 13/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.3004 - accuracy: 0.1116 - val_loss: 2.3016 - val_accuracy: 0.1006\n",
      "Epoch 14/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2992 - accuracy: 0.1050 - val_loss: 2.3018 - val_accuracy: 0.1006\n",
      "Epoch 15/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2996 - accuracy: 0.1107 - val_loss: 2.3019 - val_accuracy: 0.1006\n",
      "Epoch 16/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2997 - accuracy: 0.1181 - val_loss: 2.3021 - val_accuracy: 0.1006\n",
      "Epoch 17/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.3011 - accuracy: 0.1055 - val_loss: 2.3022 - val_accuracy: 0.0942\n",
      "Epoch 18/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.3003 - accuracy: 0.1116 - val_loss: 2.3022 - val_accuracy: 0.0942\n",
      "Epoch 19/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.3000 - accuracy: 0.1081 - val_loss: 2.3021 - val_accuracy: 0.0942\n",
      "Epoch 20/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.0974\n",
      "Epoch 21/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.3004 - accuracy: 0.1165 - val_loss: 2.3019 - val_accuracy: 0.1006\n",
      "Epoch 22/1500\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2.2988 - accuracy: 0.1238 - val_loss: 2.3018 - val_accuracy: 0.0974\n",
      "Epoch 23/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2994 - accuracy: 0.1224 - val_loss: 2.3017 - val_accuracy: 0.1006\n",
      "Epoch 24/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2976 - accuracy: 0.1156 - val_loss: 2.3016 - val_accuracy: 0.1006\n",
      "Epoch 25/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2993 - accuracy: 0.1181 - val_loss: 2.3016 - val_accuracy: 0.1006\n",
      "Epoch 26/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2988 - accuracy: 0.1197 - val_loss: 2.3017 - val_accuracy: 0.1006\n",
      "Epoch 27/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2954 - accuracy: 0.1140 - val_loss: 2.3017 - val_accuracy: 0.1006\n",
      "Epoch 28/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2996 - accuracy: 0.1159 - val_loss: 2.3016 - val_accuracy: 0.1006\n",
      "Epoch 29/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2959 - accuracy: 0.1156 - val_loss: 2.3015 - val_accuracy: 0.1006\n",
      "Epoch 30/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2967 - accuracy: 0.1116 - val_loss: 2.3014 - val_accuracy: 0.1006\n",
      "Epoch 31/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2982 - accuracy: 0.1191 - val_loss: 2.3011 - val_accuracy: 0.1006\n",
      "Epoch 32/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.3035 - accuracy: 0.1091 - val_loss: 2.3008 - val_accuracy: 0.1006\n",
      "Epoch 33/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2993 - accuracy: 0.1221 - val_loss: 2.3008 - val_accuracy: 0.1006\n",
      "Epoch 34/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2992 - accuracy: 0.1055 - val_loss: 2.3007 - val_accuracy: 0.1006\n",
      "Epoch 35/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2953 - accuracy: 0.1148 - val_loss: 2.3008 - val_accuracy: 0.1104\n",
      "Epoch 36/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2975 - accuracy: 0.1107 - val_loss: 2.3008 - val_accuracy: 0.1364\n",
      "Epoch 37/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2984 - accuracy: 0.1099 - val_loss: 2.3008 - val_accuracy: 0.1234\n",
      "Epoch 38/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2959 - accuracy: 0.1156 - val_loss: 2.3008 - val_accuracy: 0.1039\n",
      "Epoch 39/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2993 - accuracy: 0.1120 - val_loss: 2.3008 - val_accuracy: 0.1039\n",
      "Epoch 40/1500\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2.2956 - accuracy: 0.1189 - val_loss: 2.3009 - val_accuracy: 0.1039\n",
      "Epoch 41/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2984 - accuracy: 0.1197 - val_loss: 2.3009 - val_accuracy: 0.1039\n",
      "Epoch 42/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2965 - accuracy: 0.1303 - val_loss: 2.3008 - val_accuracy: 0.1104\n",
      "Epoch 43/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2925 - accuracy: 0.1270 - val_loss: 2.3005 - val_accuracy: 0.1104\n",
      "Epoch 44/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2921 - accuracy: 0.1075 - val_loss: 2.3002 - val_accuracy: 0.1364\n",
      "Epoch 45/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2958 - accuracy: 0.1217 - val_loss: 2.3002 - val_accuracy: 0.1266\n",
      "Epoch 46/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2939 - accuracy: 0.1322 - val_loss: 2.3004 - val_accuracy: 0.1169\n",
      "Epoch 47/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2962 - accuracy: 0.1026 - val_loss: 2.3006 - val_accuracy: 0.1039\n",
      "Epoch 48/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2905 - accuracy: 0.1368 - val_loss: 2.3005 - val_accuracy: 0.1039\n",
      "Epoch 49/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2935 - accuracy: 0.1246 - val_loss: 2.3002 - val_accuracy: 0.1039\n",
      "Epoch 50/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2950 - accuracy: 0.1124 - val_loss: 2.2996 - val_accuracy: 0.1039\n",
      "Epoch 51/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2909 - accuracy: 0.1124 - val_loss: 2.2991 - val_accuracy: 0.1039\n",
      "Epoch 52/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2924 - accuracy: 0.1165 - val_loss: 2.2989 - val_accuracy: 0.1039\n",
      "Epoch 53/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2934 - accuracy: 0.1140 - val_loss: 2.2989 - val_accuracy: 0.1039\n",
      "Epoch 54/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2852 - accuracy: 0.1254 - val_loss: 2.2990 - val_accuracy: 0.1039\n",
      "Epoch 55/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2902 - accuracy: 0.1257 - val_loss: 2.2988 - val_accuracy: 0.1071\n",
      "Epoch 56/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2906 - accuracy: 0.1279 - val_loss: 2.2982 - val_accuracy: 0.1071\n",
      "Epoch 57/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2844 - accuracy: 0.1384 - val_loss: 2.2975 - val_accuracy: 0.1039\n",
      "Epoch 58/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2869 - accuracy: 0.1238 - val_loss: 2.2971 - val_accuracy: 0.1071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2852 - accuracy: 0.1164 - val_loss: 2.2958 - val_accuracy: 0.1039\n",
      "Epoch 60/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2822 - accuracy: 0.1213 - val_loss: 2.2948 - val_accuracy: 0.1039\n",
      "Epoch 61/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2874 - accuracy: 0.1279 - val_loss: 2.2939 - val_accuracy: 0.1039\n",
      "Epoch 62/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2830 - accuracy: 0.1319 - val_loss: 2.2932 - val_accuracy: 0.1071\n",
      "Epoch 63/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2777 - accuracy: 0.1367 - val_loss: 2.2918 - val_accuracy: 0.1071\n",
      "Epoch 64/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2913 - accuracy: 0.1181 - val_loss: 2.2898 - val_accuracy: 0.1039\n",
      "Epoch 65/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2811 - accuracy: 0.1336 - val_loss: 2.2906 - val_accuracy: 0.1039\n",
      "Epoch 66/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2746 - accuracy: 0.1309 - val_loss: 2.2905 - val_accuracy: 0.1039\n",
      "Epoch 67/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2710 - accuracy: 0.1354 - val_loss: 2.2885 - val_accuracy: 0.1039\n",
      "Epoch 68/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2707 - accuracy: 0.1417 - val_loss: 2.2849 - val_accuracy: 0.1299\n",
      "Epoch 69/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2748 - accuracy: 0.1319 - val_loss: 2.2823 - val_accuracy: 0.1331\n",
      "Epoch 70/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2629 - accuracy: 0.1564 - val_loss: 2.2792 - val_accuracy: 0.1299\n",
      "Epoch 71/1500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2634 - accuracy: 0.1419 - val_loss: 2.2780 - val_accuracy: 0.1331\n",
      "Epoch 72/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2679 - accuracy: 0.1368 - val_loss: 2.2767 - val_accuracy: 0.1299\n",
      "Epoch 73/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2629 - accuracy: 0.1393 - val_loss: 2.2752 - val_accuracy: 0.1461\n",
      "Epoch 74/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2637 - accuracy: 0.1393 - val_loss: 2.2830 - val_accuracy: 0.1136\n",
      "Epoch 75/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2704 - accuracy: 0.1302 - val_loss: 2.2805 - val_accuracy: 0.1136\n",
      "Epoch 76/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2559 - accuracy: 0.1474 - val_loss: 2.2759 - val_accuracy: 0.1104\n",
      "Epoch 77/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2678 - accuracy: 0.1270 - val_loss: 2.2760 - val_accuracy: 0.1331\n",
      "Epoch 78/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2428 - accuracy: 0.1409 - val_loss: 2.2752 - val_accuracy: 0.1299\n",
      "Epoch 79/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2478 - accuracy: 0.1458 - val_loss: 2.2737 - val_accuracy: 0.1299\n",
      "Epoch 80/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2423 - accuracy: 0.1588 - val_loss: 2.2793 - val_accuracy: 0.1136\n",
      "Epoch 81/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2334 - accuracy: 0.1498 - val_loss: 2.2722 - val_accuracy: 0.1331\n",
      "Epoch 82/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.2614 - accuracy: 0.1474 - val_loss: 2.2753 - val_accuracy: 0.1656\n",
      "Epoch 83/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2466 - accuracy: 0.1433 - val_loss: 2.2778 - val_accuracy: 0.1623\n",
      "Epoch 84/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2356 - accuracy: 0.1531 - val_loss: 2.2709 - val_accuracy: 0.1526\n",
      "Epoch 85/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.2309 - accuracy: 0.1621 - val_loss: 2.2841 - val_accuracy: 0.1364\n",
      "Epoch 86/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2265 - accuracy: 0.1539 - val_loss: 2.2831 - val_accuracy: 0.1494\n",
      "Epoch 87/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2260 - accuracy: 0.1425 - val_loss: 2.2777 - val_accuracy: 0.1461\n",
      "Epoch 88/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.2256 - accuracy: 0.1523 - val_loss: 2.2826 - val_accuracy: 0.1429\n",
      "Epoch 89/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2238 - accuracy: 0.1474 - val_loss: 2.2822 - val_accuracy: 0.1656\n",
      "Epoch 90/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.2036 - accuracy: 0.1865 - val_loss: 2.2774 - val_accuracy: 0.1591\n",
      "Epoch 91/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.2215 - accuracy: 0.1547 - val_loss: 2.2799 - val_accuracy: 0.1526\n",
      "Epoch 92/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.2060 - accuracy: 0.1588 - val_loss: 2.2839 - val_accuracy: 0.1461\n",
      "Epoch 93/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1910 - accuracy: 0.1897 - val_loss: 2.2754 - val_accuracy: 0.1299\n",
      "Epoch 94/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1922 - accuracy: 0.1767 - val_loss: 2.2726 - val_accuracy: 0.1234\n",
      "Epoch 95/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.2051 - accuracy: 0.1759 - val_loss: 2.2854 - val_accuracy: 0.1201\n",
      "Epoch 96/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1841 - accuracy: 0.1775 - val_loss: 2.2683 - val_accuracy: 0.1494\n",
      "Epoch 97/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1871 - accuracy: 0.1735 - val_loss: 2.2903 - val_accuracy: 0.1364\n",
      "Epoch 98/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1860 - accuracy: 0.1842 - val_loss: 2.2591 - val_accuracy: 0.1526\n",
      "Epoch 99/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1827 - accuracy: 0.1743 - val_loss: 2.2770 - val_accuracy: 0.1461\n",
      "Epoch 100/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1914 - accuracy: 0.1686 - val_loss: 2.2597 - val_accuracy: 0.1558\n",
      "Epoch 101/1500\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 2.1701 - accuracy: 0.1954 - val_loss: 2.2809 - val_accuracy: 0.1461\n",
      "Epoch 102/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1669 - accuracy: 0.1914 - val_loss: 2.2373 - val_accuracy: 0.1558\n",
      "Epoch 103/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.1535 - accuracy: 0.1895 - val_loss: 2.2483 - val_accuracy: 0.1461\n",
      "Epoch 104/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1615 - accuracy: 0.1725 - val_loss: 2.2500 - val_accuracy: 0.1623\n",
      "Epoch 105/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.1675 - accuracy: 0.1836 - val_loss: 2.2385 - val_accuracy: 0.1591\n",
      "Epoch 106/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1577 - accuracy: 0.2090 - val_loss: 2.2547 - val_accuracy: 0.1688\n",
      "Epoch 107/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1348 - accuracy: 0.2064 - val_loss: 2.2050 - val_accuracy: 0.1916\n",
      "Epoch 108/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1290 - accuracy: 0.1881 - val_loss: 2.2709 - val_accuracy: 0.1656\n",
      "Epoch 109/1500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.1275 - accuracy: 0.2052 - val_loss: 2.1513 - val_accuracy: 0.2208\n",
      "Epoch 110/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1488 - accuracy: 0.1971 - val_loss: 2.2555 - val_accuracy: 0.1494\n",
      "Epoch 111/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.1347 - accuracy: 0.2052 - val_loss: 2.1703 - val_accuracy: 0.2013\n",
      "Epoch 112/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1217 - accuracy: 0.2125 - val_loss: 2.1880 - val_accuracy: 0.1883\n",
      "Epoch 113/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1290 - accuracy: 0.2248 - val_loss: 2.1686 - val_accuracy: 0.2110\n",
      "Epoch 114/1500\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 2.1143 - accuracy: 0.2233 - val_loss: 2.1426 - val_accuracy: 0.2273\n",
      "Epoch 115/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.1041 - accuracy: 0.2239 - val_loss: 2.1684 - val_accuracy: 0.2143\n",
      "Epoch 116/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1183 - accuracy: 0.2038 - val_loss: 2.1238 - val_accuracy: 0.2532\n",
      "Epoch 117/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.1146 - accuracy: 0.2155 - val_loss: 2.1969 - val_accuracy: 0.1948\n",
      "Epoch 118/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.1124 - accuracy: 0.2280 - val_loss: 2.1364 - val_accuracy: 0.2338\n",
      "Epoch 119/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.0973 - accuracy: 0.2239 - val_loss: 2.1695 - val_accuracy: 0.2013\n",
      "Epoch 120/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0904 - accuracy: 0.2321 - val_loss: 2.1027 - val_accuracy: 0.2565\n",
      "Epoch 121/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.1087 - accuracy: 0.2288 - val_loss: 2.1051 - val_accuracy: 0.2532\n",
      "Epoch 122/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.0652 - accuracy: 0.2409 - val_loss: 2.0846 - val_accuracy: 0.2630\n",
      "Epoch 123/1500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 2.0983 - accuracy: 0.2378 - val_loss: 2.1229 - val_accuracy: 0.2370\n",
      "Epoch 124/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0996 - accuracy: 0.2028 - val_loss: 2.1189 - val_accuracy: 0.2565\n",
      "Epoch 125/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.0832 - accuracy: 0.2492 - val_loss: 2.0924 - val_accuracy: 0.2825\n",
      "Epoch 126/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.0408 - accuracy: 0.2565 - val_loss: 2.1013 - val_accuracy: 0.2500\n",
      "Epoch 127/1500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.0791 - accuracy: 0.2467 - val_loss: 2.0545 - val_accuracy: 0.2597\n",
      "Epoch 128/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.0858 - accuracy: 0.2288 - val_loss: 2.0673 - val_accuracy: 0.2792\n",
      "Epoch 129/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.0508 - accuracy: 0.2207 - val_loss: 2.0845 - val_accuracy: 0.2760\n",
      "Epoch 130/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.0668 - accuracy: 0.2296 - val_loss: 2.0264 - val_accuracy: 0.3117\n",
      "Epoch 131/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.0644 - accuracy: 0.2353 - val_loss: 2.1034 - val_accuracy: 0.2468\n",
      "Epoch 132/1500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.0464 - accuracy: 0.2451 - val_loss: 2.0205 - val_accuracy: 0.2890\n",
      "Epoch 133/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.0643 - accuracy: 0.2313 - val_loss: 2.0234 - val_accuracy: 0.2955\n",
      "Epoch 134/1500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.0587 - accuracy: 0.2280 - val_loss: 1.9939 - val_accuracy: 0.3214\n",
      "Epoch 135/1500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.0735 - accuracy: 0.2259 - val_loss: 2.0794 - val_accuracy: 0.2500\n",
      "Epoch 136/1500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 2.0611 - accuracy: 0.2427 - val_loss: 1.9993 - val_accuracy: 0.3409\n",
      "Epoch 137/1500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.0689 - accuracy: 0.2345 - val_loss: 2.0968 - val_accuracy: 0.2597\n",
      "Epoch 138/1500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0755 - accuracy: 0.2206"
     ]
    }
   ],
   "source": [
    "epochs = 1500\n",
    "batch_size = 512\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1#, callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2603262,
     "status": "ok",
     "timestamp": 1598167802346,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "9bcd067b-5514-491c-8c63-db77d4fc6967"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####relu 대신 leaky relu 써보자########\n",
    "#####후에 early stopping도 추가 ########\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1598178326978,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "sTKcFoyikcjV"
   },
   "outputs": [],
   "source": [
    "#model_10: ResNet - residual block 구성\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D\n",
    ")\n",
    "\n",
    "def conv1(x):\n",
    "    x = Conv2D(64, (7,7), strides=(2,2), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv2(x, filter_in=64, filter_out=256):\n",
    "    x = MaxPooling2D((3,3), 2)(x)\n",
    "    \n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(1):#3):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "        \n",
    "    return x\n",
    "\n",
    "def conv3(x, filter_in=128, filter_out=512):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(2):#4):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv4(x, filter_in=256, filter_out=1024):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(1):#6):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv5(x, filter_in=512, filter_out=2048):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(1):#3):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_55\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1110 (Conv2D)            (None, 14, 14, 64)   3200        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1110 (Batch (None, 14, 14, 64)   256         conv2d_1110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_545 (LeakyReLU)     (None, 14, 14, 64)   0           batch_normalization_1110[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 6, 6, 64)     0           leaky_re_lu_545[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1111 (Conv2D)            (None, 6, 6, 32)     2080        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1111 (Batch (None, 6, 6, 32)     128         conv2d_1111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_546 (LeakyReLU)     (None, 6, 6, 32)     0           batch_normalization_1111[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1112 (Conv2D)            (None, 6, 6, 32)     9248        leaky_re_lu_546[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1112 (Batch (None, 6, 6, 32)     128         conv2d_1112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_547 (LeakyReLU)     (None, 6, 6, 32)     0           batch_normalization_1112[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1113 (Conv2D)            (None, 6, 6, 64)     2112        leaky_re_lu_547[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1114 (Conv2D)            (None, 6, 6, 64)     4160        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1113 (Batch (None, 6, 6, 64)     256         conv2d_1113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1114 (Batch (None, 6, 6, 64)     256         conv2d_1114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_326 (Add)                   (None, 6, 6, 64)     0           batch_normalization_1113[0][0]   \n",
      "                                                                 batch_normalization_1114[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_548 (LeakyReLU)     (None, 6, 6, 64)     0           add_326[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 6, 6, 64)     0           leaky_re_lu_548[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1115 (Conv2D)            (None, 3, 3, 32)     2080        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1115 (Batch (None, 3, 3, 32)     128         conv2d_1115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_549 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1115[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1116 (Conv2D)            (None, 3, 3, 32)     9248        leaky_re_lu_549[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1116 (Batch (None, 3, 3, 32)     128         conv2d_1116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_550 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1116[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1117 (Conv2D)            (None, 3, 3, 64)     2112        leaky_re_lu_550[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1118 (Conv2D)            (None, 3, 3, 64)     4160        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1117 (Batch (None, 3, 3, 64)     256         conv2d_1117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1118 (Batch (None, 3, 3, 64)     256         conv2d_1118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_327 (Add)                   (None, 3, 3, 64)     0           batch_normalization_1117[0][0]   \n",
      "                                                                 batch_normalization_1118[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_551 (LeakyReLU)     (None, 3, 3, 64)     0           add_327[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1119 (Conv2D)            (None, 3, 3, 32)     2080        leaky_re_lu_551[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1119 (Batch (None, 3, 3, 32)     128         conv2d_1119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_552 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1119[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1120 (Conv2D)            (None, 3, 3, 32)     9248        leaky_re_lu_552[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1120 (Batch (None, 3, 3, 32)     128         conv2d_1120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_553 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1120[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1121 (Conv2D)            (None, 3, 3, 64)     2112        leaky_re_lu_553[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1121 (Batch (None, 3, 3, 64)     256         conv2d_1121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_328 (Add)                   (None, 3, 3, 64)     0           batch_normalization_1121[0][0]   \n",
      "                                                                 leaky_re_lu_551[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_554 (LeakyReLU)     (None, 3, 3, 64)     0           add_328[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 3, 3, 64)     0           leaky_re_lu_554[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1122 (Conv2D)            (None, 2, 2, 64)     4160        dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1122 (Batch (None, 2, 2, 64)     256         conv2d_1122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_555 (LeakyReLU)     (None, 2, 2, 64)     0           batch_normalization_1122[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1123 (Conv2D)            (None, 2, 2, 64)     36928       leaky_re_lu_555[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1123 (Batch (None, 2, 2, 64)     256         conv2d_1123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_556 (LeakyReLU)     (None, 2, 2, 64)     0           batch_normalization_1123[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1124 (Conv2D)            (None, 2, 2, 128)    8320        leaky_re_lu_556[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1125 (Conv2D)            (None, 2, 2, 128)    8320        dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1124 (Batch (None, 2, 2, 128)    512         conv2d_1124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1125 (Batch (None, 2, 2, 128)    512         conv2d_1125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_329 (Add)                   (None, 2, 2, 128)    0           batch_normalization_1124[0][0]   \n",
      "                                                                 batch_normalization_1125[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_557 (LeakyReLU)     (None, 2, 2, 128)    0           add_329[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 2, 2, 128)    0           leaky_re_lu_557[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1126 (Conv2D)            (None, 1, 1, 64)     8256        dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1126 (Batch (None, 1, 1, 64)     256         conv2d_1126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_558 (LeakyReLU)     (None, 1, 1, 64)     0           batch_normalization_1126[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1127 (Conv2D)            (None, 1, 1, 64)     36928       leaky_re_lu_558[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1127 (Batch (None, 1, 1, 64)     256         conv2d_1127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_559 (LeakyReLU)     (None, 1, 1, 64)     0           batch_normalization_1127[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1128 (Conv2D)            (None, 1, 1, 128)    8320        leaky_re_lu_559[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1129 (Conv2D)            (None, 1, 1, 128)    16512       dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1128 (Batch (None, 1, 1, 128)    512         conv2d_1128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1129 (Batch (None, 1, 1, 128)    512         conv2d_1129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_330 (Add)                   (None, 1, 1, 128)    0           batch_normalization_1128[0][0]   \n",
      "                                                                 batch_normalization_1129[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_560 (LeakyReLU)     (None, 1, 1, 128)    0           add_330[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1, 1, 128)    0           leaky_re_lu_560[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_27 (Gl (None, 128)          0           dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 10)           1290        global_average_pooling2d_27[0][0]\n",
      "==================================================================================================\n",
      "Total params: 186,250\n",
      "Trainable params: 183,562\n",
      "Non-trainable params: 2,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "#모델링\n",
    "classes = 10\n",
    "tensor_in = Input(shape= train_X.shape[1:], dtype='float32', name='input')\n",
    "\n",
    "x = conv1(tensor_in)\n",
    "x = conv2(x, 32, 64)\n",
    "x = Dropout(0.4)(x)\n",
    "x = conv3(x, 32, 64)\n",
    "x = Dropout(0.4)(x)\n",
    "x = conv4(x, 64, 128)\n",
    "x = Dropout(0.4)(x)\n",
    "x = conv5(x, 64, 128)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "tensor_out = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(tensor_in, tensor_out)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "#Adam(0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19652,
     "status": "error",
     "timestamp": 1598178350080,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "cb892981-08ed-4ba9-af29-c492b265fb8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 3.3559 - accuracy: 0.0964 - val_loss: 2.9831 - val_accuracy: 0.0877\n",
      "Epoch 2/4000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3912 - accuracy: 0.1006 - val_loss: 2.8385 - val_accuracy: 0.0909\n",
      "Epoch 3/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3649 - accuracy: 0.0992 - val_loss: 2.7397 - val_accuracy: 0.0974\n",
      "Epoch 4/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1698 - accuracy: 0.1159 - val_loss: 2.6587 - val_accuracy: 0.0942\n",
      "Epoch 5/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.2307 - accuracy: 0.1103 - val_loss: 2.5902 - val_accuracy: 0.0974\n",
      "Epoch 6/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.1670 - accuracy: 0.1045 - val_loss: 2.5337 - val_accuracy: 0.0877\n",
      "Epoch 7/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.1895 - accuracy: 0.1034 - val_loss: 2.4875 - val_accuracy: 0.0877\n",
      "Epoch 8/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1855 - accuracy: 0.0918 - val_loss: 2.4508 - val_accuracy: 0.0877\n",
      "Epoch 9/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.1438 - accuracy: 0.1084 - val_loss: 2.4196 - val_accuracy: 0.0877\n",
      "Epoch 10/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1243 - accuracy: 0.0922 - val_loss: 2.3934 - val_accuracy: 0.0877\n",
      "Epoch 11/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9914 - accuracy: 0.1229 - val_loss: 2.3719 - val_accuracy: 0.0942\n",
      "Epoch 12/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.0302 - accuracy: 0.1159 - val_loss: 2.3548 - val_accuracy: 0.1006\n",
      "Epoch 13/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9630 - accuracy: 0.1075 - val_loss: 2.3416 - val_accuracy: 0.0974\n",
      "Epoch 14/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9993 - accuracy: 0.0978 - val_loss: 2.3315 - val_accuracy: 0.0942\n",
      "Epoch 15/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.9481 - accuracy: 0.1201 - val_loss: 2.3232 - val_accuracy: 0.0942\n",
      "Epoch 16/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.9802 - accuracy: 0.1064 - val_loss: 2.3178 - val_accuracy: 0.0844\n",
      "Epoch 17/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.9274 - accuracy: 0.0967 - val_loss: 2.3124 - val_accuracy: 0.0877\n",
      "Epoch 18/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.9336 - accuracy: 0.1045 - val_loss: 2.3080 - val_accuracy: 0.0779\n",
      "Epoch 19/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.9374 - accuracy: 0.1094 - val_loss: 2.3037 - val_accuracy: 0.0714\n",
      "Epoch 20/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.9103 - accuracy: 0.1084 - val_loss: 2.2997 - val_accuracy: 0.0844\n",
      "Epoch 21/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.8997 - accuracy: 0.1094 - val_loss: 2.2950 - val_accuracy: 0.0779\n",
      "Epoch 22/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.9298 - accuracy: 0.1006 - val_loss: 2.2913 - val_accuracy: 0.0877\n",
      "Epoch 23/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.8956 - accuracy: 0.1104 - val_loss: 2.2893 - val_accuracy: 0.1234\n",
      "Epoch 24/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.8087 - accuracy: 0.1173 - val_loss: 2.2888 - val_accuracy: 0.1234\n",
      "Epoch 25/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.8729 - accuracy: 0.0938 - val_loss: 2.2878 - val_accuracy: 0.1299\n",
      "Epoch 26/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.8045 - accuracy: 0.1035 - val_loss: 2.2858 - val_accuracy: 0.1461\n",
      "Epoch 27/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.8440 - accuracy: 0.1123 - val_loss: 2.2831 - val_accuracy: 0.1461\n",
      "Epoch 28/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.7647 - accuracy: 0.1075 - val_loss: 2.2809 - val_accuracy: 0.1494\n",
      "Epoch 29/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.7985 - accuracy: 0.1182 - val_loss: 2.2792 - val_accuracy: 0.1623\n",
      "Epoch 30/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.7777 - accuracy: 0.1123 - val_loss: 2.2777 - val_accuracy: 0.1623\n",
      "Epoch 31/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.7981 - accuracy: 0.1103 - val_loss: 2.2766 - val_accuracy: 0.1688\n",
      "Epoch 32/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.7751 - accuracy: 0.1341 - val_loss: 2.2756 - val_accuracy: 0.1591\n",
      "Epoch 33/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.7998 - accuracy: 0.1034 - val_loss: 2.2743 - val_accuracy: 0.1494\n",
      "Epoch 34/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.7351 - accuracy: 0.1117 - val_loss: 2.2738 - val_accuracy: 0.1494\n",
      "Epoch 35/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.7202 - accuracy: 0.1016 - val_loss: 2.2736 - val_accuracy: 0.1494\n",
      "Epoch 36/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.7096 - accuracy: 0.0977 - val_loss: 2.2730 - val_accuracy: 0.1526\n",
      "Epoch 37/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6793 - accuracy: 0.1211 - val_loss: 2.2721 - val_accuracy: 0.1558\n",
      "Epoch 38/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6852 - accuracy: 0.1201 - val_loss: 2.2715 - val_accuracy: 0.1623\n",
      "Epoch 39/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6476 - accuracy: 0.1173 - val_loss: 2.2712 - val_accuracy: 0.1494\n",
      "Epoch 40/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6726 - accuracy: 0.1201 - val_loss: 2.2709 - val_accuracy: 0.1429\n",
      "Epoch 41/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.7411 - accuracy: 0.0964 - val_loss: 2.2704 - val_accuracy: 0.1396\n",
      "Epoch 42/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.6740 - accuracy: 0.1103 - val_loss: 2.2700 - val_accuracy: 0.1461\n",
      "Epoch 43/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6002 - accuracy: 0.1201 - val_loss: 2.2693 - val_accuracy: 0.1461\n",
      "Epoch 44/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6609 - accuracy: 0.1182 - val_loss: 2.2677 - val_accuracy: 0.1461\n",
      "Epoch 45/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6416 - accuracy: 0.1187 - val_loss: 2.2665 - val_accuracy: 0.1331\n",
      "Epoch 46/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.5942 - accuracy: 0.1327 - val_loss: 2.2659 - val_accuracy: 0.1331\n",
      "Epoch 47/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6864 - accuracy: 0.1201 - val_loss: 2.2653 - val_accuracy: 0.1331\n",
      "Epoch 48/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6283 - accuracy: 0.1173 - val_loss: 2.2650 - val_accuracy: 0.1266\n",
      "Epoch 49/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6614 - accuracy: 0.1113 - val_loss: 2.2652 - val_accuracy: 0.1266\n",
      "Epoch 50/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6383 - accuracy: 0.1143 - val_loss: 2.2658 - val_accuracy: 0.1039\n",
      "Epoch 51/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5500 - accuracy: 0.1230 - val_loss: 2.2660 - val_accuracy: 0.0909\n",
      "Epoch 52/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5997 - accuracy: 0.1229 - val_loss: 2.2663 - val_accuracy: 0.0942\n",
      "Epoch 53/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5509 - accuracy: 0.1117 - val_loss: 2.2665 - val_accuracy: 0.1039\n",
      "Epoch 54/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5918 - accuracy: 0.1035 - val_loss: 2.2666 - val_accuracy: 0.1006\n",
      "Epoch 55/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6295 - accuracy: 0.1075 - val_loss: 2.2662 - val_accuracy: 0.1136\n",
      "Epoch 56/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5616 - accuracy: 0.1299 - val_loss: 2.2654 - val_accuracy: 0.1136\n",
      "Epoch 57/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5678 - accuracy: 0.1240 - val_loss: 2.2648 - val_accuracy: 0.1201\n",
      "Epoch 58/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5844 - accuracy: 0.1113 - val_loss: 2.2640 - val_accuracy: 0.1266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5125 - accuracy: 0.1260 - val_loss: 2.2632 - val_accuracy: 0.1266\n",
      "Epoch 60/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5432 - accuracy: 0.1089 - val_loss: 2.2628 - val_accuracy: 0.1396\n",
      "Epoch 61/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5274 - accuracy: 0.1397 - val_loss: 2.2621 - val_accuracy: 0.1429\n",
      "Epoch 62/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4883 - accuracy: 0.1221 - val_loss: 2.2610 - val_accuracy: 0.1429\n",
      "Epoch 63/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5257 - accuracy: 0.1074 - val_loss: 2.2594 - val_accuracy: 0.1396\n",
      "Epoch 64/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5400 - accuracy: 0.1172 - val_loss: 2.2577 - val_accuracy: 0.1494\n",
      "Epoch 65/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.4593 - accuracy: 0.1397 - val_loss: 2.2554 - val_accuracy: 0.1526\n",
      "Epoch 66/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5329 - accuracy: 0.0978 - val_loss: 2.2535 - val_accuracy: 0.1558\n",
      "Epoch 67/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5395 - accuracy: 0.1104 - val_loss: 2.2516 - val_accuracy: 0.1591\n",
      "Epoch 68/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4761 - accuracy: 0.1369 - val_loss: 2.2500 - val_accuracy: 0.1526\n",
      "Epoch 69/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4866 - accuracy: 0.1143 - val_loss: 2.2481 - val_accuracy: 0.1591\n",
      "Epoch 70/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4883 - accuracy: 0.1240 - val_loss: 2.2463 - val_accuracy: 0.1656\n",
      "Epoch 71/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5064 - accuracy: 0.0978 - val_loss: 2.2451 - val_accuracy: 0.1656\n",
      "Epoch 72/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4676 - accuracy: 0.1243 - val_loss: 2.2438 - val_accuracy: 0.1753\n",
      "Epoch 73/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4555 - accuracy: 0.1299 - val_loss: 2.2427 - val_accuracy: 0.1753\n",
      "Epoch 74/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4463 - accuracy: 0.1162 - val_loss: 2.2417 - val_accuracy: 0.1753\n",
      "Epoch 75/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.5065 - accuracy: 0.1117 - val_loss: 2.2411 - val_accuracy: 0.1786\n",
      "Epoch 76/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4623 - accuracy: 0.1215 - val_loss: 2.2408 - val_accuracy: 0.1851\n",
      "Epoch 77/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4452 - accuracy: 0.1279 - val_loss: 2.2406 - val_accuracy: 0.1916\n",
      "Epoch 78/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4190 - accuracy: 0.1397 - val_loss: 2.2399 - val_accuracy: 0.1948\n",
      "Epoch 79/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3879 - accuracy: 0.1465 - val_loss: 2.2393 - val_accuracy: 0.1981\n",
      "Epoch 80/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4164 - accuracy: 0.1439 - val_loss: 2.2384 - val_accuracy: 0.2045\n",
      "Epoch 81/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4606 - accuracy: 0.1279 - val_loss: 2.2370 - val_accuracy: 0.2013\n",
      "Epoch 82/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4072 - accuracy: 0.1215 - val_loss: 2.2357 - val_accuracy: 0.2078\n",
      "Epoch 83/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4046 - accuracy: 0.1285 - val_loss: 2.2349 - val_accuracy: 0.2143\n",
      "Epoch 84/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4548 - accuracy: 0.1182 - val_loss: 2.2342 - val_accuracy: 0.2143\n",
      "Epoch 85/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4058 - accuracy: 0.1229 - val_loss: 2.2339 - val_accuracy: 0.2175\n",
      "Epoch 86/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3797 - accuracy: 0.1383 - val_loss: 2.2337 - val_accuracy: 0.2175\n",
      "Epoch 87/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4110 - accuracy: 0.1152 - val_loss: 2.2335 - val_accuracy: 0.2143\n",
      "Epoch 88/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3521 - accuracy: 0.1387 - val_loss: 2.2331 - val_accuracy: 0.2110\n",
      "Epoch 89/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3638 - accuracy: 0.1387 - val_loss: 2.2329 - val_accuracy: 0.2143\n",
      "Epoch 90/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3966 - accuracy: 0.1318 - val_loss: 2.2322 - val_accuracy: 0.2110\n",
      "Epoch 91/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4077 - accuracy: 0.1411 - val_loss: 2.2315 - val_accuracy: 0.2110\n",
      "Epoch 92/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4299 - accuracy: 0.1162 - val_loss: 2.2309 - val_accuracy: 0.2078\n",
      "Epoch 93/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.4087 - accuracy: 0.1173 - val_loss: 2.2301 - val_accuracy: 0.2045\n",
      "Epoch 94/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3998 - accuracy: 0.1201 - val_loss: 2.2298 - val_accuracy: 0.2045\n",
      "Epoch 95/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3701 - accuracy: 0.1318 - val_loss: 2.2299 - val_accuracy: 0.1916\n",
      "Epoch 96/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3499 - accuracy: 0.1523 - val_loss: 2.2298 - val_accuracy: 0.1981\n",
      "Epoch 97/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3331 - accuracy: 0.1397 - val_loss: 2.2297 - val_accuracy: 0.1948\n",
      "Epoch 98/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3632 - accuracy: 0.1396 - val_loss: 2.2293 - val_accuracy: 0.1851\n",
      "Epoch 99/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3237 - accuracy: 0.1377 - val_loss: 2.2291 - val_accuracy: 0.1851\n",
      "Epoch 100/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3340 - accuracy: 0.1522 - val_loss: 2.2291 - val_accuracy: 0.1753\n",
      "Epoch 101/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3520 - accuracy: 0.1328 - val_loss: 2.2291 - val_accuracy: 0.1721\n",
      "Epoch 102/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3483 - accuracy: 0.1436 - val_loss: 2.2288 - val_accuracy: 0.1721\n",
      "Epoch 103/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3411 - accuracy: 0.1397 - val_loss: 2.2284 - val_accuracy: 0.1753\n",
      "Epoch 104/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3522 - accuracy: 0.1230 - val_loss: 2.2280 - val_accuracy: 0.1786\n",
      "Epoch 105/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3097 - accuracy: 0.1522 - val_loss: 2.2270 - val_accuracy: 0.1786\n",
      "Epoch 106/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3151 - accuracy: 0.1383 - val_loss: 2.2258 - val_accuracy: 0.1753\n",
      "Epoch 107/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3008 - accuracy: 0.1383 - val_loss: 2.2246 - val_accuracy: 0.1786\n",
      "Epoch 108/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3459 - accuracy: 0.1670 - val_loss: 2.2234 - val_accuracy: 0.1786\n",
      "Epoch 109/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.3234 - accuracy: 0.1425 - val_loss: 2.2220 - val_accuracy: 0.1721\n",
      "Epoch 110/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3314 - accuracy: 0.1327 - val_loss: 2.2209 - val_accuracy: 0.1753\n",
      "Epoch 111/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3012 - accuracy: 0.1445 - val_loss: 2.2200 - val_accuracy: 0.1753\n",
      "Epoch 112/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2940 - accuracy: 0.1611 - val_loss: 2.2197 - val_accuracy: 0.1753\n",
      "Epoch 113/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3067 - accuracy: 0.1494 - val_loss: 2.2197 - val_accuracy: 0.1786\n",
      "Epoch 114/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3240 - accuracy: 0.1475 - val_loss: 2.2198 - val_accuracy: 0.1721\n",
      "Epoch 115/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3044 - accuracy: 0.1536 - val_loss: 2.2196 - val_accuracy: 0.1721\n",
      "Epoch 116/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3216 - accuracy: 0.1426 - val_loss: 2.2196 - val_accuracy: 0.1688\n",
      "Epoch 117/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2946 - accuracy: 0.1582 - val_loss: 2.2195 - val_accuracy: 0.1623\n",
      "Epoch 118/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3182 - accuracy: 0.1494 - val_loss: 2.2194 - val_accuracy: 0.1591\n",
      "Epoch 119/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2904 - accuracy: 0.1522 - val_loss: 2.2200 - val_accuracy: 0.1591\n",
      "Epoch 120/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3126 - accuracy: 0.1411 - val_loss: 2.2204 - val_accuracy: 0.1623\n",
      "Epoch 121/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2908 - accuracy: 0.1425 - val_loss: 2.2208 - val_accuracy: 0.1623\n",
      "Epoch 122/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2812 - accuracy: 0.1494 - val_loss: 2.2213 - val_accuracy: 0.1591\n",
      "Epoch 123/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2891 - accuracy: 0.1611 - val_loss: 2.2217 - val_accuracy: 0.1623\n",
      "Epoch 124/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2812 - accuracy: 0.1582 - val_loss: 2.2223 - val_accuracy: 0.1591\n",
      "Epoch 125/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2875 - accuracy: 0.1620 - val_loss: 2.2226 - val_accuracy: 0.1656\n",
      "Epoch 126/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2675 - accuracy: 0.1480 - val_loss: 2.2232 - val_accuracy: 0.1656\n",
      "Epoch 127/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2595 - accuracy: 0.1582 - val_loss: 2.2241 - val_accuracy: 0.1688\n",
      "Epoch 128/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2503 - accuracy: 0.1533 - val_loss: 2.2248 - val_accuracy: 0.1656\n",
      "Epoch 129/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2835 - accuracy: 0.1550 - val_loss: 2.2254 - val_accuracy: 0.1623\n",
      "Epoch 130/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2858 - accuracy: 0.1357 - val_loss: 2.2258 - val_accuracy: 0.1623\n",
      "Epoch 131/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2739 - accuracy: 0.1453 - val_loss: 2.2260 - val_accuracy: 0.1656\n",
      "Epoch 132/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2702 - accuracy: 0.1466 - val_loss: 2.2265 - val_accuracy: 0.1656\n",
      "Epoch 133/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3002 - accuracy: 0.1676 - val_loss: 2.2271 - val_accuracy: 0.1623\n",
      "Epoch 134/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2528 - accuracy: 0.1718 - val_loss: 2.2274 - val_accuracy: 0.1656\n",
      "Epoch 135/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2330 - accuracy: 0.1777 - val_loss: 2.2279 - val_accuracy: 0.1591\n",
      "Epoch 136/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2760 - accuracy: 0.1670 - val_loss: 2.2280 - val_accuracy: 0.1656\n",
      "Epoch 137/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2546 - accuracy: 0.1927 - val_loss: 2.2277 - val_accuracy: 0.1721\n",
      "Epoch 138/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2613 - accuracy: 0.1718 - val_loss: 2.2272 - val_accuracy: 0.1721\n",
      "Epoch 139/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2706 - accuracy: 0.1718 - val_loss: 2.2270 - val_accuracy: 0.1786\n",
      "Epoch 140/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2356 - accuracy: 0.1983 - val_loss: 2.2266 - val_accuracy: 0.1786\n",
      "Epoch 141/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2645 - accuracy: 0.1718 - val_loss: 2.2263 - val_accuracy: 0.1721\n",
      "Epoch 142/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2663 - accuracy: 0.1578 - val_loss: 2.2260 - val_accuracy: 0.1721\n",
      "Epoch 143/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2167 - accuracy: 0.1606 - val_loss: 2.2256 - val_accuracy: 0.1721\n",
      "Epoch 144/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2437 - accuracy: 0.1718 - val_loss: 2.2249 - val_accuracy: 0.1688\n",
      "Epoch 145/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2428 - accuracy: 0.1855 - val_loss: 2.2244 - val_accuracy: 0.1688\n",
      "Epoch 146/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2283 - accuracy: 0.1787 - val_loss: 2.2238 - val_accuracy: 0.1688\n",
      "Epoch 147/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2133 - accuracy: 0.1774 - val_loss: 2.2234 - val_accuracy: 0.1688\n",
      "Epoch 148/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2701 - accuracy: 0.1572 - val_loss: 2.2229 - val_accuracy: 0.1688\n",
      "Epoch 149/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2627 - accuracy: 0.1453 - val_loss: 2.2220 - val_accuracy: 0.1656\n",
      "Epoch 150/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2380 - accuracy: 0.1899 - val_loss: 2.2210 - val_accuracy: 0.1656\n",
      "Epoch 151/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2115 - accuracy: 0.1788 - val_loss: 2.2202 - val_accuracy: 0.1656\n",
      "Epoch 152/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2306 - accuracy: 0.1758 - val_loss: 2.2194 - val_accuracy: 0.1656\n",
      "Epoch 153/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2532 - accuracy: 0.1620 - val_loss: 2.2186 - val_accuracy: 0.1656\n",
      "Epoch 154/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2219 - accuracy: 0.1738 - val_loss: 2.2178 - val_accuracy: 0.1656\n",
      "Epoch 155/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2022 - accuracy: 0.1904 - val_loss: 2.2168 - val_accuracy: 0.1688\n",
      "Epoch 156/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2022 - accuracy: 0.2053 - val_loss: 2.2159 - val_accuracy: 0.1688\n",
      "Epoch 157/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2579 - accuracy: 0.1550 - val_loss: 2.2148 - val_accuracy: 0.1688\n",
      "Epoch 158/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2149 - accuracy: 0.1746 - val_loss: 2.2137 - val_accuracy: 0.1656\n",
      "Epoch 159/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1968 - accuracy: 0.1983 - val_loss: 2.2126 - val_accuracy: 0.1656\n",
      "Epoch 160/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2303 - accuracy: 0.1760 - val_loss: 2.2119 - val_accuracy: 0.1688\n",
      "Epoch 161/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2400 - accuracy: 0.1718 - val_loss: 2.2108 - val_accuracy: 0.1688\n",
      "Epoch 162/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2168 - accuracy: 0.2025 - val_loss: 2.2101 - val_accuracy: 0.1688\n",
      "Epoch 163/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2140 - accuracy: 0.1758 - val_loss: 2.2098 - val_accuracy: 0.1656\n",
      "Epoch 164/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2132 - accuracy: 0.1816 - val_loss: 2.2095 - val_accuracy: 0.1656\n",
      "Epoch 165/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1809 - accuracy: 0.1895 - val_loss: 2.2088 - val_accuracy: 0.1688\n",
      "Epoch 166/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2010 - accuracy: 0.2039 - val_loss: 2.2081 - val_accuracy: 0.1688\n",
      "Epoch 167/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1956 - accuracy: 0.1758 - val_loss: 2.2073 - val_accuracy: 0.1721\n",
      "Epoch 168/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1959 - accuracy: 0.2080 - val_loss: 2.2070 - val_accuracy: 0.1721\n",
      "Epoch 169/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1950 - accuracy: 0.1816 - val_loss: 2.2066 - val_accuracy: 0.1721\n",
      "Epoch 170/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1816 - accuracy: 0.1634 - val_loss: 2.2061 - val_accuracy: 0.1721\n",
      "Epoch 171/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1798 - accuracy: 0.1963 - val_loss: 2.2057 - val_accuracy: 0.1721\n",
      "Epoch 172/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1617 - accuracy: 0.2039 - val_loss: 2.2055 - val_accuracy: 0.1721\n",
      "Epoch 173/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1894 - accuracy: 0.1983 - val_loss: 2.2052 - val_accuracy: 0.1721\n",
      "Epoch 174/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1680 - accuracy: 0.1982 - val_loss: 2.2050 - val_accuracy: 0.1721\n",
      "Epoch 175/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1786 - accuracy: 0.1802 - val_loss: 2.2041 - val_accuracy: 0.1721\n",
      "Epoch 176/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2019 - accuracy: 0.1738 - val_loss: 2.2034 - val_accuracy: 0.1721\n",
      "Epoch 177/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1919 - accuracy: 0.1992 - val_loss: 2.2026 - val_accuracy: 0.1721\n",
      "Epoch 178/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2139 - accuracy: 0.2053 - val_loss: 2.2020 - val_accuracy: 0.1721\n",
      "Epoch 179/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2114 - accuracy: 0.1865 - val_loss: 2.2013 - val_accuracy: 0.1656\n",
      "Epoch 180/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1730 - accuracy: 0.2179 - val_loss: 2.2006 - val_accuracy: 0.1656\n",
      "Epoch 181/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2014 - accuracy: 0.1992 - val_loss: 2.2000 - val_accuracy: 0.1721\n",
      "Epoch 182/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1690 - accuracy: 0.1875 - val_loss: 2.1996 - val_accuracy: 0.1721\n",
      "Epoch 183/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2087 - accuracy: 0.1969 - val_loss: 2.1992 - val_accuracy: 0.1721\n",
      "Epoch 184/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1676 - accuracy: 0.2053 - val_loss: 2.1983 - val_accuracy: 0.1721\n",
      "Epoch 185/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1885 - accuracy: 0.2041 - val_loss: 2.1969 - val_accuracy: 0.1721\n",
      "Epoch 186/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2122 - accuracy: 0.1858 - val_loss: 2.1953 - val_accuracy: 0.1753\n",
      "Epoch 187/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1820 - accuracy: 0.1982 - val_loss: 2.1940 - val_accuracy: 0.1786\n",
      "Epoch 188/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1766 - accuracy: 0.2011 - val_loss: 2.1923 - val_accuracy: 0.1786\n",
      "Epoch 189/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2107 - accuracy: 0.1885 - val_loss: 2.1909 - val_accuracy: 0.1786\n",
      "Epoch 190/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2146 - accuracy: 0.1760 - val_loss: 2.1890 - val_accuracy: 0.1818\n",
      "Epoch 191/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.1718 - accuracy: 0.1855 - val_loss: 2.1872 - val_accuracy: 0.1818\n",
      "Epoch 192/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1746 - accuracy: 0.1982 - val_loss: 2.1854 - val_accuracy: 0.1818\n",
      "Epoch 193/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2023 - accuracy: 0.1777 - val_loss: 2.1829 - val_accuracy: 0.1818\n",
      "Epoch 194/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2024 - accuracy: 0.2100 - val_loss: 2.1802 - val_accuracy: 0.1818\n",
      "Epoch 195/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1585 - accuracy: 0.2080 - val_loss: 2.1775 - val_accuracy: 0.1851\n",
      "Epoch 196/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1401 - accuracy: 0.2217 - val_loss: 2.1745 - val_accuracy: 0.1883\n",
      "Epoch 197/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1467 - accuracy: 0.1875 - val_loss: 2.1723 - val_accuracy: 0.1981\n",
      "Epoch 198/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1732 - accuracy: 0.2051 - val_loss: 2.1703 - val_accuracy: 0.1981\n",
      "Epoch 199/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1484 - accuracy: 0.2188 - val_loss: 2.1687 - val_accuracy: 0.2013\n",
      "Epoch 200/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1584 - accuracy: 0.2021 - val_loss: 2.1670 - val_accuracy: 0.2013\n",
      "Epoch 201/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1931 - accuracy: 0.1797 - val_loss: 2.1653 - val_accuracy: 0.2013\n",
      "Epoch 202/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1412 - accuracy: 0.2137 - val_loss: 2.1633 - val_accuracy: 0.2013\n",
      "Epoch 203/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1323 - accuracy: 0.2095 - val_loss: 2.1615 - val_accuracy: 0.1981\n",
      "Epoch 204/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1471 - accuracy: 0.2039 - val_loss: 2.1597 - val_accuracy: 0.2013\n",
      "Epoch 205/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1368 - accuracy: 0.1955 - val_loss: 2.1572 - val_accuracy: 0.2013\n",
      "Epoch 206/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1311 - accuracy: 0.2129 - val_loss: 2.1551 - val_accuracy: 0.2013\n",
      "Epoch 207/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1406 - accuracy: 0.1899 - val_loss: 2.1531 - val_accuracy: 0.2013\n",
      "Epoch 208/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1558 - accuracy: 0.2053 - val_loss: 2.1514 - val_accuracy: 0.2045\n",
      "Epoch 209/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1261 - accuracy: 0.2137 - val_loss: 2.1493 - val_accuracy: 0.2045\n",
      "Epoch 210/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1715 - accuracy: 0.1885 - val_loss: 2.1473 - val_accuracy: 0.2045\n",
      "Epoch 211/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1577 - accuracy: 0.2053 - val_loss: 2.1458 - val_accuracy: 0.2078\n",
      "Epoch 212/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1351 - accuracy: 0.2165 - val_loss: 2.1449 - val_accuracy: 0.2045\n",
      "Epoch 213/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1383 - accuracy: 0.2178 - val_loss: 2.1439 - val_accuracy: 0.2045\n",
      "Epoch 214/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1622 - accuracy: 0.2291 - val_loss: 2.1430 - val_accuracy: 0.2078\n",
      "Epoch 215/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1480 - accuracy: 0.2285 - val_loss: 2.1421 - val_accuracy: 0.2078\n",
      "Epoch 216/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1390 - accuracy: 0.2011 - val_loss: 2.1399 - val_accuracy: 0.2078\n",
      "Epoch 217/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1444 - accuracy: 0.2053 - val_loss: 2.1376 - val_accuracy: 0.2078\n",
      "Epoch 218/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1850 - accuracy: 0.2137 - val_loss: 2.1349 - val_accuracy: 0.2110\n",
      "Epoch 219/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1292 - accuracy: 0.2179 - val_loss: 2.1321 - val_accuracy: 0.2110\n",
      "Epoch 220/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1204 - accuracy: 0.2165 - val_loss: 2.1286 - val_accuracy: 0.2110\n",
      "Epoch 221/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1258 - accuracy: 0.2263 - val_loss: 2.1254 - val_accuracy: 0.2143\n",
      "Epoch 222/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1010 - accuracy: 0.2227 - val_loss: 2.1222 - val_accuracy: 0.2175\n",
      "Epoch 223/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1552 - accuracy: 0.2025 - val_loss: 2.1190 - val_accuracy: 0.2143\n",
      "Epoch 224/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1127 - accuracy: 0.2275 - val_loss: 2.1162 - val_accuracy: 0.2175\n",
      "Epoch 225/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1418 - accuracy: 0.2119 - val_loss: 2.1131 - val_accuracy: 0.2175\n",
      "Epoch 226/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0871 - accuracy: 0.2363 - val_loss: 2.1098 - val_accuracy: 0.2208\n",
      "Epoch 227/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1232 - accuracy: 0.2179 - val_loss: 2.1059 - val_accuracy: 0.2240\n",
      "Epoch 228/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1206 - accuracy: 0.2139 - val_loss: 2.1022 - val_accuracy: 0.2338\n",
      "Epoch 229/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1185 - accuracy: 0.2197 - val_loss: 2.0987 - val_accuracy: 0.2403\n",
      "Epoch 230/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1185 - accuracy: 0.2129 - val_loss: 2.0950 - val_accuracy: 0.2435\n",
      "Epoch 231/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1206 - accuracy: 0.2324 - val_loss: 2.0918 - val_accuracy: 0.2532\n",
      "Epoch 232/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0932 - accuracy: 0.2295 - val_loss: 2.0886 - val_accuracy: 0.2565\n",
      "Epoch 233/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0808 - accuracy: 0.2444 - val_loss: 2.0855 - val_accuracy: 0.2532\n",
      "Epoch 234/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1255 - accuracy: 0.2129 - val_loss: 2.0821 - val_accuracy: 0.2565\n",
      "Epoch 235/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1120 - accuracy: 0.2067 - val_loss: 2.0785 - val_accuracy: 0.2532\n",
      "Epoch 236/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0946 - accuracy: 0.2412 - val_loss: 2.0746 - val_accuracy: 0.2532\n",
      "Epoch 237/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1240 - accuracy: 0.2129 - val_loss: 2.0713 - val_accuracy: 0.2565\n",
      "Epoch 238/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0851 - accuracy: 0.2472 - val_loss: 2.0675 - val_accuracy: 0.2597\n",
      "Epoch 239/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1002 - accuracy: 0.2486 - val_loss: 2.0642 - val_accuracy: 0.2630\n",
      "Epoch 240/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1133 - accuracy: 0.2168 - val_loss: 2.0607 - val_accuracy: 0.2630\n",
      "Epoch 241/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1023 - accuracy: 0.2304 - val_loss: 2.0572 - val_accuracy: 0.2630\n",
      "Epoch 242/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0934 - accuracy: 0.2277 - val_loss: 2.0543 - val_accuracy: 0.2662\n",
      "Epoch 243/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1203 - accuracy: 0.2236 - val_loss: 2.0513 - val_accuracy: 0.2727\n",
      "Epoch 244/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1033 - accuracy: 0.2430 - val_loss: 2.0483 - val_accuracy: 0.2727\n",
      "Epoch 245/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1030 - accuracy: 0.2275 - val_loss: 2.0453 - val_accuracy: 0.2727\n",
      "Epoch 246/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0593 - accuracy: 0.2486 - val_loss: 2.0426 - val_accuracy: 0.2727\n",
      "Epoch 247/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0693 - accuracy: 0.2514 - val_loss: 2.0396 - val_accuracy: 0.2727\n",
      "Epoch 248/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1035 - accuracy: 0.2246 - val_loss: 2.0363 - val_accuracy: 0.2792\n",
      "Epoch 249/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0828 - accuracy: 0.2402 - val_loss: 2.0325 - val_accuracy: 0.2825\n",
      "Epoch 250/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1161 - accuracy: 0.2165 - val_loss: 2.0288 - val_accuracy: 0.2792\n",
      "Epoch 251/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0988 - accuracy: 0.2263 - val_loss: 2.0252 - val_accuracy: 0.2825\n",
      "Epoch 252/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1203 - accuracy: 0.2221 - val_loss: 2.0225 - val_accuracy: 0.2857\n",
      "Epoch 253/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0827 - accuracy: 0.2458 - val_loss: 2.0201 - val_accuracy: 0.2890\n",
      "Epoch 254/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0977 - accuracy: 0.2277 - val_loss: 2.0172 - val_accuracy: 0.2857\n",
      "Epoch 255/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0797 - accuracy: 0.2556 - val_loss: 2.0153 - val_accuracy: 0.2857\n",
      "Epoch 256/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0725 - accuracy: 0.2193 - val_loss: 2.0129 - val_accuracy: 0.2857\n",
      "Epoch 257/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0562 - accuracy: 0.2332 - val_loss: 2.0105 - val_accuracy: 0.2890\n",
      "Epoch 258/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0791 - accuracy: 0.2500 - val_loss: 2.0086 - val_accuracy: 0.2890\n",
      "Epoch 259/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0801 - accuracy: 0.2598 - val_loss: 2.0059 - val_accuracy: 0.2922\n",
      "Epoch 260/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1156 - accuracy: 0.2119 - val_loss: 2.0036 - val_accuracy: 0.2955\n",
      "Epoch 261/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0819 - accuracy: 0.2383 - val_loss: 2.0012 - val_accuracy: 0.3052\n",
      "Epoch 262/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0728 - accuracy: 0.2461 - val_loss: 1.9988 - val_accuracy: 0.3052\n",
      "Epoch 263/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0481 - accuracy: 0.2388 - val_loss: 1.9970 - val_accuracy: 0.3084\n",
      "Epoch 264/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0779 - accuracy: 0.2314 - val_loss: 1.9959 - val_accuracy: 0.3052\n",
      "Epoch 265/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0924 - accuracy: 0.2318 - val_loss: 1.9948 - val_accuracy: 0.3084\n",
      "Epoch 266/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0777 - accuracy: 0.2458 - val_loss: 1.9940 - val_accuracy: 0.3084\n",
      "Epoch 267/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0806 - accuracy: 0.2373 - val_loss: 1.9937 - val_accuracy: 0.3052\n",
      "Epoch 268/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0797 - accuracy: 0.2588 - val_loss: 1.9935 - val_accuracy: 0.3052\n",
      "Epoch 269/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0805 - accuracy: 0.2412 - val_loss: 1.9931 - val_accuracy: 0.3052\n",
      "Epoch 270/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0862 - accuracy: 0.2346 - val_loss: 1.9932 - val_accuracy: 0.3084\n",
      "Epoch 271/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0440 - accuracy: 0.2422 - val_loss: 1.9935 - val_accuracy: 0.3084\n",
      "Epoch 272/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0698 - accuracy: 0.2668 - val_loss: 1.9933 - val_accuracy: 0.3052\n",
      "Epoch 273/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0571 - accuracy: 0.2346 - val_loss: 1.9933 - val_accuracy: 0.2987\n",
      "Epoch 274/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0629 - accuracy: 0.2373 - val_loss: 1.9932 - val_accuracy: 0.2987\n",
      "Epoch 275/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0600 - accuracy: 0.2451 - val_loss: 1.9924 - val_accuracy: 0.2987\n",
      "Epoch 276/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0086 - accuracy: 0.2654 - val_loss: 1.9911 - val_accuracy: 0.3019\n",
      "Epoch 277/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0556 - accuracy: 0.2556 - val_loss: 1.9896 - val_accuracy: 0.2987\n",
      "Epoch 278/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0520 - accuracy: 0.2471 - val_loss: 1.9873 - val_accuracy: 0.3019\n",
      "Epoch 279/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0358 - accuracy: 0.2626 - val_loss: 1.9848 - val_accuracy: 0.3084\n",
      "Epoch 280/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0671 - accuracy: 0.2480 - val_loss: 1.9824 - val_accuracy: 0.3084\n",
      "Epoch 281/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0628 - accuracy: 0.2542 - val_loss: 1.9794 - val_accuracy: 0.3084\n",
      "Epoch 282/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0584 - accuracy: 0.2373 - val_loss: 1.9767 - val_accuracy: 0.3084\n",
      "Epoch 283/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0437 - accuracy: 0.2416 - val_loss: 1.9743 - val_accuracy: 0.3084\n",
      "Epoch 284/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0222 - accuracy: 0.2549 - val_loss: 1.9717 - val_accuracy: 0.3084\n",
      "Epoch 285/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0259 - accuracy: 0.2578 - val_loss: 1.9696 - val_accuracy: 0.3117\n",
      "Epoch 286/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0739 - accuracy: 0.2291 - val_loss: 1.9677 - val_accuracy: 0.3117\n",
      "Epoch 287/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0455 - accuracy: 0.2334 - val_loss: 1.9660 - val_accuracy: 0.3149\n",
      "Epoch 288/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0462 - accuracy: 0.2461 - val_loss: 1.9639 - val_accuracy: 0.3149\n",
      "Epoch 289/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0128 - accuracy: 0.2640 - val_loss: 1.9619 - val_accuracy: 0.3149\n",
      "Epoch 290/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0888 - accuracy: 0.2275 - val_loss: 1.9600 - val_accuracy: 0.3149\n",
      "Epoch 291/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0489 - accuracy: 0.2612 - val_loss: 1.9577 - val_accuracy: 0.3214\n",
      "Epoch 292/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0396 - accuracy: 0.2263 - val_loss: 1.9554 - val_accuracy: 0.3279\n",
      "Epoch 293/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0554 - accuracy: 0.2432 - val_loss: 1.9534 - val_accuracy: 0.3247\n",
      "Epoch 294/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0396 - accuracy: 0.2451 - val_loss: 1.9514 - val_accuracy: 0.3247\n",
      "Epoch 295/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0494 - accuracy: 0.2151 - val_loss: 1.9489 - val_accuracy: 0.3247\n",
      "Epoch 296/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0098 - accuracy: 0.2500 - val_loss: 1.9462 - val_accuracy: 0.3214\n",
      "Epoch 297/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0277 - accuracy: 0.2588 - val_loss: 1.9442 - val_accuracy: 0.3214\n",
      "Epoch 298/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0255 - accuracy: 0.2568 - val_loss: 1.9419 - val_accuracy: 0.3247\n",
      "Epoch 299/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0248 - accuracy: 0.2627 - val_loss: 1.9392 - val_accuracy: 0.3214\n",
      "Epoch 300/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9828 - accuracy: 0.2835 - val_loss: 1.9362 - val_accuracy: 0.3247\n",
      "Epoch 301/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0449 - accuracy: 0.2490 - val_loss: 1.9333 - val_accuracy: 0.3279\n",
      "Epoch 302/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0045 - accuracy: 0.2626 - val_loss: 1.9300 - val_accuracy: 0.3312\n",
      "Epoch 303/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0000 - accuracy: 0.2709 - val_loss: 1.9270 - val_accuracy: 0.3312\n",
      "Epoch 304/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0594 - accuracy: 0.2451 - val_loss: 1.9240 - val_accuracy: 0.3377\n",
      "Epoch 305/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0447 - accuracy: 0.2451 - val_loss: 1.9209 - val_accuracy: 0.3312\n",
      "Epoch 306/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0293 - accuracy: 0.2570 - val_loss: 1.9182 - val_accuracy: 0.3377\n",
      "Epoch 307/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0244 - accuracy: 0.2607 - val_loss: 1.9156 - val_accuracy: 0.3377\n",
      "Epoch 308/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0381 - accuracy: 0.2626 - val_loss: 1.9125 - val_accuracy: 0.3344\n",
      "Epoch 309/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0239 - accuracy: 0.2444 - val_loss: 1.9098 - val_accuracy: 0.3279\n",
      "Epoch 310/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0252 - accuracy: 0.2598 - val_loss: 1.9074 - val_accuracy: 0.3312\n",
      "Epoch 311/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0314 - accuracy: 0.2598 - val_loss: 1.9052 - val_accuracy: 0.3344\n",
      "Epoch 312/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0347 - accuracy: 0.2480 - val_loss: 1.9032 - val_accuracy: 0.3377\n",
      "Epoch 313/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0213 - accuracy: 0.2500 - val_loss: 1.9013 - val_accuracy: 0.3377\n",
      "Epoch 314/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0423 - accuracy: 0.2416 - val_loss: 1.8996 - val_accuracy: 0.3377\n",
      "Epoch 315/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0011 - accuracy: 0.2705 - val_loss: 1.8977 - val_accuracy: 0.3409\n",
      "Epoch 316/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9923 - accuracy: 0.2835 - val_loss: 1.8956 - val_accuracy: 0.3409\n",
      "Epoch 317/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0386 - accuracy: 0.2676 - val_loss: 1.8937 - val_accuracy: 0.3442\n",
      "Epoch 318/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9954 - accuracy: 0.2696 - val_loss: 1.8925 - val_accuracy: 0.3409\n",
      "Epoch 319/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0152 - accuracy: 0.2542 - val_loss: 1.8908 - val_accuracy: 0.3409\n",
      "Epoch 320/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0153 - accuracy: 0.2812 - val_loss: 1.8889 - val_accuracy: 0.3409\n",
      "Epoch 321/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0059 - accuracy: 0.2500 - val_loss: 1.8870 - val_accuracy: 0.3442\n",
      "Epoch 322/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9839 - accuracy: 0.2773 - val_loss: 1.8851 - val_accuracy: 0.3474\n",
      "Epoch 323/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9993 - accuracy: 0.2654 - val_loss: 1.8835 - val_accuracy: 0.3474\n",
      "Epoch 324/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9535 - accuracy: 0.2696 - val_loss: 1.8817 - val_accuracy: 0.3474\n",
      "Epoch 325/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9963 - accuracy: 0.2646 - val_loss: 1.8803 - val_accuracy: 0.3539\n",
      "Epoch 326/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9773 - accuracy: 0.2765 - val_loss: 1.8785 - val_accuracy: 0.3539\n",
      "Epoch 327/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9544 - accuracy: 0.2765 - val_loss: 1.8763 - val_accuracy: 0.3539\n",
      "Epoch 328/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0005 - accuracy: 0.2852 - val_loss: 1.8741 - val_accuracy: 0.3506\n",
      "Epoch 329/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9589 - accuracy: 0.2765 - val_loss: 1.8719 - val_accuracy: 0.3474\n",
      "Epoch 330/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9891 - accuracy: 0.2812 - val_loss: 1.8698 - val_accuracy: 0.3442\n",
      "Epoch 331/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9549 - accuracy: 0.2835 - val_loss: 1.8680 - val_accuracy: 0.3442\n",
      "Epoch 332/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9890 - accuracy: 0.2793 - val_loss: 1.8667 - val_accuracy: 0.3442\n",
      "Epoch 333/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0520 - accuracy: 0.2640 - val_loss: 1.8654 - val_accuracy: 0.3474\n",
      "Epoch 334/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0096 - accuracy: 0.2668 - val_loss: 1.8640 - val_accuracy: 0.3571\n",
      "Epoch 335/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0059 - accuracy: 0.2709 - val_loss: 1.8626 - val_accuracy: 0.3604\n",
      "Epoch 336/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9571 - accuracy: 0.2910 - val_loss: 1.8614 - val_accuracy: 0.3669\n",
      "Epoch 337/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9605 - accuracy: 0.2863 - val_loss: 1.8607 - val_accuracy: 0.3669\n",
      "Epoch 338/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9971 - accuracy: 0.2754 - val_loss: 1.8600 - val_accuracy: 0.3669\n",
      "Epoch 339/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9862 - accuracy: 0.2715 - val_loss: 1.8593 - val_accuracy: 0.3669\n",
      "Epoch 340/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9800 - accuracy: 0.2588 - val_loss: 1.8584 - val_accuracy: 0.3669\n",
      "Epoch 341/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9975 - accuracy: 0.2764 - val_loss: 1.8575 - val_accuracy: 0.3701\n",
      "Epoch 342/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9911 - accuracy: 0.2779 - val_loss: 1.8572 - val_accuracy: 0.3669\n",
      "Epoch 343/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9413 - accuracy: 0.2793 - val_loss: 1.8574 - val_accuracy: 0.3701\n",
      "Epoch 344/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9650 - accuracy: 0.2920 - val_loss: 1.8581 - val_accuracy: 0.3701\n",
      "Epoch 345/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9999 - accuracy: 0.2891 - val_loss: 1.8589 - val_accuracy: 0.3539\n",
      "Epoch 346/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9990 - accuracy: 0.2773 - val_loss: 1.8587 - val_accuracy: 0.3539\n",
      "Epoch 347/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9737 - accuracy: 0.2705 - val_loss: 1.8586 - val_accuracy: 0.3506\n",
      "Epoch 348/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9434 - accuracy: 0.2807 - val_loss: 1.8587 - val_accuracy: 0.3474\n",
      "Epoch 349/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9447 - accuracy: 0.2947 - val_loss: 1.8589 - val_accuracy: 0.3506\n",
      "Epoch 350/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9582 - accuracy: 0.3037 - val_loss: 1.8585 - val_accuracy: 0.3506\n",
      "Epoch 351/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9674 - accuracy: 0.2988 - val_loss: 1.8582 - val_accuracy: 0.3539\n",
      "Epoch 352/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9510 - accuracy: 0.2891 - val_loss: 1.8579 - val_accuracy: 0.3506\n",
      "Epoch 353/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9726 - accuracy: 0.2686 - val_loss: 1.8577 - val_accuracy: 0.3506\n",
      "Epoch 354/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9484 - accuracy: 0.2877 - val_loss: 1.8561 - val_accuracy: 0.3474\n",
      "Epoch 355/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9809 - accuracy: 0.2751 - val_loss: 1.8544 - val_accuracy: 0.3474\n",
      "Epoch 356/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9939 - accuracy: 0.2695 - val_loss: 1.8524 - val_accuracy: 0.3539\n",
      "Epoch 357/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9397 - accuracy: 0.2821 - val_loss: 1.8506 - val_accuracy: 0.3571\n",
      "Epoch 358/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9535 - accuracy: 0.2975 - val_loss: 1.8487 - val_accuracy: 0.3571\n",
      "Epoch 359/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9550 - accuracy: 0.2861 - val_loss: 1.8468 - val_accuracy: 0.3539\n",
      "Epoch 360/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9286 - accuracy: 0.2959 - val_loss: 1.8452 - val_accuracy: 0.3539\n",
      "Epoch 361/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9754 - accuracy: 0.2737 - val_loss: 1.8439 - val_accuracy: 0.3539\n",
      "Epoch 362/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9472 - accuracy: 0.2930 - val_loss: 1.8429 - val_accuracy: 0.3506\n",
      "Epoch 363/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9797 - accuracy: 0.2822 - val_loss: 1.8422 - val_accuracy: 0.3539\n",
      "Epoch 364/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9927 - accuracy: 0.2696 - val_loss: 1.8425 - val_accuracy: 0.3539\n",
      "Epoch 365/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9455 - accuracy: 0.2877 - val_loss: 1.8420 - val_accuracy: 0.3442\n",
      "Epoch 366/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9382 - accuracy: 0.3047 - val_loss: 1.8423 - val_accuracy: 0.3506\n",
      "Epoch 367/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9277 - accuracy: 0.2877 - val_loss: 1.8427 - val_accuracy: 0.3474\n",
      "Epoch 368/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9952 - accuracy: 0.2961 - val_loss: 1.8434 - val_accuracy: 0.3506\n",
      "Epoch 369/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9678 - accuracy: 0.3073 - val_loss: 1.8433 - val_accuracy: 0.3506\n",
      "Epoch 370/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9726 - accuracy: 0.2849 - val_loss: 1.8433 - val_accuracy: 0.3474\n",
      "Epoch 371/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9246 - accuracy: 0.2812 - val_loss: 1.8429 - val_accuracy: 0.3474\n",
      "Epoch 372/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9261 - accuracy: 0.2919 - val_loss: 1.8427 - val_accuracy: 0.3506\n",
      "Epoch 373/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9329 - accuracy: 0.3212 - val_loss: 1.8423 - val_accuracy: 0.3506\n",
      "Epoch 374/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8883 - accuracy: 0.3142 - val_loss: 1.8417 - val_accuracy: 0.3571\n",
      "Epoch 375/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9271 - accuracy: 0.2822 - val_loss: 1.8421 - val_accuracy: 0.3539\n",
      "Epoch 376/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9685 - accuracy: 0.2773 - val_loss: 1.8424 - val_accuracy: 0.3474\n",
      "Epoch 377/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9721 - accuracy: 0.2695 - val_loss: 1.8417 - val_accuracy: 0.3377\n",
      "Epoch 378/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9083 - accuracy: 0.3008 - val_loss: 1.8408 - val_accuracy: 0.3442\n",
      "Epoch 379/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9955 - accuracy: 0.2490 - val_loss: 1.8402 - val_accuracy: 0.3474\n",
      "Epoch 380/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9398 - accuracy: 0.2910 - val_loss: 1.8398 - val_accuracy: 0.3539\n",
      "Epoch 381/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9353 - accuracy: 0.2598 - val_loss: 1.8387 - val_accuracy: 0.3442\n",
      "Epoch 382/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9358 - accuracy: 0.2849 - val_loss: 1.8369 - val_accuracy: 0.3474\n",
      "Epoch 383/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9614 - accuracy: 0.2988 - val_loss: 1.8341 - val_accuracy: 0.3604\n",
      "Epoch 384/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9227 - accuracy: 0.3125 - val_loss: 1.8326 - val_accuracy: 0.3636\n",
      "Epoch 385/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9161 - accuracy: 0.2947 - val_loss: 1.8311 - val_accuracy: 0.3604\n",
      "Epoch 386/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9448 - accuracy: 0.2919 - val_loss: 1.8293 - val_accuracy: 0.3571\n",
      "Epoch 387/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9263 - accuracy: 0.3128 - val_loss: 1.8270 - val_accuracy: 0.3571\n",
      "Epoch 388/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9316 - accuracy: 0.2919 - val_loss: 1.8235 - val_accuracy: 0.3539\n",
      "Epoch 389/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9325 - accuracy: 0.2765 - val_loss: 1.8206 - val_accuracy: 0.3506\n",
      "Epoch 390/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9410 - accuracy: 0.3003 - val_loss: 1.8192 - val_accuracy: 0.3506\n",
      "Epoch 391/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9161 - accuracy: 0.3115 - val_loss: 1.8181 - val_accuracy: 0.3474\n",
      "Epoch 392/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.9065 - accuracy: 0.3073 - val_loss: 1.8180 - val_accuracy: 0.3442\n",
      "Epoch 393/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9596 - accuracy: 0.2861 - val_loss: 1.8176 - val_accuracy: 0.3474\n",
      "Epoch 394/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9255 - accuracy: 0.3031 - val_loss: 1.8173 - val_accuracy: 0.3442\n",
      "Epoch 395/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8801 - accuracy: 0.3268 - val_loss: 1.8183 - val_accuracy: 0.3474\n",
      "Epoch 396/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9085 - accuracy: 0.2807 - val_loss: 1.8201 - val_accuracy: 0.3474\n",
      "Epoch 397/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9141 - accuracy: 0.3057 - val_loss: 1.8218 - val_accuracy: 0.3442\n",
      "Epoch 398/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8977 - accuracy: 0.3174 - val_loss: 1.8225 - val_accuracy: 0.3442\n",
      "Epoch 399/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8875 - accuracy: 0.3096 - val_loss: 1.8223 - val_accuracy: 0.3377\n",
      "Epoch 400/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9010 - accuracy: 0.2989 - val_loss: 1.8206 - val_accuracy: 0.3377\n",
      "Epoch 401/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9063 - accuracy: 0.3076 - val_loss: 1.8186 - val_accuracy: 0.3377\n",
      "Epoch 402/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9480 - accuracy: 0.3008 - val_loss: 1.8158 - val_accuracy: 0.3344\n",
      "Epoch 403/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9268 - accuracy: 0.2793 - val_loss: 1.8129 - val_accuracy: 0.3377\n",
      "Epoch 404/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8918 - accuracy: 0.3252 - val_loss: 1.8107 - val_accuracy: 0.3344\n",
      "Epoch 405/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9472 - accuracy: 0.2696 - val_loss: 1.8092 - val_accuracy: 0.3312\n",
      "Epoch 406/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8684 - accuracy: 0.3213 - val_loss: 1.8075 - val_accuracy: 0.3344\n",
      "Epoch 407/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9073 - accuracy: 0.2891 - val_loss: 1.8057 - val_accuracy: 0.3344\n",
      "Epoch 408/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8962 - accuracy: 0.2919 - val_loss: 1.8036 - val_accuracy: 0.3409\n",
      "Epoch 409/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9189 - accuracy: 0.3128 - val_loss: 1.8019 - val_accuracy: 0.3409\n",
      "Epoch 410/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8658 - accuracy: 0.3296 - val_loss: 1.8021 - val_accuracy: 0.3442\n",
      "Epoch 411/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9183 - accuracy: 0.3066 - val_loss: 1.8034 - val_accuracy: 0.3442\n",
      "Epoch 412/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8913 - accuracy: 0.3203 - val_loss: 1.8046 - val_accuracy: 0.3442\n",
      "Epoch 413/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8446 - accuracy: 0.3422 - val_loss: 1.8044 - val_accuracy: 0.3409\n",
      "Epoch 414/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9138 - accuracy: 0.3115 - val_loss: 1.8053 - val_accuracy: 0.3474\n",
      "Epoch 415/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8883 - accuracy: 0.3254 - val_loss: 1.8054 - val_accuracy: 0.3506\n",
      "Epoch 416/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8969 - accuracy: 0.3018 - val_loss: 1.8058 - val_accuracy: 0.3539\n",
      "Epoch 417/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8922 - accuracy: 0.3174 - val_loss: 1.8056 - val_accuracy: 0.3571\n",
      "Epoch 418/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9302 - accuracy: 0.2979 - val_loss: 1.8052 - val_accuracy: 0.3571\n",
      "Epoch 419/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9076 - accuracy: 0.3045 - val_loss: 1.8053 - val_accuracy: 0.3604\n",
      "Epoch 420/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8810 - accuracy: 0.3115 - val_loss: 1.8071 - val_accuracy: 0.3474\n",
      "Epoch 421/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8740 - accuracy: 0.3154 - val_loss: 1.8124 - val_accuracy: 0.3409\n",
      "Epoch 422/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8824 - accuracy: 0.3066 - val_loss: 1.8188 - val_accuracy: 0.3312\n",
      "Epoch 423/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8842 - accuracy: 0.3184 - val_loss: 1.8254 - val_accuracy: 0.3409\n",
      "Epoch 424/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8933 - accuracy: 0.3128 - val_loss: 1.8320 - val_accuracy: 0.3442\n",
      "Epoch 425/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8834 - accuracy: 0.2863 - val_loss: 1.8393 - val_accuracy: 0.3377\n",
      "Epoch 426/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8840 - accuracy: 0.3296 - val_loss: 1.8454 - val_accuracy: 0.3409\n",
      "Epoch 427/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8881 - accuracy: 0.2975 - val_loss: 1.8513 - val_accuracy: 0.3377\n",
      "Epoch 428/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8968 - accuracy: 0.3254 - val_loss: 1.8560 - val_accuracy: 0.3344\n",
      "Epoch 429/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8623 - accuracy: 0.3240 - val_loss: 1.8570 - val_accuracy: 0.3344\n",
      "Epoch 430/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8365 - accuracy: 0.3394 - val_loss: 1.8578 - val_accuracy: 0.3344\n",
      "Epoch 431/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8770 - accuracy: 0.3017 - val_loss: 1.8606 - val_accuracy: 0.3442\n",
      "Epoch 432/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8551 - accuracy: 0.3223 - val_loss: 1.8626 - val_accuracy: 0.3409\n",
      "Epoch 433/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9068 - accuracy: 0.2975 - val_loss: 1.8629 - val_accuracy: 0.3377\n",
      "Epoch 434/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8600 - accuracy: 0.2961 - val_loss: 1.8640 - val_accuracy: 0.3442\n",
      "Epoch 435/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8897 - accuracy: 0.3045 - val_loss: 1.8639 - val_accuracy: 0.3409\n",
      "Epoch 436/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8355 - accuracy: 0.3226 - val_loss: 1.8623 - val_accuracy: 0.3506\n",
      "Epoch 437/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8581 - accuracy: 0.3242 - val_loss: 1.8601 - val_accuracy: 0.3506\n",
      "Epoch 438/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8511 - accuracy: 0.3492 - val_loss: 1.8577 - val_accuracy: 0.3506\n",
      "Epoch 439/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8709 - accuracy: 0.3268 - val_loss: 1.8535 - val_accuracy: 0.3539\n",
      "Epoch 440/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8920 - accuracy: 0.3340 - val_loss: 1.8518 - val_accuracy: 0.3571\n",
      "Epoch 441/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8658 - accuracy: 0.3125 - val_loss: 1.8503 - val_accuracy: 0.3474\n",
      "Epoch 442/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8687 - accuracy: 0.3184 - val_loss: 1.8494 - val_accuracy: 0.3442\n",
      "Epoch 443/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8975 - accuracy: 0.3156 - val_loss: 1.8475 - val_accuracy: 0.3442\n",
      "Epoch 444/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8763 - accuracy: 0.3184 - val_loss: 1.8466 - val_accuracy: 0.3442\n",
      "Epoch 445/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8470 - accuracy: 0.3311 - val_loss: 1.8444 - val_accuracy: 0.3409\n",
      "Epoch 446/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8536 - accuracy: 0.3320 - val_loss: 1.8414 - val_accuracy: 0.3409\n",
      "Epoch 447/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8940 - accuracy: 0.3057 - val_loss: 1.8354 - val_accuracy: 0.3377\n",
      "Epoch 448/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8440 - accuracy: 0.3436 - val_loss: 1.8288 - val_accuracy: 0.3474\n",
      "Epoch 449/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9002 - accuracy: 0.3008 - val_loss: 1.8236 - val_accuracy: 0.3506\n",
      "Epoch 450/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7917 - accuracy: 0.3447 - val_loss: 1.8187 - val_accuracy: 0.3539\n",
      "Epoch 451/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8829 - accuracy: 0.3226 - val_loss: 1.8188 - val_accuracy: 0.3604\n",
      "Epoch 452/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8578 - accuracy: 0.3324 - val_loss: 1.8170 - val_accuracy: 0.3636\n",
      "Epoch 453/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8481 - accuracy: 0.3350 - val_loss: 1.8149 - val_accuracy: 0.3604\n",
      "Epoch 454/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8577 - accuracy: 0.3203 - val_loss: 1.8114 - val_accuracy: 0.3604\n",
      "Epoch 455/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8583 - accuracy: 0.3589 - val_loss: 1.8093 - val_accuracy: 0.3669\n",
      "Epoch 456/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8264 - accuracy: 0.3296 - val_loss: 1.8053 - val_accuracy: 0.3604\n",
      "Epoch 457/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8083 - accuracy: 0.3359 - val_loss: 1.8047 - val_accuracy: 0.3636\n",
      "Epoch 458/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8524 - accuracy: 0.3394 - val_loss: 1.8032 - val_accuracy: 0.3604\n",
      "Epoch 459/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8776 - accuracy: 0.3212 - val_loss: 1.8046 - val_accuracy: 0.3604\n",
      "Epoch 460/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8629 - accuracy: 0.3301 - val_loss: 1.8085 - val_accuracy: 0.3604\n",
      "Epoch 461/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8264 - accuracy: 0.3379 - val_loss: 1.8104 - val_accuracy: 0.3571\n",
      "Epoch 462/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8559 - accuracy: 0.3073 - val_loss: 1.8134 - val_accuracy: 0.3604\n",
      "Epoch 463/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8730 - accuracy: 0.3301 - val_loss: 1.8128 - val_accuracy: 0.3669\n",
      "Epoch 464/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8597 - accuracy: 0.3115 - val_loss: 1.8094 - val_accuracy: 0.3734\n",
      "Epoch 465/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8641 - accuracy: 0.3232 - val_loss: 1.8037 - val_accuracy: 0.3701\n",
      "Epoch 466/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8560 - accuracy: 0.3310 - val_loss: 1.7978 - val_accuracy: 0.3734\n",
      "Epoch 467/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8111 - accuracy: 0.3389 - val_loss: 1.7955 - val_accuracy: 0.3734\n",
      "Epoch 468/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8004 - accuracy: 0.3643 - val_loss: 1.7922 - val_accuracy: 0.3734\n",
      "Epoch 469/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8318 - accuracy: 0.3366 - val_loss: 1.7886 - val_accuracy: 0.3734\n",
      "Epoch 470/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8958 - accuracy: 0.3142 - val_loss: 1.7882 - val_accuracy: 0.3799\n",
      "Epoch 471/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8146 - accuracy: 0.3535 - val_loss: 1.7869 - val_accuracy: 0.3766\n",
      "Epoch 472/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8420 - accuracy: 0.3359 - val_loss: 1.7819 - val_accuracy: 0.3831\n",
      "Epoch 473/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8736 - accuracy: 0.3223 - val_loss: 1.7812 - val_accuracy: 0.3831\n",
      "Epoch 474/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8617 - accuracy: 0.3154 - val_loss: 1.7799 - val_accuracy: 0.3896\n",
      "Epoch 475/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8009 - accuracy: 0.3525 - val_loss: 1.7772 - val_accuracy: 0.3864\n",
      "Epoch 476/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7664 - accuracy: 0.3855 - val_loss: 1.7766 - val_accuracy: 0.3831\n",
      "Epoch 477/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8544 - accuracy: 0.3418 - val_loss: 1.7804 - val_accuracy: 0.3831\n",
      "Epoch 478/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8332 - accuracy: 0.3394 - val_loss: 1.7867 - val_accuracy: 0.3734\n",
      "Epoch 479/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8566 - accuracy: 0.3164 - val_loss: 1.7923 - val_accuracy: 0.3669\n",
      "Epoch 480/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7948 - accuracy: 0.3506 - val_loss: 1.7968 - val_accuracy: 0.3669\n",
      "Epoch 481/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8510 - accuracy: 0.3324 - val_loss: 1.7996 - val_accuracy: 0.3636\n",
      "Epoch 482/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8282 - accuracy: 0.3226 - val_loss: 1.7990 - val_accuracy: 0.3539\n",
      "Epoch 483/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8268 - accuracy: 0.3340 - val_loss: 1.7980 - val_accuracy: 0.3506\n",
      "Epoch 484/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8206 - accuracy: 0.3380 - val_loss: 1.7956 - val_accuracy: 0.3539\n",
      "Epoch 485/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8415 - accuracy: 0.3226 - val_loss: 1.7881 - val_accuracy: 0.3506\n",
      "Epoch 486/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8145 - accuracy: 0.3398 - val_loss: 1.7828 - val_accuracy: 0.3539\n",
      "Epoch 487/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8073 - accuracy: 0.3450 - val_loss: 1.7773 - val_accuracy: 0.3539\n",
      "Epoch 488/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8636 - accuracy: 0.3296 - val_loss: 1.7735 - val_accuracy: 0.3604\n",
      "Epoch 489/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8207 - accuracy: 0.3478 - val_loss: 1.7697 - val_accuracy: 0.3701\n",
      "Epoch 490/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7944 - accuracy: 0.3352 - val_loss: 1.7680 - val_accuracy: 0.3734\n",
      "Epoch 491/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8106 - accuracy: 0.3545 - val_loss: 1.7699 - val_accuracy: 0.3636\n",
      "Epoch 492/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7820 - accuracy: 0.3645 - val_loss: 1.7717 - val_accuracy: 0.3636\n",
      "Epoch 493/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7965 - accuracy: 0.3545 - val_loss: 1.7724 - val_accuracy: 0.3669\n",
      "Epoch 494/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8038 - accuracy: 0.3545 - val_loss: 1.7743 - val_accuracy: 0.3604\n",
      "Epoch 495/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8015 - accuracy: 0.3311 - val_loss: 1.7737 - val_accuracy: 0.3669\n",
      "Epoch 496/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8159 - accuracy: 0.3645 - val_loss: 1.7705 - val_accuracy: 0.3701\n",
      "Epoch 497/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7747 - accuracy: 0.3506 - val_loss: 1.7701 - val_accuracy: 0.3701\n",
      "Epoch 498/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7997 - accuracy: 0.3366 - val_loss: 1.7712 - val_accuracy: 0.3766\n",
      "Epoch 499/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8252 - accuracy: 0.3408 - val_loss: 1.7723 - val_accuracy: 0.3766\n",
      "Epoch 500/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7924 - accuracy: 0.3603 - val_loss: 1.7711 - val_accuracy: 0.3701\n",
      "Epoch 501/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7998 - accuracy: 0.3623 - val_loss: 1.7697 - val_accuracy: 0.3701\n",
      "Epoch 502/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7461 - accuracy: 0.3673 - val_loss: 1.7696 - val_accuracy: 0.3766\n",
      "Epoch 503/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8202 - accuracy: 0.3428 - val_loss: 1.7699 - val_accuracy: 0.3799\n",
      "Epoch 504/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7757 - accuracy: 0.3575 - val_loss: 1.7747 - val_accuracy: 0.3799\n",
      "Epoch 505/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7889 - accuracy: 0.3438 - val_loss: 1.7793 - val_accuracy: 0.3929\n",
      "Epoch 506/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8505 - accuracy: 0.3457 - val_loss: 1.7849 - val_accuracy: 0.3929\n",
      "Epoch 507/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7454 - accuracy: 0.3613 - val_loss: 1.7914 - val_accuracy: 0.3864\n",
      "Epoch 508/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7862 - accuracy: 0.3659 - val_loss: 1.7917 - val_accuracy: 0.3766\n",
      "Epoch 509/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7821 - accuracy: 0.3574 - val_loss: 1.7896 - val_accuracy: 0.3799\n",
      "Epoch 510/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7747 - accuracy: 0.3827 - val_loss: 1.7916 - val_accuracy: 0.3831\n",
      "Epoch 511/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7877 - accuracy: 0.3394 - val_loss: 1.7981 - val_accuracy: 0.3831\n",
      "Epoch 512/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7930 - accuracy: 0.3301 - val_loss: 1.7987 - val_accuracy: 0.3864\n",
      "Epoch 513/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7948 - accuracy: 0.3589 - val_loss: 1.7977 - val_accuracy: 0.3799\n",
      "Epoch 514/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7508 - accuracy: 0.3841 - val_loss: 1.7888 - val_accuracy: 0.3799\n",
      "Epoch 515/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8231 - accuracy: 0.3633 - val_loss: 1.7782 - val_accuracy: 0.3799\n",
      "Epoch 516/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7667 - accuracy: 0.3613 - val_loss: 1.7692 - val_accuracy: 0.3864\n",
      "Epoch 517/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7579 - accuracy: 0.3662 - val_loss: 1.7585 - val_accuracy: 0.3929\n",
      "Epoch 518/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7807 - accuracy: 0.3877 - val_loss: 1.7494 - val_accuracy: 0.3994\n",
      "Epoch 519/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8183 - accuracy: 0.3575 - val_loss: 1.7454 - val_accuracy: 0.3961\n",
      "Epoch 520/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7888 - accuracy: 0.3506 - val_loss: 1.7421 - val_accuracy: 0.4026\n",
      "Epoch 521/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7857 - accuracy: 0.3545 - val_loss: 1.7419 - val_accuracy: 0.4058\n",
      "Epoch 522/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7937 - accuracy: 0.3564 - val_loss: 1.7420 - val_accuracy: 0.4058\n",
      "Epoch 523/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7209 - accuracy: 0.3760 - val_loss: 1.7473 - val_accuracy: 0.4058\n",
      "Epoch 524/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7500 - accuracy: 0.3715 - val_loss: 1.7538 - val_accuracy: 0.4026\n",
      "Epoch 525/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7649 - accuracy: 0.3623 - val_loss: 1.7567 - val_accuracy: 0.3929\n",
      "Epoch 526/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7615 - accuracy: 0.3701 - val_loss: 1.7585 - val_accuracy: 0.3961\n",
      "Epoch 527/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7256 - accuracy: 0.3827 - val_loss: 1.7574 - val_accuracy: 0.3896\n",
      "Epoch 528/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7641 - accuracy: 0.3561 - val_loss: 1.7580 - val_accuracy: 0.3896\n",
      "Epoch 529/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8166 - accuracy: 0.3324 - val_loss: 1.7620 - val_accuracy: 0.3831\n",
      "Epoch 530/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7592 - accuracy: 0.3643 - val_loss: 1.7665 - val_accuracy: 0.3896\n",
      "Epoch 531/4000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.7779 - accuracy: 0.3691 - val_loss: 1.7733 - val_accuracy: 0.3929\n",
      "Epoch 532/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7917 - accuracy: 0.3547 - val_loss: 1.7799 - val_accuracy: 0.3766\n",
      "Epoch 533/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7314 - accuracy: 0.3623 - val_loss: 1.7833 - val_accuracy: 0.3734\n",
      "Epoch 534/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7458 - accuracy: 0.3545 - val_loss: 1.7897 - val_accuracy: 0.3701\n",
      "Epoch 535/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7813 - accuracy: 0.3682 - val_loss: 1.7934 - val_accuracy: 0.3571\n",
      "Epoch 536/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7974 - accuracy: 0.3545 - val_loss: 1.7980 - val_accuracy: 0.3571\n",
      "Epoch 537/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7621 - accuracy: 0.3687 - val_loss: 1.7912 - val_accuracy: 0.3539\n",
      "Epoch 538/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7576 - accuracy: 0.3623 - val_loss: 1.7842 - val_accuracy: 0.3571\n",
      "Epoch 539/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7553 - accuracy: 0.3603 - val_loss: 1.7714 - val_accuracy: 0.3604\n",
      "Epoch 540/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7355 - accuracy: 0.3785 - val_loss: 1.7638 - val_accuracy: 0.3571\n",
      "Epoch 541/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7588 - accuracy: 0.3603 - val_loss: 1.7515 - val_accuracy: 0.3669\n",
      "Epoch 542/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7852 - accuracy: 0.3506 - val_loss: 1.7394 - val_accuracy: 0.3701\n",
      "Epoch 543/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7214 - accuracy: 0.3818 - val_loss: 1.7276 - val_accuracy: 0.3701\n",
      "Epoch 544/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7153 - accuracy: 0.3771 - val_loss: 1.7180 - val_accuracy: 0.3734\n",
      "Epoch 545/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7467 - accuracy: 0.3687 - val_loss: 1.7093 - val_accuracy: 0.3766\n",
      "Epoch 546/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7987 - accuracy: 0.3715 - val_loss: 1.7081 - val_accuracy: 0.3864\n",
      "Epoch 547/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7348 - accuracy: 0.3827 - val_loss: 1.7091 - val_accuracy: 0.3896\n",
      "Epoch 548/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7409 - accuracy: 0.3750 - val_loss: 1.7157 - val_accuracy: 0.3864\n",
      "Epoch 549/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7478 - accuracy: 0.3662 - val_loss: 1.7222 - val_accuracy: 0.3929\n",
      "Epoch 550/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7613 - accuracy: 0.3883 - val_loss: 1.7329 - val_accuracy: 0.3831\n",
      "Epoch 551/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7600 - accuracy: 0.3926 - val_loss: 1.7500 - val_accuracy: 0.3669\n",
      "Epoch 552/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7130 - accuracy: 0.3799 - val_loss: 1.7676 - val_accuracy: 0.3636\n",
      "Epoch 553/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7134 - accuracy: 0.3779 - val_loss: 1.7839 - val_accuracy: 0.3506\n",
      "Epoch 554/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7428 - accuracy: 0.3711 - val_loss: 1.7935 - val_accuracy: 0.3442\n",
      "Epoch 555/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7343 - accuracy: 0.3613 - val_loss: 1.7928 - val_accuracy: 0.3506\n",
      "Epoch 556/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7138 - accuracy: 0.3883 - val_loss: 1.7862 - val_accuracy: 0.3539\n",
      "Epoch 557/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7365 - accuracy: 0.3828 - val_loss: 1.7790 - val_accuracy: 0.3669\n",
      "Epoch 558/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7590 - accuracy: 0.3869 - val_loss: 1.7659 - val_accuracy: 0.3701\n",
      "Epoch 559/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7145 - accuracy: 0.3799 - val_loss: 1.7487 - val_accuracy: 0.3766\n",
      "Epoch 560/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7828 - accuracy: 0.3561 - val_loss: 1.7287 - val_accuracy: 0.3766\n",
      "Epoch 561/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7297 - accuracy: 0.3841 - val_loss: 1.7048 - val_accuracy: 0.3994\n",
      "Epoch 562/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7589 - accuracy: 0.3564 - val_loss: 1.6893 - val_accuracy: 0.3961\n",
      "Epoch 563/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6991 - accuracy: 0.4064 - val_loss: 1.6819 - val_accuracy: 0.3961\n",
      "Epoch 564/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7228 - accuracy: 0.3701 - val_loss: 1.6746 - val_accuracy: 0.4026\n",
      "Epoch 565/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.7471 - accuracy: 0.3799 - val_loss: 1.6689 - val_accuracy: 0.4091\n",
      "Epoch 566/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7440 - accuracy: 0.3740 - val_loss: 1.6683 - val_accuracy: 0.4188\n",
      "Epoch 567/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7205 - accuracy: 0.3897 - val_loss: 1.6759 - val_accuracy: 0.4058\n",
      "Epoch 568/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7970 - accuracy: 0.3575 - val_loss: 1.6833 - val_accuracy: 0.3994\n",
      "Epoch 569/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7093 - accuracy: 0.3818 - val_loss: 1.6889 - val_accuracy: 0.3961\n",
      "Epoch 570/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7370 - accuracy: 0.3809 - val_loss: 1.6954 - val_accuracy: 0.3929\n",
      "Epoch 571/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7134 - accuracy: 0.3848 - val_loss: 1.7006 - val_accuracy: 0.3961\n",
      "Epoch 572/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7228 - accuracy: 0.3730 - val_loss: 1.7113 - val_accuracy: 0.3961\n",
      "Epoch 573/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7321 - accuracy: 0.3682 - val_loss: 1.7224 - val_accuracy: 0.3929\n",
      "Epoch 574/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6684 - accuracy: 0.3841 - val_loss: 1.7364 - val_accuracy: 0.3929\n",
      "Epoch 575/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7624 - accuracy: 0.3855 - val_loss: 1.7542 - val_accuracy: 0.3734\n",
      "Epoch 576/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7189 - accuracy: 0.3838 - val_loss: 1.7671 - val_accuracy: 0.3669\n",
      "Epoch 577/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7412 - accuracy: 0.3925 - val_loss: 1.7671 - val_accuracy: 0.3701\n",
      "Epoch 578/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7068 - accuracy: 0.4008 - val_loss: 1.7639 - val_accuracy: 0.3604\n",
      "Epoch 579/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7091 - accuracy: 0.3883 - val_loss: 1.7634 - val_accuracy: 0.3636\n",
      "Epoch 580/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7340 - accuracy: 0.3757 - val_loss: 1.7624 - val_accuracy: 0.3734\n",
      "Epoch 581/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6879 - accuracy: 0.3877 - val_loss: 1.7544 - val_accuracy: 0.3864\n",
      "Epoch 582/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6881 - accuracy: 0.3945 - val_loss: 1.7478 - val_accuracy: 0.3864\n",
      "Epoch 583/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.7315 - accuracy: 0.3789 - val_loss: 1.7498 - val_accuracy: 0.3766\n",
      "Epoch 584/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6798 - accuracy: 0.3682 - val_loss: 1.7493 - val_accuracy: 0.3701\n",
      "Epoch 585/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7261 - accuracy: 0.3799 - val_loss: 1.7448 - val_accuracy: 0.3669\n",
      "Epoch 586/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7184 - accuracy: 0.3799 - val_loss: 1.7394 - val_accuracy: 0.3734\n",
      "Epoch 587/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6941 - accuracy: 0.3911 - val_loss: 1.7376 - val_accuracy: 0.3864\n",
      "Epoch 588/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7525 - accuracy: 0.4050 - val_loss: 1.7329 - val_accuracy: 0.3994\n",
      "Epoch 589/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7219 - accuracy: 0.3799 - val_loss: 1.7374 - val_accuracy: 0.3961\n",
      "Epoch 590/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7002 - accuracy: 0.3799 - val_loss: 1.7442 - val_accuracy: 0.3929\n",
      "Epoch 591/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7481 - accuracy: 0.3939 - val_loss: 1.7491 - val_accuracy: 0.3929\n",
      "Epoch 592/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7025 - accuracy: 0.3955 - val_loss: 1.7480 - val_accuracy: 0.3896\n",
      "Epoch 593/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6981 - accuracy: 0.3965 - val_loss: 1.7434 - val_accuracy: 0.3994\n",
      "Epoch 594/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6890 - accuracy: 0.3715 - val_loss: 1.7278 - val_accuracy: 0.4123\n",
      "Epoch 595/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6764 - accuracy: 0.3848 - val_loss: 1.7149 - val_accuracy: 0.4351\n",
      "Epoch 596/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6944 - accuracy: 0.3984 - val_loss: 1.7054 - val_accuracy: 0.4383\n",
      "Epoch 597/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7222 - accuracy: 0.3855 - val_loss: 1.7011 - val_accuracy: 0.4448\n",
      "Epoch 598/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6766 - accuracy: 0.4008 - val_loss: 1.6940 - val_accuracy: 0.4318\n",
      "Epoch 599/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6734 - accuracy: 0.3925 - val_loss: 1.6840 - val_accuracy: 0.4156\n",
      "Epoch 600/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6755 - accuracy: 0.4014 - val_loss: 1.6777 - val_accuracy: 0.4156\n",
      "Epoch 601/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6798 - accuracy: 0.4053 - val_loss: 1.6746 - val_accuracy: 0.4221\n",
      "Epoch 602/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6707 - accuracy: 0.3994 - val_loss: 1.6743 - val_accuracy: 0.4123\n",
      "Epoch 603/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6608 - accuracy: 0.3715 - val_loss: 1.6758 - val_accuracy: 0.4123\n",
      "Epoch 604/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6829 - accuracy: 0.4092 - val_loss: 1.6696 - val_accuracy: 0.4156\n",
      "Epoch 605/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6842 - accuracy: 0.3740 - val_loss: 1.6661 - val_accuracy: 0.4156\n",
      "Epoch 606/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7011 - accuracy: 0.3785 - val_loss: 1.6641 - val_accuracy: 0.4156\n",
      "Epoch 607/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7208 - accuracy: 0.3994 - val_loss: 1.6600 - val_accuracy: 0.4156\n",
      "Epoch 608/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6888 - accuracy: 0.3939 - val_loss: 1.6521 - val_accuracy: 0.4188\n",
      "Epoch 609/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6762 - accuracy: 0.3955 - val_loss: 1.6456 - val_accuracy: 0.4156\n",
      "Epoch 610/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6581 - accuracy: 0.3771 - val_loss: 1.6384 - val_accuracy: 0.4123\n",
      "Epoch 611/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7205 - accuracy: 0.3869 - val_loss: 1.6354 - val_accuracy: 0.4156\n",
      "Epoch 612/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6656 - accuracy: 0.3925 - val_loss: 1.6401 - val_accuracy: 0.4123\n",
      "Epoch 613/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6885 - accuracy: 0.3855 - val_loss: 1.6445 - val_accuracy: 0.4058\n",
      "Epoch 614/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6498 - accuracy: 0.4131 - val_loss: 1.6476 - val_accuracy: 0.4058\n",
      "Epoch 615/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6637 - accuracy: 0.4092 - val_loss: 1.6487 - val_accuracy: 0.4156\n",
      "Epoch 616/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6697 - accuracy: 0.3975 - val_loss: 1.6455 - val_accuracy: 0.4123\n",
      "Epoch 617/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6582 - accuracy: 0.3945 - val_loss: 1.6469 - val_accuracy: 0.4091\n",
      "Epoch 618/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6783 - accuracy: 0.3729 - val_loss: 1.6429 - val_accuracy: 0.4091\n",
      "Epoch 619/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6634 - accuracy: 0.4082 - val_loss: 1.6411 - val_accuracy: 0.4091\n",
      "Epoch 620/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6352 - accuracy: 0.4268 - val_loss: 1.6461 - val_accuracy: 0.4058\n",
      "Epoch 621/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6208 - accuracy: 0.4274 - val_loss: 1.6506 - val_accuracy: 0.4026\n",
      "Epoch 622/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6067 - accuracy: 0.4248 - val_loss: 1.6506 - val_accuracy: 0.3961\n",
      "Epoch 623/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6125 - accuracy: 0.4148 - val_loss: 1.6433 - val_accuracy: 0.4026\n",
      "Epoch 624/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6824 - accuracy: 0.3785 - val_loss: 1.6374 - val_accuracy: 0.4058\n",
      "Epoch 625/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6609 - accuracy: 0.3953 - val_loss: 1.6378 - val_accuracy: 0.4091\n",
      "Epoch 626/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6794 - accuracy: 0.3911 - val_loss: 1.6330 - val_accuracy: 0.4156\n",
      "Epoch 627/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6312 - accuracy: 0.4218 - val_loss: 1.6296 - val_accuracy: 0.4286\n",
      "Epoch 628/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6682 - accuracy: 0.3926 - val_loss: 1.6319 - val_accuracy: 0.4286\n",
      "Epoch 629/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6551 - accuracy: 0.4053 - val_loss: 1.6304 - val_accuracy: 0.4286\n",
      "Epoch 630/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6635 - accuracy: 0.4062 - val_loss: 1.6291 - val_accuracy: 0.4318\n",
      "Epoch 631/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6157 - accuracy: 0.4358 - val_loss: 1.6192 - val_accuracy: 0.4286\n",
      "Epoch 632/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6572 - accuracy: 0.4150 - val_loss: 1.6079 - val_accuracy: 0.4253\n",
      "Epoch 633/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6116 - accuracy: 0.3841 - val_loss: 1.6030 - val_accuracy: 0.4188\n",
      "Epoch 634/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6371 - accuracy: 0.4092 - val_loss: 1.6054 - val_accuracy: 0.4123\n",
      "Epoch 635/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6415 - accuracy: 0.4180 - val_loss: 1.6094 - val_accuracy: 0.4123\n",
      "Epoch 636/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5665 - accuracy: 0.4623 - val_loss: 1.6132 - val_accuracy: 0.4123\n",
      "Epoch 637/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6309 - accuracy: 0.4092 - val_loss: 1.6168 - val_accuracy: 0.4156\n",
      "Epoch 638/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6288 - accuracy: 0.3966 - val_loss: 1.6328 - val_accuracy: 0.4026\n",
      "Epoch 639/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6444 - accuracy: 0.3966 - val_loss: 1.6602 - val_accuracy: 0.3961\n",
      "Epoch 640/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6324 - accuracy: 0.4326 - val_loss: 1.6767 - val_accuracy: 0.3864\n",
      "Epoch 641/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6478 - accuracy: 0.4092 - val_loss: 1.6879 - val_accuracy: 0.3799\n",
      "Epoch 642/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5976 - accuracy: 0.4404 - val_loss: 1.6852 - val_accuracy: 0.3734\n",
      "Epoch 643/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6436 - accuracy: 0.4078 - val_loss: 1.6834 - val_accuracy: 0.3799\n",
      "Epoch 644/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5841 - accuracy: 0.4413 - val_loss: 1.6736 - val_accuracy: 0.3864\n",
      "Epoch 645/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5913 - accuracy: 0.4375 - val_loss: 1.6684 - val_accuracy: 0.3929\n",
      "Epoch 646/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6228 - accuracy: 0.4302 - val_loss: 1.6474 - val_accuracy: 0.3994\n",
      "Epoch 647/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6160 - accuracy: 0.4232 - val_loss: 1.6307 - val_accuracy: 0.4123\n",
      "Epoch 648/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6200 - accuracy: 0.4160 - val_loss: 1.6227 - val_accuracy: 0.4058\n",
      "Epoch 649/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.6305 - accuracy: 0.4204 - val_loss: 1.6278 - val_accuracy: 0.4026\n",
      "Epoch 650/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6452 - accuracy: 0.4062 - val_loss: 1.6333 - val_accuracy: 0.3994\n",
      "Epoch 651/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.5975 - accuracy: 0.4287 - val_loss: 1.6406 - val_accuracy: 0.4026\n",
      "Epoch 652/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6645 - accuracy: 0.3994 - val_loss: 1.6591 - val_accuracy: 0.4026\n",
      "Epoch 653/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6095 - accuracy: 0.4344 - val_loss: 1.6669 - val_accuracy: 0.3994\n",
      "Epoch 654/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6142 - accuracy: 0.4365 - val_loss: 1.6786 - val_accuracy: 0.3994\n",
      "Epoch 655/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6085 - accuracy: 0.4219 - val_loss: 1.7038 - val_accuracy: 0.3864\n",
      "Epoch 656/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5762 - accuracy: 0.4344 - val_loss: 1.7316 - val_accuracy: 0.3766\n",
      "Epoch 657/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6403 - accuracy: 0.3980 - val_loss: 1.7588 - val_accuracy: 0.3636\n",
      "Epoch 658/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6134 - accuracy: 0.4344 - val_loss: 1.7753 - val_accuracy: 0.3539\n",
      "Epoch 659/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5713 - accuracy: 0.4453 - val_loss: 1.7847 - val_accuracy: 0.3474\n",
      "Epoch 660/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6416 - accuracy: 0.4180 - val_loss: 1.7659 - val_accuracy: 0.3539\n",
      "Epoch 661/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6087 - accuracy: 0.4160 - val_loss: 1.7423 - val_accuracy: 0.3571\n",
      "Epoch 662/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6524 - accuracy: 0.4043 - val_loss: 1.7128 - val_accuracy: 0.3636\n",
      "Epoch 663/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5952 - accuracy: 0.4469 - val_loss: 1.6996 - val_accuracy: 0.3701\n",
      "Epoch 664/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6128 - accuracy: 0.4260 - val_loss: 1.6917 - val_accuracy: 0.3864\n",
      "Epoch 665/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5972 - accuracy: 0.4258 - val_loss: 1.6817 - val_accuracy: 0.3929\n",
      "Epoch 666/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6267 - accuracy: 0.4248 - val_loss: 1.6825 - val_accuracy: 0.3961\n",
      "Epoch 667/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6041 - accuracy: 0.4316 - val_loss: 1.7037 - val_accuracy: 0.3961\n",
      "Epoch 668/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5960 - accuracy: 0.4229 - val_loss: 1.7212 - val_accuracy: 0.3896\n",
      "Epoch 669/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5946 - accuracy: 0.4326 - val_loss: 1.7393 - val_accuracy: 0.3831\n",
      "Epoch 670/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5285 - accuracy: 0.4707 - val_loss: 1.7748 - val_accuracy: 0.3734\n",
      "Epoch 671/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6249 - accuracy: 0.4277 - val_loss: 1.8000 - val_accuracy: 0.3799\n",
      "Epoch 672/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6198 - accuracy: 0.4078 - val_loss: 1.8248 - val_accuracy: 0.3539\n",
      "Epoch 673/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5998 - accuracy: 0.4473 - val_loss: 1.8460 - val_accuracy: 0.3636\n",
      "Epoch 674/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5328 - accuracy: 0.4525 - val_loss: 1.8757 - val_accuracy: 0.3539\n",
      "Epoch 675/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5719 - accuracy: 0.4246 - val_loss: 1.9096 - val_accuracy: 0.3506\n",
      "Epoch 676/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5857 - accuracy: 0.4365 - val_loss: 1.9202 - val_accuracy: 0.3474\n",
      "Epoch 677/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5858 - accuracy: 0.4346 - val_loss: 1.9217 - val_accuracy: 0.3442\n",
      "Epoch 678/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6060 - accuracy: 0.4189 - val_loss: 1.9186 - val_accuracy: 0.3506\n",
      "Epoch 679/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5820 - accuracy: 0.4395 - val_loss: 1.9027 - val_accuracy: 0.3669\n",
      "Epoch 680/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5858 - accuracy: 0.4297 - val_loss: 1.8687 - val_accuracy: 0.3669\n",
      "Epoch 681/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6138 - accuracy: 0.4246 - val_loss: 1.8310 - val_accuracy: 0.3766\n",
      "Epoch 682/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5906 - accuracy: 0.4274 - val_loss: 1.8187 - val_accuracy: 0.3734\n",
      "Epoch 683/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5511 - accuracy: 0.4482 - val_loss: 1.7984 - val_accuracy: 0.3799\n",
      "Epoch 684/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5453 - accuracy: 0.4805 - val_loss: 1.7833 - val_accuracy: 0.3831\n",
      "Epoch 685/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5992 - accuracy: 0.4372 - val_loss: 1.7586 - val_accuracy: 0.3961\n",
      "Epoch 686/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5111 - accuracy: 0.4679 - val_loss: 1.7241 - val_accuracy: 0.4188\n",
      "Epoch 687/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5403 - accuracy: 0.4497 - val_loss: 1.7022 - val_accuracy: 0.4221\n",
      "Epoch 688/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5863 - accuracy: 0.4434 - val_loss: 1.6880 - val_accuracy: 0.4253\n",
      "Epoch 689/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5563 - accuracy: 0.4463 - val_loss: 1.6771 - val_accuracy: 0.4221\n",
      "Epoch 690/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6243 - accuracy: 0.4473 - val_loss: 1.6693 - val_accuracy: 0.4253\n",
      "Epoch 691/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6311 - accuracy: 0.4258 - val_loss: 1.6727 - val_accuracy: 0.4188\n",
      "Epoch 692/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5840 - accuracy: 0.4473 - val_loss: 1.6878 - val_accuracy: 0.4156\n",
      "Epoch 693/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6189 - accuracy: 0.4148 - val_loss: 1.6820 - val_accuracy: 0.4091\n",
      "Epoch 694/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5941 - accuracy: 0.4268 - val_loss: 1.6657 - val_accuracy: 0.4026\n",
      "Epoch 695/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5959 - accuracy: 0.4204 - val_loss: 1.6644 - val_accuracy: 0.4091\n",
      "Epoch 696/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.5733 - accuracy: 0.4385 - val_loss: 1.6632 - val_accuracy: 0.4026\n",
      "Epoch 697/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5681 - accuracy: 0.4623 - val_loss: 1.6741 - val_accuracy: 0.4058\n",
      "Epoch 698/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5561 - accuracy: 0.4455 - val_loss: 1.6878 - val_accuracy: 0.4058\n",
      "Epoch 699/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5873 - accuracy: 0.4232 - val_loss: 1.6955 - val_accuracy: 0.4058\n",
      "Epoch 700/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5446 - accuracy: 0.4511 - val_loss: 1.7057 - val_accuracy: 0.4123\n",
      "Epoch 701/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5872 - accuracy: 0.4229 - val_loss: 1.7195 - val_accuracy: 0.4156\n",
      "Epoch 702/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5166 - accuracy: 0.4648 - val_loss: 1.7370 - val_accuracy: 0.4058\n",
      "Epoch 703/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5653 - accuracy: 0.4502 - val_loss: 1.7330 - val_accuracy: 0.4091\n",
      "Epoch 704/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5344 - accuracy: 0.4721 - val_loss: 1.7153 - val_accuracy: 0.4026\n",
      "Epoch 705/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5869 - accuracy: 0.4427 - val_loss: 1.6833 - val_accuracy: 0.4091\n",
      "Epoch 706/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5709 - accuracy: 0.4427 - val_loss: 1.6447 - val_accuracy: 0.4318\n",
      "Epoch 707/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5777 - accuracy: 0.4232 - val_loss: 1.6179 - val_accuracy: 0.4416\n",
      "Epoch 708/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5407 - accuracy: 0.4473 - val_loss: 1.6053 - val_accuracy: 0.4253\n",
      "Epoch 709/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4912 - accuracy: 0.4916 - val_loss: 1.6027 - val_accuracy: 0.4253\n",
      "Epoch 710/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5456 - accuracy: 0.4441 - val_loss: 1.6127 - val_accuracy: 0.4318\n",
      "Epoch 711/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5115 - accuracy: 0.4609 - val_loss: 1.6349 - val_accuracy: 0.4221\n",
      "Epoch 712/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5735 - accuracy: 0.4372 - val_loss: 1.6648 - val_accuracy: 0.4286\n",
      "Epoch 713/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5834 - accuracy: 0.4427 - val_loss: 1.6863 - val_accuracy: 0.4286\n",
      "Epoch 714/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5099 - accuracy: 0.4511 - val_loss: 1.6976 - val_accuracy: 0.4253\n",
      "Epoch 715/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5118 - accuracy: 0.4483 - val_loss: 1.7049 - val_accuracy: 0.4286\n",
      "Epoch 716/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5498 - accuracy: 0.4385 - val_loss: 1.7359 - val_accuracy: 0.4188\n",
      "Epoch 717/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5733 - accuracy: 0.4531 - val_loss: 1.7627 - val_accuracy: 0.4253\n",
      "Epoch 718/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6073 - accuracy: 0.4455 - val_loss: 1.7659 - val_accuracy: 0.4156\n",
      "Epoch 719/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5623 - accuracy: 0.4512 - val_loss: 1.7584 - val_accuracy: 0.4091\n",
      "Epoch 720/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5585 - accuracy: 0.4497 - val_loss: 1.7295 - val_accuracy: 0.4091\n",
      "Epoch 721/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5287 - accuracy: 0.4648 - val_loss: 1.7050 - val_accuracy: 0.4123\n",
      "Epoch 722/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5233 - accuracy: 0.4539 - val_loss: 1.6762 - val_accuracy: 0.4286\n",
      "Epoch 723/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5720 - accuracy: 0.4570 - val_loss: 1.6618 - val_accuracy: 0.4351\n",
      "Epoch 724/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.5398 - accuracy: 0.4385 - val_loss: 1.6425 - val_accuracy: 0.4286\n",
      "Epoch 725/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5238 - accuracy: 0.4735 - val_loss: 1.6348 - val_accuracy: 0.4383\n",
      "Epoch 726/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5358 - accuracy: 0.4346 - val_loss: 1.6219 - val_accuracy: 0.4286\n",
      "Epoch 727/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5477 - accuracy: 0.4375 - val_loss: 1.6230 - val_accuracy: 0.4253\n",
      "Epoch 728/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5539 - accuracy: 0.4609 - val_loss: 1.6520 - val_accuracy: 0.4286\n",
      "Epoch 729/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5495 - accuracy: 0.4443 - val_loss: 1.6880 - val_accuracy: 0.4253\n",
      "Epoch 730/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5704 - accuracy: 0.4512 - val_loss: 1.7378 - val_accuracy: 0.4091\n",
      "Epoch 731/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5436 - accuracy: 0.4372 - val_loss: 1.7719 - val_accuracy: 0.3929\n",
      "Epoch 732/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5033 - accuracy: 0.4832 - val_loss: 1.8041 - val_accuracy: 0.3896\n",
      "Epoch 733/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4818 - accuracy: 0.4688 - val_loss: 1.8246 - val_accuracy: 0.3896\n",
      "Epoch 734/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5168 - accuracy: 0.4665 - val_loss: 1.8390 - val_accuracy: 0.3929\n",
      "Epoch 735/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4832 - accuracy: 0.4832 - val_loss: 1.8350 - val_accuracy: 0.3864\n",
      "Epoch 736/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5548 - accuracy: 0.4629 - val_loss: 1.8167 - val_accuracy: 0.3864\n",
      "Epoch 737/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5146 - accuracy: 0.4567 - val_loss: 1.7861 - val_accuracy: 0.4058\n",
      "Epoch 738/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5058 - accuracy: 0.4629 - val_loss: 1.7575 - val_accuracy: 0.4221\n",
      "Epoch 739/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5439 - accuracy: 0.4629 - val_loss: 1.7356 - val_accuracy: 0.4286\n",
      "Epoch 740/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5140 - accuracy: 0.4665 - val_loss: 1.7176 - val_accuracy: 0.4253\n",
      "Epoch 741/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5434 - accuracy: 0.4385 - val_loss: 1.6918 - val_accuracy: 0.4318\n",
      "Epoch 742/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5144 - accuracy: 0.4561 - val_loss: 1.6837 - val_accuracy: 0.4416\n",
      "Epoch 743/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5436 - accuracy: 0.4424 - val_loss: 1.6720 - val_accuracy: 0.4416\n",
      "Epoch 744/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4480 - accuracy: 0.4863 - val_loss: 1.6591 - val_accuracy: 0.4578\n",
      "Epoch 745/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4985 - accuracy: 0.4658 - val_loss: 1.6400 - val_accuracy: 0.4740\n",
      "Epoch 746/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4812 - accuracy: 0.4930 - val_loss: 1.6397 - val_accuracy: 0.4740\n",
      "Epoch 747/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4869 - accuracy: 0.4777 - val_loss: 1.6422 - val_accuracy: 0.4643\n",
      "Epoch 748/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5227 - accuracy: 0.4619 - val_loss: 1.6581 - val_accuracy: 0.4643\n",
      "Epoch 749/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5058 - accuracy: 0.4883 - val_loss: 1.6809 - val_accuracy: 0.4481\n",
      "Epoch 750/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4914 - accuracy: 0.4637 - val_loss: 1.7199 - val_accuracy: 0.4513\n",
      "Epoch 751/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4260 - accuracy: 0.4893 - val_loss: 1.7274 - val_accuracy: 0.4513\n",
      "Epoch 752/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5018 - accuracy: 0.4749 - val_loss: 1.7418 - val_accuracy: 0.4513\n",
      "Epoch 753/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5324 - accuracy: 0.4580 - val_loss: 1.7508 - val_accuracy: 0.4416\n",
      "Epoch 754/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4748 - accuracy: 0.4986 - val_loss: 1.7667 - val_accuracy: 0.4286\n",
      "Epoch 755/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4889 - accuracy: 0.4531 - val_loss: 1.8024 - val_accuracy: 0.4123\n",
      "Epoch 756/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4378 - accuracy: 0.4818 - val_loss: 1.8136 - val_accuracy: 0.4058\n",
      "Epoch 757/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5222 - accuracy: 0.4749 - val_loss: 1.8019 - val_accuracy: 0.4026\n",
      "Epoch 758/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4883 - accuracy: 0.4561 - val_loss: 1.7842 - val_accuracy: 0.4123\n",
      "Epoch 759/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4126 - accuracy: 0.5084 - val_loss: 1.7697 - val_accuracy: 0.4253\n",
      "Epoch 760/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5006 - accuracy: 0.4763 - val_loss: 1.7495 - val_accuracy: 0.4221\n",
      "Epoch 761/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4827 - accuracy: 0.4777 - val_loss: 1.7587 - val_accuracy: 0.4156\n",
      "Epoch 762/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5156 - accuracy: 0.4619 - val_loss: 1.7641 - val_accuracy: 0.4188\n",
      "Epoch 763/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5076 - accuracy: 0.4854 - val_loss: 1.7513 - val_accuracy: 0.4156\n",
      "Epoch 764/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5051 - accuracy: 0.4902 - val_loss: 1.7357 - val_accuracy: 0.4253\n",
      "Epoch 765/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5127 - accuracy: 0.4648 - val_loss: 1.7012 - val_accuracy: 0.4351\n",
      "Epoch 766/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4729 - accuracy: 0.4893 - val_loss: 1.6586 - val_accuracy: 0.4578\n",
      "Epoch 767/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5038 - accuracy: 0.4541 - val_loss: 1.6225 - val_accuracy: 0.4610\n",
      "Epoch 768/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4828 - accuracy: 0.4551 - val_loss: 1.6023 - val_accuracy: 0.4675\n",
      "Epoch 769/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5376 - accuracy: 0.4570 - val_loss: 1.6138 - val_accuracy: 0.4675\n",
      "Epoch 770/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5237 - accuracy: 0.4581 - val_loss: 1.6395 - val_accuracy: 0.4578\n",
      "Epoch 771/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4244 - accuracy: 0.4980 - val_loss: 1.6819 - val_accuracy: 0.4513\n",
      "Epoch 772/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4494 - accuracy: 0.5029 - val_loss: 1.7164 - val_accuracy: 0.4448\n",
      "Epoch 773/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4398 - accuracy: 0.5049 - val_loss: 1.7336 - val_accuracy: 0.4481\n",
      "Epoch 774/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4663 - accuracy: 0.4971 - val_loss: 1.7239 - val_accuracy: 0.4481\n",
      "Epoch 775/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4581 - accuracy: 0.4912 - val_loss: 1.6973 - val_accuracy: 0.4545\n",
      "Epoch 776/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4970 - accuracy: 0.4763 - val_loss: 1.6658 - val_accuracy: 0.4513\n",
      "Epoch 777/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4716 - accuracy: 0.4749 - val_loss: 1.6285 - val_accuracy: 0.4481\n",
      "Epoch 778/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4713 - accuracy: 0.4581 - val_loss: 1.6019 - val_accuracy: 0.4708\n",
      "Epoch 779/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4712 - accuracy: 0.4805 - val_loss: 1.5725 - val_accuracy: 0.4805\n",
      "Epoch 780/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4604 - accuracy: 0.4912 - val_loss: 1.5799 - val_accuracy: 0.4708\n",
      "Epoch 781/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4386 - accuracy: 0.5000 - val_loss: 1.5996 - val_accuracy: 0.4610\n",
      "Epoch 782/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4999 - accuracy: 0.4521 - val_loss: 1.6234 - val_accuracy: 0.4513\n",
      "Epoch 783/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4763 - accuracy: 0.4846 - val_loss: 1.6433 - val_accuracy: 0.4481\n",
      "Epoch 784/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4370 - accuracy: 0.4844 - val_loss: 1.6817 - val_accuracy: 0.4416\n",
      "Epoch 785/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4838 - accuracy: 0.4814 - val_loss: 1.6983 - val_accuracy: 0.4221\n",
      "Epoch 786/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4875 - accuracy: 0.4648 - val_loss: 1.7065 - val_accuracy: 0.4188\n",
      "Epoch 787/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4166 - accuracy: 0.5195 - val_loss: 1.7167 - val_accuracy: 0.4188\n",
      "Epoch 788/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4795 - accuracy: 0.5056 - val_loss: 1.7298 - val_accuracy: 0.4253\n",
      "Epoch 789/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4437 - accuracy: 0.5000 - val_loss: 1.7600 - val_accuracy: 0.3994\n",
      "Epoch 790/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4772 - accuracy: 0.4600 - val_loss: 1.7997 - val_accuracy: 0.3864\n",
      "Epoch 791/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4200 - accuracy: 0.5070 - val_loss: 1.8403 - val_accuracy: 0.3734\n",
      "Epoch 792/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4505 - accuracy: 0.5020 - val_loss: 1.8690 - val_accuracy: 0.3636\n",
      "Epoch 793/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4551 - accuracy: 0.4958 - val_loss: 1.8537 - val_accuracy: 0.3734\n",
      "Epoch 794/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4530 - accuracy: 0.4922 - val_loss: 1.8092 - val_accuracy: 0.3864\n",
      "Epoch 795/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4218 - accuracy: 0.4961 - val_loss: 1.7451 - val_accuracy: 0.3961\n",
      "Epoch 796/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4171 - accuracy: 0.5000 - val_loss: 1.6662 - val_accuracy: 0.4481\n",
      "Epoch 797/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4841 - accuracy: 0.4860 - val_loss: 1.5957 - val_accuracy: 0.4578\n",
      "Epoch 798/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4419 - accuracy: 0.4971 - val_loss: 1.5350 - val_accuracy: 0.4773\n",
      "Epoch 799/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5279 - accuracy: 0.4791 - val_loss: 1.5053 - val_accuracy: 0.4903\n",
      "Epoch 800/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3891 - accuracy: 0.5127 - val_loss: 1.5096 - val_accuracy: 0.4805\n",
      "Epoch 801/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4008 - accuracy: 0.5196 - val_loss: 1.5345 - val_accuracy: 0.4740\n",
      "Epoch 802/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4908 - accuracy: 0.4912 - val_loss: 1.5697 - val_accuracy: 0.4610\n",
      "Epoch 803/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4793 - accuracy: 0.4902 - val_loss: 1.6084 - val_accuracy: 0.4513\n",
      "Epoch 804/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4159 - accuracy: 0.5014 - val_loss: 1.6332 - val_accuracy: 0.4481\n",
      "Epoch 805/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4300 - accuracy: 0.5056 - val_loss: 1.6493 - val_accuracy: 0.4513\n",
      "Epoch 806/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4428 - accuracy: 0.5117 - val_loss: 1.6644 - val_accuracy: 0.4351\n",
      "Epoch 807/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4198 - accuracy: 0.5168 - val_loss: 1.6511 - val_accuracy: 0.4448\n",
      "Epoch 808/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4233 - accuracy: 0.5078 - val_loss: 1.6395 - val_accuracy: 0.4740\n",
      "Epoch 809/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4610 - accuracy: 0.4932 - val_loss: 1.6328 - val_accuracy: 0.4708\n",
      "Epoch 810/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3646 - accuracy: 0.5265 - val_loss: 1.6317 - val_accuracy: 0.4708\n",
      "Epoch 811/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5046 - accuracy: 0.4756 - val_loss: 1.6441 - val_accuracy: 0.4675\n",
      "Epoch 812/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3783 - accuracy: 0.5205 - val_loss: 1.6438 - val_accuracy: 0.4740\n",
      "Epoch 813/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4211 - accuracy: 0.4986 - val_loss: 1.6663 - val_accuracy: 0.4708\n",
      "Epoch 814/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4284 - accuracy: 0.4707 - val_loss: 1.6786 - val_accuracy: 0.4773\n",
      "Epoch 815/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4586 - accuracy: 0.5014 - val_loss: 1.6835 - val_accuracy: 0.4675\n",
      "Epoch 816/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3773 - accuracy: 0.5000 - val_loss: 1.6734 - val_accuracy: 0.4675\n",
      "Epoch 817/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4373 - accuracy: 0.5010 - val_loss: 1.6915 - val_accuracy: 0.4578\n",
      "Epoch 818/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3527 - accuracy: 0.5244 - val_loss: 1.6629 - val_accuracy: 0.4610\n",
      "Epoch 819/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4532 - accuracy: 0.4736 - val_loss: 1.6324 - val_accuracy: 0.4675\n",
      "Epoch 820/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4458 - accuracy: 0.4775 - val_loss: 1.5807 - val_accuracy: 0.5000\n",
      "Epoch 821/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3821 - accuracy: 0.5084 - val_loss: 1.5442 - val_accuracy: 0.5065\n",
      "Epoch 822/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4027 - accuracy: 0.5215 - val_loss: 1.5180 - val_accuracy: 0.5065\n",
      "Epoch 823/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4147 - accuracy: 0.5117 - val_loss: 1.5108 - val_accuracy: 0.5097\n",
      "Epoch 824/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4128 - accuracy: 0.5215 - val_loss: 1.4865 - val_accuracy: 0.5097\n",
      "Epoch 825/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4097 - accuracy: 0.5168 - val_loss: 1.4634 - val_accuracy: 0.5065\n",
      "Epoch 826/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3858 - accuracy: 0.5059 - val_loss: 1.4573 - val_accuracy: 0.5097\n",
      "Epoch 827/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4263 - accuracy: 0.5039 - val_loss: 1.4654 - val_accuracy: 0.5000\n",
      "Epoch 828/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4518 - accuracy: 0.5112 - val_loss: 1.4920 - val_accuracy: 0.4968\n",
      "Epoch 829/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3736 - accuracy: 0.5205 - val_loss: 1.5204 - val_accuracy: 0.4805\n",
      "Epoch 830/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3801 - accuracy: 0.5154 - val_loss: 1.5425 - val_accuracy: 0.4740\n",
      "Epoch 831/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4409 - accuracy: 0.4888 - val_loss: 1.5773 - val_accuracy: 0.4578\n",
      "Epoch 832/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4313 - accuracy: 0.5020 - val_loss: 1.5919 - val_accuracy: 0.4643\n",
      "Epoch 833/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3570 - accuracy: 0.5117 - val_loss: 1.6133 - val_accuracy: 0.4545\n",
      "Epoch 834/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4642 - accuracy: 0.4824 - val_loss: 1.6446 - val_accuracy: 0.4513\n",
      "Epoch 835/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4592 - accuracy: 0.4972 - val_loss: 1.6875 - val_accuracy: 0.4351\n",
      "Epoch 836/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4106 - accuracy: 0.5042 - val_loss: 1.7135 - val_accuracy: 0.4351\n",
      "Epoch 837/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4167 - accuracy: 0.5088 - val_loss: 1.7175 - val_accuracy: 0.4318\n",
      "Epoch 838/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4241 - accuracy: 0.5029 - val_loss: 1.7105 - val_accuracy: 0.4351\n",
      "Epoch 839/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3715 - accuracy: 0.5176 - val_loss: 1.6894 - val_accuracy: 0.4383\n",
      "Epoch 840/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3994 - accuracy: 0.5127 - val_loss: 1.6540 - val_accuracy: 0.4416\n",
      "Epoch 841/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3995 - accuracy: 0.5112 - val_loss: 1.6073 - val_accuracy: 0.4578\n",
      "Epoch 842/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4275 - accuracy: 0.4902 - val_loss: 1.5738 - val_accuracy: 0.4773\n",
      "Epoch 843/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4395 - accuracy: 0.5088 - val_loss: 1.5593 - val_accuracy: 0.4935\n",
      "Epoch 844/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4444 - accuracy: 0.4902 - val_loss: 1.5699 - val_accuracy: 0.4968\n",
      "Epoch 845/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.3818 - accuracy: 0.5137 - val_loss: 1.5729 - val_accuracy: 0.5000\n",
      "Epoch 846/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3768 - accuracy: 0.5209 - val_loss: 1.5924 - val_accuracy: 0.4968\n",
      "Epoch 847/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3845 - accuracy: 0.5098 - val_loss: 1.6226 - val_accuracy: 0.4903\n",
      "Epoch 848/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3693 - accuracy: 0.5223 - val_loss: 1.6651 - val_accuracy: 0.4643\n",
      "Epoch 849/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4593 - accuracy: 0.4688 - val_loss: 1.6818 - val_accuracy: 0.4513\n",
      "Epoch 850/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3737 - accuracy: 0.5251 - val_loss: 1.6788 - val_accuracy: 0.4578\n",
      "Epoch 851/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3912 - accuracy: 0.5209 - val_loss: 1.6425 - val_accuracy: 0.4675\n",
      "Epoch 852/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3572 - accuracy: 0.5279 - val_loss: 1.6020 - val_accuracy: 0.4935\n",
      "Epoch 853/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3872 - accuracy: 0.5215 - val_loss: 1.5691 - val_accuracy: 0.5065\n",
      "Epoch 854/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3964 - accuracy: 0.5237 - val_loss: 1.5512 - val_accuracy: 0.5130\n",
      "Epoch 855/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3991 - accuracy: 0.4860 - val_loss: 1.5636 - val_accuracy: 0.5065\n",
      "Epoch 856/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3838 - accuracy: 0.5168 - val_loss: 1.6140 - val_accuracy: 0.4805\n",
      "Epoch 857/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3809 - accuracy: 0.5168 - val_loss: 1.6831 - val_accuracy: 0.4643\n",
      "Epoch 858/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4559 - accuracy: 0.4717 - val_loss: 1.7616 - val_accuracy: 0.4610\n",
      "Epoch 859/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4036 - accuracy: 0.5042 - val_loss: 1.8207 - val_accuracy: 0.4351\n",
      "Epoch 860/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4042 - accuracy: 0.5146 - val_loss: 1.8310 - val_accuracy: 0.4221\n",
      "Epoch 861/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3770 - accuracy: 0.5312 - val_loss: 1.8074 - val_accuracy: 0.4253\n",
      "Epoch 862/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4181 - accuracy: 0.5166 - val_loss: 1.7462 - val_accuracy: 0.4416\n",
      "Epoch 863/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3957 - accuracy: 0.5042 - val_loss: 1.6836 - val_accuracy: 0.4416\n",
      "Epoch 864/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3345 - accuracy: 0.5303 - val_loss: 1.6011 - val_accuracy: 0.4578\n",
      "Epoch 865/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3598 - accuracy: 0.5056 - val_loss: 1.5240 - val_accuracy: 0.5000\n",
      "Epoch 866/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4047 - accuracy: 0.5098 - val_loss: 1.4670 - val_accuracy: 0.5000\n",
      "Epoch 867/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3726 - accuracy: 0.5293 - val_loss: 1.4255 - val_accuracy: 0.5162\n",
      "Epoch 868/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3714 - accuracy: 0.5307 - val_loss: 1.4034 - val_accuracy: 0.5227\n",
      "Epoch 869/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3140 - accuracy: 0.5461 - val_loss: 1.3990 - val_accuracy: 0.5227\n",
      "Epoch 870/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4051 - accuracy: 0.5029 - val_loss: 1.4138 - val_accuracy: 0.5000\n",
      "Epoch 871/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4190 - accuracy: 0.5056 - val_loss: 1.4236 - val_accuracy: 0.5000\n",
      "Epoch 872/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3586 - accuracy: 0.5137 - val_loss: 1.4368 - val_accuracy: 0.5065\n",
      "Epoch 873/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3692 - accuracy: 0.5283 - val_loss: 1.4527 - val_accuracy: 0.5032\n",
      "Epoch 874/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3924 - accuracy: 0.4971 - val_loss: 1.4545 - val_accuracy: 0.5032\n",
      "Epoch 875/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3846 - accuracy: 0.5244 - val_loss: 1.4524 - val_accuracy: 0.5000\n",
      "Epoch 876/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3925 - accuracy: 0.5237 - val_loss: 1.4216 - val_accuracy: 0.5032\n",
      "Epoch 877/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3159 - accuracy: 0.5349 - val_loss: 1.4207 - val_accuracy: 0.5227\n",
      "Epoch 878/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3254 - accuracy: 0.5140 - val_loss: 1.4073 - val_accuracy: 0.5325\n",
      "Epoch 879/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3727 - accuracy: 0.5049 - val_loss: 1.3997 - val_accuracy: 0.5195\n",
      "Epoch 880/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3822 - accuracy: 0.5405 - val_loss: 1.4094 - val_accuracy: 0.5162\n",
      "Epoch 881/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3383 - accuracy: 0.5447 - val_loss: 1.4127 - val_accuracy: 0.5260\n",
      "Epoch 882/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2981 - accuracy: 0.5381 - val_loss: 1.4097 - val_accuracy: 0.5292\n",
      "Epoch 883/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3659 - accuracy: 0.5293 - val_loss: 1.3846 - val_accuracy: 0.5390\n",
      "Epoch 884/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3282 - accuracy: 0.5503 - val_loss: 1.3725 - val_accuracy: 0.5584\n",
      "Epoch 885/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3638 - accuracy: 0.5293 - val_loss: 1.3757 - val_accuracy: 0.5390\n",
      "Epoch 886/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3353 - accuracy: 0.5205 - val_loss: 1.3694 - val_accuracy: 0.5422\n",
      "Epoch 887/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3359 - accuracy: 0.5489 - val_loss: 1.3837 - val_accuracy: 0.5422\n",
      "Epoch 888/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3828 - accuracy: 0.5166 - val_loss: 1.4001 - val_accuracy: 0.5422\n",
      "Epoch 889/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3681 - accuracy: 0.5293 - val_loss: 1.4160 - val_accuracy: 0.5325\n",
      "Epoch 890/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3639 - accuracy: 0.5234 - val_loss: 1.4392 - val_accuracy: 0.5195\n",
      "Epoch 891/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3419 - accuracy: 0.5215 - val_loss: 1.4680 - val_accuracy: 0.5097\n",
      "Epoch 892/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3912 - accuracy: 0.5196 - val_loss: 1.4957 - val_accuracy: 0.5032\n",
      "Epoch 893/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3234 - accuracy: 0.5391 - val_loss: 1.5021 - val_accuracy: 0.5032\n",
      "Epoch 894/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3155 - accuracy: 0.5461 - val_loss: 1.5160 - val_accuracy: 0.5130\n",
      "Epoch 895/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3471 - accuracy: 0.5293 - val_loss: 1.5128 - val_accuracy: 0.5162\n",
      "Epoch 896/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3495 - accuracy: 0.5312 - val_loss: 1.4913 - val_accuracy: 0.5357\n",
      "Epoch 897/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3539 - accuracy: 0.5410 - val_loss: 1.4703 - val_accuracy: 0.5390\n",
      "Epoch 898/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3278 - accuracy: 0.5461 - val_loss: 1.4680 - val_accuracy: 0.5325\n",
      "Epoch 899/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3410 - accuracy: 0.5363 - val_loss: 1.4914 - val_accuracy: 0.5260\n",
      "Epoch 900/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3818 - accuracy: 0.5342 - val_loss: 1.5187 - val_accuracy: 0.5032\n",
      "Epoch 901/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2892 - accuracy: 0.5587 - val_loss: 1.5582 - val_accuracy: 0.4935\n",
      "Epoch 902/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3647 - accuracy: 0.5156 - val_loss: 1.5847 - val_accuracy: 0.4675\n",
      "Epoch 903/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3581 - accuracy: 0.5196 - val_loss: 1.6094 - val_accuracy: 0.4708\n",
      "Epoch 904/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3901 - accuracy: 0.5166 - val_loss: 1.6019 - val_accuracy: 0.4643\n",
      "Epoch 905/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3265 - accuracy: 0.5447 - val_loss: 1.5383 - val_accuracy: 0.4935\n",
      "Epoch 906/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4168 - accuracy: 0.4980 - val_loss: 1.4607 - val_accuracy: 0.5065\n",
      "Epoch 907/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3289 - accuracy: 0.5312 - val_loss: 1.4006 - val_accuracy: 0.5390\n",
      "Epoch 908/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2939 - accuracy: 0.5391 - val_loss: 1.3503 - val_accuracy: 0.5584\n",
      "Epoch 909/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2607 - accuracy: 0.5664 - val_loss: 1.3155 - val_accuracy: 0.5714\n",
      "Epoch 910/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3326 - accuracy: 0.5264 - val_loss: 1.3267 - val_accuracy: 0.5649\n",
      "Epoch 911/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3743 - accuracy: 0.5430 - val_loss: 1.3765 - val_accuracy: 0.5649\n",
      "Epoch 912/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3084 - accuracy: 0.5391 - val_loss: 1.4301 - val_accuracy: 0.5325\n",
      "Epoch 913/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3619 - accuracy: 0.5391 - val_loss: 1.4874 - val_accuracy: 0.5000\n",
      "Epoch 914/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3717 - accuracy: 0.5056 - val_loss: 1.5587 - val_accuracy: 0.4935\n",
      "Epoch 915/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3069 - accuracy: 0.5400 - val_loss: 1.5937 - val_accuracy: 0.4935\n",
      "Epoch 916/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3357 - accuracy: 0.5293 - val_loss: 1.5925 - val_accuracy: 0.4903\n",
      "Epoch 917/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3160 - accuracy: 0.5447 - val_loss: 1.5271 - val_accuracy: 0.5097\n",
      "Epoch 918/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2883 - accuracy: 0.5352 - val_loss: 1.4380 - val_accuracy: 0.5455\n",
      "Epoch 919/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3326 - accuracy: 0.5405 - val_loss: 1.3378 - val_accuracy: 0.5519\n",
      "Epoch 920/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2804 - accuracy: 0.5447 - val_loss: 1.2743 - val_accuracy: 0.5877\n",
      "Epoch 921/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3016 - accuracy: 0.5419 - val_loss: 1.2591 - val_accuracy: 0.5779\n",
      "Epoch 922/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3541 - accuracy: 0.5215 - val_loss: 1.2579 - val_accuracy: 0.5714\n",
      "Epoch 923/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3443 - accuracy: 0.5469 - val_loss: 1.2582 - val_accuracy: 0.5714\n",
      "Epoch 924/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2793 - accuracy: 0.5791 - val_loss: 1.2566 - val_accuracy: 0.5682\n",
      "Epoch 925/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3545 - accuracy: 0.5127 - val_loss: 1.2667 - val_accuracy: 0.5682\n",
      "Epoch 926/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2874 - accuracy: 0.5684 - val_loss: 1.2817 - val_accuracy: 0.5617\n",
      "Epoch 927/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3433 - accuracy: 0.5400 - val_loss: 1.3108 - val_accuracy: 0.5455\n",
      "Epoch 928/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3176 - accuracy: 0.5449 - val_loss: 1.3352 - val_accuracy: 0.5552\n",
      "Epoch 929/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3236 - accuracy: 0.5531 - val_loss: 1.3524 - val_accuracy: 0.5617\n",
      "Epoch 930/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3221 - accuracy: 0.5391 - val_loss: 1.3609 - val_accuracy: 0.5584\n",
      "Epoch 931/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3309 - accuracy: 0.5405 - val_loss: 1.3658 - val_accuracy: 0.5584\n",
      "Epoch 932/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3239 - accuracy: 0.5307 - val_loss: 1.3637 - val_accuracy: 0.5552\n",
      "Epoch 933/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2940 - accuracy: 0.5654 - val_loss: 1.3485 - val_accuracy: 0.5519\n",
      "Epoch 934/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3136 - accuracy: 0.5283 - val_loss: 1.3362 - val_accuracy: 0.5487\n",
      "Epoch 935/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4034 - accuracy: 0.5059 - val_loss: 1.3224 - val_accuracy: 0.5357\n",
      "Epoch 936/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2514 - accuracy: 0.5670 - val_loss: 1.3044 - val_accuracy: 0.5455\n",
      "Epoch 937/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3037 - accuracy: 0.5537 - val_loss: 1.2966 - val_accuracy: 0.5487\n",
      "Epoch 938/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3572 - accuracy: 0.5377 - val_loss: 1.2978 - val_accuracy: 0.5487\n",
      "Epoch 939/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3051 - accuracy: 0.5405 - val_loss: 1.3024 - val_accuracy: 0.5487\n",
      "Epoch 940/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2912 - accuracy: 0.5517 - val_loss: 1.3066 - val_accuracy: 0.5682\n",
      "Epoch 941/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3205 - accuracy: 0.5488 - val_loss: 1.3203 - val_accuracy: 0.5682\n",
      "Epoch 942/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2849 - accuracy: 0.5488 - val_loss: 1.3381 - val_accuracy: 0.5682\n",
      "Epoch 943/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2901 - accuracy: 0.5479 - val_loss: 1.3529 - val_accuracy: 0.5682\n",
      "Epoch 944/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3216 - accuracy: 0.5475 - val_loss: 1.3626 - val_accuracy: 0.5682\n",
      "Epoch 945/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3260 - accuracy: 0.5459 - val_loss: 1.3667 - val_accuracy: 0.5584\n",
      "Epoch 946/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3646 - accuracy: 0.5332 - val_loss: 1.3805 - val_accuracy: 0.5649\n",
      "Epoch 947/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2985 - accuracy: 0.5573 - val_loss: 1.3764 - val_accuracy: 0.5584\n",
      "Epoch 948/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2870 - accuracy: 0.5625 - val_loss: 1.3640 - val_accuracy: 0.5584\n",
      "Epoch 949/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3424 - accuracy: 0.5363 - val_loss: 1.3870 - val_accuracy: 0.5390\n",
      "Epoch 950/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3188 - accuracy: 0.5527 - val_loss: 1.4148 - val_accuracy: 0.5357\n",
      "Epoch 951/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2151 - accuracy: 0.5964 - val_loss: 1.4349 - val_accuracy: 0.5097\n",
      "Epoch 952/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3106 - accuracy: 0.5670 - val_loss: 1.4317 - val_accuracy: 0.5130\n",
      "Epoch 953/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3203 - accuracy: 0.5332 - val_loss: 1.4000 - val_accuracy: 0.5260\n",
      "Epoch 954/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3411 - accuracy: 0.5615 - val_loss: 1.3700 - val_accuracy: 0.5487\n",
      "Epoch 955/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2619 - accuracy: 0.5625 - val_loss: 1.3487 - val_accuracy: 0.5519\n",
      "Epoch 956/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3376 - accuracy: 0.5307 - val_loss: 1.3520 - val_accuracy: 0.5519\n",
      "Epoch 957/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2801 - accuracy: 0.5596 - val_loss: 1.3690 - val_accuracy: 0.5487\n",
      "Epoch 958/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2976 - accuracy: 0.5557 - val_loss: 1.3788 - val_accuracy: 0.5390\n",
      "Epoch 959/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.3114 - accuracy: 0.5566 - val_loss: 1.3939 - val_accuracy: 0.5292\n",
      "Epoch 960/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2899 - accuracy: 0.5469 - val_loss: 1.4102 - val_accuracy: 0.5357\n",
      "Epoch 961/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2487 - accuracy: 0.5605 - val_loss: 1.4042 - val_accuracy: 0.5292\n",
      "Epoch 962/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3254 - accuracy: 0.5559 - val_loss: 1.4001 - val_accuracy: 0.5487\n",
      "Epoch 963/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2823 - accuracy: 0.5587 - val_loss: 1.3831 - val_accuracy: 0.5519\n",
      "Epoch 964/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2883 - accuracy: 0.5645 - val_loss: 1.3745 - val_accuracy: 0.5519\n",
      "Epoch 965/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2315 - accuracy: 0.5922 - val_loss: 1.3696 - val_accuracy: 0.5519\n",
      "Epoch 966/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2646 - accuracy: 0.5586 - val_loss: 1.3680 - val_accuracy: 0.5422\n",
      "Epoch 967/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2727 - accuracy: 0.5547 - val_loss: 1.3589 - val_accuracy: 0.5390\n",
      "Epoch 968/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2436 - accuracy: 0.5754 - val_loss: 1.3888 - val_accuracy: 0.5292\n",
      "Epoch 969/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2587 - accuracy: 0.5508 - val_loss: 1.4223 - val_accuracy: 0.5162\n",
      "Epoch 970/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3311 - accuracy: 0.5251 - val_loss: 1.4360 - val_accuracy: 0.5000\n",
      "Epoch 971/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2989 - accuracy: 0.5469 - val_loss: 1.4211 - val_accuracy: 0.5162\n",
      "Epoch 972/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3307 - accuracy: 0.5391 - val_loss: 1.3917 - val_accuracy: 0.5195\n",
      "Epoch 973/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3652 - accuracy: 0.5279 - val_loss: 1.3415 - val_accuracy: 0.5519\n",
      "Epoch 974/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2571 - accuracy: 0.5628 - val_loss: 1.2995 - val_accuracy: 0.5942\n",
      "Epoch 975/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2777 - accuracy: 0.5517 - val_loss: 1.2724 - val_accuracy: 0.5877\n",
      "Epoch 976/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2493 - accuracy: 0.5449 - val_loss: 1.2528 - val_accuracy: 0.5942\n",
      "Epoch 977/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2969 - accuracy: 0.5782 - val_loss: 1.2469 - val_accuracy: 0.5812\n",
      "Epoch 978/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2366 - accuracy: 0.5537 - val_loss: 1.2363 - val_accuracy: 0.5909\n",
      "Epoch 979/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2482 - accuracy: 0.5674 - val_loss: 1.2214 - val_accuracy: 0.5877\n",
      "Epoch 980/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2860 - accuracy: 0.5615 - val_loss: 1.2124 - val_accuracy: 0.5877\n",
      "Epoch 981/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2731 - accuracy: 0.5566 - val_loss: 1.2105 - val_accuracy: 0.5844\n",
      "Epoch 982/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2722 - accuracy: 0.5656 - val_loss: 1.2077 - val_accuracy: 0.5844\n",
      "Epoch 983/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2639 - accuracy: 0.5587 - val_loss: 1.2073 - val_accuracy: 0.5779\n",
      "Epoch 984/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2682 - accuracy: 0.5531 - val_loss: 1.2074 - val_accuracy: 0.5779\n",
      "Epoch 985/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3016 - accuracy: 0.5410 - val_loss: 1.2065 - val_accuracy: 0.5747\n",
      "Epoch 986/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2664 - accuracy: 0.5850 - val_loss: 1.2045 - val_accuracy: 0.5844\n",
      "Epoch 987/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2396 - accuracy: 0.5684 - val_loss: 1.2141 - val_accuracy: 0.5877\n",
      "Epoch 988/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2594 - accuracy: 0.5547 - val_loss: 1.2313 - val_accuracy: 0.5779\n",
      "Epoch 989/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2828 - accuracy: 0.5596 - val_loss: 1.2458 - val_accuracy: 0.5747\n",
      "Epoch 990/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2766 - accuracy: 0.5615 - val_loss: 1.2788 - val_accuracy: 0.5584\n",
      "Epoch 991/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2349 - accuracy: 0.5635 - val_loss: 1.3154 - val_accuracy: 0.5682\n",
      "Epoch 992/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2864 - accuracy: 0.5537 - val_loss: 1.3475 - val_accuracy: 0.5552\n",
      "Epoch 993/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2056 - accuracy: 0.5684 - val_loss: 1.3577 - val_accuracy: 0.5519\n",
      "Epoch 994/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2787 - accuracy: 0.5656 - val_loss: 1.3880 - val_accuracy: 0.5390\n",
      "Epoch 995/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2270 - accuracy: 0.5752 - val_loss: 1.4091 - val_accuracy: 0.5357\n",
      "Epoch 996/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2299 - accuracy: 0.5791 - val_loss: 1.4271 - val_accuracy: 0.5390\n",
      "Epoch 997/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3195 - accuracy: 0.5503 - val_loss: 1.4356 - val_accuracy: 0.5325\n",
      "Epoch 998/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3091 - accuracy: 0.5419 - val_loss: 1.4181 - val_accuracy: 0.5455\n",
      "Epoch 999/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1796 - accuracy: 0.5830 - val_loss: 1.3944 - val_accuracy: 0.5422\n",
      "Epoch 1000/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2275 - accuracy: 0.5964 - val_loss: 1.3657 - val_accuracy: 0.5422\n",
      "Epoch 1001/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2496 - accuracy: 0.5605 - val_loss: 1.3458 - val_accuracy: 0.5519\n",
      "Epoch 1002/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3094 - accuracy: 0.5419 - val_loss: 1.3266 - val_accuracy: 0.5617\n",
      "Epoch 1003/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2852 - accuracy: 0.5693 - val_loss: 1.3198 - val_accuracy: 0.5714\n",
      "Epoch 1004/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2692 - accuracy: 0.5559 - val_loss: 1.3230 - val_accuracy: 0.5649\n",
      "Epoch 1005/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2253 - accuracy: 0.5768 - val_loss: 1.3626 - val_accuracy: 0.5617\n",
      "Epoch 1006/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3211 - accuracy: 0.5527 - val_loss: 1.4025 - val_accuracy: 0.5455\n",
      "Epoch 1007/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2109 - accuracy: 0.5908 - val_loss: 1.4461 - val_accuracy: 0.5390\n",
      "Epoch 1008/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2215 - accuracy: 0.5908 - val_loss: 1.4856 - val_accuracy: 0.5260\n",
      "Epoch 1009/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2146 - accuracy: 0.5850 - val_loss: 1.5216 - val_accuracy: 0.5032\n",
      "Epoch 1010/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2612 - accuracy: 0.5605 - val_loss: 1.5464 - val_accuracy: 0.4968\n",
      "Epoch 1011/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2605 - accuracy: 0.5475 - val_loss: 1.5206 - val_accuracy: 0.4968\n",
      "Epoch 1012/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2525 - accuracy: 0.5615 - val_loss: 1.4652 - val_accuracy: 0.5000\n",
      "Epoch 1013/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2098 - accuracy: 0.5967 - val_loss: 1.4040 - val_accuracy: 0.5162\n",
      "Epoch 1014/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2532 - accuracy: 0.5664 - val_loss: 1.3500 - val_accuracy: 0.5487\n",
      "Epoch 1015/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2125 - accuracy: 0.5752 - val_loss: 1.3102 - val_accuracy: 0.5682\n",
      "Epoch 1016/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2197 - accuracy: 0.5820 - val_loss: 1.2945 - val_accuracy: 0.5649\n",
      "Epoch 1017/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1753 - accuracy: 0.5964 - val_loss: 1.2956 - val_accuracy: 0.5617\n",
      "Epoch 1018/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1910 - accuracy: 0.5964 - val_loss: 1.2753 - val_accuracy: 0.5682\n",
      "Epoch 1019/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2292 - accuracy: 0.5880 - val_loss: 1.2599 - val_accuracy: 0.5682\n",
      "Epoch 1020/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2336 - accuracy: 0.5573 - val_loss: 1.2335 - val_accuracy: 0.5747\n",
      "Epoch 1021/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2254 - accuracy: 0.5752 - val_loss: 1.2215 - val_accuracy: 0.5877\n",
      "Epoch 1022/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2316 - accuracy: 0.5879 - val_loss: 1.2124 - val_accuracy: 0.5877\n",
      "Epoch 1023/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2390 - accuracy: 0.5573 - val_loss: 1.2050 - val_accuracy: 0.5974\n",
      "Epoch 1024/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2341 - accuracy: 0.5869 - val_loss: 1.2068 - val_accuracy: 0.5909\n",
      "Epoch 1025/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2464 - accuracy: 0.5670 - val_loss: 1.2098 - val_accuracy: 0.5844\n",
      "Epoch 1026/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2463 - accuracy: 0.5811 - val_loss: 1.2191 - val_accuracy: 0.5877\n",
      "Epoch 1027/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2501 - accuracy: 0.5938 - val_loss: 1.2250 - val_accuracy: 0.5909\n",
      "Epoch 1028/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2204 - accuracy: 0.5967 - val_loss: 1.2247 - val_accuracy: 0.5909\n",
      "Epoch 1029/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2077 - accuracy: 0.5859 - val_loss: 1.2222 - val_accuracy: 0.5909\n",
      "Epoch 1030/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2088 - accuracy: 0.5801 - val_loss: 1.2268 - val_accuracy: 0.5909\n",
      "Epoch 1031/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2132 - accuracy: 0.5824 - val_loss: 1.2318 - val_accuracy: 0.5877\n",
      "Epoch 1032/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2084 - accuracy: 0.5859 - val_loss: 1.2400 - val_accuracy: 0.6006\n",
      "Epoch 1033/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2413 - accuracy: 0.5740 - val_loss: 1.2206 - val_accuracy: 0.5974\n",
      "Epoch 1034/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2341 - accuracy: 0.5781 - val_loss: 1.2012 - val_accuracy: 0.6136\n",
      "Epoch 1035/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2146 - accuracy: 0.5684 - val_loss: 1.1807 - val_accuracy: 0.6136\n",
      "Epoch 1036/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1905 - accuracy: 0.5810 - val_loss: 1.1795 - val_accuracy: 0.6104\n",
      "Epoch 1037/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2256 - accuracy: 0.5754 - val_loss: 1.1923 - val_accuracy: 0.6234\n",
      "Epoch 1038/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2068 - accuracy: 0.5947 - val_loss: 1.2094 - val_accuracy: 0.6104\n",
      "Epoch 1039/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1566 - accuracy: 0.5967 - val_loss: 1.2216 - val_accuracy: 0.6104\n",
      "Epoch 1040/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2035 - accuracy: 0.5723 - val_loss: 1.2212 - val_accuracy: 0.6136\n",
      "Epoch 1041/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2102 - accuracy: 0.5938 - val_loss: 1.2267 - val_accuracy: 0.6039\n",
      "Epoch 1042/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3049 - accuracy: 0.5381 - val_loss: 1.2409 - val_accuracy: 0.5877\n",
      "Epoch 1043/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2020 - accuracy: 0.5964 - val_loss: 1.2421 - val_accuracy: 0.5844\n",
      "Epoch 1044/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1811 - accuracy: 0.6034 - val_loss: 1.2356 - val_accuracy: 0.5877\n",
      "Epoch 1045/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2283 - accuracy: 0.5824 - val_loss: 1.2307 - val_accuracy: 0.5942\n",
      "Epoch 1046/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1843 - accuracy: 0.5824 - val_loss: 1.2222 - val_accuracy: 0.5909\n",
      "Epoch 1047/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2413 - accuracy: 0.5820 - val_loss: 1.2179 - val_accuracy: 0.5877\n",
      "Epoch 1048/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1547 - accuracy: 0.6034 - val_loss: 1.2327 - val_accuracy: 0.5779\n",
      "Epoch 1049/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1930 - accuracy: 0.5918 - val_loss: 1.2416 - val_accuracy: 0.5812\n",
      "Epoch 1050/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2373 - accuracy: 0.5726 - val_loss: 1.2754 - val_accuracy: 0.5779\n",
      "Epoch 1051/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1375 - accuracy: 0.5936 - val_loss: 1.2791 - val_accuracy: 0.5747\n",
      "Epoch 1052/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1452 - accuracy: 0.6064 - val_loss: 1.2705 - val_accuracy: 0.5779\n",
      "Epoch 1053/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2193 - accuracy: 0.5824 - val_loss: 1.2199 - val_accuracy: 0.5909\n",
      "Epoch 1054/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2235 - accuracy: 0.5850 - val_loss: 1.1808 - val_accuracy: 0.5942\n",
      "Epoch 1055/4000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.2586 - accuracy: 0.5830 - val_loss: 1.1383 - val_accuracy: 0.6169\n",
      "Epoch 1056/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1504 - accuracy: 0.6094 - val_loss: 1.1146 - val_accuracy: 0.6396\n",
      "Epoch 1057/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1464 - accuracy: 0.6047 - val_loss: 1.1010 - val_accuracy: 0.6429\n",
      "Epoch 1058/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1601 - accuracy: 0.5824 - val_loss: 1.1084 - val_accuracy: 0.6429\n",
      "Epoch 1059/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2111 - accuracy: 0.5889 - val_loss: 1.1201 - val_accuracy: 0.6494\n",
      "Epoch 1060/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2084 - accuracy: 0.5796 - val_loss: 1.1405 - val_accuracy: 0.6429\n",
      "Epoch 1061/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1662 - accuracy: 0.5928 - val_loss: 1.1681 - val_accuracy: 0.6201\n",
      "Epoch 1062/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1768 - accuracy: 0.6064 - val_loss: 1.1934 - val_accuracy: 0.6104\n",
      "Epoch 1063/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2121 - accuracy: 0.5791 - val_loss: 1.2133 - val_accuracy: 0.6039\n",
      "Epoch 1064/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2324 - accuracy: 0.5880 - val_loss: 1.2318 - val_accuracy: 0.5974\n",
      "Epoch 1065/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1184 - accuracy: 0.6133 - val_loss: 1.2224 - val_accuracy: 0.5974\n",
      "Epoch 1066/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1656 - accuracy: 0.6075 - val_loss: 1.1857 - val_accuracy: 0.6071\n",
      "Epoch 1067/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2457 - accuracy: 0.5596 - val_loss: 1.1480 - val_accuracy: 0.6201\n",
      "Epoch 1068/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2215 - accuracy: 0.5782 - val_loss: 1.1353 - val_accuracy: 0.6136\n",
      "Epoch 1069/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1842 - accuracy: 0.5894 - val_loss: 1.1675 - val_accuracy: 0.6006\n",
      "Epoch 1070/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1944 - accuracy: 0.5768 - val_loss: 1.1901 - val_accuracy: 0.5974\n",
      "Epoch 1071/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1533 - accuracy: 0.6133 - val_loss: 1.2279 - val_accuracy: 0.5974\n",
      "Epoch 1072/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1871 - accuracy: 0.5781 - val_loss: 1.2759 - val_accuracy: 0.5714\n",
      "Epoch 1073/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2172 - accuracy: 0.5918 - val_loss: 1.3023 - val_accuracy: 0.5487\n",
      "Epoch 1074/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1602 - accuracy: 0.6075 - val_loss: 1.3132 - val_accuracy: 0.5455\n",
      "Epoch 1075/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1793 - accuracy: 0.5879 - val_loss: 1.2748 - val_accuracy: 0.5487\n",
      "Epoch 1076/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1855 - accuracy: 0.5922 - val_loss: 1.2248 - val_accuracy: 0.5844\n",
      "Epoch 1077/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1803 - accuracy: 0.6145 - val_loss: 1.1837 - val_accuracy: 0.6006\n",
      "Epoch 1078/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1468 - accuracy: 0.5986 - val_loss: 1.1491 - val_accuracy: 0.6039\n",
      "Epoch 1079/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2290 - accuracy: 0.5852 - val_loss: 1.1247 - val_accuracy: 0.6169\n",
      "Epoch 1080/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1844 - accuracy: 0.5938 - val_loss: 1.1126 - val_accuracy: 0.6331\n",
      "Epoch 1081/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1199 - accuracy: 0.6215 - val_loss: 1.1024 - val_accuracy: 0.6299\n",
      "Epoch 1082/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1666 - accuracy: 0.5879 - val_loss: 1.1049 - val_accuracy: 0.6266\n",
      "Epoch 1083/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2073 - accuracy: 0.5782 - val_loss: 1.1068 - val_accuracy: 0.6201\n",
      "Epoch 1084/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1817 - accuracy: 0.6084 - val_loss: 1.1121 - val_accuracy: 0.6104\n",
      "Epoch 1085/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1556 - accuracy: 0.6089 - val_loss: 1.1186 - val_accuracy: 0.6136\n",
      "Epoch 1086/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1980 - accuracy: 0.5964 - val_loss: 1.1272 - val_accuracy: 0.6104\n",
      "Epoch 1087/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1287 - accuracy: 0.6064 - val_loss: 1.1387 - val_accuracy: 0.6104\n",
      "Epoch 1088/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2165 - accuracy: 0.5645 - val_loss: 1.1521 - val_accuracy: 0.5974\n",
      "Epoch 1089/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2081 - accuracy: 0.5936 - val_loss: 1.1560 - val_accuracy: 0.5942\n",
      "Epoch 1090/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1520 - accuracy: 0.6074 - val_loss: 1.1616 - val_accuracy: 0.5909\n",
      "Epoch 1091/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1097 - accuracy: 0.6411 - val_loss: 1.1606 - val_accuracy: 0.5942\n",
      "Epoch 1092/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1542 - accuracy: 0.6035 - val_loss: 1.1517 - val_accuracy: 0.5974\n",
      "Epoch 1093/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1316 - accuracy: 0.6211 - val_loss: 1.1421 - val_accuracy: 0.6006\n",
      "Epoch 1094/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1748 - accuracy: 0.6133 - val_loss: 1.1180 - val_accuracy: 0.6071\n",
      "Epoch 1095/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1326 - accuracy: 0.6025 - val_loss: 1.0961 - val_accuracy: 0.6234\n",
      "Epoch 1096/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2117 - accuracy: 0.5740 - val_loss: 1.0878 - val_accuracy: 0.6201\n",
      "Epoch 1097/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1867 - accuracy: 0.5894 - val_loss: 1.0914 - val_accuracy: 0.6136\n",
      "Epoch 1098/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1341 - accuracy: 0.6103 - val_loss: 1.0949 - val_accuracy: 0.6201\n",
      "Epoch 1099/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1416 - accuracy: 0.6162 - val_loss: 1.0887 - val_accuracy: 0.6299\n",
      "Epoch 1100/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1185 - accuracy: 0.6103 - val_loss: 1.0843 - val_accuracy: 0.6201\n",
      "Epoch 1101/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1187 - accuracy: 0.6103 - val_loss: 1.0835 - val_accuracy: 0.6169\n",
      "Epoch 1102/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1604 - accuracy: 0.6074 - val_loss: 1.0937 - val_accuracy: 0.6136\n",
      "Epoch 1103/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1000 - accuracy: 0.6289 - val_loss: 1.1091 - val_accuracy: 0.6071\n",
      "Epoch 1104/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2400 - accuracy: 0.5503 - val_loss: 1.1244 - val_accuracy: 0.5974\n",
      "Epoch 1105/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1718 - accuracy: 0.6016 - val_loss: 1.1428 - val_accuracy: 0.6006\n",
      "Epoch 1106/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1989 - accuracy: 0.5889 - val_loss: 1.1635 - val_accuracy: 0.6039\n",
      "Epoch 1107/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0755 - accuracy: 0.6215 - val_loss: 1.1907 - val_accuracy: 0.5942\n",
      "Epoch 1108/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0999 - accuracy: 0.6162 - val_loss: 1.2165 - val_accuracy: 0.5844\n",
      "Epoch 1109/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1175 - accuracy: 0.6271 - val_loss: 1.2531 - val_accuracy: 0.5747\n",
      "Epoch 1110/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1693 - accuracy: 0.6145 - val_loss: 1.2761 - val_accuracy: 0.5552\n",
      "Epoch 1111/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0948 - accuracy: 0.6145 - val_loss: 1.2962 - val_accuracy: 0.5617\n",
      "Epoch 1112/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1637 - accuracy: 0.6123 - val_loss: 1.3033 - val_accuracy: 0.5519\n",
      "Epoch 1113/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1495 - accuracy: 0.6240 - val_loss: 1.3104 - val_accuracy: 0.5487\n",
      "Epoch 1114/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1391 - accuracy: 0.6172 - val_loss: 1.2822 - val_accuracy: 0.5584\n",
      "Epoch 1115/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1197 - accuracy: 0.6172 - val_loss: 1.2699 - val_accuracy: 0.5519\n",
      "Epoch 1116/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2109 - accuracy: 0.6020 - val_loss: 1.2795 - val_accuracy: 0.5682\n",
      "Epoch 1117/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1681 - accuracy: 0.5894 - val_loss: 1.3234 - val_accuracy: 0.5682\n",
      "Epoch 1118/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0816 - accuracy: 0.6104 - val_loss: 1.3892 - val_accuracy: 0.5519\n",
      "Epoch 1119/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1038 - accuracy: 0.6133 - val_loss: 1.4714 - val_accuracy: 0.5390\n",
      "Epoch 1120/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0930 - accuracy: 0.6313 - val_loss: 1.5615 - val_accuracy: 0.5162\n",
      "Epoch 1121/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0933 - accuracy: 0.6377 - val_loss: 1.6096 - val_accuracy: 0.5227\n",
      "Epoch 1122/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1404 - accuracy: 0.6201 - val_loss: 1.6209 - val_accuracy: 0.5097\n",
      "Epoch 1123/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1227 - accuracy: 0.6020 - val_loss: 1.6042 - val_accuracy: 0.5097\n",
      "Epoch 1124/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1682 - accuracy: 0.6104 - val_loss: 1.5164 - val_accuracy: 0.5195\n",
      "Epoch 1125/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1325 - accuracy: 0.6173 - val_loss: 1.4168 - val_accuracy: 0.5519\n",
      "Epoch 1126/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1113 - accuracy: 0.6201 - val_loss: 1.3176 - val_accuracy: 0.5682\n",
      "Epoch 1127/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1382 - accuracy: 0.6299 - val_loss: 1.2583 - val_accuracy: 0.5844\n",
      "Epoch 1128/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0894 - accuracy: 0.6145 - val_loss: 1.2020 - val_accuracy: 0.5909\n",
      "Epoch 1129/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1406 - accuracy: 0.6143 - val_loss: 1.1726 - val_accuracy: 0.5974\n",
      "Epoch 1130/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2017 - accuracy: 0.5908 - val_loss: 1.1679 - val_accuracy: 0.5877\n",
      "Epoch 1131/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1071 - accuracy: 0.6191 - val_loss: 1.1714 - val_accuracy: 0.5942\n",
      "Epoch 1132/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0936 - accuracy: 0.6162 - val_loss: 1.1613 - val_accuracy: 0.5974\n",
      "Epoch 1133/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1135 - accuracy: 0.6243 - val_loss: 1.1484 - val_accuracy: 0.5974\n",
      "Epoch 1134/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0885 - accuracy: 0.6445 - val_loss: 1.1313 - val_accuracy: 0.6006\n",
      "Epoch 1135/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1138 - accuracy: 0.6313 - val_loss: 1.1324 - val_accuracy: 0.5942\n",
      "Epoch 1136/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1588 - accuracy: 0.5838 - val_loss: 1.1542 - val_accuracy: 0.5942\n",
      "Epoch 1137/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1655 - accuracy: 0.6094 - val_loss: 1.1956 - val_accuracy: 0.5844\n",
      "Epoch 1138/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1088 - accuracy: 0.6172 - val_loss: 1.2373 - val_accuracy: 0.5649\n",
      "Epoch 1139/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1132 - accuracy: 0.6211 - val_loss: 1.2824 - val_accuracy: 0.5487\n",
      "Epoch 1140/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0894 - accuracy: 0.6215 - val_loss: 1.3260 - val_accuracy: 0.5390\n",
      "Epoch 1141/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1443 - accuracy: 0.5922 - val_loss: 1.3226 - val_accuracy: 0.5390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1142/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0452 - accuracy: 0.6367 - val_loss: 1.2961 - val_accuracy: 0.5357\n",
      "Epoch 1143/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1183 - accuracy: 0.6123 - val_loss: 1.2720 - val_accuracy: 0.5455\n",
      "Epoch 1144/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1568 - accuracy: 0.5936 - val_loss: 1.2268 - val_accuracy: 0.5682\n",
      "Epoch 1145/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1254 - accuracy: 0.6257 - val_loss: 1.1817 - val_accuracy: 0.5747\n",
      "Epoch 1146/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1072 - accuracy: 0.6243 - val_loss: 1.1469 - val_accuracy: 0.5942\n",
      "Epoch 1147/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1222 - accuracy: 0.6229 - val_loss: 1.1315 - val_accuracy: 0.5974\n",
      "Epoch 1148/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1087 - accuracy: 0.6377 - val_loss: 1.1400 - val_accuracy: 0.6006\n",
      "Epoch 1149/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1174 - accuracy: 0.6075 - val_loss: 1.1578 - val_accuracy: 0.6006\n",
      "Epoch 1150/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0727 - accuracy: 0.6299 - val_loss: 1.1622 - val_accuracy: 0.6039\n",
      "Epoch 1151/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1116 - accuracy: 0.6341 - val_loss: 1.1592 - val_accuracy: 0.6136\n",
      "Epoch 1152/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1283 - accuracy: 0.6094 - val_loss: 1.1501 - val_accuracy: 0.6039\n",
      "Epoch 1153/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0821 - accuracy: 0.6257 - val_loss: 1.1577 - val_accuracy: 0.6136\n",
      "Epoch 1154/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1092 - accuracy: 0.6260 - val_loss: 1.1685 - val_accuracy: 0.5942\n",
      "Epoch 1155/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1123 - accuracy: 0.6211 - val_loss: 1.1631 - val_accuracy: 0.5909\n",
      "Epoch 1156/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0523 - accuracy: 0.6466 - val_loss: 1.1604 - val_accuracy: 0.5942\n",
      "Epoch 1157/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0600 - accuracy: 0.6270 - val_loss: 1.1506 - val_accuracy: 0.6104\n",
      "Epoch 1158/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.0771 - accuracy: 0.6285 - val_loss: 1.1488 - val_accuracy: 0.6136\n",
      "Epoch 1159/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0744 - accuracy: 0.6230 - val_loss: 1.1392 - val_accuracy: 0.6234\n",
      "Epoch 1160/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1228 - accuracy: 0.6369 - val_loss: 1.1312 - val_accuracy: 0.6169\n",
      "Epoch 1161/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0662 - accuracy: 0.6309 - val_loss: 1.1282 - val_accuracy: 0.5942\n",
      "Epoch 1162/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1267 - accuracy: 0.6215 - val_loss: 1.1308 - val_accuracy: 0.5747\n",
      "Epoch 1163/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0885 - accuracy: 0.6230 - val_loss: 1.1315 - val_accuracy: 0.5747\n",
      "Epoch 1164/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0370 - accuracy: 0.6338 - val_loss: 1.1388 - val_accuracy: 0.5812\n",
      "Epoch 1165/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0981 - accuracy: 0.6285 - val_loss: 1.1546 - val_accuracy: 0.5779\n",
      "Epoch 1166/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0811 - accuracy: 0.6211 - val_loss: 1.1694 - val_accuracy: 0.5714\n",
      "Epoch 1167/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1701 - accuracy: 0.6006 - val_loss: 1.1787 - val_accuracy: 0.5747\n",
      "Epoch 1168/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1059 - accuracy: 0.6494 - val_loss: 1.1804 - val_accuracy: 0.5779\n",
      "Epoch 1169/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0844 - accuracy: 0.6369 - val_loss: 1.1846 - val_accuracy: 0.5779\n",
      "Epoch 1170/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0303 - accuracy: 0.6504 - val_loss: 1.1970 - val_accuracy: 0.5844\n",
      "Epoch 1171/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0819 - accuracy: 0.6426 - val_loss: 1.2008 - val_accuracy: 0.5909\n",
      "Epoch 1172/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1226 - accuracy: 0.6162 - val_loss: 1.1930 - val_accuracy: 0.5779\n",
      "Epoch 1173/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0357 - accuracy: 0.6550 - val_loss: 1.1889 - val_accuracy: 0.5844\n",
      "Epoch 1174/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0722 - accuracy: 0.6397 - val_loss: 1.1821 - val_accuracy: 0.5747\n",
      "Epoch 1175/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0585 - accuracy: 0.6426 - val_loss: 1.1738 - val_accuracy: 0.5779\n",
      "Epoch 1176/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0388 - accuracy: 0.6536 - val_loss: 1.1643 - val_accuracy: 0.5877\n",
      "Epoch 1177/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1054 - accuracy: 0.6240 - val_loss: 1.1613 - val_accuracy: 0.5974\n",
      "Epoch 1178/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0460 - accuracy: 0.6387 - val_loss: 1.1633 - val_accuracy: 0.5942\n",
      "Epoch 1179/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1101 - accuracy: 0.6270 - val_loss: 1.1798 - val_accuracy: 0.5812\n",
      "Epoch 1180/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1432 - accuracy: 0.6327 - val_loss: 1.1917 - val_accuracy: 0.5747\n",
      "Epoch 1181/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0415 - accuracy: 0.6439 - val_loss: 1.1889 - val_accuracy: 0.6104\n",
      "Epoch 1182/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0912 - accuracy: 0.6387 - val_loss: 1.1673 - val_accuracy: 0.6104\n",
      "Epoch 1183/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1005 - accuracy: 0.6131 - val_loss: 1.1425 - val_accuracy: 0.6169\n",
      "Epoch 1184/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0978 - accuracy: 0.6328 - val_loss: 1.1180 - val_accuracy: 0.6234\n",
      "Epoch 1185/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0899 - accuracy: 0.6289 - val_loss: 1.0981 - val_accuracy: 0.6039\n",
      "Epoch 1186/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0244 - accuracy: 0.6508 - val_loss: 1.0873 - val_accuracy: 0.6169\n",
      "Epoch 1187/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1087 - accuracy: 0.6240 - val_loss: 1.1045 - val_accuracy: 0.6169\n",
      "Epoch 1188/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0618 - accuracy: 0.6348 - val_loss: 1.1269 - val_accuracy: 0.6104\n",
      "Epoch 1189/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0734 - accuracy: 0.6260 - val_loss: 1.1488 - val_accuracy: 0.5942\n",
      "Epoch 1190/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0806 - accuracy: 0.6289 - val_loss: 1.1920 - val_accuracy: 0.5974\n",
      "Epoch 1191/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0684 - accuracy: 0.6377 - val_loss: 1.2183 - val_accuracy: 0.5909\n",
      "Epoch 1192/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0424 - accuracy: 0.6369 - val_loss: 1.2524 - val_accuracy: 0.5877\n",
      "Epoch 1193/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0467 - accuracy: 0.6426 - val_loss: 1.2665 - val_accuracy: 0.5844\n",
      "Epoch 1194/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0370 - accuracy: 0.6536 - val_loss: 1.2554 - val_accuracy: 0.5844\n",
      "Epoch 1195/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0374 - accuracy: 0.6480 - val_loss: 1.2496 - val_accuracy: 0.5877\n",
      "Epoch 1196/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0797 - accuracy: 0.6113 - val_loss: 1.2572 - val_accuracy: 0.5844\n",
      "Epoch 1197/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0541 - accuracy: 0.6543 - val_loss: 1.2729 - val_accuracy: 0.5812\n",
      "Epoch 1198/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0505 - accuracy: 0.6355 - val_loss: 1.3056 - val_accuracy: 0.5649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1199/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1041 - accuracy: 0.6191 - val_loss: 1.3476 - val_accuracy: 0.5714\n",
      "Epoch 1200/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0735 - accuracy: 0.6348 - val_loss: 1.3675 - val_accuracy: 0.5617\n",
      "Epoch 1201/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0849 - accuracy: 0.6338 - val_loss: 1.3686 - val_accuracy: 0.5584\n",
      "Epoch 1202/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0975 - accuracy: 0.6445 - val_loss: 1.3793 - val_accuracy: 0.5552\n",
      "Epoch 1203/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0328 - accuracy: 0.6523 - val_loss: 1.3727 - val_accuracy: 0.5617\n",
      "Epoch 1204/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0505 - accuracy: 0.6257 - val_loss: 1.3932 - val_accuracy: 0.5455\n",
      "Epoch 1205/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0169 - accuracy: 0.6522 - val_loss: 1.4052 - val_accuracy: 0.5455\n",
      "Epoch 1206/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0235 - accuracy: 0.6465 - val_loss: 1.4137 - val_accuracy: 0.5390\n",
      "Epoch 1207/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0551 - accuracy: 0.6367 - val_loss: 1.4393 - val_accuracy: 0.5357\n",
      "Epoch 1208/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0090 - accuracy: 0.6522 - val_loss: 1.4223 - val_accuracy: 0.5325\n",
      "Epoch 1209/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1371 - accuracy: 0.6182 - val_loss: 1.3974 - val_accuracy: 0.5390\n",
      "Epoch 1210/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0428 - accuracy: 0.6411 - val_loss: 1.3710 - val_accuracy: 0.5422\n",
      "Epoch 1211/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1033 - accuracy: 0.6250 - val_loss: 1.3407 - val_accuracy: 0.5552\n",
      "Epoch 1212/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1013 - accuracy: 0.6172 - val_loss: 1.3072 - val_accuracy: 0.5682\n",
      "Epoch 1213/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0115 - accuracy: 0.6704 - val_loss: 1.3113 - val_accuracy: 0.5714\n",
      "Epoch 1214/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0264 - accuracy: 0.6357 - val_loss: 1.3278 - val_accuracy: 0.5682\n",
      "Epoch 1215/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0848 - accuracy: 0.6367 - val_loss: 1.3459 - val_accuracy: 0.5487\n",
      "Epoch 1216/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0575 - accuracy: 0.6465 - val_loss: 1.3490 - val_accuracy: 0.5487\n",
      "Epoch 1217/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0033 - accuracy: 0.6662 - val_loss: 1.3412 - val_accuracy: 0.5455\n",
      "Epoch 1218/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0377 - accuracy: 0.6411 - val_loss: 1.3149 - val_accuracy: 0.5552\n",
      "Epoch 1219/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0666 - accuracy: 0.6355 - val_loss: 1.2897 - val_accuracy: 0.5519\n",
      "Epoch 1220/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0136 - accuracy: 0.6550 - val_loss: 1.2604 - val_accuracy: 0.5682\n",
      "Epoch 1221/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9955 - accuracy: 0.6650 - val_loss: 1.2333 - val_accuracy: 0.5682\n",
      "Epoch 1222/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0765 - accuracy: 0.6318 - val_loss: 1.2057 - val_accuracy: 0.5779\n",
      "Epoch 1223/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0546 - accuracy: 0.6387 - val_loss: 1.1909 - val_accuracy: 0.5844\n",
      "Epoch 1224/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0430 - accuracy: 0.6455 - val_loss: 1.2011 - val_accuracy: 0.5812\n",
      "Epoch 1225/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0412 - accuracy: 0.6522 - val_loss: 1.2430 - val_accuracy: 0.5747\n",
      "Epoch 1226/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0388 - accuracy: 0.6533 - val_loss: 1.2949 - val_accuracy: 0.5649\n",
      "Epoch 1227/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0026 - accuracy: 0.6611 - val_loss: 1.3389 - val_accuracy: 0.5487\n",
      "Epoch 1228/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0843 - accuracy: 0.6355 - val_loss: 1.3568 - val_accuracy: 0.5519\n",
      "Epoch 1229/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0324 - accuracy: 0.6411 - val_loss: 1.3612 - val_accuracy: 0.5487\n",
      "Epoch 1230/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0718 - accuracy: 0.6367 - val_loss: 1.3389 - val_accuracy: 0.5552\n",
      "Epoch 1231/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0991 - accuracy: 0.6313 - val_loss: 1.3441 - val_accuracy: 0.5617\n",
      "Epoch 1232/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0451 - accuracy: 0.6348 - val_loss: 1.3693 - val_accuracy: 0.5552\n",
      "Epoch 1233/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0908 - accuracy: 0.6466 - val_loss: 1.3741 - val_accuracy: 0.5552\n",
      "Epoch 1234/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0111 - accuracy: 0.6709 - val_loss: 1.4032 - val_accuracy: 0.5519\n",
      "Epoch 1235/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0466 - accuracy: 0.6377 - val_loss: 1.4311 - val_accuracy: 0.5357\n",
      "Epoch 1236/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0357 - accuracy: 0.6453 - val_loss: 1.4237 - val_accuracy: 0.5357\n",
      "Epoch 1237/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9842 - accuracy: 0.6729 - val_loss: 1.4091 - val_accuracy: 0.5455\n",
      "Epoch 1238/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0321 - accuracy: 0.6453 - val_loss: 1.3565 - val_accuracy: 0.5617\n",
      "Epoch 1239/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0915 - accuracy: 0.6338 - val_loss: 1.3121 - val_accuracy: 0.5682\n",
      "Epoch 1240/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0205 - accuracy: 0.6536 - val_loss: 1.2630 - val_accuracy: 0.5747\n",
      "Epoch 1241/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0268 - accuracy: 0.6508 - val_loss: 1.2469 - val_accuracy: 0.5779\n",
      "Epoch 1242/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0682 - accuracy: 0.6285 - val_loss: 1.2306 - val_accuracy: 0.5747\n",
      "Epoch 1243/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0793 - accuracy: 0.6313 - val_loss: 1.2186 - val_accuracy: 0.5877\n",
      "Epoch 1244/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9883 - accuracy: 0.6650 - val_loss: 1.2180 - val_accuracy: 0.5877\n",
      "Epoch 1245/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0763 - accuracy: 0.6327 - val_loss: 1.2305 - val_accuracy: 0.5844\n",
      "Epoch 1246/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0585 - accuracy: 0.6411 - val_loss: 1.2647 - val_accuracy: 0.5779\n",
      "Epoch 1247/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0076 - accuracy: 0.6523 - val_loss: 1.2985 - val_accuracy: 0.5779\n",
      "Epoch 1248/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0817 - accuracy: 0.6250 - val_loss: 1.3202 - val_accuracy: 0.5812\n",
      "Epoch 1249/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0303 - accuracy: 0.6411 - val_loss: 1.3177 - val_accuracy: 0.5747\n",
      "Epoch 1250/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0017 - accuracy: 0.6582 - val_loss: 1.3021 - val_accuracy: 0.5682\n",
      "Epoch 1251/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0408 - accuracy: 0.6872 - val_loss: 1.2974 - val_accuracy: 0.5617\n",
      "Epoch 1252/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0425 - accuracy: 0.6550 - val_loss: 1.2969 - val_accuracy: 0.5422\n",
      "Epoch 1253/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0416 - accuracy: 0.6522 - val_loss: 1.3080 - val_accuracy: 0.5292\n",
      "Epoch 1254/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0324 - accuracy: 0.6564 - val_loss: 1.2976 - val_accuracy: 0.5390\n",
      "Epoch 1255/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1154 - accuracy: 0.6348 - val_loss: 1.2649 - val_accuracy: 0.5519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1256/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9710 - accuracy: 0.6660 - val_loss: 1.2305 - val_accuracy: 0.5682\n",
      "Epoch 1257/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0238 - accuracy: 0.6606 - val_loss: 1.2512 - val_accuracy: 0.5812\n",
      "Epoch 1258/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.0424 - accuracy: 0.6494 - val_loss: 1.2700 - val_accuracy: 0.5779\n",
      "Epoch 1259/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1036 - accuracy: 0.6055 - val_loss: 1.2601 - val_accuracy: 0.5779\n",
      "Epoch 1260/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0136 - accuracy: 0.6634 - val_loss: 1.2257 - val_accuracy: 0.5942\n",
      "Epoch 1261/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9823 - accuracy: 0.6816 - val_loss: 1.1874 - val_accuracy: 0.5974\n",
      "Epoch 1262/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0253 - accuracy: 0.6453 - val_loss: 1.1527 - val_accuracy: 0.5942\n",
      "Epoch 1263/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0434 - accuracy: 0.6533 - val_loss: 1.1384 - val_accuracy: 0.5974\n",
      "Epoch 1264/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0067 - accuracy: 0.6504 - val_loss: 1.1308 - val_accuracy: 0.5909\n",
      "Epoch 1265/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0381 - accuracy: 0.6299 - val_loss: 1.1456 - val_accuracy: 0.6104\n",
      "Epoch 1266/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0040 - accuracy: 0.6572 - val_loss: 1.1615 - val_accuracy: 0.6071\n",
      "Epoch 1267/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9896 - accuracy: 0.6660 - val_loss: 1.1733 - val_accuracy: 0.5909\n",
      "Epoch 1268/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9906 - accuracy: 0.6729 - val_loss: 1.1880 - val_accuracy: 0.5942\n",
      "Epoch 1269/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9883 - accuracy: 0.6816 - val_loss: 1.1986 - val_accuracy: 0.5844\n",
      "Epoch 1270/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0412 - accuracy: 0.6406 - val_loss: 1.1911 - val_accuracy: 0.5812\n",
      "Epoch 1271/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0655 - accuracy: 0.6397 - val_loss: 1.1705 - val_accuracy: 0.5877\n",
      "Epoch 1272/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0183 - accuracy: 0.6508 - val_loss: 1.1399 - val_accuracy: 0.5974\n",
      "Epoch 1273/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9494 - accuracy: 0.6680 - val_loss: 1.1046 - val_accuracy: 0.6071\n",
      "Epoch 1274/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0437 - accuracy: 0.6369 - val_loss: 1.0852 - val_accuracy: 0.6104\n",
      "Epoch 1275/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0316 - accuracy: 0.6536 - val_loss: 1.0759 - val_accuracy: 0.6104\n",
      "Epoch 1276/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0409 - accuracy: 0.6313 - val_loss: 1.0758 - val_accuracy: 0.6039\n",
      "Epoch 1277/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0658 - accuracy: 0.6494 - val_loss: 1.0758 - val_accuracy: 0.6136\n",
      "Epoch 1278/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9940 - accuracy: 0.6662 - val_loss: 1.0959 - val_accuracy: 0.6234\n",
      "Epoch 1279/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9522 - accuracy: 0.6865 - val_loss: 1.1112 - val_accuracy: 0.6136\n",
      "Epoch 1280/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9935 - accuracy: 0.6631 - val_loss: 1.1101 - val_accuracy: 0.6234\n",
      "Epoch 1281/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9629 - accuracy: 0.6788 - val_loss: 1.0902 - val_accuracy: 0.6266\n",
      "Epoch 1282/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0311 - accuracy: 0.6660 - val_loss: 1.0708 - val_accuracy: 0.6331\n",
      "Epoch 1283/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9700 - accuracy: 0.6453 - val_loss: 1.0571 - val_accuracy: 0.6364\n",
      "Epoch 1284/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9929 - accuracy: 0.6680 - val_loss: 1.0640 - val_accuracy: 0.6299\n",
      "Epoch 1285/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0177 - accuracy: 0.6648 - val_loss: 1.0841 - val_accuracy: 0.6169\n",
      "Epoch 1286/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0257 - accuracy: 0.6578 - val_loss: 1.1142 - val_accuracy: 0.6201\n",
      "Epoch 1287/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0137 - accuracy: 0.6436 - val_loss: 1.1546 - val_accuracy: 0.6006\n",
      "Epoch 1288/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9735 - accuracy: 0.6662 - val_loss: 1.2072 - val_accuracy: 0.6006\n",
      "Epoch 1289/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9555 - accuracy: 0.6924 - val_loss: 1.2431 - val_accuracy: 0.6071\n",
      "Epoch 1290/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9863 - accuracy: 0.6690 - val_loss: 1.2512 - val_accuracy: 0.5974\n",
      "Epoch 1291/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9833 - accuracy: 0.6484 - val_loss: 1.2292 - val_accuracy: 0.6071\n",
      "Epoch 1292/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9950 - accuracy: 0.6572 - val_loss: 1.2171 - val_accuracy: 0.5942\n",
      "Epoch 1293/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0168 - accuracy: 0.6550 - val_loss: 1.2084 - val_accuracy: 0.6006\n",
      "Epoch 1294/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9739 - accuracy: 0.6955 - val_loss: 1.1851 - val_accuracy: 0.6201\n",
      "Epoch 1295/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9530 - accuracy: 0.6872 - val_loss: 1.1399 - val_accuracy: 0.6201\n",
      "Epoch 1296/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0168 - accuracy: 0.6621 - val_loss: 1.1148 - val_accuracy: 0.6136\n",
      "Epoch 1297/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9978 - accuracy: 0.6611 - val_loss: 1.1065 - val_accuracy: 0.6136\n",
      "Epoch 1298/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9997 - accuracy: 0.6578 - val_loss: 1.1015 - val_accuracy: 0.6201\n",
      "Epoch 1299/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9799 - accuracy: 0.6802 - val_loss: 1.1128 - val_accuracy: 0.6201\n",
      "Epoch 1300/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9750 - accuracy: 0.6738 - val_loss: 1.1304 - val_accuracy: 0.6136\n",
      "Epoch 1301/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9795 - accuracy: 0.6760 - val_loss: 1.1459 - val_accuracy: 0.6071\n",
      "Epoch 1302/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9485 - accuracy: 0.6758 - val_loss: 1.1549 - val_accuracy: 0.6039\n",
      "Epoch 1303/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9432 - accuracy: 0.6760 - val_loss: 1.1561 - val_accuracy: 0.6006\n",
      "Epoch 1304/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0031 - accuracy: 0.6611 - val_loss: 1.1693 - val_accuracy: 0.5974\n",
      "Epoch 1305/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0025 - accuracy: 0.6641 - val_loss: 1.1589 - val_accuracy: 0.6039\n",
      "Epoch 1306/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9675 - accuracy: 0.6631 - val_loss: 1.1347 - val_accuracy: 0.6136\n",
      "Epoch 1307/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9737 - accuracy: 0.6777 - val_loss: 1.1015 - val_accuracy: 0.6299\n",
      "Epoch 1308/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9655 - accuracy: 0.6797 - val_loss: 1.0749 - val_accuracy: 0.6364\n",
      "Epoch 1309/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9393 - accuracy: 0.6875 - val_loss: 1.0584 - val_accuracy: 0.6429\n",
      "Epoch 1310/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9726 - accuracy: 0.6592 - val_loss: 1.0465 - val_accuracy: 0.6396\n",
      "Epoch 1311/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9466 - accuracy: 0.6844 - val_loss: 1.0427 - val_accuracy: 0.6494\n",
      "Epoch 1312/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9486 - accuracy: 0.6865 - val_loss: 1.0410 - val_accuracy: 0.6461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1313/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9726 - accuracy: 0.6816 - val_loss: 1.0493 - val_accuracy: 0.6266\n",
      "Epoch 1314/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0321 - accuracy: 0.6602 - val_loss: 1.0572 - val_accuracy: 0.6266\n",
      "Epoch 1315/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9759 - accuracy: 0.6699 - val_loss: 1.0698 - val_accuracy: 0.6364\n",
      "Epoch 1316/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9165 - accuracy: 0.6836 - val_loss: 1.0696 - val_accuracy: 0.6299\n",
      "Epoch 1317/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9605 - accuracy: 0.6924 - val_loss: 1.0667 - val_accuracy: 0.6364\n",
      "Epoch 1318/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9307 - accuracy: 0.6758 - val_loss: 1.0716 - val_accuracy: 0.6364\n",
      "Epoch 1319/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9961 - accuracy: 0.6718 - val_loss: 1.0687 - val_accuracy: 0.6429\n",
      "Epoch 1320/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9725 - accuracy: 0.6718 - val_loss: 1.0691 - val_accuracy: 0.6331\n",
      "Epoch 1321/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9605 - accuracy: 0.6802 - val_loss: 1.0539 - val_accuracy: 0.6364\n",
      "Epoch 1322/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9323 - accuracy: 0.6768 - val_loss: 1.0502 - val_accuracy: 0.6266\n",
      "Epoch 1323/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9543 - accuracy: 0.6858 - val_loss: 1.0570 - val_accuracy: 0.6266\n",
      "Epoch 1324/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9393 - accuracy: 0.6844 - val_loss: 1.0673 - val_accuracy: 0.6299\n",
      "Epoch 1325/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9339 - accuracy: 0.6746 - val_loss: 1.0852 - val_accuracy: 0.6234\n",
      "Epoch 1326/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0095 - accuracy: 0.6504 - val_loss: 1.0984 - val_accuracy: 0.6169\n",
      "Epoch 1327/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9856 - accuracy: 0.6729 - val_loss: 1.0902 - val_accuracy: 0.6039\n",
      "Epoch 1328/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9673 - accuracy: 0.6621 - val_loss: 1.0793 - val_accuracy: 0.6006\n",
      "Epoch 1329/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9301 - accuracy: 0.6941 - val_loss: 1.0763 - val_accuracy: 0.6201\n",
      "Epoch 1330/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9668 - accuracy: 0.6830 - val_loss: 1.0749 - val_accuracy: 0.6234\n",
      "Epoch 1331/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9747 - accuracy: 0.6729 - val_loss: 1.0815 - val_accuracy: 0.6234\n",
      "Epoch 1332/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9257 - accuracy: 0.6969 - val_loss: 1.0964 - val_accuracy: 0.6071\n",
      "Epoch 1333/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0539 - accuracy: 0.6328 - val_loss: 1.1074 - val_accuracy: 0.6104\n",
      "Epoch 1334/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9592 - accuracy: 0.6774 - val_loss: 1.1167 - val_accuracy: 0.6104\n",
      "Epoch 1335/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9716 - accuracy: 0.6592 - val_loss: 1.1390 - val_accuracy: 0.6104\n",
      "Epoch 1336/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9502 - accuracy: 0.6816 - val_loss: 1.1435 - val_accuracy: 0.6071\n",
      "Epoch 1337/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9798 - accuracy: 0.6872 - val_loss: 1.1409 - val_accuracy: 0.6136\n",
      "Epoch 1338/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9908 - accuracy: 0.6606 - val_loss: 1.1430 - val_accuracy: 0.6169\n",
      "Epoch 1339/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9257 - accuracy: 0.6844 - val_loss: 1.1365 - val_accuracy: 0.6104\n",
      "Epoch 1340/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9422 - accuracy: 0.6895 - val_loss: 1.1272 - val_accuracy: 0.6169\n",
      "Epoch 1341/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9653 - accuracy: 0.6621 - val_loss: 1.1096 - val_accuracy: 0.6201\n",
      "Epoch 1342/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9158 - accuracy: 0.6963 - val_loss: 1.0835 - val_accuracy: 0.6331\n",
      "Epoch 1343/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9845 - accuracy: 0.6689 - val_loss: 1.0830 - val_accuracy: 0.6364\n",
      "Epoch 1344/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8784 - accuracy: 0.7123 - val_loss: 1.0837 - val_accuracy: 0.6299\n",
      "Epoch 1345/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9445 - accuracy: 0.6872 - val_loss: 1.0930 - val_accuracy: 0.6396\n",
      "Epoch 1346/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9643 - accuracy: 0.6802 - val_loss: 1.0989 - val_accuracy: 0.6266\n",
      "Epoch 1347/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0106 - accuracy: 0.6582 - val_loss: 1.1112 - val_accuracy: 0.6234\n",
      "Epoch 1348/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9384 - accuracy: 0.6858 - val_loss: 1.1537 - val_accuracy: 0.6136\n",
      "Epoch 1349/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9545 - accuracy: 0.6885 - val_loss: 1.2026 - val_accuracy: 0.6039\n",
      "Epoch 1350/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9433 - accuracy: 0.6620 - val_loss: 1.2300 - val_accuracy: 0.5974\n",
      "Epoch 1351/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9353 - accuracy: 0.6885 - val_loss: 1.2798 - val_accuracy: 0.5877\n",
      "Epoch 1352/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9376 - accuracy: 0.6914 - val_loss: 1.3333 - val_accuracy: 0.5779\n",
      "Epoch 1353/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9750 - accuracy: 0.6564 - val_loss: 1.3509 - val_accuracy: 0.5617\n",
      "Epoch 1354/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9598 - accuracy: 0.6621 - val_loss: 1.3297 - val_accuracy: 0.5487\n",
      "Epoch 1355/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9071 - accuracy: 0.6973 - val_loss: 1.2970 - val_accuracy: 0.5487\n",
      "Epoch 1356/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9436 - accuracy: 0.6927 - val_loss: 1.2562 - val_accuracy: 0.5584\n",
      "Epoch 1357/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9916 - accuracy: 0.6494 - val_loss: 1.2166 - val_accuracy: 0.5812\n",
      "Epoch 1358/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9619 - accuracy: 0.6836 - val_loss: 1.1843 - val_accuracy: 0.5779\n",
      "Epoch 1359/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9463 - accuracy: 0.6830 - val_loss: 1.1707 - val_accuracy: 0.5844\n",
      "Epoch 1360/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9711 - accuracy: 0.6816 - val_loss: 1.1553 - val_accuracy: 0.6039\n",
      "Epoch 1361/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9865 - accuracy: 0.6592 - val_loss: 1.1503 - val_accuracy: 0.6234\n",
      "Epoch 1362/4000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9266 - accuracy: 0.6807 - val_loss: 1.1422 - val_accuracy: 0.6169\n",
      "Epoch 1363/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9628 - accuracy: 0.6983 - val_loss: 1.1501 - val_accuracy: 0.6169\n",
      "Epoch 1364/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9037 - accuracy: 0.6914 - val_loss: 1.1645 - val_accuracy: 0.6071\n",
      "Epoch 1365/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9316 - accuracy: 0.6904 - val_loss: 1.1633 - val_accuracy: 0.6136\n",
      "Epoch 1366/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0076 - accuracy: 0.6602 - val_loss: 1.1713 - val_accuracy: 0.6136\n",
      "Epoch 1367/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9260 - accuracy: 0.6826 - val_loss: 1.1902 - val_accuracy: 0.5909\n",
      "Epoch 1368/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8984 - accuracy: 0.7053 - val_loss: 1.1988 - val_accuracy: 0.5909\n",
      "Epoch 1369/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9653 - accuracy: 0.6855 - val_loss: 1.1971 - val_accuracy: 0.5909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1370/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9536 - accuracy: 0.6836 - val_loss: 1.1855 - val_accuracy: 0.5909\n",
      "Epoch 1371/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8744 - accuracy: 0.6941 - val_loss: 1.1664 - val_accuracy: 0.5877\n",
      "Epoch 1372/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9765 - accuracy: 0.6680 - val_loss: 1.1423 - val_accuracy: 0.5909\n",
      "Epoch 1373/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9388 - accuracy: 0.6760 - val_loss: 1.1295 - val_accuracy: 0.6006\n",
      "Epoch 1374/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9582 - accuracy: 0.6774 - val_loss: 1.1451 - val_accuracy: 0.5974\n",
      "Epoch 1375/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9122 - accuracy: 0.6826 - val_loss: 1.1526 - val_accuracy: 0.5974\n",
      "Epoch 1376/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9427 - accuracy: 0.6816 - val_loss: 1.1432 - val_accuracy: 0.6136\n",
      "Epoch 1377/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9284 - accuracy: 0.6895 - val_loss: 1.1468 - val_accuracy: 0.6169\n",
      "Epoch 1378/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9498 - accuracy: 0.6846 - val_loss: 1.1700 - val_accuracy: 0.6071\n",
      "Epoch 1379/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9552 - accuracy: 0.6797 - val_loss: 1.2065 - val_accuracy: 0.6006\n",
      "Epoch 1380/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9377 - accuracy: 0.6826 - val_loss: 1.2155 - val_accuracy: 0.6039\n",
      "Epoch 1381/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8888 - accuracy: 0.6924 - val_loss: 1.2180 - val_accuracy: 0.6104\n",
      "Epoch 1382/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9844 - accuracy: 0.6826 - val_loss: 1.2309 - val_accuracy: 0.6039\n",
      "Epoch 1383/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0134 - accuracy: 0.6746 - val_loss: 1.2137 - val_accuracy: 0.6039\n",
      "Epoch 1384/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8902 - accuracy: 0.7039 - val_loss: 1.1814 - val_accuracy: 0.6201\n",
      "Epoch 1385/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8643 - accuracy: 0.7151 - val_loss: 1.1582 - val_accuracy: 0.6201\n",
      "Epoch 1386/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8888 - accuracy: 0.6885 - val_loss: 1.1484 - val_accuracy: 0.6299\n",
      "Epoch 1387/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8558 - accuracy: 0.7053 - val_loss: 1.1436 - val_accuracy: 0.6299\n",
      "Epoch 1388/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9920 - accuracy: 0.6611 - val_loss: 1.1386 - val_accuracy: 0.6331\n",
      "Epoch 1389/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9511 - accuracy: 0.6924 - val_loss: 1.1259 - val_accuracy: 0.6299\n",
      "Epoch 1390/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9442 - accuracy: 0.6816 - val_loss: 1.1137 - val_accuracy: 0.6234\n",
      "Epoch 1391/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9256 - accuracy: 0.6875 - val_loss: 1.1062 - val_accuracy: 0.6201\n",
      "Epoch 1392/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9413 - accuracy: 0.7025 - val_loss: 1.1034 - val_accuracy: 0.6201\n",
      "Epoch 1393/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8948 - accuracy: 0.7151 - val_loss: 1.1014 - val_accuracy: 0.6299\n",
      "Epoch 1394/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9131 - accuracy: 0.6836 - val_loss: 1.1007 - val_accuracy: 0.6266\n",
      "Epoch 1395/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8910 - accuracy: 0.7041 - val_loss: 1.1061 - val_accuracy: 0.6266\n",
      "Epoch 1396/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8997 - accuracy: 0.7151 - val_loss: 1.1167 - val_accuracy: 0.6299\n",
      "Epoch 1397/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9383 - accuracy: 0.6858 - val_loss: 1.1273 - val_accuracy: 0.6234\n",
      "Epoch 1398/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.9202 - accuracy: 0.7002 - val_loss: 1.1291 - val_accuracy: 0.6299\n",
      "Epoch 1399/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9362 - accuracy: 0.6913 - val_loss: 1.1293 - val_accuracy: 0.6364\n",
      "Epoch 1400/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8703 - accuracy: 0.7031 - val_loss: 1.1147 - val_accuracy: 0.6396\n",
      "Epoch 1401/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9006 - accuracy: 0.6941 - val_loss: 1.1004 - val_accuracy: 0.6429\n",
      "Epoch 1402/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9688 - accuracy: 0.6816 - val_loss: 1.0894 - val_accuracy: 0.6494\n",
      "Epoch 1403/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9083 - accuracy: 0.6872 - val_loss: 1.0921 - val_accuracy: 0.6429\n",
      "Epoch 1404/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8995 - accuracy: 0.6973 - val_loss: 1.1014 - val_accuracy: 0.6396\n",
      "Epoch 1405/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8987 - accuracy: 0.6885 - val_loss: 1.1067 - val_accuracy: 0.6364\n",
      "Epoch 1406/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9403 - accuracy: 0.6885 - val_loss: 1.1118 - val_accuracy: 0.6299\n",
      "Epoch 1407/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9787 - accuracy: 0.6826 - val_loss: 1.1092 - val_accuracy: 0.6266\n",
      "Epoch 1408/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9291 - accuracy: 0.6846 - val_loss: 1.1050 - val_accuracy: 0.6201\n",
      "Epoch 1409/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8551 - accuracy: 0.7197 - val_loss: 1.1097 - val_accuracy: 0.6201\n",
      "Epoch 1410/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9232 - accuracy: 0.7109 - val_loss: 1.1210 - val_accuracy: 0.6136\n",
      "Epoch 1411/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9108 - accuracy: 0.6787 - val_loss: 1.1281 - val_accuracy: 0.6266\n",
      "Epoch 1412/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8607 - accuracy: 0.7039 - val_loss: 1.1325 - val_accuracy: 0.6104\n",
      "Epoch 1413/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8824 - accuracy: 0.7002 - val_loss: 1.1291 - val_accuracy: 0.6136\n",
      "Epoch 1414/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9167 - accuracy: 0.6943 - val_loss: 1.1197 - val_accuracy: 0.6071\n",
      "Epoch 1415/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9447 - accuracy: 0.6899 - val_loss: 1.1122 - val_accuracy: 0.6396\n",
      "Epoch 1416/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8932 - accuracy: 0.7051 - val_loss: 1.1062 - val_accuracy: 0.6364\n",
      "Epoch 1417/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9209 - accuracy: 0.6934 - val_loss: 1.0899 - val_accuracy: 0.6331\n",
      "Epoch 1418/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9057 - accuracy: 0.6913 - val_loss: 1.0770 - val_accuracy: 0.6429\n",
      "Epoch 1419/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8591 - accuracy: 0.7137 - val_loss: 1.0628 - val_accuracy: 0.6396\n",
      "Epoch 1420/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9304 - accuracy: 0.6865 - val_loss: 1.0532 - val_accuracy: 0.6494\n",
      "Epoch 1421/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8719 - accuracy: 0.6913 - val_loss: 1.0447 - val_accuracy: 0.6494\n",
      "Epoch 1422/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8761 - accuracy: 0.7109 - val_loss: 1.0419 - val_accuracy: 0.6494\n",
      "Epoch 1423/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8821 - accuracy: 0.7025 - val_loss: 1.0535 - val_accuracy: 0.6429\n",
      "Epoch 1424/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8685 - accuracy: 0.7123 - val_loss: 1.0701 - val_accuracy: 0.6396\n",
      "Epoch 1425/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8948 - accuracy: 0.6992 - val_loss: 1.0952 - val_accuracy: 0.6494\n",
      "Epoch 1426/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9342 - accuracy: 0.7081 - val_loss: 1.1479 - val_accuracy: 0.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1427/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9357 - accuracy: 0.6858 - val_loss: 1.1937 - val_accuracy: 0.6104\n",
      "Epoch 1428/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8900 - accuracy: 0.7158 - val_loss: 1.2270 - val_accuracy: 0.5974\n",
      "Epoch 1429/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8966 - accuracy: 0.6973 - val_loss: 1.1997 - val_accuracy: 0.6006\n",
      "Epoch 1430/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8488 - accuracy: 0.7123 - val_loss: 1.1691 - val_accuracy: 0.6104\n",
      "Epoch 1431/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9171 - accuracy: 0.6914 - val_loss: 1.1402 - val_accuracy: 0.6104\n",
      "Epoch 1432/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8458 - accuracy: 0.7179 - val_loss: 1.1447 - val_accuracy: 0.6071\n",
      "Epoch 1433/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9064 - accuracy: 0.6997 - val_loss: 1.1808 - val_accuracy: 0.5942\n",
      "Epoch 1434/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9279 - accuracy: 0.6913 - val_loss: 1.2626 - val_accuracy: 0.5714\n",
      "Epoch 1435/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8880 - accuracy: 0.6963 - val_loss: 1.3415 - val_accuracy: 0.5422\n",
      "Epoch 1436/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9035 - accuracy: 0.6982 - val_loss: 1.4038 - val_accuracy: 0.5325\n",
      "Epoch 1437/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8458 - accuracy: 0.7227 - val_loss: 1.4064 - val_accuracy: 0.5390\n",
      "Epoch 1438/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8818 - accuracy: 0.6802 - val_loss: 1.3843 - val_accuracy: 0.5519\n",
      "Epoch 1439/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8629 - accuracy: 0.7227 - val_loss: 1.3598 - val_accuracy: 0.5714\n",
      "Epoch 1440/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9154 - accuracy: 0.6914 - val_loss: 1.3075 - val_accuracy: 0.5714\n",
      "Epoch 1441/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9279 - accuracy: 0.6802 - val_loss: 1.2435 - val_accuracy: 0.5844\n",
      "Epoch 1442/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8411 - accuracy: 0.7246 - val_loss: 1.1859 - val_accuracy: 0.6169\n",
      "Epoch 1443/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9494 - accuracy: 0.6997 - val_loss: 1.1455 - val_accuracy: 0.6299\n",
      "Epoch 1444/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8914 - accuracy: 0.6872 - val_loss: 1.1241 - val_accuracy: 0.6299\n",
      "Epoch 1445/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9094 - accuracy: 0.6927 - val_loss: 1.1072 - val_accuracy: 0.6429\n",
      "Epoch 1446/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9300 - accuracy: 0.6816 - val_loss: 1.0969 - val_accuracy: 0.6591\n",
      "Epoch 1447/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8533 - accuracy: 0.7081 - val_loss: 1.0959 - val_accuracy: 0.6494\n",
      "Epoch 1448/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9442 - accuracy: 0.7039 - val_loss: 1.1079 - val_accuracy: 0.6429\n",
      "Epoch 1449/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8737 - accuracy: 0.6934 - val_loss: 1.1289 - val_accuracy: 0.6299\n",
      "Epoch 1450/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9435 - accuracy: 0.6943 - val_loss: 1.1628 - val_accuracy: 0.6104\n",
      "Epoch 1451/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8876 - accuracy: 0.6955 - val_loss: 1.2012 - val_accuracy: 0.5942\n",
      "Epoch 1452/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8571 - accuracy: 0.7158 - val_loss: 1.2195 - val_accuracy: 0.6039\n",
      "Epoch 1453/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8745 - accuracy: 0.7095 - val_loss: 1.2142 - val_accuracy: 0.6006\n",
      "Epoch 1454/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8962 - accuracy: 0.6816 - val_loss: 1.2048 - val_accuracy: 0.6104\n",
      "Epoch 1455/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8998 - accuracy: 0.6997 - val_loss: 1.1906 - val_accuracy: 0.6104\n",
      "Epoch 1456/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8783 - accuracy: 0.7095 - val_loss: 1.1845 - val_accuracy: 0.6104\n",
      "Epoch 1457/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8951 - accuracy: 0.7090 - val_loss: 1.1830 - val_accuracy: 0.6104\n",
      "Epoch 1458/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8616 - accuracy: 0.7168 - val_loss: 1.1866 - val_accuracy: 0.6169\n",
      "Epoch 1459/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9256 - accuracy: 0.6872 - val_loss: 1.1842 - val_accuracy: 0.6169\n",
      "Epoch 1460/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8997 - accuracy: 0.7304 - val_loss: 1.1930 - val_accuracy: 0.6071\n",
      "Epoch 1461/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8633 - accuracy: 0.7061 - val_loss: 1.1987 - val_accuracy: 0.6006\n",
      "Epoch 1462/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8313 - accuracy: 0.7246 - val_loss: 1.2185 - val_accuracy: 0.6006\n",
      "Epoch 1463/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8851 - accuracy: 0.6865 - val_loss: 1.2198 - val_accuracy: 0.6006\n",
      "Epoch 1464/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9274 - accuracy: 0.7025 - val_loss: 1.2231 - val_accuracy: 0.5942\n",
      "Epoch 1465/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8321 - accuracy: 0.7344 - val_loss: 1.2294 - val_accuracy: 0.5812\n",
      "Epoch 1466/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8925 - accuracy: 0.7012 - val_loss: 1.2300 - val_accuracy: 0.5779\n",
      "Epoch 1467/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7465 - accuracy: 0.7430 - val_loss: 1.2202 - val_accuracy: 0.5844\n",
      "Epoch 1468/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9545 - accuracy: 0.6826 - val_loss: 1.2051 - val_accuracy: 0.5909\n",
      "Epoch 1469/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8887 - accuracy: 0.7041 - val_loss: 1.1922 - val_accuracy: 0.6006\n",
      "Epoch 1470/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9131 - accuracy: 0.6807 - val_loss: 1.1658 - val_accuracy: 0.6071\n",
      "Epoch 1471/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9058 - accuracy: 0.7012 - val_loss: 1.1489 - val_accuracy: 0.6169\n",
      "Epoch 1472/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8485 - accuracy: 0.7025 - val_loss: 1.1311 - val_accuracy: 0.6136\n",
      "Epoch 1473/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8679 - accuracy: 0.7178 - val_loss: 1.1268 - val_accuracy: 0.6136\n",
      "Epoch 1474/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9061 - accuracy: 0.7109 - val_loss: 1.1533 - val_accuracy: 0.6104\n",
      "Epoch 1475/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9143 - accuracy: 0.6983 - val_loss: 1.1899 - val_accuracy: 0.6006\n",
      "Epoch 1476/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8945 - accuracy: 0.7193 - val_loss: 1.2317 - val_accuracy: 0.5812\n",
      "Epoch 1477/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8539 - accuracy: 0.7061 - val_loss: 1.2665 - val_accuracy: 0.5812\n",
      "Epoch 1478/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8097 - accuracy: 0.7304 - val_loss: 1.3005 - val_accuracy: 0.5779\n",
      "Epoch 1479/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8969 - accuracy: 0.6941 - val_loss: 1.3162 - val_accuracy: 0.5844\n",
      "Epoch 1480/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8976 - accuracy: 0.7109 - val_loss: 1.3098 - val_accuracy: 0.5909\n",
      "Epoch 1481/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8702 - accuracy: 0.7151 - val_loss: 1.2651 - val_accuracy: 0.5909\n",
      "Epoch 1482/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8343 - accuracy: 0.7285 - val_loss: 1.2263 - val_accuracy: 0.5942\n",
      "Epoch 1483/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9393 - accuracy: 0.6904 - val_loss: 1.1803 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1484/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8196 - accuracy: 0.7360 - val_loss: 1.1331 - val_accuracy: 0.6266\n",
      "Epoch 1485/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9236 - accuracy: 0.6955 - val_loss: 1.1074 - val_accuracy: 0.6331\n",
      "Epoch 1486/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8865 - accuracy: 0.7179 - val_loss: 1.0869 - val_accuracy: 0.6266\n",
      "Epoch 1487/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8274 - accuracy: 0.7053 - val_loss: 1.0880 - val_accuracy: 0.6266\n",
      "Epoch 1488/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8508 - accuracy: 0.7165 - val_loss: 1.1132 - val_accuracy: 0.6299\n",
      "Epoch 1489/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8052 - accuracy: 0.7246 - val_loss: 1.1538 - val_accuracy: 0.6071\n",
      "Epoch 1490/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8263 - accuracy: 0.7139 - val_loss: 1.1953 - val_accuracy: 0.6006\n",
      "Epoch 1491/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9064 - accuracy: 0.6997 - val_loss: 1.2296 - val_accuracy: 0.5974\n",
      "Epoch 1492/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8798 - accuracy: 0.6997 - val_loss: 1.2380 - val_accuracy: 0.6039\n",
      "Epoch 1493/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8744 - accuracy: 0.7151 - val_loss: 1.2478 - val_accuracy: 0.6201\n",
      "Epoch 1494/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9081 - accuracy: 0.6955 - val_loss: 1.2203 - val_accuracy: 0.6201\n",
      "Epoch 1495/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8304 - accuracy: 0.7137 - val_loss: 1.2004 - val_accuracy: 0.6201\n",
      "Epoch 1496/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7986 - accuracy: 0.7354 - val_loss: 1.2063 - val_accuracy: 0.6201\n",
      "Epoch 1497/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8639 - accuracy: 0.7090 - val_loss: 1.2230 - val_accuracy: 0.6104\n",
      "Epoch 1498/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8055 - accuracy: 0.7246 - val_loss: 1.2260 - val_accuracy: 0.6136\n",
      "Epoch 1499/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8519 - accuracy: 0.7277 - val_loss: 1.2344 - val_accuracy: 0.6104\n",
      "Epoch 1500/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8971 - accuracy: 0.6924 - val_loss: 1.2285 - val_accuracy: 0.6006\n",
      "Epoch 1501/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8826 - accuracy: 0.7100 - val_loss: 1.2412 - val_accuracy: 0.6006\n",
      "Epoch 1502/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8465 - accuracy: 0.7080 - val_loss: 1.2681 - val_accuracy: 0.5942\n",
      "Epoch 1503/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8492 - accuracy: 0.7263 - val_loss: 1.3118 - val_accuracy: 0.5844\n",
      "Epoch 1504/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9566 - accuracy: 0.6885 - val_loss: 1.3514 - val_accuracy: 0.5747\n",
      "Epoch 1505/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7967 - accuracy: 0.7360 - val_loss: 1.3421 - val_accuracy: 0.5714\n",
      "Epoch 1506/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8148 - accuracy: 0.7363 - val_loss: 1.3281 - val_accuracy: 0.5649\n",
      "Epoch 1507/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8455 - accuracy: 0.7318 - val_loss: 1.2703 - val_accuracy: 0.5844\n",
      "Epoch 1508/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8908 - accuracy: 0.6973 - val_loss: 1.2183 - val_accuracy: 0.5844\n",
      "Epoch 1509/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7963 - accuracy: 0.7451 - val_loss: 1.1905 - val_accuracy: 0.5909\n",
      "Epoch 1510/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8749 - accuracy: 0.7148 - val_loss: 1.1696 - val_accuracy: 0.5909\n",
      "Epoch 1511/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8397 - accuracy: 0.7109 - val_loss: 1.1635 - val_accuracy: 0.5974\n",
      "Epoch 1512/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8616 - accuracy: 0.7139 - val_loss: 1.1787 - val_accuracy: 0.6071\n",
      "Epoch 1513/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7890 - accuracy: 0.7363 - val_loss: 1.1837 - val_accuracy: 0.6104\n",
      "Epoch 1514/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8353 - accuracy: 0.7067 - val_loss: 1.1778 - val_accuracy: 0.6104\n",
      "Epoch 1515/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8678 - accuracy: 0.7067 - val_loss: 1.1698 - val_accuracy: 0.6266\n",
      "Epoch 1516/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8348 - accuracy: 0.7197 - val_loss: 1.1566 - val_accuracy: 0.6299\n",
      "Epoch 1517/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8293 - accuracy: 0.7165 - val_loss: 1.1105 - val_accuracy: 0.6364\n",
      "Epoch 1518/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7826 - accuracy: 0.7291 - val_loss: 1.0636 - val_accuracy: 0.6396\n",
      "Epoch 1519/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8577 - accuracy: 0.7061 - val_loss: 1.0426 - val_accuracy: 0.6364\n",
      "Epoch 1520/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9035 - accuracy: 0.7100 - val_loss: 1.0341 - val_accuracy: 0.6461\n",
      "Epoch 1521/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8564 - accuracy: 0.7217 - val_loss: 1.0432 - val_accuracy: 0.6461\n",
      "Epoch 1522/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8627 - accuracy: 0.7025 - val_loss: 1.0760 - val_accuracy: 0.6201\n",
      "Epoch 1523/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8553 - accuracy: 0.7100 - val_loss: 1.1286 - val_accuracy: 0.6234\n",
      "Epoch 1524/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8270 - accuracy: 0.7304 - val_loss: 1.1987 - val_accuracy: 0.6136\n",
      "Epoch 1525/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8940 - accuracy: 0.7025 - val_loss: 1.2705 - val_accuracy: 0.6104\n",
      "Epoch 1526/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8344 - accuracy: 0.7100 - val_loss: 1.3302 - val_accuracy: 0.6039\n",
      "Epoch 1527/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8503 - accuracy: 0.7100 - val_loss: 1.3597 - val_accuracy: 0.5974\n",
      "Epoch 1528/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8655 - accuracy: 0.7221 - val_loss: 1.3441 - val_accuracy: 0.5844\n",
      "Epoch 1529/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9177 - accuracy: 0.7039 - val_loss: 1.3064 - val_accuracy: 0.5877\n",
      "Epoch 1530/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8213 - accuracy: 0.7168 - val_loss: 1.2498 - val_accuracy: 0.5942\n",
      "Epoch 1531/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8432 - accuracy: 0.7090 - val_loss: 1.1923 - val_accuracy: 0.6039\n",
      "Epoch 1532/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8272 - accuracy: 0.7236 - val_loss: 1.1560 - val_accuracy: 0.5974\n",
      "Epoch 1533/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8449 - accuracy: 0.7139 - val_loss: 1.1414 - val_accuracy: 0.6039\n",
      "Epoch 1534/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8062 - accuracy: 0.7304 - val_loss: 1.1363 - val_accuracy: 0.6071\n",
      "Epoch 1535/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8321 - accuracy: 0.7266 - val_loss: 1.1553 - val_accuracy: 0.6136\n",
      "Epoch 1536/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9159 - accuracy: 0.6826 - val_loss: 1.1853 - val_accuracy: 0.6039\n",
      "Epoch 1537/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8387 - accuracy: 0.7249 - val_loss: 1.2096 - val_accuracy: 0.6006\n",
      "Epoch 1538/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8045 - accuracy: 0.7393 - val_loss: 1.2339 - val_accuracy: 0.6071\n",
      "Epoch 1539/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7916 - accuracy: 0.7354 - val_loss: 1.2542 - val_accuracy: 0.6071\n",
      "Epoch 1540/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8447 - accuracy: 0.7285 - val_loss: 1.2469 - val_accuracy: 0.6071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1541/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8375 - accuracy: 0.7363 - val_loss: 1.2163 - val_accuracy: 0.6071\n",
      "Epoch 1542/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8436 - accuracy: 0.7236 - val_loss: 1.1702 - val_accuracy: 0.6104\n",
      "Epoch 1543/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8198 - accuracy: 0.7363 - val_loss: 1.1168 - val_accuracy: 0.6169\n",
      "Epoch 1544/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9080 - accuracy: 0.6955 - val_loss: 1.0803 - val_accuracy: 0.6266\n",
      "Epoch 1545/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8448 - accuracy: 0.7193 - val_loss: 1.0735 - val_accuracy: 0.6331\n",
      "Epoch 1546/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8604 - accuracy: 0.7100 - val_loss: 1.0749 - val_accuracy: 0.6331\n",
      "Epoch 1547/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8325 - accuracy: 0.7291 - val_loss: 1.0665 - val_accuracy: 0.6364\n",
      "Epoch 1548/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8372 - accuracy: 0.7109 - val_loss: 1.0541 - val_accuracy: 0.6364\n",
      "Epoch 1549/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8037 - accuracy: 0.7324 - val_loss: 1.0441 - val_accuracy: 0.6364\n",
      "Epoch 1550/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7993 - accuracy: 0.7277 - val_loss: 1.0492 - val_accuracy: 0.6331\n",
      "Epoch 1551/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7718 - accuracy: 0.7430 - val_loss: 1.0502 - val_accuracy: 0.6201\n",
      "Epoch 1552/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8700 - accuracy: 0.7179 - val_loss: 1.0524 - val_accuracy: 0.6266\n",
      "Epoch 1553/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8574 - accuracy: 0.7263 - val_loss: 1.0832 - val_accuracy: 0.6364\n",
      "Epoch 1554/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7827 - accuracy: 0.7363 - val_loss: 1.1186 - val_accuracy: 0.6396\n",
      "Epoch 1555/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8433 - accuracy: 0.7139 - val_loss: 1.1361 - val_accuracy: 0.6429\n",
      "Epoch 1556/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8247 - accuracy: 0.7314 - val_loss: 1.1361 - val_accuracy: 0.6364\n",
      "Epoch 1557/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8376 - accuracy: 0.7188 - val_loss: 1.1350 - val_accuracy: 0.6266\n",
      "Epoch 1558/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8701 - accuracy: 0.7041 - val_loss: 1.1411 - val_accuracy: 0.6266\n",
      "Epoch 1559/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8038 - accuracy: 0.7486 - val_loss: 1.1683 - val_accuracy: 0.6299\n",
      "Epoch 1560/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8361 - accuracy: 0.7291 - val_loss: 1.1916 - val_accuracy: 0.6364\n",
      "Epoch 1561/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8526 - accuracy: 0.7002 - val_loss: 1.2352 - val_accuracy: 0.6266\n",
      "Epoch 1562/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8306 - accuracy: 0.7263 - val_loss: 1.2818 - val_accuracy: 0.6071\n",
      "Epoch 1563/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8312 - accuracy: 0.7256 - val_loss: 1.3050 - val_accuracy: 0.6039\n",
      "Epoch 1564/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8213 - accuracy: 0.7256 - val_loss: 1.3137 - val_accuracy: 0.6071\n",
      "Epoch 1565/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8195 - accuracy: 0.7188 - val_loss: 1.3012 - val_accuracy: 0.6039\n",
      "Epoch 1566/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8380 - accuracy: 0.7179 - val_loss: 1.2595 - val_accuracy: 0.6169\n",
      "Epoch 1567/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8347 - accuracy: 0.7263 - val_loss: 1.2150 - val_accuracy: 0.6234\n",
      "Epoch 1568/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7975 - accuracy: 0.7416 - val_loss: 1.1807 - val_accuracy: 0.6331\n",
      "Epoch 1569/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8593 - accuracy: 0.7285 - val_loss: 1.1622 - val_accuracy: 0.6299\n",
      "Epoch 1570/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8357 - accuracy: 0.7246 - val_loss: 1.1596 - val_accuracy: 0.6396\n",
      "Epoch 1571/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8287 - accuracy: 0.7304 - val_loss: 1.1718 - val_accuracy: 0.6234\n",
      "Epoch 1572/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7707 - accuracy: 0.7500 - val_loss: 1.1835 - val_accuracy: 0.6201\n",
      "Epoch 1573/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7625 - accuracy: 0.7432 - val_loss: 1.1978 - val_accuracy: 0.6071\n",
      "Epoch 1574/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7911 - accuracy: 0.7416 - val_loss: 1.2144 - val_accuracy: 0.6039\n",
      "Epoch 1575/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8721 - accuracy: 0.7109 - val_loss: 1.2217 - val_accuracy: 0.6039\n",
      "Epoch 1576/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8163 - accuracy: 0.7277 - val_loss: 1.2274 - val_accuracy: 0.6006\n",
      "Epoch 1577/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8256 - accuracy: 0.7332 - val_loss: 1.2392 - val_accuracy: 0.6039\n",
      "Epoch 1578/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7952 - accuracy: 0.7500 - val_loss: 1.2454 - val_accuracy: 0.5942\n",
      "Epoch 1579/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8586 - accuracy: 0.7207 - val_loss: 1.2589 - val_accuracy: 0.5877\n",
      "Epoch 1580/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7625 - accuracy: 0.7500 - val_loss: 1.2615 - val_accuracy: 0.5877\n",
      "Epoch 1581/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8174 - accuracy: 0.7129 - val_loss: 1.2707 - val_accuracy: 0.6071\n",
      "Epoch 1582/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7967 - accuracy: 0.7373 - val_loss: 1.2860 - val_accuracy: 0.6136\n",
      "Epoch 1583/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8648 - accuracy: 0.7249 - val_loss: 1.3011 - val_accuracy: 0.6201\n",
      "Epoch 1584/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7813 - accuracy: 0.7374 - val_loss: 1.3273 - val_accuracy: 0.6104\n",
      "Epoch 1585/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7681 - accuracy: 0.7514 - val_loss: 1.3552 - val_accuracy: 0.6136\n",
      "Epoch 1586/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9046 - accuracy: 0.7002 - val_loss: 1.3897 - val_accuracy: 0.6006\n",
      "Epoch 1587/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7855 - accuracy: 0.7402 - val_loss: 1.4029 - val_accuracy: 0.5844\n",
      "Epoch 1588/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8344 - accuracy: 0.7165 - val_loss: 1.3864 - val_accuracy: 0.5682\n",
      "Epoch 1589/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8183 - accuracy: 0.7295 - val_loss: 1.2935 - val_accuracy: 0.5812\n",
      "Epoch 1590/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7677 - accuracy: 0.7388 - val_loss: 1.2240 - val_accuracy: 0.6039\n",
      "Epoch 1591/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7345 - accuracy: 0.7607 - val_loss: 1.1532 - val_accuracy: 0.6136\n",
      "Epoch 1592/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7933 - accuracy: 0.7416 - val_loss: 1.1098 - val_accuracy: 0.6331\n",
      "Epoch 1593/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7945 - accuracy: 0.7305 - val_loss: 1.0901 - val_accuracy: 0.6364\n",
      "Epoch 1594/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8408 - accuracy: 0.7193 - val_loss: 1.0720 - val_accuracy: 0.6331\n",
      "Epoch 1595/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7771 - accuracy: 0.7451 - val_loss: 1.0843 - val_accuracy: 0.6331\n",
      "Epoch 1596/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7772 - accuracy: 0.7432 - val_loss: 1.1131 - val_accuracy: 0.6234\n",
      "Epoch 1597/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7762 - accuracy: 0.7528 - val_loss: 1.1691 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1598/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8128 - accuracy: 0.7318 - val_loss: 1.2305 - val_accuracy: 0.6136\n",
      "Epoch 1599/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8944 - accuracy: 0.7053 - val_loss: 1.2694 - val_accuracy: 0.6136\n",
      "Epoch 1600/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7884 - accuracy: 0.7363 - val_loss: 1.2825 - val_accuracy: 0.6104\n",
      "Epoch 1601/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8597 - accuracy: 0.7188 - val_loss: 1.2786 - val_accuracy: 0.6104\n",
      "Epoch 1602/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8242 - accuracy: 0.7383 - val_loss: 1.2005 - val_accuracy: 0.6299\n",
      "Epoch 1603/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8255 - accuracy: 0.7277 - val_loss: 1.1291 - val_accuracy: 0.6331\n",
      "Epoch 1604/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8160 - accuracy: 0.7305 - val_loss: 1.0798 - val_accuracy: 0.6396\n",
      "Epoch 1605/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8064 - accuracy: 0.7249 - val_loss: 1.0643 - val_accuracy: 0.6526\n",
      "Epoch 1606/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7960 - accuracy: 0.7422 - val_loss: 1.0683 - val_accuracy: 0.6526\n",
      "Epoch 1607/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8098 - accuracy: 0.7402 - val_loss: 1.0736 - val_accuracy: 0.6526\n",
      "Epoch 1608/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7627 - accuracy: 0.7510 - val_loss: 1.0749 - val_accuracy: 0.6558\n",
      "Epoch 1609/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8084 - accuracy: 0.7207 - val_loss: 1.0712 - val_accuracy: 0.6526\n",
      "Epoch 1610/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7149 - accuracy: 0.7849 - val_loss: 1.0790 - val_accuracy: 0.6331\n",
      "Epoch 1611/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7993 - accuracy: 0.7393 - val_loss: 1.0998 - val_accuracy: 0.6234\n",
      "Epoch 1612/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7534 - accuracy: 0.7441 - val_loss: 1.1537 - val_accuracy: 0.6104\n",
      "Epoch 1613/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7787 - accuracy: 0.7275 - val_loss: 1.2164 - val_accuracy: 0.5974\n",
      "Epoch 1614/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8202 - accuracy: 0.7067 - val_loss: 1.2711 - val_accuracy: 0.5942\n",
      "Epoch 1615/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8309 - accuracy: 0.7236 - val_loss: 1.2796 - val_accuracy: 0.5942\n",
      "Epoch 1616/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7400 - accuracy: 0.7584 - val_loss: 1.2607 - val_accuracy: 0.6039\n",
      "Epoch 1617/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7908 - accuracy: 0.7432 - val_loss: 1.2523 - val_accuracy: 0.6006\n",
      "Epoch 1618/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8026 - accuracy: 0.7430 - val_loss: 1.2600 - val_accuracy: 0.6006\n",
      "Epoch 1619/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8056 - accuracy: 0.7363 - val_loss: 1.2751 - val_accuracy: 0.6071\n",
      "Epoch 1620/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7884 - accuracy: 0.7430 - val_loss: 1.2433 - val_accuracy: 0.6169\n",
      "Epoch 1621/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7820 - accuracy: 0.7472 - val_loss: 1.2292 - val_accuracy: 0.6234\n",
      "Epoch 1622/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7503 - accuracy: 0.7500 - val_loss: 1.2295 - val_accuracy: 0.6169\n",
      "Epoch 1623/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7602 - accuracy: 0.7393 - val_loss: 1.2384 - val_accuracy: 0.6071\n",
      "Epoch 1624/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7487 - accuracy: 0.7559 - val_loss: 1.2511 - val_accuracy: 0.6104\n",
      "Epoch 1625/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7634 - accuracy: 0.7402 - val_loss: 1.2412 - val_accuracy: 0.6136\n",
      "Epoch 1626/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7598 - accuracy: 0.7584 - val_loss: 1.2770 - val_accuracy: 0.6071\n",
      "Epoch 1627/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7622 - accuracy: 0.7549 - val_loss: 1.3044 - val_accuracy: 0.6006\n",
      "Epoch 1628/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8247 - accuracy: 0.7137 - val_loss: 1.3642 - val_accuracy: 0.5974\n",
      "Epoch 1629/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7988 - accuracy: 0.7263 - val_loss: 1.3713 - val_accuracy: 0.6039\n",
      "Epoch 1630/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7436 - accuracy: 0.7402 - val_loss: 1.3485 - val_accuracy: 0.6039\n",
      "Epoch 1631/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7906 - accuracy: 0.7451 - val_loss: 1.3488 - val_accuracy: 0.5974\n",
      "Epoch 1632/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8096 - accuracy: 0.7354 - val_loss: 1.3445 - val_accuracy: 0.6006\n",
      "Epoch 1633/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7802 - accuracy: 0.7542 - val_loss: 1.3584 - val_accuracy: 0.5942\n",
      "Epoch 1634/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7959 - accuracy: 0.7263 - val_loss: 1.3926 - val_accuracy: 0.5844\n",
      "Epoch 1635/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8288 - accuracy: 0.7314 - val_loss: 1.4236 - val_accuracy: 0.5714\n",
      "Epoch 1636/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8050 - accuracy: 0.7256 - val_loss: 1.4465 - val_accuracy: 0.5779\n",
      "Epoch 1637/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8442 - accuracy: 0.7346 - val_loss: 1.4512 - val_accuracy: 0.5747\n",
      "Epoch 1638/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8026 - accuracy: 0.7249 - val_loss: 1.4816 - val_accuracy: 0.5682\n",
      "Epoch 1639/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8226 - accuracy: 0.7061 - val_loss: 1.4900 - val_accuracy: 0.5714\n",
      "Epoch 1640/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7714 - accuracy: 0.7549 - val_loss: 1.4141 - val_accuracy: 0.5714\n",
      "Epoch 1641/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7758 - accuracy: 0.7458 - val_loss: 1.3243 - val_accuracy: 0.5942\n",
      "Epoch 1642/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7783 - accuracy: 0.7472 - val_loss: 1.2360 - val_accuracy: 0.6234\n",
      "Epoch 1643/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7661 - accuracy: 0.7383 - val_loss: 1.1436 - val_accuracy: 0.6558\n",
      "Epoch 1644/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7545 - accuracy: 0.7607 - val_loss: 1.0722 - val_accuracy: 0.6591\n",
      "Epoch 1645/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7626 - accuracy: 0.7441 - val_loss: 1.0327 - val_accuracy: 0.6688\n",
      "Epoch 1646/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8158 - accuracy: 0.7221 - val_loss: 1.0154 - val_accuracy: 0.6688\n",
      "Epoch 1647/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7983 - accuracy: 0.7332 - val_loss: 1.0093 - val_accuracy: 0.6688\n",
      "Epoch 1648/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7876 - accuracy: 0.7568 - val_loss: 1.0089 - val_accuracy: 0.6558\n",
      "Epoch 1649/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7568 - accuracy: 0.7480 - val_loss: 1.0226 - val_accuracy: 0.6494\n",
      "Epoch 1650/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7577 - accuracy: 0.7514 - val_loss: 1.0334 - val_accuracy: 0.6396\n",
      "Epoch 1651/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7662 - accuracy: 0.7458 - val_loss: 1.0285 - val_accuracy: 0.6396\n",
      "Epoch 1652/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7625 - accuracy: 0.7471 - val_loss: 1.0182 - val_accuracy: 0.6558\n",
      "Epoch 1653/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7673 - accuracy: 0.7441 - val_loss: 1.0165 - val_accuracy: 0.6558\n",
      "Epoch 1654/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7711 - accuracy: 0.7412 - val_loss: 1.0209 - val_accuracy: 0.6688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1655/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7771 - accuracy: 0.7360 - val_loss: 1.0336 - val_accuracy: 0.6688\n",
      "Epoch 1656/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7849 - accuracy: 0.7263 - val_loss: 1.0576 - val_accuracy: 0.6623\n",
      "Epoch 1657/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8007 - accuracy: 0.7393 - val_loss: 1.0834 - val_accuracy: 0.6623\n",
      "Epoch 1658/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7628 - accuracy: 0.7556 - val_loss: 1.1362 - val_accuracy: 0.6396\n",
      "Epoch 1659/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7369 - accuracy: 0.7668 - val_loss: 1.1976 - val_accuracy: 0.6169\n",
      "Epoch 1660/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7490 - accuracy: 0.7514 - val_loss: 1.2231 - val_accuracy: 0.6266\n",
      "Epoch 1661/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7472 - accuracy: 0.7637 - val_loss: 1.2286 - val_accuracy: 0.6331\n",
      "Epoch 1662/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7751 - accuracy: 0.7332 - val_loss: 1.2220 - val_accuracy: 0.6331\n",
      "Epoch 1663/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7861 - accuracy: 0.7458 - val_loss: 1.2316 - val_accuracy: 0.6331\n",
      "Epoch 1664/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7820 - accuracy: 0.7246 - val_loss: 1.2313 - val_accuracy: 0.6364\n",
      "Epoch 1665/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7715 - accuracy: 0.7500 - val_loss: 1.2186 - val_accuracy: 0.6364\n",
      "Epoch 1666/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8326 - accuracy: 0.7295 - val_loss: 1.1937 - val_accuracy: 0.6364\n",
      "Epoch 1667/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7941 - accuracy: 0.7432 - val_loss: 1.1764 - val_accuracy: 0.6299\n",
      "Epoch 1668/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7500 - accuracy: 0.7444 - val_loss: 1.1438 - val_accuracy: 0.6364\n",
      "Epoch 1669/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7521 - accuracy: 0.7578 - val_loss: 1.1515 - val_accuracy: 0.6331\n",
      "Epoch 1670/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8471 - accuracy: 0.7346 - val_loss: 1.1752 - val_accuracy: 0.6136\n",
      "Epoch 1671/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7740 - accuracy: 0.7627 - val_loss: 1.2055 - val_accuracy: 0.6201\n",
      "Epoch 1672/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7524 - accuracy: 0.7461 - val_loss: 1.2594 - val_accuracy: 0.6169\n",
      "Epoch 1673/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7308 - accuracy: 0.7696 - val_loss: 1.3043 - val_accuracy: 0.6169\n",
      "Epoch 1674/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8147 - accuracy: 0.7332 - val_loss: 1.3798 - val_accuracy: 0.6136\n",
      "Epoch 1675/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8081 - accuracy: 0.7227 - val_loss: 1.4923 - val_accuracy: 0.5779\n",
      "Epoch 1676/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7488 - accuracy: 0.7539 - val_loss: 1.5971 - val_accuracy: 0.5552\n",
      "Epoch 1677/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8058 - accuracy: 0.7373 - val_loss: 1.6989 - val_accuracy: 0.5227\n",
      "Epoch 1678/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7618 - accuracy: 0.7472 - val_loss: 1.7155 - val_accuracy: 0.5162\n",
      "Epoch 1679/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7401 - accuracy: 0.7598 - val_loss: 1.6651 - val_accuracy: 0.5292\n",
      "Epoch 1680/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7816 - accuracy: 0.7383 - val_loss: 1.5747 - val_accuracy: 0.5487\n",
      "Epoch 1681/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7982 - accuracy: 0.7256 - val_loss: 1.4899 - val_accuracy: 0.5812\n",
      "Epoch 1682/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7709 - accuracy: 0.7528 - val_loss: 1.4254 - val_accuracy: 0.6006\n",
      "Epoch 1683/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7327 - accuracy: 0.7514 - val_loss: 1.3945 - val_accuracy: 0.6104\n",
      "Epoch 1684/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7436 - accuracy: 0.7480 - val_loss: 1.3792 - val_accuracy: 0.6201\n",
      "Epoch 1685/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6880 - accuracy: 0.7654 - val_loss: 1.3603 - val_accuracy: 0.6169\n",
      "Epoch 1686/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7825 - accuracy: 0.7291 - val_loss: 1.2998 - val_accuracy: 0.6299\n",
      "Epoch 1687/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7514 - accuracy: 0.7584 - val_loss: 1.2260 - val_accuracy: 0.6429\n",
      "Epoch 1688/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7467 - accuracy: 0.7472 - val_loss: 1.1824 - val_accuracy: 0.6591\n",
      "Epoch 1689/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7368 - accuracy: 0.7584 - val_loss: 1.1530 - val_accuracy: 0.6591\n",
      "Epoch 1690/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7708 - accuracy: 0.7490 - val_loss: 1.1288 - val_accuracy: 0.6591\n",
      "Epoch 1691/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7316 - accuracy: 0.7520 - val_loss: 1.1229 - val_accuracy: 0.6558\n",
      "Epoch 1692/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7759 - accuracy: 0.7559 - val_loss: 1.1221 - val_accuracy: 0.6656\n",
      "Epoch 1693/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8163 - accuracy: 0.7332 - val_loss: 1.1305 - val_accuracy: 0.6558\n",
      "Epoch 1694/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7632 - accuracy: 0.7539 - val_loss: 1.1232 - val_accuracy: 0.6591\n",
      "Epoch 1695/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7915 - accuracy: 0.7402 - val_loss: 1.1244 - val_accuracy: 0.6429\n",
      "Epoch 1696/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8019 - accuracy: 0.7354 - val_loss: 1.1337 - val_accuracy: 0.6364\n",
      "Epoch 1697/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7427 - accuracy: 0.7471 - val_loss: 1.1474 - val_accuracy: 0.6364\n",
      "Epoch 1698/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7859 - accuracy: 0.7277 - val_loss: 1.1344 - val_accuracy: 0.6396\n",
      "Epoch 1699/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6913 - accuracy: 0.7754 - val_loss: 1.1150 - val_accuracy: 0.6526\n",
      "Epoch 1700/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7224 - accuracy: 0.7705 - val_loss: 1.1320 - val_accuracy: 0.6558\n",
      "Epoch 1701/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7858 - accuracy: 0.7441 - val_loss: 1.1778 - val_accuracy: 0.6494\n",
      "Epoch 1702/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6778 - accuracy: 0.7821 - val_loss: 1.2494 - val_accuracy: 0.6266\n",
      "Epoch 1703/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7340 - accuracy: 0.7402 - val_loss: 1.3158 - val_accuracy: 0.6201\n",
      "Epoch 1704/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7733 - accuracy: 0.7578 - val_loss: 1.3234 - val_accuracy: 0.6201\n",
      "Epoch 1705/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7566 - accuracy: 0.7472 - val_loss: 1.3061 - val_accuracy: 0.6266\n",
      "Epoch 1706/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7531 - accuracy: 0.7640 - val_loss: 1.2717 - val_accuracy: 0.6234\n",
      "Epoch 1707/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7348 - accuracy: 0.7617 - val_loss: 1.2617 - val_accuracy: 0.6234\n",
      "Epoch 1708/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7496 - accuracy: 0.7542 - val_loss: 1.2764 - val_accuracy: 0.6266\n",
      "Epoch 1709/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7544 - accuracy: 0.7480 - val_loss: 1.2724 - val_accuracy: 0.6364\n",
      "Epoch 1710/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7183 - accuracy: 0.7607 - val_loss: 1.2576 - val_accuracy: 0.6396\n",
      "Epoch 1711/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7797 - accuracy: 0.7461 - val_loss: 1.2340 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1712/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7811 - accuracy: 0.7388 - val_loss: 1.2149 - val_accuracy: 0.6331\n",
      "Epoch 1713/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7447 - accuracy: 0.7570 - val_loss: 1.1996 - val_accuracy: 0.6266\n",
      "Epoch 1714/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7268 - accuracy: 0.7514 - val_loss: 1.1916 - val_accuracy: 0.6331\n",
      "Epoch 1715/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7172 - accuracy: 0.7656 - val_loss: 1.1834 - val_accuracy: 0.6396\n",
      "Epoch 1716/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6961 - accuracy: 0.7744 - val_loss: 1.1802 - val_accuracy: 0.6331\n",
      "Epoch 1717/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7435 - accuracy: 0.7360 - val_loss: 1.1799 - val_accuracy: 0.6396\n",
      "Epoch 1718/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7589 - accuracy: 0.7607 - val_loss: 1.1801 - val_accuracy: 0.6299\n",
      "Epoch 1719/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7081 - accuracy: 0.7656 - val_loss: 1.1673 - val_accuracy: 0.6331\n",
      "Epoch 1720/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7662 - accuracy: 0.7490 - val_loss: 1.1599 - val_accuracy: 0.6331\n",
      "Epoch 1721/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7755 - accuracy: 0.7422 - val_loss: 1.1481 - val_accuracy: 0.6364\n",
      "Epoch 1722/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8346 - accuracy: 0.7430 - val_loss: 1.1427 - val_accuracy: 0.6364\n",
      "Epoch 1723/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7711 - accuracy: 0.7514 - val_loss: 1.1473 - val_accuracy: 0.6364\n",
      "Epoch 1724/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6880 - accuracy: 0.7646 - val_loss: 1.1551 - val_accuracy: 0.6364\n",
      "Epoch 1725/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7485 - accuracy: 0.7374 - val_loss: 1.1775 - val_accuracy: 0.6169\n",
      "Epoch 1726/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7171 - accuracy: 0.7686 - val_loss: 1.1975 - val_accuracy: 0.6169\n",
      "Epoch 1727/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7352 - accuracy: 0.7490 - val_loss: 1.2084 - val_accuracy: 0.6136\n",
      "Epoch 1728/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7603 - accuracy: 0.7556 - val_loss: 1.2048 - val_accuracy: 0.6006\n",
      "Epoch 1729/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7173 - accuracy: 0.7598 - val_loss: 1.2155 - val_accuracy: 0.5974\n",
      "Epoch 1730/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7949 - accuracy: 0.7344 - val_loss: 1.2041 - val_accuracy: 0.5974\n",
      "Epoch 1731/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7199 - accuracy: 0.7637 - val_loss: 1.1900 - val_accuracy: 0.6039\n",
      "Epoch 1732/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7345 - accuracy: 0.7559 - val_loss: 1.1764 - val_accuracy: 0.6104\n",
      "Epoch 1733/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7489 - accuracy: 0.7383 - val_loss: 1.1644 - val_accuracy: 0.6234\n",
      "Epoch 1734/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7704 - accuracy: 0.7451 - val_loss: 1.1547 - val_accuracy: 0.6234\n",
      "Epoch 1735/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8425 - accuracy: 0.7137 - val_loss: 1.1369 - val_accuracy: 0.6331\n",
      "Epoch 1736/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7153 - accuracy: 0.7637 - val_loss: 1.1184 - val_accuracy: 0.6364\n",
      "Epoch 1737/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7717 - accuracy: 0.7360 - val_loss: 1.0977 - val_accuracy: 0.6494\n",
      "Epoch 1738/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7632 - accuracy: 0.7451 - val_loss: 1.0854 - val_accuracy: 0.6526\n",
      "Epoch 1739/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7458 - accuracy: 0.7500 - val_loss: 1.0737 - val_accuracy: 0.6623\n",
      "Epoch 1740/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7026 - accuracy: 0.7654 - val_loss: 1.0692 - val_accuracy: 0.6526\n",
      "Epoch 1741/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7061 - accuracy: 0.7695 - val_loss: 1.0664 - val_accuracy: 0.6558\n",
      "Epoch 1742/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7665 - accuracy: 0.7514 - val_loss: 1.0682 - val_accuracy: 0.6526\n",
      "Epoch 1743/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7839 - accuracy: 0.7441 - val_loss: 1.0812 - val_accuracy: 0.6364\n",
      "Epoch 1744/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7347 - accuracy: 0.7520 - val_loss: 1.0928 - val_accuracy: 0.6461\n",
      "Epoch 1745/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7483 - accuracy: 0.7520 - val_loss: 1.1104 - val_accuracy: 0.6299\n",
      "Epoch 1746/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7232 - accuracy: 0.7612 - val_loss: 1.1247 - val_accuracy: 0.6234\n",
      "Epoch 1747/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6910 - accuracy: 0.7723 - val_loss: 1.1207 - val_accuracy: 0.6234\n",
      "Epoch 1748/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7036 - accuracy: 0.7646 - val_loss: 1.1171 - val_accuracy: 0.6331\n",
      "Epoch 1749/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7237 - accuracy: 0.7559 - val_loss: 1.1052 - val_accuracy: 0.6558\n",
      "Epoch 1750/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7884 - accuracy: 0.7444 - val_loss: 1.1045 - val_accuracy: 0.6558\n",
      "Epoch 1751/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7583 - accuracy: 0.7607 - val_loss: 1.0985 - val_accuracy: 0.6494\n",
      "Epoch 1752/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7095 - accuracy: 0.7793 - val_loss: 1.0964 - val_accuracy: 0.6591\n",
      "Epoch 1753/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7105 - accuracy: 0.7539 - val_loss: 1.0989 - val_accuracy: 0.6558\n",
      "Epoch 1754/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7422 - accuracy: 0.7402 - val_loss: 1.1029 - val_accuracy: 0.6526\n",
      "Epoch 1755/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7082 - accuracy: 0.7542 - val_loss: 1.1077 - val_accuracy: 0.6396\n",
      "Epoch 1756/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6964 - accuracy: 0.7849 - val_loss: 1.1237 - val_accuracy: 0.6461\n",
      "Epoch 1757/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7247 - accuracy: 0.7607 - val_loss: 1.1365 - val_accuracy: 0.6396\n",
      "Epoch 1758/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7881 - accuracy: 0.7318 - val_loss: 1.1528 - val_accuracy: 0.6396\n",
      "Epoch 1759/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8142 - accuracy: 0.7291 - val_loss: 1.1605 - val_accuracy: 0.6494\n",
      "Epoch 1760/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7644 - accuracy: 0.7458 - val_loss: 1.1454 - val_accuracy: 0.6331\n",
      "Epoch 1761/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6851 - accuracy: 0.7765 - val_loss: 1.1377 - val_accuracy: 0.6429\n",
      "Epoch 1762/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7814 - accuracy: 0.7510 - val_loss: 1.1333 - val_accuracy: 0.6688\n",
      "Epoch 1763/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7646 - accuracy: 0.7500 - val_loss: 1.1311 - val_accuracy: 0.6526\n",
      "Epoch 1764/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7482 - accuracy: 0.7500 - val_loss: 1.1411 - val_accuracy: 0.6591\n",
      "Epoch 1765/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7048 - accuracy: 0.7682 - val_loss: 1.1579 - val_accuracy: 0.6623\n",
      "Epoch 1766/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7690 - accuracy: 0.7402 - val_loss: 1.1769 - val_accuracy: 0.6623\n",
      "Epoch 1767/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8039 - accuracy: 0.7402 - val_loss: 1.1936 - val_accuracy: 0.6494\n",
      "Epoch 1768/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7381 - accuracy: 0.7490 - val_loss: 1.2040 - val_accuracy: 0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1769/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7233 - accuracy: 0.7646 - val_loss: 1.2095 - val_accuracy: 0.6234\n",
      "Epoch 1770/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7225 - accuracy: 0.7715 - val_loss: 1.2088 - val_accuracy: 0.6039\n",
      "Epoch 1771/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7315 - accuracy: 0.7773 - val_loss: 1.2005 - val_accuracy: 0.6136\n",
      "Epoch 1772/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7859 - accuracy: 0.7432 - val_loss: 1.1952 - val_accuracy: 0.6299\n",
      "Epoch 1773/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6498 - accuracy: 0.7723 - val_loss: 1.1933 - val_accuracy: 0.6331\n",
      "Epoch 1774/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7555 - accuracy: 0.7556 - val_loss: 1.1831 - val_accuracy: 0.6299\n",
      "Epoch 1775/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6843 - accuracy: 0.7822 - val_loss: 1.1751 - val_accuracy: 0.6396\n",
      "Epoch 1776/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7301 - accuracy: 0.7539 - val_loss: 1.1519 - val_accuracy: 0.6396\n",
      "Epoch 1777/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7056 - accuracy: 0.7723 - val_loss: 1.1295 - val_accuracy: 0.6461\n",
      "Epoch 1778/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7269 - accuracy: 0.7705 - val_loss: 1.1013 - val_accuracy: 0.6494\n",
      "Epoch 1779/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7350 - accuracy: 0.7584 - val_loss: 1.0840 - val_accuracy: 0.6558\n",
      "Epoch 1780/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6847 - accuracy: 0.7842 - val_loss: 1.0855 - val_accuracy: 0.6429\n",
      "Epoch 1781/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6977 - accuracy: 0.7607 - val_loss: 1.1115 - val_accuracy: 0.6396\n",
      "Epoch 1782/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6904 - accuracy: 0.7779 - val_loss: 1.1430 - val_accuracy: 0.6299\n",
      "Epoch 1783/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6679 - accuracy: 0.7861 - val_loss: 1.1332 - val_accuracy: 0.6396\n",
      "Epoch 1784/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7378 - accuracy: 0.7529 - val_loss: 1.1172 - val_accuracy: 0.6429\n",
      "Epoch 1785/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7476 - accuracy: 0.7668 - val_loss: 1.0980 - val_accuracy: 0.6331\n",
      "Epoch 1786/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6572 - accuracy: 0.7877 - val_loss: 1.0854 - val_accuracy: 0.6558\n",
      "Epoch 1787/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7422 - accuracy: 0.7578 - val_loss: 1.0828 - val_accuracy: 0.6623\n",
      "Epoch 1788/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7263 - accuracy: 0.7744 - val_loss: 1.0859 - val_accuracy: 0.6558\n",
      "Epoch 1789/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7381 - accuracy: 0.7520 - val_loss: 1.0887 - val_accuracy: 0.6494\n",
      "Epoch 1790/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7064 - accuracy: 0.7656 - val_loss: 1.0927 - val_accuracy: 0.6429\n",
      "Epoch 1791/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7467 - accuracy: 0.7514 - val_loss: 1.1052 - val_accuracy: 0.6429\n",
      "Epoch 1792/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7388 - accuracy: 0.7402 - val_loss: 1.1219 - val_accuracy: 0.6364\n",
      "Epoch 1793/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7162 - accuracy: 0.7458 - val_loss: 1.1504 - val_accuracy: 0.6234\n",
      "Epoch 1794/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7827 - accuracy: 0.7682 - val_loss: 1.1757 - val_accuracy: 0.6234\n",
      "Epoch 1795/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7020 - accuracy: 0.7793 - val_loss: 1.2091 - val_accuracy: 0.6136\n",
      "Epoch 1796/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7141 - accuracy: 0.7461 - val_loss: 1.2191 - val_accuracy: 0.6006\n",
      "Epoch 1797/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6919 - accuracy: 0.7754 - val_loss: 1.1929 - val_accuracy: 0.6039\n",
      "Epoch 1798/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7114 - accuracy: 0.7744 - val_loss: 1.1651 - val_accuracy: 0.6169\n",
      "Epoch 1799/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7195 - accuracy: 0.7607 - val_loss: 1.1449 - val_accuracy: 0.6201\n",
      "Epoch 1800/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7381 - accuracy: 0.7444 - val_loss: 1.1384 - val_accuracy: 0.6299\n",
      "Epoch 1801/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7254 - accuracy: 0.7556 - val_loss: 1.1448 - val_accuracy: 0.6201\n",
      "Epoch 1802/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7356 - accuracy: 0.7682 - val_loss: 1.1565 - val_accuracy: 0.6299\n",
      "Epoch 1803/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6917 - accuracy: 0.7668 - val_loss: 1.1678 - val_accuracy: 0.6169\n",
      "Epoch 1804/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7620 - accuracy: 0.7314 - val_loss: 1.1680 - val_accuracy: 0.6266\n",
      "Epoch 1805/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7207 - accuracy: 0.7528 - val_loss: 1.1702 - val_accuracy: 0.6299\n",
      "Epoch 1806/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7138 - accuracy: 0.7656 - val_loss: 1.1737 - val_accuracy: 0.6429\n",
      "Epoch 1807/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7329 - accuracy: 0.7637 - val_loss: 1.1793 - val_accuracy: 0.6461\n",
      "Epoch 1808/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6746 - accuracy: 0.7682 - val_loss: 1.1903 - val_accuracy: 0.6429\n",
      "Epoch 1809/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7047 - accuracy: 0.7754 - val_loss: 1.2026 - val_accuracy: 0.6461\n",
      "Epoch 1810/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7652 - accuracy: 0.7617 - val_loss: 1.2021 - val_accuracy: 0.6331\n",
      "Epoch 1811/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7112 - accuracy: 0.7578 - val_loss: 1.1837 - val_accuracy: 0.6429\n",
      "Epoch 1812/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7351 - accuracy: 0.7598 - val_loss: 1.1732 - val_accuracy: 0.6526\n",
      "Epoch 1813/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6997 - accuracy: 0.7598 - val_loss: 1.1409 - val_accuracy: 0.6396\n",
      "Epoch 1814/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7389 - accuracy: 0.7549 - val_loss: 1.1252 - val_accuracy: 0.6429\n",
      "Epoch 1815/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7226 - accuracy: 0.7542 - val_loss: 1.1131 - val_accuracy: 0.6526\n",
      "Epoch 1816/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6665 - accuracy: 0.7637 - val_loss: 1.0983 - val_accuracy: 0.6558\n",
      "Epoch 1817/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7561 - accuracy: 0.7510 - val_loss: 1.0963 - val_accuracy: 0.6656\n",
      "Epoch 1818/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6433 - accuracy: 0.8017 - val_loss: 1.0987 - val_accuracy: 0.6526\n",
      "Epoch 1819/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6613 - accuracy: 0.7863 - val_loss: 1.1023 - val_accuracy: 0.6591\n",
      "Epoch 1820/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6982 - accuracy: 0.7751 - val_loss: 1.1032 - val_accuracy: 0.6591\n",
      "Epoch 1821/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7813 - accuracy: 0.7393 - val_loss: 1.1022 - val_accuracy: 0.6461\n",
      "Epoch 1822/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7379 - accuracy: 0.7612 - val_loss: 1.1018 - val_accuracy: 0.6526\n",
      "Epoch 1823/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6864 - accuracy: 0.7821 - val_loss: 1.1091 - val_accuracy: 0.6494\n",
      "Epoch 1824/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7070 - accuracy: 0.7686 - val_loss: 1.1104 - val_accuracy: 0.6396\n",
      "Epoch 1825/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6947 - accuracy: 0.7626 - val_loss: 1.1069 - val_accuracy: 0.6461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1826/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6967 - accuracy: 0.7764 - val_loss: 1.1023 - val_accuracy: 0.6494\n",
      "Epoch 1827/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6811 - accuracy: 0.7654 - val_loss: 1.1036 - val_accuracy: 0.6558\n",
      "Epoch 1828/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7056 - accuracy: 0.7654 - val_loss: 1.1111 - val_accuracy: 0.6364\n",
      "Epoch 1829/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7070 - accuracy: 0.7709 - val_loss: 1.1190 - val_accuracy: 0.6331\n",
      "Epoch 1830/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6501 - accuracy: 0.7737 - val_loss: 1.1354 - val_accuracy: 0.6396\n",
      "Epoch 1831/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6641 - accuracy: 0.7900 - val_loss: 1.1386 - val_accuracy: 0.6461\n",
      "Epoch 1832/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7132 - accuracy: 0.7751 - val_loss: 1.1505 - val_accuracy: 0.6234\n",
      "Epoch 1833/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7082 - accuracy: 0.7723 - val_loss: 1.1741 - val_accuracy: 0.6136\n",
      "Epoch 1834/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7416 - accuracy: 0.7682 - val_loss: 1.2154 - val_accuracy: 0.6136\n",
      "Epoch 1835/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6985 - accuracy: 0.7617 - val_loss: 1.2499 - val_accuracy: 0.6169\n",
      "Epoch 1836/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6808 - accuracy: 0.7835 - val_loss: 1.2694 - val_accuracy: 0.6201\n",
      "Epoch 1837/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6462 - accuracy: 0.7900 - val_loss: 1.2688 - val_accuracy: 0.6169\n",
      "Epoch 1838/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7249 - accuracy: 0.7668 - val_loss: 1.2578 - val_accuracy: 0.6201\n",
      "Epoch 1839/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6781 - accuracy: 0.7709 - val_loss: 1.2184 - val_accuracy: 0.6299\n",
      "Epoch 1840/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6904 - accuracy: 0.7793 - val_loss: 1.1944 - val_accuracy: 0.6266\n",
      "Epoch 1841/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7194 - accuracy: 0.7598 - val_loss: 1.1900 - val_accuracy: 0.6234\n",
      "Epoch 1842/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7159 - accuracy: 0.7520 - val_loss: 1.1689 - val_accuracy: 0.6331\n",
      "Epoch 1843/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6951 - accuracy: 0.7612 - val_loss: 1.1573 - val_accuracy: 0.6429\n",
      "Epoch 1844/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7588 - accuracy: 0.7627 - val_loss: 1.1399 - val_accuracy: 0.6429\n",
      "Epoch 1845/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7349 - accuracy: 0.7539 - val_loss: 1.1162 - val_accuracy: 0.6461\n",
      "Epoch 1846/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6833 - accuracy: 0.7754 - val_loss: 1.0924 - val_accuracy: 0.6623\n",
      "Epoch 1847/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7325 - accuracy: 0.7514 - val_loss: 1.0800 - val_accuracy: 0.6721\n",
      "Epoch 1848/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7253 - accuracy: 0.7637 - val_loss: 1.0731 - val_accuracy: 0.6623\n",
      "Epoch 1849/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7018 - accuracy: 0.7682 - val_loss: 1.0724 - val_accuracy: 0.6591\n",
      "Epoch 1850/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6947 - accuracy: 0.7765 - val_loss: 1.0655 - val_accuracy: 0.6656\n",
      "Epoch 1851/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7238 - accuracy: 0.7472 - val_loss: 1.0706 - val_accuracy: 0.6656\n",
      "Epoch 1852/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6507 - accuracy: 0.7835 - val_loss: 1.0746 - val_accuracy: 0.6591\n",
      "Epoch 1853/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6418 - accuracy: 0.7861 - val_loss: 1.0806 - val_accuracy: 0.6494\n",
      "Epoch 1854/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6412 - accuracy: 0.7835 - val_loss: 1.0950 - val_accuracy: 0.6461\n",
      "Epoch 1855/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6996 - accuracy: 0.7725 - val_loss: 1.0917 - val_accuracy: 0.6299\n",
      "Epoch 1856/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7660 - accuracy: 0.7416 - val_loss: 1.0762 - val_accuracy: 0.6331\n",
      "Epoch 1857/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7012 - accuracy: 0.7783 - val_loss: 1.0722 - val_accuracy: 0.6364\n",
      "Epoch 1858/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7098 - accuracy: 0.7578 - val_loss: 1.0651 - val_accuracy: 0.6429\n",
      "Epoch 1859/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6704 - accuracy: 0.7822 - val_loss: 1.0602 - val_accuracy: 0.6461\n",
      "Epoch 1860/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7046 - accuracy: 0.7737 - val_loss: 1.0700 - val_accuracy: 0.6494\n",
      "Epoch 1861/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6729 - accuracy: 0.7835 - val_loss: 1.0755 - val_accuracy: 0.6623\n",
      "Epoch 1862/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7022 - accuracy: 0.7696 - val_loss: 1.0872 - val_accuracy: 0.6526\n",
      "Epoch 1863/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6878 - accuracy: 0.7919 - val_loss: 1.1153 - val_accuracy: 0.6461\n",
      "Epoch 1864/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6640 - accuracy: 0.7705 - val_loss: 1.1417 - val_accuracy: 0.6234\n",
      "Epoch 1865/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6926 - accuracy: 0.7744 - val_loss: 1.1613 - val_accuracy: 0.6364\n",
      "Epoch 1866/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7443 - accuracy: 0.7556 - val_loss: 1.1788 - val_accuracy: 0.6266\n",
      "Epoch 1867/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6611 - accuracy: 0.7930 - val_loss: 1.1893 - val_accuracy: 0.6266\n",
      "Epoch 1868/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6616 - accuracy: 0.7723 - val_loss: 1.2057 - val_accuracy: 0.6396\n",
      "Epoch 1869/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6304 - accuracy: 0.7849 - val_loss: 1.1774 - val_accuracy: 0.6429\n",
      "Epoch 1870/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7254 - accuracy: 0.7444 - val_loss: 1.1554 - val_accuracy: 0.6494\n",
      "Epoch 1871/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7392 - accuracy: 0.7559 - val_loss: 1.1121 - val_accuracy: 0.6429\n",
      "Epoch 1872/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7488 - accuracy: 0.7486 - val_loss: 1.0876 - val_accuracy: 0.6558\n",
      "Epoch 1873/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7077 - accuracy: 0.7584 - val_loss: 1.0847 - val_accuracy: 0.6558\n",
      "Epoch 1874/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7166 - accuracy: 0.7612 - val_loss: 1.0897 - val_accuracy: 0.6526\n",
      "Epoch 1875/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6564 - accuracy: 0.7979 - val_loss: 1.0964 - val_accuracy: 0.6688\n",
      "Epoch 1876/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6658 - accuracy: 0.7807 - val_loss: 1.1135 - val_accuracy: 0.6688\n",
      "Epoch 1877/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7145 - accuracy: 0.7725 - val_loss: 1.1418 - val_accuracy: 0.6494\n",
      "Epoch 1878/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6886 - accuracy: 0.7696 - val_loss: 1.1676 - val_accuracy: 0.6429\n",
      "Epoch 1879/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6792 - accuracy: 0.7754 - val_loss: 1.1874 - val_accuracy: 0.6396\n",
      "Epoch 1880/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6374 - accuracy: 0.7919 - val_loss: 1.1951 - val_accuracy: 0.6429\n",
      "Epoch 1881/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6986 - accuracy: 0.7588 - val_loss: 1.1880 - val_accuracy: 0.6494\n",
      "Epoch 1882/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7159 - accuracy: 0.7640 - val_loss: 1.1841 - val_accuracy: 0.6526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1883/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7244 - accuracy: 0.7556 - val_loss: 1.1661 - val_accuracy: 0.6526\n",
      "Epoch 1884/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6688 - accuracy: 0.7779 - val_loss: 1.1541 - val_accuracy: 0.6623\n",
      "Epoch 1885/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6673 - accuracy: 0.7832 - val_loss: 1.1581 - val_accuracy: 0.6494\n",
      "Epoch 1886/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6670 - accuracy: 0.7910 - val_loss: 1.1488 - val_accuracy: 0.6494\n",
      "Epoch 1887/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6779 - accuracy: 0.7989 - val_loss: 1.1458 - val_accuracy: 0.6494\n",
      "Epoch 1888/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6950 - accuracy: 0.7737 - val_loss: 1.1254 - val_accuracy: 0.6526\n",
      "Epoch 1889/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6446 - accuracy: 0.7891 - val_loss: 1.1044 - val_accuracy: 0.6558\n",
      "Epoch 1890/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6868 - accuracy: 0.7754 - val_loss: 1.0922 - val_accuracy: 0.6721\n",
      "Epoch 1891/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6816 - accuracy: 0.7861 - val_loss: 1.0876 - val_accuracy: 0.6688\n",
      "Epoch 1892/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7090 - accuracy: 0.7709 - val_loss: 1.0841 - val_accuracy: 0.6623\n",
      "Epoch 1893/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6335 - accuracy: 0.7939 - val_loss: 1.0838 - val_accuracy: 0.6591\n",
      "Epoch 1894/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7100 - accuracy: 0.7584 - val_loss: 1.0854 - val_accuracy: 0.6656\n",
      "Epoch 1895/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6782 - accuracy: 0.7773 - val_loss: 1.0974 - val_accuracy: 0.6591\n",
      "Epoch 1896/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6680 - accuracy: 0.7754 - val_loss: 1.1161 - val_accuracy: 0.6591\n",
      "Epoch 1897/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6634 - accuracy: 0.7773 - val_loss: 1.1470 - val_accuracy: 0.6461\n",
      "Epoch 1898/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6308 - accuracy: 0.7881 - val_loss: 1.1778 - val_accuracy: 0.6331\n",
      "Epoch 1899/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7000 - accuracy: 0.7737 - val_loss: 1.1730 - val_accuracy: 0.6299\n",
      "Epoch 1900/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6858 - accuracy: 0.7751 - val_loss: 1.1376 - val_accuracy: 0.6461\n",
      "Epoch 1901/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7001 - accuracy: 0.7737 - val_loss: 1.1135 - val_accuracy: 0.6526\n",
      "Epoch 1902/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6523 - accuracy: 0.7979 - val_loss: 1.0816 - val_accuracy: 0.6688\n",
      "Epoch 1903/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6957 - accuracy: 0.7803 - val_loss: 1.0616 - val_accuracy: 0.6558\n",
      "Epoch 1904/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6662 - accuracy: 0.7725 - val_loss: 1.0527 - val_accuracy: 0.6494\n",
      "Epoch 1905/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6976 - accuracy: 0.7793 - val_loss: 1.0602 - val_accuracy: 0.6526\n",
      "Epoch 1906/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7118 - accuracy: 0.7682 - val_loss: 1.0671 - val_accuracy: 0.6623\n",
      "Epoch 1907/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6673 - accuracy: 0.7891 - val_loss: 1.0802 - val_accuracy: 0.6591\n",
      "Epoch 1908/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6439 - accuracy: 0.7910 - val_loss: 1.0907 - val_accuracy: 0.6494\n",
      "Epoch 1909/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6337 - accuracy: 0.7905 - val_loss: 1.0852 - val_accuracy: 0.6526\n",
      "Epoch 1910/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6140 - accuracy: 0.7947 - val_loss: 1.0835 - val_accuracy: 0.6558\n",
      "Epoch 1911/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6348 - accuracy: 0.7988 - val_loss: 1.0830 - val_accuracy: 0.6591\n",
      "Epoch 1912/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6259 - accuracy: 0.7920 - val_loss: 1.0756 - val_accuracy: 0.6688\n",
      "Epoch 1913/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7136 - accuracy: 0.7500 - val_loss: 1.0766 - val_accuracy: 0.6688\n",
      "Epoch 1914/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6701 - accuracy: 0.7779 - val_loss: 1.0837 - val_accuracy: 0.6558\n",
      "Epoch 1915/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6902 - accuracy: 0.7754 - val_loss: 1.0956 - val_accuracy: 0.6558\n",
      "Epoch 1916/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6947 - accuracy: 0.7598 - val_loss: 1.1134 - val_accuracy: 0.6526\n",
      "Epoch 1917/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6229 - accuracy: 0.7891 - val_loss: 1.1368 - val_accuracy: 0.6429\n",
      "Epoch 1918/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6191 - accuracy: 0.7947 - val_loss: 1.1460 - val_accuracy: 0.6396\n",
      "Epoch 1919/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6380 - accuracy: 0.7849 - val_loss: 1.1432 - val_accuracy: 0.6396\n",
      "Epoch 1920/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6908 - accuracy: 0.7905 - val_loss: 1.1317 - val_accuracy: 0.6429\n",
      "Epoch 1921/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7101 - accuracy: 0.7695 - val_loss: 1.1085 - val_accuracy: 0.6591\n",
      "Epoch 1922/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6516 - accuracy: 0.7822 - val_loss: 1.0868 - val_accuracy: 0.6558\n",
      "Epoch 1923/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6344 - accuracy: 0.7871 - val_loss: 1.0669 - val_accuracy: 0.6623\n",
      "Epoch 1924/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6888 - accuracy: 0.7734 - val_loss: 1.0469 - val_accuracy: 0.6591\n",
      "Epoch 1925/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6453 - accuracy: 0.7949 - val_loss: 1.0353 - val_accuracy: 0.6656\n",
      "Epoch 1926/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6616 - accuracy: 0.7737 - val_loss: 1.0257 - val_accuracy: 0.6883\n",
      "Epoch 1927/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6574 - accuracy: 0.7734 - val_loss: 1.0259 - val_accuracy: 0.6981\n",
      "Epoch 1928/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6293 - accuracy: 0.8047 - val_loss: 1.0353 - val_accuracy: 0.6981\n",
      "Epoch 1929/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6559 - accuracy: 0.7852 - val_loss: 1.0461 - val_accuracy: 0.6948\n",
      "Epoch 1930/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6543 - accuracy: 0.7793 - val_loss: 1.0740 - val_accuracy: 0.6721\n",
      "Epoch 1931/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6917 - accuracy: 0.7682 - val_loss: 1.1113 - val_accuracy: 0.6494\n",
      "Epoch 1932/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6986 - accuracy: 0.7607 - val_loss: 1.1488 - val_accuracy: 0.6396\n",
      "Epoch 1933/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6173 - accuracy: 0.8128 - val_loss: 1.1615 - val_accuracy: 0.6429\n",
      "Epoch 1934/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6602 - accuracy: 0.7852 - val_loss: 1.1821 - val_accuracy: 0.6331\n",
      "Epoch 1935/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6489 - accuracy: 0.7900 - val_loss: 1.1949 - val_accuracy: 0.6234\n",
      "Epoch 1936/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6598 - accuracy: 0.7682 - val_loss: 1.1871 - val_accuracy: 0.6331\n",
      "Epoch 1937/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7069 - accuracy: 0.7676 - val_loss: 1.1832 - val_accuracy: 0.6331\n",
      "Epoch 1938/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6987 - accuracy: 0.7812 - val_loss: 1.1828 - val_accuracy: 0.6461\n",
      "Epoch 1939/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6231 - accuracy: 0.7905 - val_loss: 1.1630 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1940/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7395 - accuracy: 0.7510 - val_loss: 1.1602 - val_accuracy: 0.6429\n",
      "Epoch 1941/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6232 - accuracy: 0.7998 - val_loss: 1.1572 - val_accuracy: 0.6494\n",
      "Epoch 1942/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6328 - accuracy: 0.7939 - val_loss: 1.1527 - val_accuracy: 0.6494\n",
      "Epoch 1943/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6757 - accuracy: 0.7646 - val_loss: 1.1453 - val_accuracy: 0.6461\n",
      "Epoch 1944/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5724 - accuracy: 0.8086 - val_loss: 1.1403 - val_accuracy: 0.6526\n",
      "Epoch 1945/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6594 - accuracy: 0.7803 - val_loss: 1.1455 - val_accuracy: 0.6494\n",
      "Epoch 1946/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6217 - accuracy: 0.7891 - val_loss: 1.1517 - val_accuracy: 0.6526\n",
      "Epoch 1947/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6464 - accuracy: 0.7754 - val_loss: 1.1640 - val_accuracy: 0.6396\n",
      "Epoch 1948/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6871 - accuracy: 0.7764 - val_loss: 1.1942 - val_accuracy: 0.6299\n",
      "Epoch 1949/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6779 - accuracy: 0.7584 - val_loss: 1.2240 - val_accuracy: 0.6266\n",
      "Epoch 1950/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6820 - accuracy: 0.7881 - val_loss: 1.2273 - val_accuracy: 0.6266\n",
      "Epoch 1951/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6035 - accuracy: 0.7947 - val_loss: 1.2329 - val_accuracy: 0.6201\n",
      "Epoch 1952/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5917 - accuracy: 0.8066 - val_loss: 1.2336 - val_accuracy: 0.6169\n",
      "Epoch 1953/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6179 - accuracy: 0.7988 - val_loss: 1.2210 - val_accuracy: 0.6136\n",
      "Epoch 1954/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6101 - accuracy: 0.8073 - val_loss: 1.2081 - val_accuracy: 0.6169\n",
      "Epoch 1955/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6481 - accuracy: 0.7891 - val_loss: 1.2089 - val_accuracy: 0.6136\n",
      "Epoch 1956/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6627 - accuracy: 0.7881 - val_loss: 1.1913 - val_accuracy: 0.6201\n",
      "Epoch 1957/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6652 - accuracy: 0.7842 - val_loss: 1.1710 - val_accuracy: 0.6169\n",
      "Epoch 1958/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6175 - accuracy: 0.7863 - val_loss: 1.1545 - val_accuracy: 0.6299\n",
      "Epoch 1959/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6217 - accuracy: 0.7933 - val_loss: 1.1524 - val_accuracy: 0.6429\n",
      "Epoch 1960/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6257 - accuracy: 0.7891 - val_loss: 1.1474 - val_accuracy: 0.6396\n",
      "Epoch 1961/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6554 - accuracy: 0.7979 - val_loss: 1.1423 - val_accuracy: 0.6364\n",
      "Epoch 1962/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6416 - accuracy: 0.7668 - val_loss: 1.1472 - val_accuracy: 0.6266\n",
      "Epoch 1963/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6287 - accuracy: 0.7939 - val_loss: 1.1517 - val_accuracy: 0.6234\n",
      "Epoch 1964/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5994 - accuracy: 0.8027 - val_loss: 1.1666 - val_accuracy: 0.6364\n",
      "Epoch 1965/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6893 - accuracy: 0.7910 - val_loss: 1.1816 - val_accuracy: 0.6461\n",
      "Epoch 1966/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6534 - accuracy: 0.7905 - val_loss: 1.1787 - val_accuracy: 0.6364\n",
      "Epoch 1967/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6382 - accuracy: 0.7705 - val_loss: 1.1790 - val_accuracy: 0.6331\n",
      "Epoch 1968/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6545 - accuracy: 0.7871 - val_loss: 1.1607 - val_accuracy: 0.6169\n",
      "Epoch 1969/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6088 - accuracy: 0.7947 - val_loss: 1.1437 - val_accuracy: 0.6266\n",
      "Epoch 1970/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6370 - accuracy: 0.8008 - val_loss: 1.1270 - val_accuracy: 0.6266\n",
      "Epoch 1971/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6705 - accuracy: 0.7773 - val_loss: 1.1221 - val_accuracy: 0.6234\n",
      "Epoch 1972/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6279 - accuracy: 0.8045 - val_loss: 1.1158 - val_accuracy: 0.6234\n",
      "Epoch 1973/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6028 - accuracy: 0.8017 - val_loss: 1.1155 - val_accuracy: 0.6299\n",
      "Epoch 1974/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6125 - accuracy: 0.7900 - val_loss: 1.1159 - val_accuracy: 0.6331\n",
      "Epoch 1975/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6798 - accuracy: 0.7627 - val_loss: 1.1146 - val_accuracy: 0.6331\n",
      "Epoch 1976/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6322 - accuracy: 0.7905 - val_loss: 1.1175 - val_accuracy: 0.6331\n",
      "Epoch 1977/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6560 - accuracy: 0.7933 - val_loss: 1.1400 - val_accuracy: 0.6364\n",
      "Epoch 1978/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6434 - accuracy: 0.7961 - val_loss: 1.1725 - val_accuracy: 0.6331\n",
      "Epoch 1979/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5769 - accuracy: 0.8115 - val_loss: 1.1892 - val_accuracy: 0.6201\n",
      "Epoch 1980/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6305 - accuracy: 0.7754 - val_loss: 1.1873 - val_accuracy: 0.6234\n",
      "Epoch 1981/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7076 - accuracy: 0.7682 - val_loss: 1.1473 - val_accuracy: 0.6299\n",
      "Epoch 1982/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6490 - accuracy: 0.7696 - val_loss: 1.0964 - val_accuracy: 0.6461\n",
      "Epoch 1983/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6693 - accuracy: 0.7682 - val_loss: 1.0586 - val_accuracy: 0.6558\n",
      "Epoch 1984/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6478 - accuracy: 0.7803 - val_loss: 1.0479 - val_accuracy: 0.6558\n",
      "Epoch 1985/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6192 - accuracy: 0.7852 - val_loss: 1.0535 - val_accuracy: 0.6656\n",
      "Epoch 1986/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6029 - accuracy: 0.7939 - val_loss: 1.0640 - val_accuracy: 0.6753\n",
      "Epoch 1987/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6287 - accuracy: 0.7852 - val_loss: 1.0618 - val_accuracy: 0.6721\n",
      "Epoch 1988/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6110 - accuracy: 0.8128 - val_loss: 1.0600 - val_accuracy: 0.6721\n",
      "Epoch 1989/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6048 - accuracy: 0.7979 - val_loss: 1.0546 - val_accuracy: 0.6558\n",
      "Epoch 1990/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6308 - accuracy: 0.7910 - val_loss: 1.0655 - val_accuracy: 0.6526\n",
      "Epoch 1991/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6615 - accuracy: 0.7933 - val_loss: 1.0914 - val_accuracy: 0.6558\n",
      "Epoch 1992/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6639 - accuracy: 0.7852 - val_loss: 1.1368 - val_accuracy: 0.6526\n",
      "Epoch 1993/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6288 - accuracy: 0.7900 - val_loss: 1.1773 - val_accuracy: 0.6526\n",
      "Epoch 1994/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6048 - accuracy: 0.8008 - val_loss: 1.1807 - val_accuracy: 0.6461\n",
      "Epoch 1995/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6683 - accuracy: 0.7919 - val_loss: 1.1850 - val_accuracy: 0.6396\n",
      "Epoch 1996/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5729 - accuracy: 0.8037 - val_loss: 1.1765 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1997/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6222 - accuracy: 0.7877 - val_loss: 1.1461 - val_accuracy: 0.6429\n",
      "Epoch 1998/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6324 - accuracy: 0.7933 - val_loss: 1.1219 - val_accuracy: 0.6331\n",
      "Epoch 1999/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6257 - accuracy: 0.7961 - val_loss: 1.1188 - val_accuracy: 0.6331\n",
      "Epoch 2000/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5651 - accuracy: 0.8115 - val_loss: 1.1225 - val_accuracy: 0.6299\n",
      "Epoch 2001/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6723 - accuracy: 0.7807 - val_loss: 1.1259 - val_accuracy: 0.6429\n",
      "Epoch 2002/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6680 - accuracy: 0.7779 - val_loss: 1.1271 - val_accuracy: 0.6461\n",
      "Epoch 2003/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6443 - accuracy: 0.7793 - val_loss: 1.1401 - val_accuracy: 0.6299\n",
      "Epoch 2004/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5864 - accuracy: 0.8105 - val_loss: 1.1631 - val_accuracy: 0.6396\n",
      "Epoch 2005/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6030 - accuracy: 0.8105 - val_loss: 1.1809 - val_accuracy: 0.6364\n",
      "Epoch 2006/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6235 - accuracy: 0.7959 - val_loss: 1.1909 - val_accuracy: 0.6234\n",
      "Epoch 2007/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6023 - accuracy: 0.8076 - val_loss: 1.1860 - val_accuracy: 0.6266\n",
      "Epoch 2008/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5994 - accuracy: 0.8047 - val_loss: 1.1843 - val_accuracy: 0.6331\n",
      "Epoch 2009/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6277 - accuracy: 0.7910 - val_loss: 1.1783 - val_accuracy: 0.6364\n",
      "Epoch 2010/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6402 - accuracy: 0.7920 - val_loss: 1.1749 - val_accuracy: 0.6331\n",
      "Epoch 2011/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6113 - accuracy: 0.8087 - val_loss: 1.1727 - val_accuracy: 0.6299\n",
      "Epoch 2012/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6504 - accuracy: 0.7793 - val_loss: 1.1832 - val_accuracy: 0.6234\n",
      "Epoch 2013/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5629 - accuracy: 0.8045 - val_loss: 1.2039 - val_accuracy: 0.6429\n",
      "Epoch 2014/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6032 - accuracy: 0.7975 - val_loss: 1.2338 - val_accuracy: 0.6364\n",
      "Epoch 2015/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5652 - accuracy: 0.8226 - val_loss: 1.2647 - val_accuracy: 0.6201\n",
      "Epoch 2016/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6201 - accuracy: 0.8008 - val_loss: 1.2956 - val_accuracy: 0.6201\n",
      "Epoch 2017/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6327 - accuracy: 0.7877 - val_loss: 1.3209 - val_accuracy: 0.6266\n",
      "Epoch 2018/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6602 - accuracy: 0.7949 - val_loss: 1.2958 - val_accuracy: 0.6299\n",
      "Epoch 2019/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6537 - accuracy: 0.7881 - val_loss: 1.2479 - val_accuracy: 0.6429\n",
      "Epoch 2020/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5784 - accuracy: 0.8101 - val_loss: 1.1893 - val_accuracy: 0.6396\n",
      "Epoch 2021/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5936 - accuracy: 0.7988 - val_loss: 1.1567 - val_accuracy: 0.6364\n",
      "Epoch 2022/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6643 - accuracy: 0.7871 - val_loss: 1.1434 - val_accuracy: 0.6331\n",
      "Epoch 2023/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6057 - accuracy: 0.7939 - val_loss: 1.1362 - val_accuracy: 0.6461\n",
      "Epoch 2024/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6128 - accuracy: 0.8003 - val_loss: 1.1360 - val_accuracy: 0.6623\n",
      "Epoch 2025/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5995 - accuracy: 0.7961 - val_loss: 1.1280 - val_accuracy: 0.6656\n",
      "Epoch 2026/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6071 - accuracy: 0.8105 - val_loss: 1.1122 - val_accuracy: 0.6656\n",
      "Epoch 2027/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6441 - accuracy: 0.7835 - val_loss: 1.1058 - val_accuracy: 0.6656\n",
      "Epoch 2028/4000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6594 - accuracy: 0.7832 - val_loss: 1.1079 - val_accuracy: 0.6558\n",
      "Epoch 2029/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6269 - accuracy: 0.7959 - val_loss: 1.1164 - val_accuracy: 0.6526\n",
      "Epoch 2030/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6674 - accuracy: 0.7871 - val_loss: 1.1301 - val_accuracy: 0.6526\n",
      "Epoch 2031/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6243 - accuracy: 0.7863 - val_loss: 1.1160 - val_accuracy: 0.6591\n",
      "Epoch 2032/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6147 - accuracy: 0.7877 - val_loss: 1.0940 - val_accuracy: 0.6688\n",
      "Epoch 2033/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5932 - accuracy: 0.8066 - val_loss: 1.0883 - val_accuracy: 0.6623\n",
      "Epoch 2034/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6045 - accuracy: 0.7947 - val_loss: 1.0909 - val_accuracy: 0.6688\n",
      "Epoch 2035/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5878 - accuracy: 0.7988 - val_loss: 1.1063 - val_accuracy: 0.6721\n",
      "Epoch 2036/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6197 - accuracy: 0.8017 - val_loss: 1.1133 - val_accuracy: 0.6656\n",
      "Epoch 2037/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6653 - accuracy: 0.7877 - val_loss: 1.1108 - val_accuracy: 0.6688\n",
      "Epoch 2038/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6204 - accuracy: 0.8076 - val_loss: 1.0920 - val_accuracy: 0.6623\n",
      "Epoch 2039/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6522 - accuracy: 0.7900 - val_loss: 1.0725 - val_accuracy: 0.6656\n",
      "Epoch 2040/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5816 - accuracy: 0.7989 - val_loss: 1.0673 - val_accuracy: 0.6721\n",
      "Epoch 2041/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6534 - accuracy: 0.7891 - val_loss: 1.0671 - val_accuracy: 0.6721\n",
      "Epoch 2042/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6693 - accuracy: 0.7821 - val_loss: 1.0652 - val_accuracy: 0.6623\n",
      "Epoch 2043/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6878 - accuracy: 0.7807 - val_loss: 1.0847 - val_accuracy: 0.6461\n",
      "Epoch 2044/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6037 - accuracy: 0.8017 - val_loss: 1.1061 - val_accuracy: 0.6396\n",
      "Epoch 2045/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6200 - accuracy: 0.7947 - val_loss: 1.1308 - val_accuracy: 0.6429\n",
      "Epoch 2046/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6682 - accuracy: 0.7754 - val_loss: 1.1381 - val_accuracy: 0.6396\n",
      "Epoch 2047/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6006 - accuracy: 0.8027 - val_loss: 1.1354 - val_accuracy: 0.6234\n",
      "Epoch 2048/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6351 - accuracy: 0.8003 - val_loss: 1.1404 - val_accuracy: 0.6364\n",
      "Epoch 2049/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6214 - accuracy: 0.7988 - val_loss: 1.1302 - val_accuracy: 0.6429\n",
      "Epoch 2050/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6717 - accuracy: 0.7779 - val_loss: 1.1159 - val_accuracy: 0.6623\n",
      "Epoch 2051/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6414 - accuracy: 0.7835 - val_loss: 1.0964 - val_accuracy: 0.6656\n",
      "Epoch 2052/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6102 - accuracy: 0.7998 - val_loss: 1.0755 - val_accuracy: 0.6721\n",
      "Epoch 2053/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5958 - accuracy: 0.8087 - val_loss: 1.0691 - val_accuracy: 0.6688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2054/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6987 - accuracy: 0.7514 - val_loss: 1.0716 - val_accuracy: 0.6461\n",
      "Epoch 2055/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6891 - accuracy: 0.7696 - val_loss: 1.0890 - val_accuracy: 0.6494\n",
      "Epoch 2056/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6145 - accuracy: 0.7905 - val_loss: 1.1069 - val_accuracy: 0.6558\n",
      "Epoch 2057/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5975 - accuracy: 0.7849 - val_loss: 1.1056 - val_accuracy: 0.6526\n",
      "Epoch 2058/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6340 - accuracy: 0.7861 - val_loss: 1.0996 - val_accuracy: 0.6656\n",
      "Epoch 2059/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6576 - accuracy: 0.7751 - val_loss: 1.0952 - val_accuracy: 0.6623\n",
      "Epoch 2060/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5606 - accuracy: 0.8170 - val_loss: 1.0982 - val_accuracy: 0.6753\n",
      "Epoch 2061/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6483 - accuracy: 0.7852 - val_loss: 1.0909 - val_accuracy: 0.6721\n",
      "Epoch 2062/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6162 - accuracy: 0.7998 - val_loss: 1.0763 - val_accuracy: 0.6786\n",
      "Epoch 2063/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6719 - accuracy: 0.7905 - val_loss: 1.0824 - val_accuracy: 0.6753\n",
      "Epoch 2064/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5795 - accuracy: 0.8057 - val_loss: 1.1044 - val_accuracy: 0.6558\n",
      "Epoch 2065/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6227 - accuracy: 0.7734 - val_loss: 1.1454 - val_accuracy: 0.6429\n",
      "Epoch 2066/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5943 - accuracy: 0.8008 - val_loss: 1.1715 - val_accuracy: 0.6299\n",
      "Epoch 2067/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5975 - accuracy: 0.8003 - val_loss: 1.1944 - val_accuracy: 0.6266\n",
      "Epoch 2068/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5994 - accuracy: 0.7905 - val_loss: 1.2138 - val_accuracy: 0.6266\n",
      "Epoch 2069/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5620 - accuracy: 0.8198 - val_loss: 1.2244 - val_accuracy: 0.6234\n",
      "Epoch 2070/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6805 - accuracy: 0.7723 - val_loss: 1.2396 - val_accuracy: 0.6299\n",
      "Epoch 2071/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5598 - accuracy: 0.8125 - val_loss: 1.2700 - val_accuracy: 0.6169\n",
      "Epoch 2072/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5945 - accuracy: 0.8047 - val_loss: 1.3145 - val_accuracy: 0.6169\n",
      "Epoch 2073/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6329 - accuracy: 0.8226 - val_loss: 1.3378 - val_accuracy: 0.6039\n",
      "Epoch 2074/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6615 - accuracy: 0.7871 - val_loss: 1.3808 - val_accuracy: 0.5844\n",
      "Epoch 2075/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6256 - accuracy: 0.7849 - val_loss: 1.4080 - val_accuracy: 0.5747\n",
      "Epoch 2076/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6520 - accuracy: 0.7988 - val_loss: 1.3801 - val_accuracy: 0.5779\n",
      "Epoch 2077/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5749 - accuracy: 0.7979 - val_loss: 1.3269 - val_accuracy: 0.5844\n",
      "Epoch 2078/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5774 - accuracy: 0.8076 - val_loss: 1.2853 - val_accuracy: 0.5877\n",
      "Epoch 2079/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5575 - accuracy: 0.8226 - val_loss: 1.2648 - val_accuracy: 0.5942\n",
      "Epoch 2080/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6252 - accuracy: 0.7979 - val_loss: 1.2565 - val_accuracy: 0.5909\n",
      "Epoch 2081/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5754 - accuracy: 0.8125 - val_loss: 1.2303 - val_accuracy: 0.6006\n",
      "Epoch 2082/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5804 - accuracy: 0.8115 - val_loss: 1.2470 - val_accuracy: 0.6234\n",
      "Epoch 2083/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5383 - accuracy: 0.8359 - val_loss: 1.2612 - val_accuracy: 0.6299\n",
      "Epoch 2084/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5598 - accuracy: 0.8170 - val_loss: 1.2540 - val_accuracy: 0.6364\n",
      "Epoch 2085/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5953 - accuracy: 0.8045 - val_loss: 1.2520 - val_accuracy: 0.6364\n",
      "Epoch 2086/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6140 - accuracy: 0.7900 - val_loss: 1.2613 - val_accuracy: 0.6331\n",
      "Epoch 2087/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5880 - accuracy: 0.8115 - val_loss: 1.2436 - val_accuracy: 0.6396\n",
      "Epoch 2088/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5940 - accuracy: 0.8086 - val_loss: 1.2341 - val_accuracy: 0.6299\n",
      "Epoch 2089/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6021 - accuracy: 0.7933 - val_loss: 1.2348 - val_accuracy: 0.6266\n",
      "Epoch 2090/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6346 - accuracy: 0.7961 - val_loss: 1.2052 - val_accuracy: 0.6364\n",
      "Epoch 2091/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6025 - accuracy: 0.8018 - val_loss: 1.1907 - val_accuracy: 0.6234\n",
      "Epoch 2092/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6161 - accuracy: 0.7989 - val_loss: 1.1742 - val_accuracy: 0.6266\n",
      "Epoch 2093/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5749 - accuracy: 0.8059 - val_loss: 1.1584 - val_accuracy: 0.6364\n",
      "Epoch 2094/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5213 - accuracy: 0.8240 - val_loss: 1.1651 - val_accuracy: 0.6266\n",
      "Epoch 2095/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5700 - accuracy: 0.8338 - val_loss: 1.1608 - val_accuracy: 0.6266\n",
      "Epoch 2096/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6231 - accuracy: 0.7933 - val_loss: 1.1585 - val_accuracy: 0.6364\n",
      "Epoch 2097/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5703 - accuracy: 0.8066 - val_loss: 1.1602 - val_accuracy: 0.6364\n",
      "Epoch 2098/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5658 - accuracy: 0.8076 - val_loss: 1.1663 - val_accuracy: 0.6201\n",
      "Epoch 2099/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6547 - accuracy: 0.7930 - val_loss: 1.1778 - val_accuracy: 0.6136\n",
      "Epoch 2100/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6742 - accuracy: 0.7905 - val_loss: 1.1710 - val_accuracy: 0.6136\n",
      "Epoch 2101/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5608 - accuracy: 0.8045 - val_loss: 1.1304 - val_accuracy: 0.6201\n",
      "Epoch 2102/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5932 - accuracy: 0.8027 - val_loss: 1.0940 - val_accuracy: 0.6266\n",
      "Epoch 2103/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6060 - accuracy: 0.8184 - val_loss: 1.0714 - val_accuracy: 0.6461\n",
      "Epoch 2104/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5887 - accuracy: 0.7961 - val_loss: 1.0649 - val_accuracy: 0.6396\n",
      "Epoch 2105/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6256 - accuracy: 0.8073 - val_loss: 1.0724 - val_accuracy: 0.6526\n",
      "Epoch 2106/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5951 - accuracy: 0.8027 - val_loss: 1.0923 - val_accuracy: 0.6429\n",
      "Epoch 2107/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6011 - accuracy: 0.7988 - val_loss: 1.1178 - val_accuracy: 0.6364\n",
      "Epoch 2108/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5785 - accuracy: 0.8047 - val_loss: 1.1611 - val_accuracy: 0.6234\n",
      "Epoch 2109/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6631 - accuracy: 0.7744 - val_loss: 1.2271 - val_accuracy: 0.6169\n",
      "Epoch 2110/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6158 - accuracy: 0.7881 - val_loss: 1.2742 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2111/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5939 - accuracy: 0.8156 - val_loss: 1.2939 - val_accuracy: 0.6169\n",
      "Epoch 2112/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6493 - accuracy: 0.7920 - val_loss: 1.2474 - val_accuracy: 0.6234\n",
      "Epoch 2113/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5826 - accuracy: 0.8174 - val_loss: 1.2011 - val_accuracy: 0.6201\n",
      "Epoch 2114/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6505 - accuracy: 0.7919 - val_loss: 1.1880 - val_accuracy: 0.6364\n",
      "Epoch 2115/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6219 - accuracy: 0.7863 - val_loss: 1.1773 - val_accuracy: 0.6299\n",
      "Epoch 2116/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6493 - accuracy: 0.7988 - val_loss: 1.1483 - val_accuracy: 0.6364\n",
      "Epoch 2117/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5950 - accuracy: 0.8027 - val_loss: 1.1140 - val_accuracy: 0.6266\n",
      "Epoch 2118/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6012 - accuracy: 0.7905 - val_loss: 1.1073 - val_accuracy: 0.6331\n",
      "Epoch 2119/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6107 - accuracy: 0.7891 - val_loss: 1.0986 - val_accuracy: 0.6266\n",
      "Epoch 2120/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5847 - accuracy: 0.8128 - val_loss: 1.0985 - val_accuracy: 0.6331\n",
      "Epoch 2121/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6217 - accuracy: 0.7998 - val_loss: 1.1044 - val_accuracy: 0.6364\n",
      "Epoch 2122/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6023 - accuracy: 0.7910 - val_loss: 1.1268 - val_accuracy: 0.6331\n",
      "Epoch 2123/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6426 - accuracy: 0.8017 - val_loss: 1.1634 - val_accuracy: 0.6364\n",
      "Epoch 2124/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6005 - accuracy: 0.8008 - val_loss: 1.2293 - val_accuracy: 0.6201\n",
      "Epoch 2125/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6047 - accuracy: 0.8087 - val_loss: 1.3066 - val_accuracy: 0.6071\n",
      "Epoch 2126/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6312 - accuracy: 0.7961 - val_loss: 1.3422 - val_accuracy: 0.6071\n",
      "Epoch 2127/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5834 - accuracy: 0.8059 - val_loss: 1.3545 - val_accuracy: 0.5974\n",
      "Epoch 2128/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6113 - accuracy: 0.7939 - val_loss: 1.3393 - val_accuracy: 0.6104\n",
      "Epoch 2129/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5982 - accuracy: 0.8145 - val_loss: 1.3033 - val_accuracy: 0.6266\n",
      "Epoch 2130/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6045 - accuracy: 0.7989 - val_loss: 1.2729 - val_accuracy: 0.6104\n",
      "Epoch 2131/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5885 - accuracy: 0.8008 - val_loss: 1.2244 - val_accuracy: 0.6364\n",
      "Epoch 2132/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6045 - accuracy: 0.8105 - val_loss: 1.1893 - val_accuracy: 0.6364\n",
      "Epoch 2133/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5779 - accuracy: 0.8003 - val_loss: 1.1821 - val_accuracy: 0.6299\n",
      "Epoch 2134/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6138 - accuracy: 0.8101 - val_loss: 1.2082 - val_accuracy: 0.6299\n",
      "Epoch 2135/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5857 - accuracy: 0.7998 - val_loss: 1.2398 - val_accuracy: 0.6136\n",
      "Epoch 2136/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5977 - accuracy: 0.8045 - val_loss: 1.2934 - val_accuracy: 0.6169\n",
      "Epoch 2137/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5809 - accuracy: 0.8086 - val_loss: 1.3540 - val_accuracy: 0.6039\n",
      "Epoch 2138/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5960 - accuracy: 0.8154 - val_loss: 1.4205 - val_accuracy: 0.5877\n",
      "Epoch 2139/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6415 - accuracy: 0.7989 - val_loss: 1.4881 - val_accuracy: 0.5747\n",
      "Epoch 2140/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5531 - accuracy: 0.8320 - val_loss: 1.5249 - val_accuracy: 0.5714\n",
      "Epoch 2141/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5743 - accuracy: 0.8017 - val_loss: 1.5189 - val_accuracy: 0.5812\n",
      "Epoch 2142/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6282 - accuracy: 0.7849 - val_loss: 1.4935 - val_accuracy: 0.5909\n",
      "Epoch 2143/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5956 - accuracy: 0.8017 - val_loss: 1.4698 - val_accuracy: 0.6006\n",
      "Epoch 2144/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5687 - accuracy: 0.8291 - val_loss: 1.4186 - val_accuracy: 0.6104\n",
      "Epoch 2145/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5652 - accuracy: 0.8240 - val_loss: 1.3742 - val_accuracy: 0.5974\n",
      "Epoch 2146/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5710 - accuracy: 0.8115 - val_loss: 1.3366 - val_accuracy: 0.6006\n",
      "Epoch 2147/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6524 - accuracy: 0.7877 - val_loss: 1.2951 - val_accuracy: 0.6331\n",
      "Epoch 2148/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5227 - accuracy: 0.8242 - val_loss: 1.2822 - val_accuracy: 0.6299\n",
      "Epoch 2149/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6139 - accuracy: 0.8174 - val_loss: 1.2852 - val_accuracy: 0.6299\n",
      "Epoch 2150/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6164 - accuracy: 0.7905 - val_loss: 1.3050 - val_accuracy: 0.6169\n",
      "Epoch 2151/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6074 - accuracy: 0.8059 - val_loss: 1.3446 - val_accuracy: 0.6169\n",
      "Epoch 2152/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5975 - accuracy: 0.8101 - val_loss: 1.3746 - val_accuracy: 0.6266\n",
      "Epoch 2153/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6215 - accuracy: 0.7910 - val_loss: 1.3914 - val_accuracy: 0.6299\n",
      "Epoch 2154/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6038 - accuracy: 0.7905 - val_loss: 1.3549 - val_accuracy: 0.6234\n",
      "Epoch 2155/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5619 - accuracy: 0.8135 - val_loss: 1.3093 - val_accuracy: 0.6364\n",
      "Epoch 2156/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5903 - accuracy: 0.8086 - val_loss: 1.2815 - val_accuracy: 0.6266\n",
      "Epoch 2157/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5406 - accuracy: 0.8254 - val_loss: 1.2402 - val_accuracy: 0.6234\n",
      "Epoch 2158/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5867 - accuracy: 0.7835 - val_loss: 1.2156 - val_accuracy: 0.6299\n",
      "Epoch 2159/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5804 - accuracy: 0.8045 - val_loss: 1.2051 - val_accuracy: 0.6299\n",
      "Epoch 2160/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5845 - accuracy: 0.8154 - val_loss: 1.2089 - val_accuracy: 0.6396\n",
      "Epoch 2161/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6084 - accuracy: 0.7949 - val_loss: 1.2229 - val_accuracy: 0.6461\n",
      "Epoch 2162/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5747 - accuracy: 0.8047 - val_loss: 1.2411 - val_accuracy: 0.6526\n",
      "Epoch 2163/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6043 - accuracy: 0.8057 - val_loss: 1.2634 - val_accuracy: 0.6558\n",
      "Epoch 2164/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5659 - accuracy: 0.8128 - val_loss: 1.2724 - val_accuracy: 0.6526\n",
      "Epoch 2165/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6155 - accuracy: 0.8037 - val_loss: 1.3033 - val_accuracy: 0.6364\n",
      "Epoch 2166/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6488 - accuracy: 0.7849 - val_loss: 1.3414 - val_accuracy: 0.6104\n",
      "Epoch 2167/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5882 - accuracy: 0.8135 - val_loss: 1.3458 - val_accuracy: 0.6169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2168/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5220 - accuracy: 0.8352 - val_loss: 1.3075 - val_accuracy: 0.6136\n",
      "Epoch 2169/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6076 - accuracy: 0.7975 - val_loss: 1.2299 - val_accuracy: 0.6201\n",
      "Epoch 2170/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5848 - accuracy: 0.8087 - val_loss: 1.1578 - val_accuracy: 0.6201\n",
      "Epoch 2171/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6275 - accuracy: 0.8031 - val_loss: 1.1170 - val_accuracy: 0.6266\n",
      "Epoch 2172/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6047 - accuracy: 0.7989 - val_loss: 1.1024 - val_accuracy: 0.6429\n",
      "Epoch 2173/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5401 - accuracy: 0.8198 - val_loss: 1.1114 - val_accuracy: 0.6429\n",
      "Epoch 2174/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5502 - accuracy: 0.8174 - val_loss: 1.1282 - val_accuracy: 0.6429\n",
      "Epoch 2175/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6588 - accuracy: 0.7877 - val_loss: 1.1605 - val_accuracy: 0.6494\n",
      "Epoch 2176/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5638 - accuracy: 0.8115 - val_loss: 1.2051 - val_accuracy: 0.6396\n",
      "Epoch 2177/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5889 - accuracy: 0.8066 - val_loss: 1.2397 - val_accuracy: 0.6234\n",
      "Epoch 2178/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5501 - accuracy: 0.8203 - val_loss: 1.2812 - val_accuracy: 0.6104\n",
      "Epoch 2179/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6007 - accuracy: 0.8018 - val_loss: 1.3077 - val_accuracy: 0.6006\n",
      "Epoch 2180/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5703 - accuracy: 0.8128 - val_loss: 1.3172 - val_accuracy: 0.5974\n",
      "Epoch 2181/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5379 - accuracy: 0.8170 - val_loss: 1.2796 - val_accuracy: 0.6071\n",
      "Epoch 2182/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5308 - accuracy: 0.8296 - val_loss: 1.2358 - val_accuracy: 0.6104\n",
      "Epoch 2183/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5535 - accuracy: 0.8142 - val_loss: 1.2000 - val_accuracy: 0.6234\n",
      "Epoch 2184/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5664 - accuracy: 0.8170 - val_loss: 1.1791 - val_accuracy: 0.6461\n",
      "Epoch 2185/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5672 - accuracy: 0.8142 - val_loss: 1.1662 - val_accuracy: 0.6526\n",
      "Epoch 2186/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5489 - accuracy: 0.8271 - val_loss: 1.1547 - val_accuracy: 0.6526\n",
      "Epoch 2187/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5527 - accuracy: 0.8184 - val_loss: 1.1548 - val_accuracy: 0.6396\n",
      "Epoch 2188/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4816 - accuracy: 0.8492 - val_loss: 1.1574 - val_accuracy: 0.6396\n",
      "Epoch 2189/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5251 - accuracy: 0.8184 - val_loss: 1.1750 - val_accuracy: 0.6331\n",
      "Epoch 2190/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6566 - accuracy: 0.7783 - val_loss: 1.1951 - val_accuracy: 0.6461\n",
      "Epoch 2191/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5659 - accuracy: 0.8135 - val_loss: 1.2019 - val_accuracy: 0.6429\n",
      "Epoch 2192/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5798 - accuracy: 0.8045 - val_loss: 1.1902 - val_accuracy: 0.6429\n",
      "Epoch 2193/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6194 - accuracy: 0.8017 - val_loss: 1.1762 - val_accuracy: 0.6429\n",
      "Epoch 2194/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6435 - accuracy: 0.7919 - val_loss: 1.1629 - val_accuracy: 0.6429\n",
      "Epoch 2195/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5403 - accuracy: 0.8213 - val_loss: 1.1561 - val_accuracy: 0.6526\n",
      "Epoch 2196/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6026 - accuracy: 0.8125 - val_loss: 1.1646 - val_accuracy: 0.6558\n",
      "Epoch 2197/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5551 - accuracy: 0.8115 - val_loss: 1.1794 - val_accuracy: 0.6494\n",
      "Epoch 2198/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6114 - accuracy: 0.7949 - val_loss: 1.1878 - val_accuracy: 0.6494\n",
      "Epoch 2199/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5633 - accuracy: 0.7933 - val_loss: 1.2040 - val_accuracy: 0.6429\n",
      "Epoch 2200/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5806 - accuracy: 0.8156 - val_loss: 1.2403 - val_accuracy: 0.6201\n",
      "Epoch 2201/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5187 - accuracy: 0.8324 - val_loss: 1.2808 - val_accuracy: 0.6136\n",
      "Epoch 2202/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5258 - accuracy: 0.8125 - val_loss: 1.3076 - val_accuracy: 0.6006\n",
      "Epoch 2203/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5616 - accuracy: 0.8223 - val_loss: 1.3282 - val_accuracy: 0.6006\n",
      "Epoch 2204/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5527 - accuracy: 0.8105 - val_loss: 1.3487 - val_accuracy: 0.5812\n",
      "Epoch 2205/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5677 - accuracy: 0.8086 - val_loss: 1.3631 - val_accuracy: 0.5844\n",
      "Epoch 2206/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6053 - accuracy: 0.7959 - val_loss: 1.3446 - val_accuracy: 0.5812\n",
      "Epoch 2207/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5787 - accuracy: 0.8145 - val_loss: 1.3166 - val_accuracy: 0.5844\n",
      "Epoch 2208/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5841 - accuracy: 0.8198 - val_loss: 1.2742 - val_accuracy: 0.5844\n",
      "Epoch 2209/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6154 - accuracy: 0.7900 - val_loss: 1.2482 - val_accuracy: 0.5844\n",
      "Epoch 2210/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5960 - accuracy: 0.8037 - val_loss: 1.2459 - val_accuracy: 0.6039\n",
      "Epoch 2211/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5614 - accuracy: 0.8115 - val_loss: 1.2439 - val_accuracy: 0.6201\n",
      "Epoch 2212/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5583 - accuracy: 0.8017 - val_loss: 1.2581 - val_accuracy: 0.6331\n",
      "Epoch 2213/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5009 - accuracy: 0.8394 - val_loss: 1.2877 - val_accuracy: 0.6331\n",
      "Epoch 2214/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5549 - accuracy: 0.8045 - val_loss: 1.3119 - val_accuracy: 0.6201\n",
      "Epoch 2215/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5793 - accuracy: 0.8073 - val_loss: 1.3182 - val_accuracy: 0.6136\n",
      "Epoch 2216/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5926 - accuracy: 0.8037 - val_loss: 1.3024 - val_accuracy: 0.6169\n",
      "Epoch 2217/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6305 - accuracy: 0.7920 - val_loss: 1.2799 - val_accuracy: 0.6299\n",
      "Epoch 2218/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5754 - accuracy: 0.8128 - val_loss: 1.2435 - val_accuracy: 0.6494\n",
      "Epoch 2219/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5174 - accuracy: 0.8198 - val_loss: 1.2027 - val_accuracy: 0.6429\n",
      "Epoch 2220/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5504 - accuracy: 0.8115 - val_loss: 1.1834 - val_accuracy: 0.6396\n",
      "Epoch 2221/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6003 - accuracy: 0.8115 - val_loss: 1.1715 - val_accuracy: 0.6429\n",
      "Epoch 2222/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5549 - accuracy: 0.8198 - val_loss: 1.1663 - val_accuracy: 0.6364\n",
      "Epoch 2223/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5617 - accuracy: 0.8324 - val_loss: 1.1697 - val_accuracy: 0.6331\n",
      "Epoch 2224/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5642 - accuracy: 0.8170 - val_loss: 1.1920 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2225/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5101 - accuracy: 0.8142 - val_loss: 1.2499 - val_accuracy: 0.6136\n",
      "Epoch 2226/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4849 - accuracy: 0.8478 - val_loss: 1.2883 - val_accuracy: 0.6104\n",
      "Epoch 2227/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5387 - accuracy: 0.8232 - val_loss: 1.3385 - val_accuracy: 0.5974\n",
      "Epoch 2228/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5934 - accuracy: 0.8125 - val_loss: 1.3534 - val_accuracy: 0.5877\n",
      "Epoch 2229/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5838 - accuracy: 0.7989 - val_loss: 1.3188 - val_accuracy: 0.6071\n",
      "Epoch 2230/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5160 - accuracy: 0.8311 - val_loss: 1.2892 - val_accuracy: 0.6039\n",
      "Epoch 2231/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5489 - accuracy: 0.8223 - val_loss: 1.2573 - val_accuracy: 0.6104\n",
      "Epoch 2232/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5361 - accuracy: 0.8059 - val_loss: 1.2483 - val_accuracy: 0.6104\n",
      "Epoch 2233/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5142 - accuracy: 0.8464 - val_loss: 1.2332 - val_accuracy: 0.6266\n",
      "Epoch 2234/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5677 - accuracy: 0.8059 - val_loss: 1.2281 - val_accuracy: 0.6234\n",
      "Epoch 2235/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5238 - accuracy: 0.8268 - val_loss: 1.2219 - val_accuracy: 0.6364\n",
      "Epoch 2236/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5651 - accuracy: 0.8096 - val_loss: 1.2287 - val_accuracy: 0.6494\n",
      "Epoch 2237/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5487 - accuracy: 0.8115 - val_loss: 1.2586 - val_accuracy: 0.6331\n",
      "Epoch 2238/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5877 - accuracy: 0.8115 - val_loss: 1.3033 - val_accuracy: 0.6136\n",
      "Epoch 2239/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5614 - accuracy: 0.8193 - val_loss: 1.3210 - val_accuracy: 0.6136\n",
      "Epoch 2240/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5592 - accuracy: 0.8156 - val_loss: 1.2919 - val_accuracy: 0.6266\n",
      "Epoch 2241/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5638 - accuracy: 0.8115 - val_loss: 1.2663 - val_accuracy: 0.6331\n",
      "Epoch 2242/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5383 - accuracy: 0.8242 - val_loss: 1.2527 - val_accuracy: 0.6234\n",
      "Epoch 2243/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5296 - accuracy: 0.8282 - val_loss: 1.2636 - val_accuracy: 0.6331\n",
      "Epoch 2244/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4746 - accuracy: 0.8438 - val_loss: 1.2713 - val_accuracy: 0.6169\n",
      "Epoch 2245/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5534 - accuracy: 0.8203 - val_loss: 1.2977 - val_accuracy: 0.6006\n",
      "Epoch 2246/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5777 - accuracy: 0.8145 - val_loss: 1.3332 - val_accuracy: 0.5942\n",
      "Epoch 2247/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5429 - accuracy: 0.8115 - val_loss: 1.3837 - val_accuracy: 0.5877\n",
      "Epoch 2248/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5589 - accuracy: 0.8037 - val_loss: 1.4336 - val_accuracy: 0.5747\n",
      "Epoch 2249/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5300 - accuracy: 0.8203 - val_loss: 1.4628 - val_accuracy: 0.5682\n",
      "Epoch 2250/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5445 - accuracy: 0.8059 - val_loss: 1.4469 - val_accuracy: 0.5844\n",
      "Epoch 2251/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5233 - accuracy: 0.8436 - val_loss: 1.3995 - val_accuracy: 0.5974\n",
      "Epoch 2252/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5398 - accuracy: 0.8170 - val_loss: 1.3484 - val_accuracy: 0.6039\n",
      "Epoch 2253/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5227 - accuracy: 0.8203 - val_loss: 1.2810 - val_accuracy: 0.6071\n",
      "Epoch 2254/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5990 - accuracy: 0.8073 - val_loss: 1.2283 - val_accuracy: 0.6299\n",
      "Epoch 2255/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5975 - accuracy: 0.7949 - val_loss: 1.2116 - val_accuracy: 0.6364\n",
      "Epoch 2256/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5542 - accuracy: 0.8105 - val_loss: 1.2012 - val_accuracy: 0.6299\n",
      "Epoch 2257/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5588 - accuracy: 0.8045 - val_loss: 1.1931 - val_accuracy: 0.6331\n",
      "Epoch 2258/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5525 - accuracy: 0.8115 - val_loss: 1.1874 - val_accuracy: 0.6364\n",
      "Epoch 2259/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5695 - accuracy: 0.8135 - val_loss: 1.2114 - val_accuracy: 0.6201\n",
      "Epoch 2260/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5635 - accuracy: 0.8059 - val_loss: 1.2949 - val_accuracy: 0.6104\n",
      "Epoch 2261/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5344 - accuracy: 0.8301 - val_loss: 1.3870 - val_accuracy: 0.5877\n",
      "Epoch 2262/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5217 - accuracy: 0.8296 - val_loss: 1.4364 - val_accuracy: 0.5779\n",
      "Epoch 2263/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5318 - accuracy: 0.8213 - val_loss: 1.4836 - val_accuracy: 0.5682\n",
      "Epoch 2264/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5720 - accuracy: 0.8142 - val_loss: 1.5297 - val_accuracy: 0.5552\n",
      "Epoch 2265/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5144 - accuracy: 0.8174 - val_loss: 1.5133 - val_accuracy: 0.5584\n",
      "Epoch 2266/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5974 - accuracy: 0.8045 - val_loss: 1.4938 - val_accuracy: 0.5714\n",
      "Epoch 2267/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4397 - accuracy: 0.8436 - val_loss: 1.4696 - val_accuracy: 0.5714\n",
      "Epoch 2268/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5167 - accuracy: 0.8352 - val_loss: 1.4368 - val_accuracy: 0.5747\n",
      "Epoch 2269/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5125 - accuracy: 0.8310 - val_loss: 1.3738 - val_accuracy: 0.5974\n",
      "Epoch 2270/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5324 - accuracy: 0.8045 - val_loss: 1.3220 - val_accuracy: 0.6039\n",
      "Epoch 2271/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5519 - accuracy: 0.8240 - val_loss: 1.2609 - val_accuracy: 0.6234\n",
      "Epoch 2272/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6152 - accuracy: 0.8096 - val_loss: 1.2323 - val_accuracy: 0.6234\n",
      "Epoch 2273/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5556 - accuracy: 0.8135 - val_loss: 1.2370 - val_accuracy: 0.6364\n",
      "Epoch 2274/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5035 - accuracy: 0.8422 - val_loss: 1.2688 - val_accuracy: 0.6201\n",
      "Epoch 2275/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5335 - accuracy: 0.8436 - val_loss: 1.3274 - val_accuracy: 0.6006\n",
      "Epoch 2276/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5770 - accuracy: 0.8086 - val_loss: 1.4008 - val_accuracy: 0.5812\n",
      "Epoch 2277/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5850 - accuracy: 0.7949 - val_loss: 1.4926 - val_accuracy: 0.5747\n",
      "Epoch 2278/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5539 - accuracy: 0.8174 - val_loss: 1.5633 - val_accuracy: 0.5682\n",
      "Epoch 2279/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5396 - accuracy: 0.8101 - val_loss: 1.5949 - val_accuracy: 0.5617\n",
      "Epoch 2280/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5109 - accuracy: 0.8320 - val_loss: 1.6235 - val_accuracy: 0.5519\n",
      "Epoch 2281/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5735 - accuracy: 0.8142 - val_loss: 1.5813 - val_accuracy: 0.5617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2282/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5545 - accuracy: 0.8213 - val_loss: 1.5443 - val_accuracy: 0.5584\n",
      "Epoch 2283/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5384 - accuracy: 0.8213 - val_loss: 1.4767 - val_accuracy: 0.5682\n",
      "Epoch 2284/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5254 - accuracy: 0.8198 - val_loss: 1.4425 - val_accuracy: 0.5682\n",
      "Epoch 2285/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5209 - accuracy: 0.8320 - val_loss: 1.3988 - val_accuracy: 0.5714\n",
      "Epoch 2286/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5201 - accuracy: 0.8338 - val_loss: 1.3720 - val_accuracy: 0.5649\n",
      "Epoch 2287/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5206 - accuracy: 0.8262 - val_loss: 1.3398 - val_accuracy: 0.5779\n",
      "Epoch 2288/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5367 - accuracy: 0.8240 - val_loss: 1.3128 - val_accuracy: 0.5844\n",
      "Epoch 2289/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5924 - accuracy: 0.8115 - val_loss: 1.2809 - val_accuracy: 0.5974\n",
      "Epoch 2290/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6194 - accuracy: 0.7877 - val_loss: 1.2769 - val_accuracy: 0.5974\n",
      "Epoch 2291/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5178 - accuracy: 0.8379 - val_loss: 1.2853 - val_accuracy: 0.6136\n",
      "Epoch 2292/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5509 - accuracy: 0.8226 - val_loss: 1.3106 - val_accuracy: 0.5974\n",
      "Epoch 2293/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5438 - accuracy: 0.8281 - val_loss: 1.3080 - val_accuracy: 0.5909\n",
      "Epoch 2294/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5740 - accuracy: 0.7919 - val_loss: 1.3069 - val_accuracy: 0.5974\n",
      "Epoch 2295/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5304 - accuracy: 0.8252 - val_loss: 1.3015 - val_accuracy: 0.5974\n",
      "Epoch 2296/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5717 - accuracy: 0.8017 - val_loss: 1.2706 - val_accuracy: 0.6071\n",
      "Epoch 2297/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5391 - accuracy: 0.8198 - val_loss: 1.2558 - val_accuracy: 0.6136\n",
      "Epoch 2298/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5647 - accuracy: 0.8170 - val_loss: 1.2725 - val_accuracy: 0.6071\n",
      "Epoch 2299/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5556 - accuracy: 0.8135 - val_loss: 1.2880 - val_accuracy: 0.6006\n",
      "Epoch 2300/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5562 - accuracy: 0.8212 - val_loss: 1.2952 - val_accuracy: 0.5942\n",
      "Epoch 2301/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5707 - accuracy: 0.8184 - val_loss: 1.2881 - val_accuracy: 0.6006\n",
      "Epoch 2302/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5703 - accuracy: 0.8135 - val_loss: 1.3061 - val_accuracy: 0.5974\n",
      "Epoch 2303/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5808 - accuracy: 0.8115 - val_loss: 1.3380 - val_accuracy: 0.6071\n",
      "Epoch 2304/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5508 - accuracy: 0.8101 - val_loss: 1.3437 - val_accuracy: 0.6039\n",
      "Epoch 2305/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5598 - accuracy: 0.8076 - val_loss: 1.3029 - val_accuracy: 0.6104\n",
      "Epoch 2306/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5120 - accuracy: 0.8359 - val_loss: 1.2783 - val_accuracy: 0.6169\n",
      "Epoch 2307/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5819 - accuracy: 0.8076 - val_loss: 1.2761 - val_accuracy: 0.6136\n",
      "Epoch 2308/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4979 - accuracy: 0.8291 - val_loss: 1.2654 - val_accuracy: 0.6266\n",
      "Epoch 2309/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5241 - accuracy: 0.8198 - val_loss: 1.2682 - val_accuracy: 0.6364\n",
      "Epoch 2310/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5570 - accuracy: 0.8174 - val_loss: 1.2632 - val_accuracy: 0.6364\n",
      "Epoch 2311/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5790 - accuracy: 0.8115 - val_loss: 1.2664 - val_accuracy: 0.6266\n",
      "Epoch 2312/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5501 - accuracy: 0.8226 - val_loss: 1.2718 - val_accuracy: 0.6364\n",
      "Epoch 2313/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5240 - accuracy: 0.8268 - val_loss: 1.2628 - val_accuracy: 0.6104\n",
      "Epoch 2314/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5121 - accuracy: 0.8291 - val_loss: 1.2788 - val_accuracy: 0.6136\n",
      "Epoch 2315/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5037 - accuracy: 0.8282 - val_loss: 1.2820 - val_accuracy: 0.6169\n",
      "Epoch 2316/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5294 - accuracy: 0.8193 - val_loss: 1.2715 - val_accuracy: 0.6169\n",
      "Epoch 2317/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5462 - accuracy: 0.8311 - val_loss: 1.2379 - val_accuracy: 0.6169\n",
      "Epoch 2318/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5654 - accuracy: 0.8164 - val_loss: 1.2316 - val_accuracy: 0.6234\n",
      "Epoch 2319/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5402 - accuracy: 0.8242 - val_loss: 1.2243 - val_accuracy: 0.6331\n",
      "Epoch 2320/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5635 - accuracy: 0.8018 - val_loss: 1.2245 - val_accuracy: 0.6299\n",
      "Epoch 2321/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5390 - accuracy: 0.8291 - val_loss: 1.2125 - val_accuracy: 0.6364\n",
      "Epoch 2322/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5600 - accuracy: 0.8271 - val_loss: 1.2069 - val_accuracy: 0.6331\n",
      "Epoch 2323/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5285 - accuracy: 0.8389 - val_loss: 1.2177 - val_accuracy: 0.6299\n",
      "Epoch 2324/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5205 - accuracy: 0.8324 - val_loss: 1.2546 - val_accuracy: 0.6039\n",
      "Epoch 2325/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5283 - accuracy: 0.8330 - val_loss: 1.3403 - val_accuracy: 0.5682\n",
      "Epoch 2326/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5431 - accuracy: 0.8296 - val_loss: 1.4677 - val_accuracy: 0.5519\n",
      "Epoch 2327/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5233 - accuracy: 0.8268 - val_loss: 1.6472 - val_accuracy: 0.5292\n",
      "Epoch 2328/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5937 - accuracy: 0.8047 - val_loss: 1.7508 - val_accuracy: 0.5032\n",
      "Epoch 2329/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5608 - accuracy: 0.8105 - val_loss: 1.7802 - val_accuracy: 0.5032\n",
      "Epoch 2330/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5541 - accuracy: 0.8135 - val_loss: 1.7482 - val_accuracy: 0.5130\n",
      "Epoch 2331/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5646 - accuracy: 0.8170 - val_loss: 1.6372 - val_accuracy: 0.5260\n",
      "Epoch 2332/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5232 - accuracy: 0.8320 - val_loss: 1.5057 - val_accuracy: 0.5714\n",
      "Epoch 2333/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5629 - accuracy: 0.8184 - val_loss: 1.3989 - val_accuracy: 0.5942\n",
      "Epoch 2334/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4580 - accuracy: 0.8366 - val_loss: 1.3089 - val_accuracy: 0.6006\n",
      "Epoch 2335/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5037 - accuracy: 0.8492 - val_loss: 1.2647 - val_accuracy: 0.6071\n",
      "Epoch 2336/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5322 - accuracy: 0.8262 - val_loss: 1.2351 - val_accuracy: 0.6234\n",
      "Epoch 2337/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5262 - accuracy: 0.8193 - val_loss: 1.2175 - val_accuracy: 0.6266\n",
      "Epoch 2338/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5233 - accuracy: 0.8320 - val_loss: 1.1968 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2339/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5649 - accuracy: 0.8125 - val_loss: 1.1847 - val_accuracy: 0.6364\n",
      "Epoch 2340/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4812 - accuracy: 0.8324 - val_loss: 1.1695 - val_accuracy: 0.6494\n",
      "Epoch 2341/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4824 - accuracy: 0.8352 - val_loss: 1.1769 - val_accuracy: 0.6558\n",
      "Epoch 2342/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4664 - accuracy: 0.8350 - val_loss: 1.1943 - val_accuracy: 0.6591\n",
      "Epoch 2343/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5115 - accuracy: 0.8389 - val_loss: 1.2108 - val_accuracy: 0.6526\n",
      "Epoch 2344/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5138 - accuracy: 0.8422 - val_loss: 1.1980 - val_accuracy: 0.6461\n",
      "Epoch 2345/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5336 - accuracy: 0.8213 - val_loss: 1.1897 - val_accuracy: 0.6526\n",
      "Epoch 2346/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5212 - accuracy: 0.8156 - val_loss: 1.1842 - val_accuracy: 0.6494\n",
      "Epoch 2347/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5435 - accuracy: 0.8394 - val_loss: 1.1678 - val_accuracy: 0.6591\n",
      "Epoch 2348/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4533 - accuracy: 0.8575 - val_loss: 1.1630 - val_accuracy: 0.6558\n",
      "Epoch 2349/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5078 - accuracy: 0.8350 - val_loss: 1.1597 - val_accuracy: 0.6494\n",
      "Epoch 2350/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4895 - accuracy: 0.8467 - val_loss: 1.1699 - val_accuracy: 0.6494\n",
      "Epoch 2351/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5495 - accuracy: 0.8301 - val_loss: 1.1799 - val_accuracy: 0.6429\n",
      "Epoch 2352/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5114 - accuracy: 0.8340 - val_loss: 1.1971 - val_accuracy: 0.6266\n",
      "Epoch 2353/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5389 - accuracy: 0.8184 - val_loss: 1.2238 - val_accuracy: 0.6201\n",
      "Epoch 2354/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4849 - accuracy: 0.8359 - val_loss: 1.2473 - val_accuracy: 0.6201\n",
      "Epoch 2355/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4831 - accuracy: 0.8268 - val_loss: 1.2591 - val_accuracy: 0.6234\n",
      "Epoch 2356/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5479 - accuracy: 0.8226 - val_loss: 1.2362 - val_accuracy: 0.6234\n",
      "Epoch 2357/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5264 - accuracy: 0.8282 - val_loss: 1.1758 - val_accuracy: 0.6364\n",
      "Epoch 2358/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5238 - accuracy: 0.8359 - val_loss: 1.1285 - val_accuracy: 0.6526\n",
      "Epoch 2359/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5314 - accuracy: 0.8212 - val_loss: 1.1159 - val_accuracy: 0.6623\n",
      "Epoch 2360/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5333 - accuracy: 0.8170 - val_loss: 1.1189 - val_accuracy: 0.6558\n",
      "Epoch 2361/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5234 - accuracy: 0.8226 - val_loss: 1.1234 - val_accuracy: 0.6656\n",
      "Epoch 2362/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4845 - accuracy: 0.8589 - val_loss: 1.1191 - val_accuracy: 0.6688\n",
      "Epoch 2363/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5206 - accuracy: 0.8350 - val_loss: 1.1182 - val_accuracy: 0.6656\n",
      "Epoch 2364/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4897 - accuracy: 0.8369 - val_loss: 1.1206 - val_accuracy: 0.6753\n",
      "Epoch 2365/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5751 - accuracy: 0.8135 - val_loss: 1.1130 - val_accuracy: 0.6786\n",
      "Epoch 2366/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4907 - accuracy: 0.8506 - val_loss: 1.1069 - val_accuracy: 0.6753\n",
      "Epoch 2367/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5936 - accuracy: 0.8031 - val_loss: 1.1044 - val_accuracy: 0.6818\n",
      "Epoch 2368/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5381 - accuracy: 0.8125 - val_loss: 1.1104 - val_accuracy: 0.6688\n",
      "Epoch 2369/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5057 - accuracy: 0.8232 - val_loss: 1.1212 - val_accuracy: 0.6623\n",
      "Epoch 2370/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4705 - accuracy: 0.8492 - val_loss: 1.1495 - val_accuracy: 0.6526\n",
      "Epoch 2371/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5199 - accuracy: 0.8281 - val_loss: 1.1784 - val_accuracy: 0.6461\n",
      "Epoch 2372/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4884 - accuracy: 0.8320 - val_loss: 1.2173 - val_accuracy: 0.6396\n",
      "Epoch 2373/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5829 - accuracy: 0.7979 - val_loss: 1.2393 - val_accuracy: 0.6201\n",
      "Epoch 2374/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5386 - accuracy: 0.8282 - val_loss: 1.2638 - val_accuracy: 0.6006\n",
      "Epoch 2375/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5475 - accuracy: 0.8281 - val_loss: 1.3045 - val_accuracy: 0.6136\n",
      "Epoch 2376/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5001 - accuracy: 0.8320 - val_loss: 1.3290 - val_accuracy: 0.6104\n",
      "Epoch 2377/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4898 - accuracy: 0.8296 - val_loss: 1.3401 - val_accuracy: 0.6104\n",
      "Epoch 2378/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4971 - accuracy: 0.8418 - val_loss: 1.3288 - val_accuracy: 0.6006\n",
      "Epoch 2379/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4751 - accuracy: 0.8438 - val_loss: 1.3132 - val_accuracy: 0.6039\n",
      "Epoch 2380/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4812 - accuracy: 0.8310 - val_loss: 1.2898 - val_accuracy: 0.6299\n",
      "Epoch 2381/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5520 - accuracy: 0.8242 - val_loss: 1.2649 - val_accuracy: 0.6429\n",
      "Epoch 2382/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5063 - accuracy: 0.8240 - val_loss: 1.2274 - val_accuracy: 0.6623\n",
      "Epoch 2383/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6116 - accuracy: 0.8073 - val_loss: 1.1870 - val_accuracy: 0.6721\n",
      "Epoch 2384/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5083 - accuracy: 0.8128 - val_loss: 1.1559 - val_accuracy: 0.6721\n",
      "Epoch 2385/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5233 - accuracy: 0.8240 - val_loss: 1.1138 - val_accuracy: 0.6721\n",
      "Epoch 2386/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5104 - accuracy: 0.8428 - val_loss: 1.0952 - val_accuracy: 0.6818\n",
      "Epoch 2387/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5072 - accuracy: 0.8338 - val_loss: 1.0948 - val_accuracy: 0.6786\n",
      "Epoch 2388/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5341 - accuracy: 0.8164 - val_loss: 1.1116 - val_accuracy: 0.6688\n",
      "Epoch 2389/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4509 - accuracy: 0.8450 - val_loss: 1.1372 - val_accuracy: 0.6429\n",
      "Epoch 2390/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5338 - accuracy: 0.8184 - val_loss: 1.1710 - val_accuracy: 0.6396\n",
      "Epoch 2391/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4887 - accuracy: 0.8436 - val_loss: 1.2101 - val_accuracy: 0.6299\n",
      "Epoch 2392/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5486 - accuracy: 0.8135 - val_loss: 1.2174 - val_accuracy: 0.6234\n",
      "Epoch 2393/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5025 - accuracy: 0.8350 - val_loss: 1.2094 - val_accuracy: 0.6266\n",
      "Epoch 2394/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4916 - accuracy: 0.8301 - val_loss: 1.1871 - val_accuracy: 0.6364\n",
      "Epoch 2395/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6052 - accuracy: 0.7975 - val_loss: 1.1806 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2396/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5311 - accuracy: 0.8296 - val_loss: 1.1715 - val_accuracy: 0.6591\n",
      "Epoch 2397/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5233 - accuracy: 0.8324 - val_loss: 1.1927 - val_accuracy: 0.6396\n",
      "Epoch 2398/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5448 - accuracy: 0.8240 - val_loss: 1.2173 - val_accuracy: 0.6429\n",
      "Epoch 2399/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4967 - accuracy: 0.8252 - val_loss: 1.2370 - val_accuracy: 0.6299\n",
      "Epoch 2400/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5050 - accuracy: 0.8438 - val_loss: 1.2319 - val_accuracy: 0.6234\n",
      "Epoch 2401/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5676 - accuracy: 0.8164 - val_loss: 1.2334 - val_accuracy: 0.6299\n",
      "Epoch 2402/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5197 - accuracy: 0.8282 - val_loss: 1.2380 - val_accuracy: 0.6299\n",
      "Epoch 2403/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4910 - accuracy: 0.8359 - val_loss: 1.2270 - val_accuracy: 0.6396\n",
      "Epoch 2404/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4821 - accuracy: 0.8324 - val_loss: 1.2175 - val_accuracy: 0.6429\n",
      "Epoch 2405/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5221 - accuracy: 0.8350 - val_loss: 1.2054 - val_accuracy: 0.6429\n",
      "Epoch 2406/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4651 - accuracy: 0.8398 - val_loss: 1.1985 - val_accuracy: 0.6461\n",
      "Epoch 2407/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5633 - accuracy: 0.8145 - val_loss: 1.1882 - val_accuracy: 0.6331\n",
      "Epoch 2408/4000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4792 - accuracy: 0.8268 - val_loss: 1.1761 - val_accuracy: 0.6364\n",
      "Epoch 2409/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4957 - accuracy: 0.8380 - val_loss: 1.1752 - val_accuracy: 0.6461\n",
      "Epoch 2410/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5051 - accuracy: 0.8268 - val_loss: 1.1779 - val_accuracy: 0.6396\n",
      "Epoch 2411/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4857 - accuracy: 0.8252 - val_loss: 1.1845 - val_accuracy: 0.6396\n",
      "Epoch 2412/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4914 - accuracy: 0.8282 - val_loss: 1.1921 - val_accuracy: 0.6429\n",
      "Epoch 2413/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4944 - accuracy: 0.8271 - val_loss: 1.2096 - val_accuracy: 0.6461\n",
      "Epoch 2414/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5374 - accuracy: 0.8184 - val_loss: 1.2063 - val_accuracy: 0.6591\n",
      "Epoch 2415/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4565 - accuracy: 0.8478 - val_loss: 1.2076 - val_accuracy: 0.6494\n",
      "Epoch 2416/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5217 - accuracy: 0.8422 - val_loss: 1.2135 - val_accuracy: 0.6526\n",
      "Epoch 2417/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5172 - accuracy: 0.8394 - val_loss: 1.2293 - val_accuracy: 0.6429\n",
      "Epoch 2418/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4970 - accuracy: 0.8301 - val_loss: 1.2430 - val_accuracy: 0.6494\n",
      "Epoch 2419/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4214 - accuracy: 0.8575 - val_loss: 1.2516 - val_accuracy: 0.6494\n",
      "Epoch 2420/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5589 - accuracy: 0.8101 - val_loss: 1.2564 - val_accuracy: 0.6396\n",
      "Epoch 2421/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5428 - accuracy: 0.8156 - val_loss: 1.2519 - val_accuracy: 0.6396\n",
      "Epoch 2422/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4691 - accuracy: 0.8545 - val_loss: 1.2731 - val_accuracy: 0.6136\n",
      "Epoch 2423/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4869 - accuracy: 0.8379 - val_loss: 1.2767 - val_accuracy: 0.6104\n",
      "Epoch 2424/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4755 - accuracy: 0.8467 - val_loss: 1.2787 - val_accuracy: 0.6169\n",
      "Epoch 2425/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5126 - accuracy: 0.8324 - val_loss: 1.2905 - val_accuracy: 0.6039\n",
      "Epoch 2426/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5258 - accuracy: 0.8320 - val_loss: 1.2778 - val_accuracy: 0.6234\n",
      "Epoch 2427/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5755 - accuracy: 0.8184 - val_loss: 1.2562 - val_accuracy: 0.6201\n",
      "Epoch 2428/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5274 - accuracy: 0.8320 - val_loss: 1.2344 - val_accuracy: 0.6234\n",
      "Epoch 2429/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4281 - accuracy: 0.8561 - val_loss: 1.2156 - val_accuracy: 0.6429\n",
      "Epoch 2430/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5313 - accuracy: 0.8170 - val_loss: 1.2075 - val_accuracy: 0.6623\n",
      "Epoch 2431/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4562 - accuracy: 0.8408 - val_loss: 1.2043 - val_accuracy: 0.6558\n",
      "Epoch 2432/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4661 - accuracy: 0.8340 - val_loss: 1.2013 - val_accuracy: 0.6623\n",
      "Epoch 2433/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5005 - accuracy: 0.8428 - val_loss: 1.2094 - val_accuracy: 0.6558\n",
      "Epoch 2434/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5171 - accuracy: 0.8450 - val_loss: 1.2329 - val_accuracy: 0.6364\n",
      "Epoch 2435/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4678 - accuracy: 0.8254 - val_loss: 1.2523 - val_accuracy: 0.6494\n",
      "Epoch 2436/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5159 - accuracy: 0.8156 - val_loss: 1.2646 - val_accuracy: 0.6461\n",
      "Epoch 2437/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4901 - accuracy: 0.8492 - val_loss: 1.2640 - val_accuracy: 0.6494\n",
      "Epoch 2438/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5243 - accuracy: 0.8311 - val_loss: 1.2582 - val_accuracy: 0.6558\n",
      "Epoch 2439/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5281 - accuracy: 0.8242 - val_loss: 1.2461 - val_accuracy: 0.6558\n",
      "Epoch 2440/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4471 - accuracy: 0.8673 - val_loss: 1.2506 - val_accuracy: 0.6558\n",
      "Epoch 2441/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5212 - accuracy: 0.8291 - val_loss: 1.2597 - val_accuracy: 0.6591\n",
      "Epoch 2442/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5046 - accuracy: 0.8436 - val_loss: 1.2794 - val_accuracy: 0.6526\n",
      "Epoch 2443/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4892 - accuracy: 0.8408 - val_loss: 1.2735 - val_accuracy: 0.6656\n",
      "Epoch 2444/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5105 - accuracy: 0.8338 - val_loss: 1.2690 - val_accuracy: 0.6656\n",
      "Epoch 2445/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5298 - accuracy: 0.8408 - val_loss: 1.2543 - val_accuracy: 0.6721\n",
      "Epoch 2446/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5018 - accuracy: 0.8281 - val_loss: 1.2380 - val_accuracy: 0.6721\n",
      "Epoch 2447/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4956 - accuracy: 0.8447 - val_loss: 1.2337 - val_accuracy: 0.6688\n",
      "Epoch 2448/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5146 - accuracy: 0.8380 - val_loss: 1.2318 - val_accuracy: 0.6623\n",
      "Epoch 2449/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5282 - accuracy: 0.8226 - val_loss: 1.2313 - val_accuracy: 0.6623\n",
      "Epoch 2450/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5452 - accuracy: 0.8338 - val_loss: 1.2286 - val_accuracy: 0.6623\n",
      "Epoch 2451/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4778 - accuracy: 0.8366 - val_loss: 1.2278 - val_accuracy: 0.6461\n",
      "Epoch 2452/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5337 - accuracy: 0.8380 - val_loss: 1.2286 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2453/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4962 - accuracy: 0.8380 - val_loss: 1.2363 - val_accuracy: 0.6396\n",
      "Epoch 2454/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4797 - accuracy: 0.8467 - val_loss: 1.2368 - val_accuracy: 0.6396\n",
      "Epoch 2455/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5115 - accuracy: 0.8311 - val_loss: 1.2243 - val_accuracy: 0.6429\n",
      "Epoch 2456/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5463 - accuracy: 0.8184 - val_loss: 1.2128 - val_accuracy: 0.6396\n",
      "Epoch 2457/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4623 - accuracy: 0.8477 - val_loss: 1.1953 - val_accuracy: 0.6364\n",
      "Epoch 2458/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4458 - accuracy: 0.8575 - val_loss: 1.1829 - val_accuracy: 0.6461\n",
      "Epoch 2459/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4904 - accuracy: 0.8340 - val_loss: 1.1830 - val_accuracy: 0.6396\n",
      "Epoch 2460/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4999 - accuracy: 0.8394 - val_loss: 1.1816 - val_accuracy: 0.6396\n",
      "Epoch 2461/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4943 - accuracy: 0.8324 - val_loss: 1.1772 - val_accuracy: 0.6461\n",
      "Epoch 2462/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5044 - accuracy: 0.8369 - val_loss: 1.1767 - val_accuracy: 0.6494\n",
      "Epoch 2463/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5397 - accuracy: 0.8212 - val_loss: 1.1842 - val_accuracy: 0.6591\n",
      "Epoch 2464/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4916 - accuracy: 0.8408 - val_loss: 1.1990 - val_accuracy: 0.6623\n",
      "Epoch 2465/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4668 - accuracy: 0.8589 - val_loss: 1.2105 - val_accuracy: 0.6461\n",
      "Epoch 2466/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4906 - accuracy: 0.8296 - val_loss: 1.2184 - val_accuracy: 0.6461\n",
      "Epoch 2467/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5377 - accuracy: 0.8301 - val_loss: 1.2266 - val_accuracy: 0.6494\n",
      "Epoch 2468/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4585 - accuracy: 0.8561 - val_loss: 1.2560 - val_accuracy: 0.6331\n",
      "Epoch 2469/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4956 - accuracy: 0.8340 - val_loss: 1.3103 - val_accuracy: 0.6234\n",
      "Epoch 2470/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4524 - accuracy: 0.8464 - val_loss: 1.3787 - val_accuracy: 0.6169\n",
      "Epoch 2471/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4768 - accuracy: 0.8408 - val_loss: 1.4372 - val_accuracy: 0.5942\n",
      "Epoch 2472/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4995 - accuracy: 0.8486 - val_loss: 1.4666 - val_accuracy: 0.5779\n",
      "Epoch 2473/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5151 - accuracy: 0.8226 - val_loss: 1.4780 - val_accuracy: 0.5682\n",
      "Epoch 2474/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4615 - accuracy: 0.8324 - val_loss: 1.4507 - val_accuracy: 0.5747\n",
      "Epoch 2475/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5125 - accuracy: 0.8193 - val_loss: 1.4143 - val_accuracy: 0.5877\n",
      "Epoch 2476/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4908 - accuracy: 0.8380 - val_loss: 1.3757 - val_accuracy: 0.6039\n",
      "Epoch 2477/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4490 - accuracy: 0.8603 - val_loss: 1.3399 - val_accuracy: 0.6299\n",
      "Epoch 2478/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4601 - accuracy: 0.8478 - val_loss: 1.3089 - val_accuracy: 0.6429\n",
      "Epoch 2479/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4635 - accuracy: 0.8547 - val_loss: 1.2819 - val_accuracy: 0.6558\n",
      "Epoch 2480/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4842 - accuracy: 0.8330 - val_loss: 1.2581 - val_accuracy: 0.6396\n",
      "Epoch 2481/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4873 - accuracy: 0.8447 - val_loss: 1.2438 - val_accuracy: 0.6494\n",
      "Epoch 2482/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4734 - accuracy: 0.8457 - val_loss: 1.2275 - val_accuracy: 0.6591\n",
      "Epoch 2483/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4497 - accuracy: 0.8408 - val_loss: 1.2228 - val_accuracy: 0.6591\n",
      "Epoch 2484/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4603 - accuracy: 0.8422 - val_loss: 1.2325 - val_accuracy: 0.6558\n",
      "Epoch 2485/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5265 - accuracy: 0.8212 - val_loss: 1.2555 - val_accuracy: 0.6623\n",
      "Epoch 2486/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4740 - accuracy: 0.8301 - val_loss: 1.2808 - val_accuracy: 0.6494\n",
      "Epoch 2487/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4742 - accuracy: 0.8496 - val_loss: 1.3002 - val_accuracy: 0.6331\n",
      "Epoch 2488/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4797 - accuracy: 0.8330 - val_loss: 1.3104 - val_accuracy: 0.6169\n",
      "Epoch 2489/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4832 - accuracy: 0.8478 - val_loss: 1.3027 - val_accuracy: 0.6136\n",
      "Epoch 2490/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5308 - accuracy: 0.8408 - val_loss: 1.2725 - val_accuracy: 0.6299\n",
      "Epoch 2491/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4916 - accuracy: 0.8436 - val_loss: 1.2437 - val_accuracy: 0.6461\n",
      "Epoch 2492/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4911 - accuracy: 0.8252 - val_loss: 1.2210 - val_accuracy: 0.6494\n",
      "Epoch 2493/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4800 - accuracy: 0.8350 - val_loss: 1.2053 - val_accuracy: 0.6396\n",
      "Epoch 2494/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4947 - accuracy: 0.8359 - val_loss: 1.1958 - val_accuracy: 0.6461\n",
      "Epoch 2495/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5141 - accuracy: 0.8193 - val_loss: 1.1940 - val_accuracy: 0.6526\n",
      "Epoch 2496/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4848 - accuracy: 0.8240 - val_loss: 1.2098 - val_accuracy: 0.6494\n",
      "Epoch 2497/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4782 - accuracy: 0.8436 - val_loss: 1.2408 - val_accuracy: 0.6461\n",
      "Epoch 2498/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4381 - accuracy: 0.8589 - val_loss: 1.2880 - val_accuracy: 0.6331\n",
      "Epoch 2499/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5364 - accuracy: 0.8262 - val_loss: 1.3212 - val_accuracy: 0.6266\n",
      "Epoch 2500/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4772 - accuracy: 0.8547 - val_loss: 1.3315 - val_accuracy: 0.6331\n",
      "Epoch 2501/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4979 - accuracy: 0.8359 - val_loss: 1.3203 - val_accuracy: 0.6364\n",
      "Epoch 2502/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4779 - accuracy: 0.8310 - val_loss: 1.3058 - val_accuracy: 0.6396\n",
      "Epoch 2503/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4516 - accuracy: 0.8603 - val_loss: 1.2706 - val_accuracy: 0.6331\n",
      "Epoch 2504/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4838 - accuracy: 0.8350 - val_loss: 1.2330 - val_accuracy: 0.6429\n",
      "Epoch 2505/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4929 - accuracy: 0.8436 - val_loss: 1.2110 - val_accuracy: 0.6526\n",
      "Epoch 2506/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4384 - accuracy: 0.8575 - val_loss: 1.2129 - val_accuracy: 0.6526\n",
      "Epoch 2507/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4436 - accuracy: 0.8457 - val_loss: 1.2099 - val_accuracy: 0.6591\n",
      "Epoch 2508/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4832 - accuracy: 0.8282 - val_loss: 1.2160 - val_accuracy: 0.6623\n",
      "Epoch 2509/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4506 - accuracy: 0.8506 - val_loss: 1.2261 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2510/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5327 - accuracy: 0.8128 - val_loss: 1.2322 - val_accuracy: 0.6396\n",
      "Epoch 2511/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4756 - accuracy: 0.8436 - val_loss: 1.2480 - val_accuracy: 0.6396\n",
      "Epoch 2512/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4665 - accuracy: 0.8525 - val_loss: 1.2743 - val_accuracy: 0.6266\n",
      "Epoch 2513/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5438 - accuracy: 0.8240 - val_loss: 1.3103 - val_accuracy: 0.6039\n",
      "Epoch 2514/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5096 - accuracy: 0.8436 - val_loss: 1.3330 - val_accuracy: 0.5779\n",
      "Epoch 2515/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5176 - accuracy: 0.8156 - val_loss: 1.3176 - val_accuracy: 0.5942\n",
      "Epoch 2516/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4791 - accuracy: 0.8447 - val_loss: 1.2685 - val_accuracy: 0.6136\n",
      "Epoch 2517/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5262 - accuracy: 0.8324 - val_loss: 1.2310 - val_accuracy: 0.6461\n",
      "Epoch 2518/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4481 - accuracy: 0.8520 - val_loss: 1.2081 - val_accuracy: 0.6591\n",
      "Epoch 2519/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4300 - accuracy: 0.8652 - val_loss: 1.2009 - val_accuracy: 0.6721\n",
      "Epoch 2520/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4768 - accuracy: 0.8436 - val_loss: 1.2079 - val_accuracy: 0.6753\n",
      "Epoch 2521/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5008 - accuracy: 0.8428 - val_loss: 1.2324 - val_accuracy: 0.6623\n",
      "Epoch 2522/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4398 - accuracy: 0.8525 - val_loss: 1.2585 - val_accuracy: 0.6494\n",
      "Epoch 2523/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4771 - accuracy: 0.8389 - val_loss: 1.2955 - val_accuracy: 0.6169\n",
      "Epoch 2524/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4462 - accuracy: 0.8555 - val_loss: 1.3292 - val_accuracy: 0.6071\n",
      "Epoch 2525/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4914 - accuracy: 0.8418 - val_loss: 1.3828 - val_accuracy: 0.6006\n",
      "Epoch 2526/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4592 - accuracy: 0.8643 - val_loss: 1.4224 - val_accuracy: 0.6006\n",
      "Epoch 2527/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4662 - accuracy: 0.8394 - val_loss: 1.4638 - val_accuracy: 0.5877\n",
      "Epoch 2528/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4780 - accuracy: 0.8352 - val_loss: 1.4715 - val_accuracy: 0.5974\n",
      "Epoch 2529/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5093 - accuracy: 0.8359 - val_loss: 1.4490 - val_accuracy: 0.5942\n",
      "Epoch 2530/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4793 - accuracy: 0.8438 - val_loss: 1.4214 - val_accuracy: 0.6039\n",
      "Epoch 2531/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4499 - accuracy: 0.8467 - val_loss: 1.3828 - val_accuracy: 0.6104\n",
      "Epoch 2532/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4985 - accuracy: 0.8447 - val_loss: 1.3240 - val_accuracy: 0.6201\n",
      "Epoch 2533/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4654 - accuracy: 0.8436 - val_loss: 1.2891 - val_accuracy: 0.6299\n",
      "Epoch 2534/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4468 - accuracy: 0.8525 - val_loss: 1.2797 - val_accuracy: 0.6461\n",
      "Epoch 2535/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4231 - accuracy: 0.8715 - val_loss: 1.2913 - val_accuracy: 0.6429\n",
      "Epoch 2536/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5060 - accuracy: 0.8516 - val_loss: 1.3261 - val_accuracy: 0.6136\n",
      "Epoch 2537/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4617 - accuracy: 0.8457 - val_loss: 1.3883 - val_accuracy: 0.5942\n",
      "Epoch 2538/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4799 - accuracy: 0.8408 - val_loss: 1.4463 - val_accuracy: 0.5779\n",
      "Epoch 2539/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4985 - accuracy: 0.8366 - val_loss: 1.4809 - val_accuracy: 0.5714\n",
      "Epoch 2540/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4365 - accuracy: 0.8672 - val_loss: 1.4637 - val_accuracy: 0.5812\n",
      "Epoch 2541/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4845 - accuracy: 0.8394 - val_loss: 1.4392 - val_accuracy: 0.5877\n",
      "Epoch 2542/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5385 - accuracy: 0.8320 - val_loss: 1.4016 - val_accuracy: 0.5942\n",
      "Epoch 2543/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4030 - accuracy: 0.8673 - val_loss: 1.3688 - val_accuracy: 0.6039\n",
      "Epoch 2544/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5031 - accuracy: 0.8338 - val_loss: 1.3287 - val_accuracy: 0.6039\n",
      "Epoch 2545/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4762 - accuracy: 0.8428 - val_loss: 1.3124 - val_accuracy: 0.6201\n",
      "Epoch 2546/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5078 - accuracy: 0.8352 - val_loss: 1.3075 - val_accuracy: 0.6234\n",
      "Epoch 2547/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4541 - accuracy: 0.8492 - val_loss: 1.3121 - val_accuracy: 0.6169\n",
      "Epoch 2548/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4613 - accuracy: 0.8594 - val_loss: 1.3006 - val_accuracy: 0.6169\n",
      "Epoch 2549/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4928 - accuracy: 0.8520 - val_loss: 1.3052 - val_accuracy: 0.5974\n",
      "Epoch 2550/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4985 - accuracy: 0.8366 - val_loss: 1.3146 - val_accuracy: 0.5942\n",
      "Epoch 2551/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4433 - accuracy: 0.8555 - val_loss: 1.3336 - val_accuracy: 0.5714\n",
      "Epoch 2552/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5122 - accuracy: 0.8296 - val_loss: 1.3635 - val_accuracy: 0.5714\n",
      "Epoch 2553/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5078 - accuracy: 0.8330 - val_loss: 1.4170 - val_accuracy: 0.5617\n",
      "Epoch 2554/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4779 - accuracy: 0.8464 - val_loss: 1.4857 - val_accuracy: 0.5584\n",
      "Epoch 2555/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4996 - accuracy: 0.8492 - val_loss: 1.5389 - val_accuracy: 0.5487\n",
      "Epoch 2556/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5036 - accuracy: 0.8422 - val_loss: 1.5939 - val_accuracy: 0.5584\n",
      "Epoch 2557/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5601 - accuracy: 0.8156 - val_loss: 1.6384 - val_accuracy: 0.5455\n",
      "Epoch 2558/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4788 - accuracy: 0.8464 - val_loss: 1.6323 - val_accuracy: 0.5487\n",
      "Epoch 2559/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4607 - accuracy: 0.8438 - val_loss: 1.5879 - val_accuracy: 0.5649\n",
      "Epoch 2560/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4759 - accuracy: 0.8496 - val_loss: 1.5198 - val_accuracy: 0.5519\n",
      "Epoch 2561/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4829 - accuracy: 0.8418 - val_loss: 1.4451 - val_accuracy: 0.5877\n",
      "Epoch 2562/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4666 - accuracy: 0.8478 - val_loss: 1.3999 - val_accuracy: 0.6071\n",
      "Epoch 2563/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4676 - accuracy: 0.8438 - val_loss: 1.3841 - val_accuracy: 0.6136\n",
      "Epoch 2564/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5107 - accuracy: 0.8340 - val_loss: 1.4025 - val_accuracy: 0.6169\n",
      "Epoch 2565/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4333 - accuracy: 0.8682 - val_loss: 1.4195 - val_accuracy: 0.6201\n",
      "Epoch 2566/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4513 - accuracy: 0.8547 - val_loss: 1.4449 - val_accuracy: 0.6006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2567/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5136 - accuracy: 0.8492 - val_loss: 1.4693 - val_accuracy: 0.6006\n",
      "Epoch 2568/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5034 - accuracy: 0.8408 - val_loss: 1.4816 - val_accuracy: 0.6071\n",
      "Epoch 2569/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4898 - accuracy: 0.8478 - val_loss: 1.4620 - val_accuracy: 0.6039\n",
      "Epoch 2570/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5032 - accuracy: 0.8408 - val_loss: 1.4235 - val_accuracy: 0.6266\n",
      "Epoch 2571/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5141 - accuracy: 0.8254 - val_loss: 1.3780 - val_accuracy: 0.6364\n",
      "Epoch 2572/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4457 - accuracy: 0.8520 - val_loss: 1.3485 - val_accuracy: 0.6364\n",
      "Epoch 2573/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4963 - accuracy: 0.8240 - val_loss: 1.3261 - val_accuracy: 0.6494\n",
      "Epoch 2574/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4770 - accuracy: 0.8516 - val_loss: 1.3042 - val_accuracy: 0.6558\n",
      "Epoch 2575/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4511 - accuracy: 0.8535 - val_loss: 1.2875 - val_accuracy: 0.6591\n",
      "Epoch 2576/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4425 - accuracy: 0.8613 - val_loss: 1.2833 - val_accuracy: 0.6591\n",
      "Epoch 2577/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5148 - accuracy: 0.8394 - val_loss: 1.2939 - val_accuracy: 0.6429\n",
      "Epoch 2578/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4732 - accuracy: 0.8398 - val_loss: 1.3275 - val_accuracy: 0.6169\n",
      "Epoch 2579/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5133 - accuracy: 0.8398 - val_loss: 1.3507 - val_accuracy: 0.6234\n",
      "Epoch 2580/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4786 - accuracy: 0.8291 - val_loss: 1.3644 - val_accuracy: 0.6071\n",
      "Epoch 2581/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4787 - accuracy: 0.8478 - val_loss: 1.3870 - val_accuracy: 0.6006\n",
      "Epoch 2582/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4779 - accuracy: 0.8545 - val_loss: 1.4225 - val_accuracy: 0.5974\n",
      "Epoch 2583/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4944 - accuracy: 0.8394 - val_loss: 1.4722 - val_accuracy: 0.5942\n",
      "Epoch 2584/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4081 - accuracy: 0.8633 - val_loss: 1.5003 - val_accuracy: 0.6104\n",
      "Epoch 2585/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4564 - accuracy: 0.8555 - val_loss: 1.4962 - val_accuracy: 0.6104\n",
      "Epoch 2586/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4249 - accuracy: 0.8574 - val_loss: 1.4773 - val_accuracy: 0.6169\n",
      "Epoch 2587/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4930 - accuracy: 0.8350 - val_loss: 1.4487 - val_accuracy: 0.6136\n",
      "Epoch 2588/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4460 - accuracy: 0.8535 - val_loss: 1.4047 - val_accuracy: 0.6234\n",
      "Epoch 2589/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4583 - accuracy: 0.8525 - val_loss: 1.3885 - val_accuracy: 0.6234\n",
      "Epoch 2590/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4158 - accuracy: 0.8643 - val_loss: 1.3756 - val_accuracy: 0.6201\n",
      "Epoch 2591/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4594 - accuracy: 0.8506 - val_loss: 1.3507 - val_accuracy: 0.6266\n",
      "Epoch 2592/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4569 - accuracy: 0.8535 - val_loss: 1.3356 - val_accuracy: 0.6266\n",
      "Epoch 2593/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4670 - accuracy: 0.8428 - val_loss: 1.3236 - val_accuracy: 0.6299\n",
      "Epoch 2594/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4949 - accuracy: 0.8450 - val_loss: 1.3491 - val_accuracy: 0.6331\n",
      "Epoch 2595/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4611 - accuracy: 0.8478 - val_loss: 1.3812 - val_accuracy: 0.6201\n",
      "Epoch 2596/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4720 - accuracy: 0.8324 - val_loss: 1.3869 - val_accuracy: 0.6136\n",
      "Epoch 2597/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4913 - accuracy: 0.8398 - val_loss: 1.3687 - val_accuracy: 0.6104\n",
      "Epoch 2598/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4272 - accuracy: 0.8604 - val_loss: 1.3287 - val_accuracy: 0.6201\n",
      "Epoch 2599/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5124 - accuracy: 0.8352 - val_loss: 1.2831 - val_accuracy: 0.6526\n",
      "Epoch 2600/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4810 - accuracy: 0.8320 - val_loss: 1.2552 - val_accuracy: 0.6494\n",
      "Epoch 2601/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4574 - accuracy: 0.8422 - val_loss: 1.2348 - val_accuracy: 0.6623\n",
      "Epoch 2602/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4844 - accuracy: 0.8464 - val_loss: 1.2351 - val_accuracy: 0.6591\n",
      "Epoch 2603/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3979 - accuracy: 0.8617 - val_loss: 1.2551 - val_accuracy: 0.6429\n",
      "Epoch 2604/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4853 - accuracy: 0.8296 - val_loss: 1.2866 - val_accuracy: 0.6234\n",
      "Epoch 2605/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4333 - accuracy: 0.8594 - val_loss: 1.3216 - val_accuracy: 0.6201\n",
      "Epoch 2606/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5185 - accuracy: 0.8389 - val_loss: 1.3444 - val_accuracy: 0.6136\n",
      "Epoch 2607/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4820 - accuracy: 0.8398 - val_loss: 1.3505 - val_accuracy: 0.6169\n",
      "Epoch 2608/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4837 - accuracy: 0.8457 - val_loss: 1.3719 - val_accuracy: 0.6169\n",
      "Epoch 2609/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4206 - accuracy: 0.8721 - val_loss: 1.3685 - val_accuracy: 0.6169\n",
      "Epoch 2610/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4232 - accuracy: 0.8721 - val_loss: 1.3501 - val_accuracy: 0.6234\n",
      "Epoch 2611/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4576 - accuracy: 0.8492 - val_loss: 1.3044 - val_accuracy: 0.6364\n",
      "Epoch 2612/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4419 - accuracy: 0.8617 - val_loss: 1.2900 - val_accuracy: 0.6364\n",
      "Epoch 2613/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4688 - accuracy: 0.8394 - val_loss: 1.2720 - val_accuracy: 0.6331\n",
      "Epoch 2614/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4710 - accuracy: 0.8408 - val_loss: 1.2756 - val_accuracy: 0.6169\n",
      "Epoch 2615/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4791 - accuracy: 0.8575 - val_loss: 1.2797 - val_accuracy: 0.6234\n",
      "Epoch 2616/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4851 - accuracy: 0.8447 - val_loss: 1.2818 - val_accuracy: 0.6331\n",
      "Epoch 2617/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4834 - accuracy: 0.8380 - val_loss: 1.2846 - val_accuracy: 0.6299\n",
      "Epoch 2618/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4646 - accuracy: 0.8478 - val_loss: 1.2806 - val_accuracy: 0.6331\n",
      "Epoch 2619/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4138 - accuracy: 0.8701 - val_loss: 1.2715 - val_accuracy: 0.6461\n",
      "Epoch 2620/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4138 - accuracy: 0.8631 - val_loss: 1.2567 - val_accuracy: 0.6494\n",
      "Epoch 2621/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4665 - accuracy: 0.8486 - val_loss: 1.2502 - val_accuracy: 0.6526\n",
      "Epoch 2622/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4611 - accuracy: 0.8584 - val_loss: 1.2525 - val_accuracy: 0.6656\n",
      "Epoch 2623/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4161 - accuracy: 0.8589 - val_loss: 1.2616 - val_accuracy: 0.6753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2624/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4405 - accuracy: 0.8486 - val_loss: 1.2774 - val_accuracy: 0.6753\n",
      "Epoch 2625/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4086 - accuracy: 0.8770 - val_loss: 1.2923 - val_accuracy: 0.6688\n",
      "Epoch 2626/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4414 - accuracy: 0.8535 - val_loss: 1.3004 - val_accuracy: 0.6656\n",
      "Epoch 2627/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5258 - accuracy: 0.8291 - val_loss: 1.3138 - val_accuracy: 0.6623\n",
      "Epoch 2628/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4615 - accuracy: 0.8408 - val_loss: 1.3342 - val_accuracy: 0.6494\n",
      "Epoch 2629/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4396 - accuracy: 0.8545 - val_loss: 1.3577 - val_accuracy: 0.6201\n",
      "Epoch 2630/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4172 - accuracy: 0.8575 - val_loss: 1.3810 - val_accuracy: 0.6266\n",
      "Epoch 2631/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4459 - accuracy: 0.8575 - val_loss: 1.3693 - val_accuracy: 0.6429\n",
      "Epoch 2632/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4419 - accuracy: 0.8492 - val_loss: 1.3581 - val_accuracy: 0.6461\n",
      "Epoch 2633/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4444 - accuracy: 0.8603 - val_loss: 1.3537 - val_accuracy: 0.6494\n",
      "Epoch 2634/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4536 - accuracy: 0.8464 - val_loss: 1.3531 - val_accuracy: 0.6364\n",
      "Epoch 2635/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4867 - accuracy: 0.8394 - val_loss: 1.3427 - val_accuracy: 0.6429\n",
      "Epoch 2636/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4638 - accuracy: 0.8506 - val_loss: 1.3300 - val_accuracy: 0.6364\n",
      "Epoch 2637/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4497 - accuracy: 0.8673 - val_loss: 1.3175 - val_accuracy: 0.6461\n",
      "Epoch 2638/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4647 - accuracy: 0.8438 - val_loss: 1.3094 - val_accuracy: 0.6429\n",
      "Epoch 2639/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4705 - accuracy: 0.8450 - val_loss: 1.2981 - val_accuracy: 0.6461\n",
      "Epoch 2640/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5400 - accuracy: 0.8240 - val_loss: 1.2958 - val_accuracy: 0.6461\n",
      "Epoch 2641/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4361 - accuracy: 0.8659 - val_loss: 1.2851 - val_accuracy: 0.6364\n",
      "Epoch 2642/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4395 - accuracy: 0.8428 - val_loss: 1.2734 - val_accuracy: 0.6461\n",
      "Epoch 2643/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4748 - accuracy: 0.8350 - val_loss: 1.2675 - val_accuracy: 0.6526\n",
      "Epoch 2644/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5057 - accuracy: 0.8226 - val_loss: 1.2744 - val_accuracy: 0.6558\n",
      "Epoch 2645/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4558 - accuracy: 0.8438 - val_loss: 1.2783 - val_accuracy: 0.6526\n",
      "Epoch 2646/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4585 - accuracy: 0.8516 - val_loss: 1.2835 - val_accuracy: 0.6461\n",
      "Epoch 2647/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4465 - accuracy: 0.8574 - val_loss: 1.2837 - val_accuracy: 0.6526\n",
      "Epoch 2648/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5160 - accuracy: 0.8389 - val_loss: 1.2807 - val_accuracy: 0.6591\n",
      "Epoch 2649/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4924 - accuracy: 0.8296 - val_loss: 1.2848 - val_accuracy: 0.6558\n",
      "Epoch 2650/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4624 - accuracy: 0.8564 - val_loss: 1.2895 - val_accuracy: 0.6494\n",
      "Epoch 2651/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5112 - accuracy: 0.8310 - val_loss: 1.2974 - val_accuracy: 0.6429\n",
      "Epoch 2652/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4190 - accuracy: 0.8687 - val_loss: 1.3077 - val_accuracy: 0.6299\n",
      "Epoch 2653/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5386 - accuracy: 0.8242 - val_loss: 1.3154 - val_accuracy: 0.6234\n",
      "Epoch 2654/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4393 - accuracy: 0.8631 - val_loss: 1.3107 - val_accuracy: 0.6201\n",
      "Epoch 2655/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4236 - accuracy: 0.8701 - val_loss: 1.2984 - val_accuracy: 0.6234\n",
      "Epoch 2656/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4424 - accuracy: 0.8477 - val_loss: 1.2885 - val_accuracy: 0.6266\n",
      "Epoch 2657/4000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4240 - accuracy: 0.8617 - val_loss: 1.2984 - val_accuracy: 0.6299\n",
      "Epoch 2658/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4786 - accuracy: 0.8478 - val_loss: 1.3030 - val_accuracy: 0.6169\n",
      "Epoch 2659/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4109 - accuracy: 0.8740 - val_loss: 1.2980 - val_accuracy: 0.6201\n",
      "Epoch 2660/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4520 - accuracy: 0.8535 - val_loss: 1.3030 - val_accuracy: 0.6104\n",
      "Epoch 2661/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4940 - accuracy: 0.8281 - val_loss: 1.3090 - val_accuracy: 0.6071\n",
      "Epoch 2662/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4613 - accuracy: 0.8428 - val_loss: 1.3025 - val_accuracy: 0.6136\n",
      "Epoch 2663/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4733 - accuracy: 0.8408 - val_loss: 1.3136 - val_accuracy: 0.6104\n",
      "Epoch 2664/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4656 - accuracy: 0.8555 - val_loss: 1.3252 - val_accuracy: 0.6136\n",
      "Epoch 2665/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4351 - accuracy: 0.8594 - val_loss: 1.3223 - val_accuracy: 0.6169\n",
      "Epoch 2666/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4938 - accuracy: 0.8310 - val_loss: 1.3615 - val_accuracy: 0.6039\n",
      "Epoch 2667/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4439 - accuracy: 0.8701 - val_loss: 1.3586 - val_accuracy: 0.6136\n",
      "Epoch 2668/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5048 - accuracy: 0.8422 - val_loss: 1.3486 - val_accuracy: 0.6234\n",
      "Epoch 2669/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4685 - accuracy: 0.8408 - val_loss: 1.3513 - val_accuracy: 0.6169\n",
      "Epoch 2670/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4827 - accuracy: 0.8422 - val_loss: 1.3437 - val_accuracy: 0.6201\n",
      "Epoch 2671/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4180 - accuracy: 0.8545 - val_loss: 1.3519 - val_accuracy: 0.6169\n",
      "Epoch 2672/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4444 - accuracy: 0.8516 - val_loss: 1.3818 - val_accuracy: 0.6006\n",
      "Epoch 2673/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4561 - accuracy: 0.8418 - val_loss: 1.4271 - val_accuracy: 0.5812\n",
      "Epoch 2674/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5270 - accuracy: 0.8226 - val_loss: 1.4650 - val_accuracy: 0.5812\n",
      "Epoch 2675/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4754 - accuracy: 0.8408 - val_loss: 1.5007 - val_accuracy: 0.5779\n",
      "Epoch 2676/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4379 - accuracy: 0.8478 - val_loss: 1.4927 - val_accuracy: 0.5779\n",
      "Epoch 2677/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5035 - accuracy: 0.8389 - val_loss: 1.4451 - val_accuracy: 0.5812\n",
      "Epoch 2678/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5311 - accuracy: 0.8366 - val_loss: 1.3678 - val_accuracy: 0.5844\n",
      "Epoch 2679/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4405 - accuracy: 0.8575 - val_loss: 1.3217 - val_accuracy: 0.6136\n",
      "Epoch 2680/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4309 - accuracy: 0.8643 - val_loss: 1.2986 - val_accuracy: 0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2681/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4631 - accuracy: 0.8574 - val_loss: 1.3020 - val_accuracy: 0.6364\n",
      "Epoch 2682/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4683 - accuracy: 0.8436 - val_loss: 1.2952 - val_accuracy: 0.6364\n",
      "Epoch 2683/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5166 - accuracy: 0.8213 - val_loss: 1.2943 - val_accuracy: 0.6396\n",
      "Epoch 2684/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4849 - accuracy: 0.8447 - val_loss: 1.3079 - val_accuracy: 0.6364\n",
      "Epoch 2685/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4972 - accuracy: 0.8436 - val_loss: 1.3271 - val_accuracy: 0.6331\n",
      "Epoch 2686/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4042 - accuracy: 0.8730 - val_loss: 1.3454 - val_accuracy: 0.6299\n",
      "Epoch 2687/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4021 - accuracy: 0.8547 - val_loss: 1.3426 - val_accuracy: 0.6266\n",
      "Epoch 2688/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4713 - accuracy: 0.8398 - val_loss: 1.3399 - val_accuracy: 0.6201\n",
      "Epoch 2689/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4608 - accuracy: 0.8520 - val_loss: 1.3303 - val_accuracy: 0.6201\n",
      "Epoch 2690/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4899 - accuracy: 0.8477 - val_loss: 1.3389 - val_accuracy: 0.6201\n",
      "Epoch 2691/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4372 - accuracy: 0.8555 - val_loss: 1.3661 - val_accuracy: 0.6071\n",
      "Epoch 2692/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4664 - accuracy: 0.8422 - val_loss: 1.4041 - val_accuracy: 0.5877\n",
      "Epoch 2693/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4501 - accuracy: 0.8534 - val_loss: 1.4104 - val_accuracy: 0.5942\n",
      "Epoch 2694/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4438 - accuracy: 0.8617 - val_loss: 1.4087 - val_accuracy: 0.5877\n",
      "Epoch 2695/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4610 - accuracy: 0.8301 - val_loss: 1.4030 - val_accuracy: 0.5877\n",
      "Epoch 2696/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4225 - accuracy: 0.8604 - val_loss: 1.4121 - val_accuracy: 0.5974\n",
      "Epoch 2697/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4374 - accuracy: 0.8492 - val_loss: 1.4193 - val_accuracy: 0.6039\n",
      "Epoch 2698/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4133 - accuracy: 0.8691 - val_loss: 1.4433 - val_accuracy: 0.6039\n",
      "Epoch 2699/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3561 - accuracy: 0.8771 - val_loss: 1.4677 - val_accuracy: 0.6006\n",
      "Epoch 2700/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3696 - accuracy: 0.8771 - val_loss: 1.4748 - val_accuracy: 0.6104\n",
      "Epoch 2701/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4517 - accuracy: 0.8604 - val_loss: 1.4409 - val_accuracy: 0.6104\n",
      "Epoch 2702/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4383 - accuracy: 0.8477 - val_loss: 1.4229 - val_accuracy: 0.6201\n",
      "Epoch 2703/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4444 - accuracy: 0.8447 - val_loss: 1.3891 - val_accuracy: 0.6266\n",
      "Epoch 2704/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4238 - accuracy: 0.8564 - val_loss: 1.3565 - val_accuracy: 0.6266\n",
      "Epoch 2705/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4870 - accuracy: 0.8436 - val_loss: 1.3529 - val_accuracy: 0.6234\n",
      "Epoch 2706/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5044 - accuracy: 0.8478 - val_loss: 1.3414 - val_accuracy: 0.6266\n",
      "Epoch 2707/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4833 - accuracy: 0.8547 - val_loss: 1.3361 - val_accuracy: 0.6331\n",
      "Epoch 2708/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4289 - accuracy: 0.8534 - val_loss: 1.3240 - val_accuracy: 0.6461\n",
      "Epoch 2709/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5129 - accuracy: 0.8268 - val_loss: 1.3037 - val_accuracy: 0.6558\n",
      "Epoch 2710/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4048 - accuracy: 0.8604 - val_loss: 1.3065 - val_accuracy: 0.6331\n",
      "Epoch 2711/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4053 - accuracy: 0.8594 - val_loss: 1.3146 - val_accuracy: 0.6266\n",
      "Epoch 2712/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3880 - accuracy: 0.8743 - val_loss: 1.3114 - val_accuracy: 0.6136\n",
      "Epoch 2713/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4423 - accuracy: 0.8516 - val_loss: 1.3173 - val_accuracy: 0.6039\n",
      "Epoch 2714/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4410 - accuracy: 0.8631 - val_loss: 1.3271 - val_accuracy: 0.6104\n",
      "Epoch 2715/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4581 - accuracy: 0.8645 - val_loss: 1.3375 - val_accuracy: 0.6234\n",
      "Epoch 2716/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4240 - accuracy: 0.8652 - val_loss: 1.3381 - val_accuracy: 0.6266\n",
      "Epoch 2717/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4389 - accuracy: 0.8496 - val_loss: 1.3561 - val_accuracy: 0.6266\n",
      "Epoch 2718/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4698 - accuracy: 0.8525 - val_loss: 1.3796 - val_accuracy: 0.6136\n",
      "Epoch 2719/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4105 - accuracy: 0.8617 - val_loss: 1.3887 - val_accuracy: 0.6071\n",
      "Epoch 2720/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4138 - accuracy: 0.8631 - val_loss: 1.3992 - val_accuracy: 0.6039\n",
      "Epoch 2721/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4635 - accuracy: 0.8574 - val_loss: 1.4069 - val_accuracy: 0.6039\n",
      "Epoch 2722/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4541 - accuracy: 0.8477 - val_loss: 1.4044 - val_accuracy: 0.6071\n",
      "Epoch 2723/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4852 - accuracy: 0.8447 - val_loss: 1.3978 - val_accuracy: 0.6071\n",
      "Epoch 2724/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4496 - accuracy: 0.8496 - val_loss: 1.3936 - val_accuracy: 0.6136\n",
      "Epoch 2725/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4537 - accuracy: 0.8478 - val_loss: 1.3935 - val_accuracy: 0.6071\n",
      "Epoch 2726/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4077 - accuracy: 0.8743 - val_loss: 1.3856 - val_accuracy: 0.6169\n",
      "Epoch 2727/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4631 - accuracy: 0.8428 - val_loss: 1.3805 - val_accuracy: 0.6201\n",
      "Epoch 2728/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4464 - accuracy: 0.8561 - val_loss: 1.3790 - val_accuracy: 0.6169\n",
      "Epoch 2729/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4458 - accuracy: 0.8467 - val_loss: 1.3819 - val_accuracy: 0.6169\n",
      "Epoch 2730/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4476 - accuracy: 0.8555 - val_loss: 1.3748 - val_accuracy: 0.6039\n",
      "Epoch 2731/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4989 - accuracy: 0.8464 - val_loss: 1.3369 - val_accuracy: 0.6039\n",
      "Epoch 2732/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4768 - accuracy: 0.8438 - val_loss: 1.3132 - val_accuracy: 0.6201\n",
      "Epoch 2733/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4619 - accuracy: 0.8478 - val_loss: 1.3074 - val_accuracy: 0.6266\n",
      "Epoch 2734/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4759 - accuracy: 0.8394 - val_loss: 1.3140 - val_accuracy: 0.6136\n",
      "Epoch 2735/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4640 - accuracy: 0.8525 - val_loss: 1.3410 - val_accuracy: 0.6266\n",
      "Epoch 2736/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4674 - accuracy: 0.8330 - val_loss: 1.3489 - val_accuracy: 0.6234\n",
      "Epoch 2737/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4438 - accuracy: 0.8631 - val_loss: 1.3832 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2738/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4682 - accuracy: 0.8398 - val_loss: 1.4121 - val_accuracy: 0.5942\n",
      "Epoch 2739/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4117 - accuracy: 0.8659 - val_loss: 1.4427 - val_accuracy: 0.5779\n",
      "Epoch 2740/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4766 - accuracy: 0.8516 - val_loss: 1.4931 - val_accuracy: 0.5714\n",
      "Epoch 2741/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4373 - accuracy: 0.8525 - val_loss: 1.5273 - val_accuracy: 0.5844\n",
      "Epoch 2742/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4449 - accuracy: 0.8506 - val_loss: 1.5313 - val_accuracy: 0.5844\n",
      "Epoch 2743/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4155 - accuracy: 0.8750 - val_loss: 1.5134 - val_accuracy: 0.5812\n",
      "Epoch 2744/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4541 - accuracy: 0.8310 - val_loss: 1.4885 - val_accuracy: 0.5747\n",
      "Epoch 2745/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4520 - accuracy: 0.8506 - val_loss: 1.4987 - val_accuracy: 0.6006\n",
      "Epoch 2746/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4618 - accuracy: 0.8520 - val_loss: 1.5274 - val_accuracy: 0.6136\n",
      "Epoch 2747/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4611 - accuracy: 0.8520 - val_loss: 1.5777 - val_accuracy: 0.6169\n",
      "Epoch 2748/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4911 - accuracy: 0.8492 - val_loss: 1.5442 - val_accuracy: 0.5974\n",
      "Epoch 2749/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4247 - accuracy: 0.8561 - val_loss: 1.4824 - val_accuracy: 0.6104\n",
      "Epoch 2750/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4236 - accuracy: 0.8652 - val_loss: 1.4270 - val_accuracy: 0.6136\n",
      "Epoch 2751/4000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4195 - accuracy: 0.8643 - val_loss: 1.3904 - val_accuracy: 0.6136\n",
      "Epoch 2752/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4594 - accuracy: 0.8561 - val_loss: 1.3568 - val_accuracy: 0.6266\n",
      "Epoch 2753/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4387 - accuracy: 0.8603 - val_loss: 1.3279 - val_accuracy: 0.6071\n",
      "Epoch 2754/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4569 - accuracy: 0.8492 - val_loss: 1.3131 - val_accuracy: 0.6266\n",
      "Epoch 2755/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4487 - accuracy: 0.8506 - val_loss: 1.2619 - val_accuracy: 0.6364\n",
      "Epoch 2756/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4196 - accuracy: 0.8547 - val_loss: 1.2272 - val_accuracy: 0.6656\n",
      "Epoch 2757/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4086 - accuracy: 0.8631 - val_loss: 1.2388 - val_accuracy: 0.6494\n",
      "Epoch 2758/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4391 - accuracy: 0.8408 - val_loss: 1.2745 - val_accuracy: 0.6396\n",
      "Epoch 2759/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4159 - accuracy: 0.8715 - val_loss: 1.3087 - val_accuracy: 0.6331\n",
      "Epoch 2760/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4233 - accuracy: 0.8603 - val_loss: 1.3340 - val_accuracy: 0.6331\n",
      "Epoch 2761/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4546 - accuracy: 0.8545 - val_loss: 1.3523 - val_accuracy: 0.6364\n",
      "Epoch 2762/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4123 - accuracy: 0.8603 - val_loss: 1.3523 - val_accuracy: 0.6299\n",
      "Epoch 2763/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4128 - accuracy: 0.8534 - val_loss: 1.3562 - val_accuracy: 0.6169\n",
      "Epoch 2764/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4232 - accuracy: 0.8584 - val_loss: 1.3496 - val_accuracy: 0.6104\n",
      "Epoch 2765/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4396 - accuracy: 0.8486 - val_loss: 1.3411 - val_accuracy: 0.6136\n",
      "Epoch 2766/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4650 - accuracy: 0.8547 - val_loss: 1.3257 - val_accuracy: 0.6266\n",
      "Epoch 2767/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4605 - accuracy: 0.8564 - val_loss: 1.3137 - val_accuracy: 0.6136\n",
      "Epoch 2768/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4485 - accuracy: 0.8477 - val_loss: 1.2931 - val_accuracy: 0.6201\n",
      "Epoch 2769/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4537 - accuracy: 0.8418 - val_loss: 1.2823 - val_accuracy: 0.6364\n",
      "Epoch 2770/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5020 - accuracy: 0.8311 - val_loss: 1.2950 - val_accuracy: 0.6299\n",
      "Epoch 2771/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4492 - accuracy: 0.8520 - val_loss: 1.2975 - val_accuracy: 0.6201\n",
      "Epoch 2772/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4569 - accuracy: 0.8492 - val_loss: 1.2992 - val_accuracy: 0.6299\n",
      "Epoch 2773/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4257 - accuracy: 0.8574 - val_loss: 1.3025 - val_accuracy: 0.6364\n",
      "Epoch 2774/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5048 - accuracy: 0.8350 - val_loss: 1.3084 - val_accuracy: 0.6169\n",
      "Epoch 2775/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4393 - accuracy: 0.8589 - val_loss: 1.3209 - val_accuracy: 0.6136\n",
      "Epoch 2776/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4644 - accuracy: 0.8525 - val_loss: 1.3339 - val_accuracy: 0.6104\n",
      "Epoch 2777/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4266 - accuracy: 0.8584 - val_loss: 1.3232 - val_accuracy: 0.6169\n",
      "Epoch 2778/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4158 - accuracy: 0.8408 - val_loss: 1.3089 - val_accuracy: 0.6299\n",
      "Epoch 2779/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4329 - accuracy: 0.8574 - val_loss: 1.2895 - val_accuracy: 0.6461\n",
      "Epoch 2780/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3722 - accuracy: 0.8701 - val_loss: 1.2869 - val_accuracy: 0.6494\n",
      "Epoch 2781/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4604 - accuracy: 0.8457 - val_loss: 1.2842 - val_accuracy: 0.6591\n",
      "Epoch 2782/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4573 - accuracy: 0.8464 - val_loss: 1.2886 - val_accuracy: 0.6461\n",
      "Epoch 2783/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4081 - accuracy: 0.8604 - val_loss: 1.2911 - val_accuracy: 0.6331\n",
      "Epoch 2784/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4444 - accuracy: 0.8535 - val_loss: 1.2961 - val_accuracy: 0.6331\n",
      "Epoch 2785/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4393 - accuracy: 0.8535 - val_loss: 1.3045 - val_accuracy: 0.6234\n",
      "Epoch 2786/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4202 - accuracy: 0.8584 - val_loss: 1.3018 - val_accuracy: 0.6396\n",
      "Epoch 2787/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4244 - accuracy: 0.8687 - val_loss: 1.3164 - val_accuracy: 0.6429\n",
      "Epoch 2788/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4789 - accuracy: 0.8369 - val_loss: 1.3481 - val_accuracy: 0.6266\n",
      "Epoch 2789/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4324 - accuracy: 0.8594 - val_loss: 1.4055 - val_accuracy: 0.6169\n",
      "Epoch 2790/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4442 - accuracy: 0.8672 - val_loss: 1.5056 - val_accuracy: 0.5747\n",
      "Epoch 2791/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4058 - accuracy: 0.8701 - val_loss: 1.5967 - val_accuracy: 0.5617\n",
      "Epoch 2792/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3942 - accuracy: 0.8771 - val_loss: 1.6847 - val_accuracy: 0.5487\n",
      "Epoch 2793/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4211 - accuracy: 0.8631 - val_loss: 1.7298 - val_accuracy: 0.5455\n",
      "Epoch 2794/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4228 - accuracy: 0.8687 - val_loss: 1.7478 - val_accuracy: 0.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2795/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3802 - accuracy: 0.8799 - val_loss: 1.7329 - val_accuracy: 0.5519\n",
      "Epoch 2796/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3708 - accuracy: 0.8757 - val_loss: 1.6743 - val_accuracy: 0.5584\n",
      "Epoch 2797/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4517 - accuracy: 0.8555 - val_loss: 1.6047 - val_accuracy: 0.5649\n",
      "Epoch 2798/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4244 - accuracy: 0.8652 - val_loss: 1.5397 - val_accuracy: 0.5747\n",
      "Epoch 2799/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4864 - accuracy: 0.8350 - val_loss: 1.5082 - val_accuracy: 0.5747\n",
      "Epoch 2800/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4495 - accuracy: 0.8457 - val_loss: 1.4762 - val_accuracy: 0.5942\n",
      "Epoch 2801/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4200 - accuracy: 0.8450 - val_loss: 1.4521 - val_accuracy: 0.5942\n",
      "Epoch 2802/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4123 - accuracy: 0.8760 - val_loss: 1.4331 - val_accuracy: 0.5942\n",
      "Epoch 2803/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4991 - accuracy: 0.8464 - val_loss: 1.4127 - val_accuracy: 0.5974\n",
      "Epoch 2804/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4058 - accuracy: 0.8652 - val_loss: 1.4030 - val_accuracy: 0.5877\n",
      "Epoch 2805/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4685 - accuracy: 0.8547 - val_loss: 1.4087 - val_accuracy: 0.5942\n",
      "Epoch 2806/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4196 - accuracy: 0.8525 - val_loss: 1.4098 - val_accuracy: 0.5942\n",
      "Epoch 2807/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3769 - accuracy: 0.8750 - val_loss: 1.4020 - val_accuracy: 0.5942\n",
      "Epoch 2808/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5258 - accuracy: 0.8408 - val_loss: 1.3888 - val_accuracy: 0.6071\n",
      "Epoch 2809/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4392 - accuracy: 0.8545 - val_loss: 1.3562 - val_accuracy: 0.6201\n",
      "Epoch 2810/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4326 - accuracy: 0.8574 - val_loss: 1.3243 - val_accuracy: 0.6266\n",
      "Epoch 2811/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4264 - accuracy: 0.8467 - val_loss: 1.2873 - val_accuracy: 0.6429\n",
      "Epoch 2812/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4325 - accuracy: 0.8631 - val_loss: 1.2594 - val_accuracy: 0.6429\n",
      "Epoch 2813/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4214 - accuracy: 0.8682 - val_loss: 1.2439 - val_accuracy: 0.6526\n",
      "Epoch 2814/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4263 - accuracy: 0.8547 - val_loss: 1.2348 - val_accuracy: 0.6591\n",
      "Epoch 2815/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4157 - accuracy: 0.8613 - val_loss: 1.2293 - val_accuracy: 0.6591\n",
      "Epoch 2816/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4707 - accuracy: 0.8422 - val_loss: 1.2286 - val_accuracy: 0.6591\n",
      "Epoch 2817/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4499 - accuracy: 0.8525 - val_loss: 1.2406 - val_accuracy: 0.6558\n",
      "Epoch 2818/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4180 - accuracy: 0.8757 - val_loss: 1.2490 - val_accuracy: 0.6461\n",
      "Epoch 2819/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4723 - accuracy: 0.8561 - val_loss: 1.2675 - val_accuracy: 0.6461\n",
      "Epoch 2820/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3818 - accuracy: 0.8623 - val_loss: 1.2867 - val_accuracy: 0.6299\n",
      "Epoch 2821/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4571 - accuracy: 0.8506 - val_loss: 1.2917 - val_accuracy: 0.6266\n",
      "Epoch 2822/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4471 - accuracy: 0.8438 - val_loss: 1.2957 - val_accuracy: 0.6234\n",
      "Epoch 2823/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4477 - accuracy: 0.8659 - val_loss: 1.2870 - val_accuracy: 0.6201\n",
      "Epoch 2824/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4184 - accuracy: 0.8701 - val_loss: 1.2980 - val_accuracy: 0.6169\n",
      "Epoch 2825/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4038 - accuracy: 0.8691 - val_loss: 1.3079 - val_accuracy: 0.6169\n",
      "Epoch 2826/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4265 - accuracy: 0.8604 - val_loss: 1.3008 - val_accuracy: 0.6266\n",
      "Epoch 2827/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3786 - accuracy: 0.8603 - val_loss: 1.2931 - val_accuracy: 0.6266\n",
      "Epoch 2828/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3971 - accuracy: 0.8711 - val_loss: 1.2795 - val_accuracy: 0.6201\n",
      "Epoch 2829/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4895 - accuracy: 0.8398 - val_loss: 1.2914 - val_accuracy: 0.6201\n",
      "Epoch 2830/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4145 - accuracy: 0.8691 - val_loss: 1.3133 - val_accuracy: 0.6201\n",
      "Epoch 2831/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4389 - accuracy: 0.8520 - val_loss: 1.3260 - val_accuracy: 0.6234\n",
      "Epoch 2832/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4545 - accuracy: 0.8564 - val_loss: 1.3415 - val_accuracy: 0.6104\n",
      "Epoch 2833/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4109 - accuracy: 0.8799 - val_loss: 1.3612 - val_accuracy: 0.6104\n",
      "Epoch 2834/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4049 - accuracy: 0.8603 - val_loss: 1.3879 - val_accuracy: 0.6104\n",
      "Epoch 2835/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4331 - accuracy: 0.8478 - val_loss: 1.4179 - val_accuracy: 0.5974\n",
      "Epoch 2836/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4658 - accuracy: 0.8547 - val_loss: 1.4219 - val_accuracy: 0.6071\n",
      "Epoch 2837/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4292 - accuracy: 0.8682 - val_loss: 1.4149 - val_accuracy: 0.6039\n",
      "Epoch 2838/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4484 - accuracy: 0.8534 - val_loss: 1.4174 - val_accuracy: 0.6071\n",
      "Epoch 2839/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3932 - accuracy: 0.8564 - val_loss: 1.4245 - val_accuracy: 0.6169\n",
      "Epoch 2840/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4612 - accuracy: 0.8575 - val_loss: 1.4249 - val_accuracy: 0.6104\n",
      "Epoch 2841/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4266 - accuracy: 0.8534 - val_loss: 1.4196 - val_accuracy: 0.6136\n",
      "Epoch 2842/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4049 - accuracy: 0.8574 - val_loss: 1.4160 - val_accuracy: 0.6104\n",
      "Epoch 2843/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4229 - accuracy: 0.8672 - val_loss: 1.3779 - val_accuracy: 0.6169\n",
      "Epoch 2844/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4637 - accuracy: 0.8520 - val_loss: 1.3278 - val_accuracy: 0.6299\n",
      "Epoch 2845/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4610 - accuracy: 0.8506 - val_loss: 1.2829 - val_accuracy: 0.6429\n",
      "Epoch 2846/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4204 - accuracy: 0.8534 - val_loss: 1.2668 - val_accuracy: 0.6461\n",
      "Epoch 2847/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4339 - accuracy: 0.8564 - val_loss: 1.2506 - val_accuracy: 0.6461\n",
      "Epoch 2848/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4199 - accuracy: 0.8673 - val_loss: 1.2553 - val_accuracy: 0.6429\n",
      "Epoch 2849/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3874 - accuracy: 0.8715 - val_loss: 1.2900 - val_accuracy: 0.6201\n",
      "Epoch 2850/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3983 - accuracy: 0.8721 - val_loss: 1.3386 - val_accuracy: 0.6006\n",
      "Epoch 2851/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4543 - accuracy: 0.8545 - val_loss: 1.3732 - val_accuracy: 0.5942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2852/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4229 - accuracy: 0.8555 - val_loss: 1.3804 - val_accuracy: 0.5877\n",
      "Epoch 2853/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4040 - accuracy: 0.8740 - val_loss: 1.3517 - val_accuracy: 0.5909\n",
      "Epoch 2854/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4845 - accuracy: 0.8506 - val_loss: 1.3132 - val_accuracy: 0.6234\n",
      "Epoch 2855/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4399 - accuracy: 0.8506 - val_loss: 1.2710 - val_accuracy: 0.6364\n",
      "Epoch 2856/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3589 - accuracy: 0.8771 - val_loss: 1.2379 - val_accuracy: 0.6461\n",
      "Epoch 2857/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4189 - accuracy: 0.8575 - val_loss: 1.2350 - val_accuracy: 0.6461\n",
      "Epoch 2858/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4014 - accuracy: 0.8589 - val_loss: 1.2566 - val_accuracy: 0.6429\n",
      "Epoch 2859/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4456 - accuracy: 0.8594 - val_loss: 1.2995 - val_accuracy: 0.6331\n",
      "Epoch 2860/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4360 - accuracy: 0.8603 - val_loss: 1.3511 - val_accuracy: 0.6104\n",
      "Epoch 2861/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4439 - accuracy: 0.8545 - val_loss: 1.4010 - val_accuracy: 0.6039\n",
      "Epoch 2862/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4833 - accuracy: 0.8496 - val_loss: 1.4557 - val_accuracy: 0.5942\n",
      "Epoch 2863/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4084 - accuracy: 0.8589 - val_loss: 1.5060 - val_accuracy: 0.5877\n",
      "Epoch 2864/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4234 - accuracy: 0.8623 - val_loss: 1.5711 - val_accuracy: 0.5812\n",
      "Epoch 2865/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4207 - accuracy: 0.8662 - val_loss: 1.6725 - val_accuracy: 0.5552\n",
      "Epoch 2866/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4076 - accuracy: 0.8575 - val_loss: 1.7522 - val_accuracy: 0.5390\n",
      "Epoch 2867/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4178 - accuracy: 0.8575 - val_loss: 1.7925 - val_accuracy: 0.5325\n",
      "Epoch 2868/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4500 - accuracy: 0.8555 - val_loss: 1.7820 - val_accuracy: 0.5195\n",
      "Epoch 2869/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4683 - accuracy: 0.8506 - val_loss: 1.7472 - val_accuracy: 0.5390\n",
      "Epoch 2870/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3844 - accuracy: 0.8799 - val_loss: 1.6875 - val_accuracy: 0.5292\n",
      "Epoch 2871/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4297 - accuracy: 0.8673 - val_loss: 1.6174 - val_accuracy: 0.5422\n",
      "Epoch 2872/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4437 - accuracy: 0.8545 - val_loss: 1.5677 - val_accuracy: 0.5617\n",
      "Epoch 2873/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3900 - accuracy: 0.8779 - val_loss: 1.5191 - val_accuracy: 0.5714\n",
      "Epoch 2874/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3946 - accuracy: 0.8721 - val_loss: 1.4777 - val_accuracy: 0.5747\n",
      "Epoch 2875/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4019 - accuracy: 0.8740 - val_loss: 1.4692 - val_accuracy: 0.5747\n",
      "Epoch 2876/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4549 - accuracy: 0.8574 - val_loss: 1.4986 - val_accuracy: 0.5844\n",
      "Epoch 2877/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4559 - accuracy: 0.8594 - val_loss: 1.5370 - val_accuracy: 0.5909\n",
      "Epoch 2878/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4415 - accuracy: 0.8645 - val_loss: 1.5520 - val_accuracy: 0.5844\n",
      "Epoch 2879/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4260 - accuracy: 0.8545 - val_loss: 1.5291 - val_accuracy: 0.5844\n",
      "Epoch 2880/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3996 - accuracy: 0.8682 - val_loss: 1.4947 - val_accuracy: 0.5877\n",
      "Epoch 2881/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4279 - accuracy: 0.8617 - val_loss: 1.4502 - val_accuracy: 0.5909\n",
      "Epoch 2882/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4161 - accuracy: 0.8673 - val_loss: 1.3887 - val_accuracy: 0.6136\n",
      "Epoch 2883/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4109 - accuracy: 0.8701 - val_loss: 1.3311 - val_accuracy: 0.6299\n",
      "Epoch 2884/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4460 - accuracy: 0.8547 - val_loss: 1.2859 - val_accuracy: 0.6364\n",
      "Epoch 2885/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3576 - accuracy: 0.8809 - val_loss: 1.2665 - val_accuracy: 0.6299\n",
      "Epoch 2886/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4449 - accuracy: 0.8478 - val_loss: 1.2632 - val_accuracy: 0.6494\n",
      "Epoch 2887/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3974 - accuracy: 0.8701 - val_loss: 1.2657 - val_accuracy: 0.6526\n",
      "Epoch 2888/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3904 - accuracy: 0.8715 - val_loss: 1.2658 - val_accuracy: 0.6558\n",
      "Epoch 2889/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4062 - accuracy: 0.8701 - val_loss: 1.2790 - val_accuracy: 0.6721\n",
      "Epoch 2890/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4430 - accuracy: 0.8547 - val_loss: 1.3059 - val_accuracy: 0.6526\n",
      "Epoch 2891/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3865 - accuracy: 0.8659 - val_loss: 1.3174 - val_accuracy: 0.6429\n",
      "Epoch 2892/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3775 - accuracy: 0.8809 - val_loss: 1.3200 - val_accuracy: 0.6494\n",
      "Epoch 2893/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4129 - accuracy: 0.8687 - val_loss: 1.3140 - val_accuracy: 0.6396\n",
      "Epoch 2894/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3767 - accuracy: 0.8750 - val_loss: 1.2997 - val_accuracy: 0.6299\n",
      "Epoch 2895/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3911 - accuracy: 0.8662 - val_loss: 1.2907 - val_accuracy: 0.6494\n",
      "Epoch 2896/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4118 - accuracy: 0.8662 - val_loss: 1.2794 - val_accuracy: 0.6461\n",
      "Epoch 2897/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3866 - accuracy: 0.8652 - val_loss: 1.2755 - val_accuracy: 0.6396\n",
      "Epoch 2898/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4226 - accuracy: 0.8617 - val_loss: 1.2811 - val_accuracy: 0.6429\n",
      "Epoch 2899/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4293 - accuracy: 0.8478 - val_loss: 1.2796 - val_accuracy: 0.6461\n",
      "Epoch 2900/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4270 - accuracy: 0.8561 - val_loss: 1.2823 - val_accuracy: 0.6461\n",
      "Epoch 2901/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4152 - accuracy: 0.8771 - val_loss: 1.2760 - val_accuracy: 0.6494\n",
      "Epoch 2902/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4205 - accuracy: 0.8687 - val_loss: 1.2884 - val_accuracy: 0.6526\n",
      "Epoch 2903/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4077 - accuracy: 0.8623 - val_loss: 1.3027 - val_accuracy: 0.6494\n",
      "Epoch 2904/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4026 - accuracy: 0.8672 - val_loss: 1.3086 - val_accuracy: 0.6429\n",
      "Epoch 2905/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3860 - accuracy: 0.8730 - val_loss: 1.3096 - val_accuracy: 0.6331\n",
      "Epoch 2906/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3741 - accuracy: 0.8682 - val_loss: 1.3166 - val_accuracy: 0.6299\n",
      "Epoch 2907/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4206 - accuracy: 0.8711 - val_loss: 1.3387 - val_accuracy: 0.6396\n",
      "Epoch 2908/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3886 - accuracy: 0.8603 - val_loss: 1.3597 - val_accuracy: 0.6234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2909/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4280 - accuracy: 0.8672 - val_loss: 1.3869 - val_accuracy: 0.6234\n",
      "Epoch 2910/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3724 - accuracy: 0.8953 - val_loss: 1.4244 - val_accuracy: 0.6136\n",
      "Epoch 2911/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3650 - accuracy: 0.8848 - val_loss: 1.4462 - val_accuracy: 0.6071\n",
      "Epoch 2912/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3955 - accuracy: 0.8687 - val_loss: 1.4702 - val_accuracy: 0.6006\n",
      "Epoch 2913/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4176 - accuracy: 0.8547 - val_loss: 1.4939 - val_accuracy: 0.5974\n",
      "Epoch 2914/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4232 - accuracy: 0.8760 - val_loss: 1.5037 - val_accuracy: 0.5974\n",
      "Epoch 2915/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3857 - accuracy: 0.8743 - val_loss: 1.5005 - val_accuracy: 0.5844\n",
      "Epoch 2916/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4259 - accuracy: 0.8564 - val_loss: 1.4525 - val_accuracy: 0.5844\n",
      "Epoch 2917/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4143 - accuracy: 0.8659 - val_loss: 1.3930 - val_accuracy: 0.6071\n",
      "Epoch 2918/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3884 - accuracy: 0.8757 - val_loss: 1.3374 - val_accuracy: 0.6104\n",
      "Epoch 2919/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3828 - accuracy: 0.8838 - val_loss: 1.2989 - val_accuracy: 0.6299\n",
      "Epoch 2920/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4473 - accuracy: 0.8672 - val_loss: 1.2671 - val_accuracy: 0.6396\n",
      "Epoch 2921/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4156 - accuracy: 0.8594 - val_loss: 1.2588 - val_accuracy: 0.6396\n",
      "Epoch 2922/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3954 - accuracy: 0.8574 - val_loss: 1.2556 - val_accuracy: 0.6364\n",
      "Epoch 2923/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4093 - accuracy: 0.8701 - val_loss: 1.2731 - val_accuracy: 0.6364\n",
      "Epoch 2924/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3994 - accuracy: 0.8711 - val_loss: 1.2734 - val_accuracy: 0.6396\n",
      "Epoch 2925/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4023 - accuracy: 0.8711 - val_loss: 1.2729 - val_accuracy: 0.6461\n",
      "Epoch 2926/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3820 - accuracy: 0.8770 - val_loss: 1.2686 - val_accuracy: 0.6526\n",
      "Epoch 2927/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4266 - accuracy: 0.8652 - val_loss: 1.2661 - val_accuracy: 0.6526\n",
      "Epoch 2928/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4433 - accuracy: 0.8617 - val_loss: 1.2788 - val_accuracy: 0.6526\n",
      "Epoch 2929/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4454 - accuracy: 0.8659 - val_loss: 1.3002 - val_accuracy: 0.6331\n",
      "Epoch 2930/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4653 - accuracy: 0.8477 - val_loss: 1.3437 - val_accuracy: 0.6234\n",
      "Epoch 2931/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3946 - accuracy: 0.8715 - val_loss: 1.3426 - val_accuracy: 0.6266\n",
      "Epoch 2932/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4327 - accuracy: 0.8631 - val_loss: 1.3210 - val_accuracy: 0.6331\n",
      "Epoch 2933/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4220 - accuracy: 0.8589 - val_loss: 1.2914 - val_accuracy: 0.6364\n",
      "Epoch 2934/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4020 - accuracy: 0.8757 - val_loss: 1.2588 - val_accuracy: 0.6494\n",
      "Epoch 2935/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4610 - accuracy: 0.8492 - val_loss: 1.2374 - val_accuracy: 0.6623\n",
      "Epoch 2936/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3835 - accuracy: 0.8883 - val_loss: 1.2259 - val_accuracy: 0.6623\n",
      "Epoch 2937/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3713 - accuracy: 0.8828 - val_loss: 1.2225 - val_accuracy: 0.6688\n",
      "Epoch 2938/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3706 - accuracy: 0.8789 - val_loss: 1.2157 - val_accuracy: 0.6786\n",
      "Epoch 2939/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4226 - accuracy: 0.8687 - val_loss: 1.2211 - val_accuracy: 0.6753\n",
      "Epoch 2940/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4271 - accuracy: 0.8645 - val_loss: 1.2280 - val_accuracy: 0.6753\n",
      "Epoch 2941/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4316 - accuracy: 0.8617 - val_loss: 1.2388 - val_accuracy: 0.6721\n",
      "Epoch 2942/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3902 - accuracy: 0.8730 - val_loss: 1.2464 - val_accuracy: 0.6656\n",
      "Epoch 2943/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4009 - accuracy: 0.8750 - val_loss: 1.2589 - val_accuracy: 0.6558\n",
      "Epoch 2944/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3830 - accuracy: 0.8682 - val_loss: 1.2773 - val_accuracy: 0.6558\n",
      "Epoch 2945/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3768 - accuracy: 0.8785 - val_loss: 1.2916 - val_accuracy: 0.6461\n",
      "Epoch 2946/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4086 - accuracy: 0.8729 - val_loss: 1.3047 - val_accuracy: 0.6396\n",
      "Epoch 2947/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4110 - accuracy: 0.8673 - val_loss: 1.3037 - val_accuracy: 0.6364\n",
      "Epoch 2948/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4480 - accuracy: 0.8506 - val_loss: 1.3046 - val_accuracy: 0.6396\n",
      "Epoch 2949/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4223 - accuracy: 0.8589 - val_loss: 1.3254 - val_accuracy: 0.6429\n",
      "Epoch 2950/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3826 - accuracy: 0.8673 - val_loss: 1.3252 - val_accuracy: 0.6429\n",
      "Epoch 2951/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3689 - accuracy: 0.8740 - val_loss: 1.3330 - val_accuracy: 0.6461\n",
      "Epoch 2952/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3998 - accuracy: 0.8771 - val_loss: 1.3261 - val_accuracy: 0.6396\n",
      "Epoch 2953/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4044 - accuracy: 0.8617 - val_loss: 1.3070 - val_accuracy: 0.6396\n",
      "Epoch 2954/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3997 - accuracy: 0.8729 - val_loss: 1.2889 - val_accuracy: 0.6526\n",
      "Epoch 2955/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4150 - accuracy: 0.8575 - val_loss: 1.2761 - val_accuracy: 0.6461\n",
      "Epoch 2956/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3929 - accuracy: 0.8617 - val_loss: 1.2728 - val_accuracy: 0.6591\n",
      "Epoch 2957/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4349 - accuracy: 0.8574 - val_loss: 1.2705 - val_accuracy: 0.6558\n",
      "Epoch 2958/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4342 - accuracy: 0.8715 - val_loss: 1.2734 - val_accuracy: 0.6558\n",
      "Epoch 2959/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3517 - accuracy: 0.8730 - val_loss: 1.2817 - val_accuracy: 0.6558\n",
      "Epoch 2960/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3832 - accuracy: 0.8711 - val_loss: 1.3060 - val_accuracy: 0.6461\n",
      "Epoch 2961/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4475 - accuracy: 0.8645 - val_loss: 1.3158 - val_accuracy: 0.6461\n",
      "Epoch 2962/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3601 - accuracy: 0.8896 - val_loss: 1.3269 - val_accuracy: 0.6526\n",
      "Epoch 2963/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3885 - accuracy: 0.8652 - val_loss: 1.3391 - val_accuracy: 0.6429\n",
      "Epoch 2964/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4113 - accuracy: 0.8633 - val_loss: 1.3455 - val_accuracy: 0.6429\n",
      "Epoch 2965/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4636 - accuracy: 0.8450 - val_loss: 1.3453 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2966/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4110 - accuracy: 0.8623 - val_loss: 1.3279 - val_accuracy: 0.6266\n",
      "Epoch 2967/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3519 - accuracy: 0.8827 - val_loss: 1.3105 - val_accuracy: 0.6331\n",
      "Epoch 2968/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3516 - accuracy: 0.8841 - val_loss: 1.3018 - val_accuracy: 0.6429\n",
      "Epoch 2969/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4041 - accuracy: 0.8743 - val_loss: 1.2862 - val_accuracy: 0.6591\n",
      "Epoch 2970/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4416 - accuracy: 0.8589 - val_loss: 1.2760 - val_accuracy: 0.6494\n",
      "Epoch 2971/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3694 - accuracy: 0.8701 - val_loss: 1.2634 - val_accuracy: 0.6656\n",
      "Epoch 2972/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4091 - accuracy: 0.8631 - val_loss: 1.2644 - val_accuracy: 0.6656\n",
      "Epoch 2973/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3955 - accuracy: 0.8623 - val_loss: 1.2739 - val_accuracy: 0.6656\n",
      "Epoch 2974/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4491 - accuracy: 0.8687 - val_loss: 1.2877 - val_accuracy: 0.6526\n",
      "Epoch 2975/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4014 - accuracy: 0.8682 - val_loss: 1.3155 - val_accuracy: 0.6591\n",
      "Epoch 2976/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3928 - accuracy: 0.8673 - val_loss: 1.3501 - val_accuracy: 0.6396\n",
      "Epoch 2977/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3723 - accuracy: 0.8828 - val_loss: 1.3870 - val_accuracy: 0.6364\n",
      "Epoch 2978/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4011 - accuracy: 0.8643 - val_loss: 1.4150 - val_accuracy: 0.6299\n",
      "Epoch 2979/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3825 - accuracy: 0.8779 - val_loss: 1.4320 - val_accuracy: 0.6396\n",
      "Epoch 2980/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4337 - accuracy: 0.8525 - val_loss: 1.4405 - val_accuracy: 0.6331\n",
      "Epoch 2981/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4330 - accuracy: 0.8574 - val_loss: 1.4386 - val_accuracy: 0.6169\n",
      "Epoch 2982/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3800 - accuracy: 0.8740 - val_loss: 1.4083 - val_accuracy: 0.6104\n",
      "Epoch 2983/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3999 - accuracy: 0.8729 - val_loss: 1.3698 - val_accuracy: 0.6071\n",
      "Epoch 2984/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4230 - accuracy: 0.8603 - val_loss: 1.3383 - val_accuracy: 0.6201\n",
      "Epoch 2985/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3824 - accuracy: 0.8855 - val_loss: 1.3115 - val_accuracy: 0.6266\n",
      "Epoch 2986/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3641 - accuracy: 0.8813 - val_loss: 1.2961 - val_accuracy: 0.6396\n",
      "Epoch 2987/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3512 - accuracy: 0.8828 - val_loss: 1.2890 - val_accuracy: 0.6558\n",
      "Epoch 2988/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3772 - accuracy: 0.8715 - val_loss: 1.2931 - val_accuracy: 0.6558\n",
      "Epoch 2989/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3804 - accuracy: 0.8584 - val_loss: 1.3040 - val_accuracy: 0.6429\n",
      "Epoch 2990/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3900 - accuracy: 0.8687 - val_loss: 1.3181 - val_accuracy: 0.6461\n",
      "Epoch 2991/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4626 - accuracy: 0.8506 - val_loss: 1.3105 - val_accuracy: 0.6364\n",
      "Epoch 2992/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4086 - accuracy: 0.8623 - val_loss: 1.3048 - val_accuracy: 0.6364\n",
      "Epoch 2993/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4171 - accuracy: 0.8691 - val_loss: 1.3159 - val_accuracy: 0.6266\n",
      "Epoch 2994/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3853 - accuracy: 0.8633 - val_loss: 1.3116 - val_accuracy: 0.6364\n",
      "Epoch 2995/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4059 - accuracy: 0.8547 - val_loss: 1.2946 - val_accuracy: 0.6623\n",
      "Epoch 2996/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3576 - accuracy: 0.8809 - val_loss: 1.2779 - val_accuracy: 0.6623\n",
      "Epoch 2997/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4187 - accuracy: 0.8561 - val_loss: 1.2677 - val_accuracy: 0.6786\n",
      "Epoch 2998/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3775 - accuracy: 0.8980 - val_loss: 1.2671 - val_accuracy: 0.6786\n",
      "Epoch 2999/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3802 - accuracy: 0.8789 - val_loss: 1.2722 - val_accuracy: 0.6623\n",
      "Epoch 3000/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3850 - accuracy: 0.8643 - val_loss: 1.2994 - val_accuracy: 0.6429\n",
      "Epoch 3001/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3419 - accuracy: 0.8857 - val_loss: 1.3464 - val_accuracy: 0.6461\n",
      "Epoch 3002/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3917 - accuracy: 0.8757 - val_loss: 1.3990 - val_accuracy: 0.6364\n",
      "Epoch 3003/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3466 - accuracy: 0.8799 - val_loss: 1.4336 - val_accuracy: 0.6201\n",
      "Epoch 3004/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4114 - accuracy: 0.8743 - val_loss: 1.4544 - val_accuracy: 0.6104\n",
      "Epoch 3005/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3629 - accuracy: 0.8916 - val_loss: 1.4653 - val_accuracy: 0.6071\n",
      "Epoch 3006/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4212 - accuracy: 0.8643 - val_loss: 1.4482 - val_accuracy: 0.6006\n",
      "Epoch 3007/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3524 - accuracy: 0.8877 - val_loss: 1.4132 - val_accuracy: 0.6136\n",
      "Epoch 3008/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3171 - accuracy: 0.8939 - val_loss: 1.3706 - val_accuracy: 0.6169\n",
      "Epoch 3009/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4320 - accuracy: 0.8687 - val_loss: 1.3281 - val_accuracy: 0.6299\n",
      "Epoch 3010/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4262 - accuracy: 0.8682 - val_loss: 1.3133 - val_accuracy: 0.6591\n",
      "Epoch 3011/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3548 - accuracy: 0.8841 - val_loss: 1.3071 - val_accuracy: 0.6656\n",
      "Epoch 3012/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4037 - accuracy: 0.8645 - val_loss: 1.3036 - val_accuracy: 0.6494\n",
      "Epoch 3013/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3305 - accuracy: 0.8925 - val_loss: 1.3003 - val_accuracy: 0.6526\n",
      "Epoch 3014/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3551 - accuracy: 0.8779 - val_loss: 1.2941 - val_accuracy: 0.6753\n",
      "Epoch 3015/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4106 - accuracy: 0.8662 - val_loss: 1.2932 - val_accuracy: 0.6656\n",
      "Epoch 3016/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3924 - accuracy: 0.8750 - val_loss: 1.2893 - val_accuracy: 0.6721\n",
      "Epoch 3017/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3635 - accuracy: 0.8687 - val_loss: 1.2947 - val_accuracy: 0.6591\n",
      "Epoch 3018/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4068 - accuracy: 0.8687 - val_loss: 1.3214 - val_accuracy: 0.6591\n",
      "Epoch 3019/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3685 - accuracy: 0.8721 - val_loss: 1.3520 - val_accuracy: 0.6494\n",
      "Epoch 3020/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4139 - accuracy: 0.8659 - val_loss: 1.3762 - val_accuracy: 0.6201\n",
      "Epoch 3021/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3765 - accuracy: 0.8673 - val_loss: 1.4243 - val_accuracy: 0.6169\n",
      "Epoch 3022/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4191 - accuracy: 0.8506 - val_loss: 1.4736 - val_accuracy: 0.5909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3023/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4645 - accuracy: 0.8477 - val_loss: 1.5167 - val_accuracy: 0.5877\n",
      "Epoch 3024/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3779 - accuracy: 0.8730 - val_loss: 1.5251 - val_accuracy: 0.5779\n",
      "Epoch 3025/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3795 - accuracy: 0.8631 - val_loss: 1.5139 - val_accuracy: 0.5747\n",
      "Epoch 3026/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4142 - accuracy: 0.8643 - val_loss: 1.4867 - val_accuracy: 0.5812\n",
      "Epoch 3027/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4829 - accuracy: 0.8506 - val_loss: 1.4425 - val_accuracy: 0.5877\n",
      "Epoch 3028/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4304 - accuracy: 0.8631 - val_loss: 1.4085 - val_accuracy: 0.5974\n",
      "Epoch 3029/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3466 - accuracy: 0.8869 - val_loss: 1.3721 - val_accuracy: 0.6169\n",
      "Epoch 3030/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3868 - accuracy: 0.8760 - val_loss: 1.3571 - val_accuracy: 0.6201\n",
      "Epoch 3031/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4114 - accuracy: 0.8687 - val_loss: 1.3582 - val_accuracy: 0.6136\n",
      "Epoch 3032/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3496 - accuracy: 0.8809 - val_loss: 1.3923 - val_accuracy: 0.5974\n",
      "Epoch 3033/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3588 - accuracy: 0.8838 - val_loss: 1.4239 - val_accuracy: 0.5909\n",
      "Epoch 3034/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4419 - accuracy: 0.8574 - val_loss: 1.4626 - val_accuracy: 0.5877\n",
      "Epoch 3035/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3549 - accuracy: 0.8867 - val_loss: 1.5141 - val_accuracy: 0.5779\n",
      "Epoch 3036/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4025 - accuracy: 0.8687 - val_loss: 1.5719 - val_accuracy: 0.5649\n",
      "Epoch 3037/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3937 - accuracy: 0.8659 - val_loss: 1.5934 - val_accuracy: 0.5584\n",
      "Epoch 3038/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3674 - accuracy: 0.8771 - val_loss: 1.6017 - val_accuracy: 0.5487\n",
      "Epoch 3039/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3840 - accuracy: 0.8779 - val_loss: 1.5521 - val_accuracy: 0.5682\n",
      "Epoch 3040/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3439 - accuracy: 0.8896 - val_loss: 1.4813 - val_accuracy: 0.5909\n",
      "Epoch 3041/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3503 - accuracy: 0.8911 - val_loss: 1.4105 - val_accuracy: 0.6104\n",
      "Epoch 3042/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3657 - accuracy: 0.8867 - val_loss: 1.3328 - val_accuracy: 0.6396\n",
      "Epoch 3043/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3652 - accuracy: 0.8869 - val_loss: 1.2804 - val_accuracy: 0.6558\n",
      "Epoch 3044/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4067 - accuracy: 0.8643 - val_loss: 1.2381 - val_accuracy: 0.6688\n",
      "Epoch 3045/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3950 - accuracy: 0.8760 - val_loss: 1.2207 - val_accuracy: 0.6656\n",
      "Epoch 3046/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4868 - accuracy: 0.8506 - val_loss: 1.2155 - val_accuracy: 0.6623\n",
      "Epoch 3047/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3466 - accuracy: 0.8687 - val_loss: 1.2154 - val_accuracy: 0.6721\n",
      "Epoch 3048/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3733 - accuracy: 0.8701 - val_loss: 1.2144 - val_accuracy: 0.6688\n",
      "Epoch 3049/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3682 - accuracy: 0.8813 - val_loss: 1.2259 - val_accuracy: 0.6623\n",
      "Epoch 3050/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3584 - accuracy: 0.8869 - val_loss: 1.2422 - val_accuracy: 0.6558\n",
      "Epoch 3051/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4055 - accuracy: 0.8604 - val_loss: 1.2572 - val_accuracy: 0.6396\n",
      "Epoch 3052/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4064 - accuracy: 0.8799 - val_loss: 1.2747 - val_accuracy: 0.6429\n",
      "Epoch 3053/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3962 - accuracy: 0.8760 - val_loss: 1.3164 - val_accuracy: 0.6396\n",
      "Epoch 3054/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3701 - accuracy: 0.8682 - val_loss: 1.3491 - val_accuracy: 0.6234\n",
      "Epoch 3055/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4202 - accuracy: 0.8617 - val_loss: 1.3497 - val_accuracy: 0.6136\n",
      "Epoch 3056/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4088 - accuracy: 0.8652 - val_loss: 1.3502 - val_accuracy: 0.6201\n",
      "Epoch 3057/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3863 - accuracy: 0.8771 - val_loss: 1.3393 - val_accuracy: 0.6169\n",
      "Epoch 3058/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3507 - accuracy: 0.8813 - val_loss: 1.3331 - val_accuracy: 0.6234\n",
      "Epoch 3059/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3448 - accuracy: 0.8841 - val_loss: 1.3295 - val_accuracy: 0.6299\n",
      "Epoch 3060/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3838 - accuracy: 0.8813 - val_loss: 1.3205 - val_accuracy: 0.6364\n",
      "Epoch 3061/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3993 - accuracy: 0.8813 - val_loss: 1.3327 - val_accuracy: 0.6364\n",
      "Epoch 3062/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4079 - accuracy: 0.8757 - val_loss: 1.3821 - val_accuracy: 0.6234\n",
      "Epoch 3063/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3804 - accuracy: 0.8887 - val_loss: 1.4438 - val_accuracy: 0.6071\n",
      "Epoch 3064/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3619 - accuracy: 0.8809 - val_loss: 1.5164 - val_accuracy: 0.5942\n",
      "Epoch 3065/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4216 - accuracy: 0.8589 - val_loss: 1.6022 - val_accuracy: 0.5844\n",
      "Epoch 3066/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3769 - accuracy: 0.8818 - val_loss: 1.6926 - val_accuracy: 0.5682\n",
      "Epoch 3067/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3966 - accuracy: 0.8721 - val_loss: 1.7337 - val_accuracy: 0.5714\n",
      "Epoch 3068/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3846 - accuracy: 0.8740 - val_loss: 1.7359 - val_accuracy: 0.5747\n",
      "Epoch 3069/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3896 - accuracy: 0.8743 - val_loss: 1.6865 - val_accuracy: 0.5812\n",
      "Epoch 3070/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4045 - accuracy: 0.8534 - val_loss: 1.5789 - val_accuracy: 0.5974\n",
      "Epoch 3071/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3780 - accuracy: 0.8779 - val_loss: 1.4904 - val_accuracy: 0.6006\n",
      "Epoch 3072/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3721 - accuracy: 0.8715 - val_loss: 1.4252 - val_accuracy: 0.6104\n",
      "Epoch 3073/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4152 - accuracy: 0.8672 - val_loss: 1.3850 - val_accuracy: 0.6039\n",
      "Epoch 3074/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3990 - accuracy: 0.8743 - val_loss: 1.3704 - val_accuracy: 0.6071\n",
      "Epoch 3075/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3958 - accuracy: 0.8672 - val_loss: 1.3570 - val_accuracy: 0.6266\n",
      "Epoch 3076/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3899 - accuracy: 0.8750 - val_loss: 1.3531 - val_accuracy: 0.6364\n",
      "Epoch 3077/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3941 - accuracy: 0.8789 - val_loss: 1.3660 - val_accuracy: 0.6364\n",
      "Epoch 3078/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3557 - accuracy: 0.8838 - val_loss: 1.3774 - val_accuracy: 0.6396\n",
      "Epoch 3079/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3878 - accuracy: 0.8711 - val_loss: 1.4037 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3080/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3447 - accuracy: 0.8877 - val_loss: 1.4214 - val_accuracy: 0.6331\n",
      "Epoch 3081/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4036 - accuracy: 0.8631 - val_loss: 1.4438 - val_accuracy: 0.6201\n",
      "Epoch 3082/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3864 - accuracy: 0.8771 - val_loss: 1.4694 - val_accuracy: 0.6039\n",
      "Epoch 3083/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3994 - accuracy: 0.8659 - val_loss: 1.4803 - val_accuracy: 0.5974\n",
      "Epoch 3084/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3989 - accuracy: 0.8729 - val_loss: 1.4888 - val_accuracy: 0.6039\n",
      "Epoch 3085/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4013 - accuracy: 0.8633 - val_loss: 1.4807 - val_accuracy: 0.6039\n",
      "Epoch 3086/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4238 - accuracy: 0.8701 - val_loss: 1.4588 - val_accuracy: 0.5974\n",
      "Epoch 3087/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4632 - accuracy: 0.8436 - val_loss: 1.4497 - val_accuracy: 0.6104\n",
      "Epoch 3088/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3976 - accuracy: 0.8740 - val_loss: 1.4416 - val_accuracy: 0.6234\n",
      "Epoch 3089/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4026 - accuracy: 0.8673 - val_loss: 1.4164 - val_accuracy: 0.6396\n",
      "Epoch 3090/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4030 - accuracy: 0.8771 - val_loss: 1.3884 - val_accuracy: 0.6526\n",
      "Epoch 3091/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3613 - accuracy: 0.8841 - val_loss: 1.3653 - val_accuracy: 0.6558\n",
      "Epoch 3092/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3829 - accuracy: 0.8701 - val_loss: 1.3373 - val_accuracy: 0.6526\n",
      "Epoch 3093/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4091 - accuracy: 0.8631 - val_loss: 1.3149 - val_accuracy: 0.6688\n",
      "Epoch 3094/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4441 - accuracy: 0.8631 - val_loss: 1.3041 - val_accuracy: 0.6656\n",
      "Epoch 3095/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3826 - accuracy: 0.8672 - val_loss: 1.2908 - val_accuracy: 0.6656\n",
      "Epoch 3096/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3307 - accuracy: 0.8869 - val_loss: 1.2965 - val_accuracy: 0.6688\n",
      "Epoch 3097/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3654 - accuracy: 0.8779 - val_loss: 1.2997 - val_accuracy: 0.6721\n",
      "Epoch 3098/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3888 - accuracy: 0.8730 - val_loss: 1.3007 - val_accuracy: 0.6688\n",
      "Epoch 3099/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3817 - accuracy: 0.8701 - val_loss: 1.2981 - val_accuracy: 0.6591\n",
      "Epoch 3100/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3551 - accuracy: 0.8869 - val_loss: 1.2981 - val_accuracy: 0.6526\n",
      "Epoch 3101/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3854 - accuracy: 0.8701 - val_loss: 1.2793 - val_accuracy: 0.6461\n",
      "Epoch 3102/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3056 - accuracy: 0.8925 - val_loss: 1.2654 - val_accuracy: 0.6558\n",
      "Epoch 3103/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3191 - accuracy: 0.8925 - val_loss: 1.2618 - val_accuracy: 0.6558\n",
      "Epoch 3104/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3334 - accuracy: 0.8925 - val_loss: 1.2648 - val_accuracy: 0.6656\n",
      "Epoch 3105/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4216 - accuracy: 0.8729 - val_loss: 1.2662 - val_accuracy: 0.6558\n",
      "Epoch 3106/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3879 - accuracy: 0.8673 - val_loss: 1.2714 - val_accuracy: 0.6591\n",
      "Epoch 3107/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4161 - accuracy: 0.8617 - val_loss: 1.2822 - val_accuracy: 0.6623\n",
      "Epoch 3108/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3572 - accuracy: 0.8848 - val_loss: 1.2977 - val_accuracy: 0.6656\n",
      "Epoch 3109/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3055 - accuracy: 0.8994 - val_loss: 1.3033 - val_accuracy: 0.6623\n",
      "Epoch 3110/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3562 - accuracy: 0.8841 - val_loss: 1.3081 - val_accuracy: 0.6623\n",
      "Epoch 3111/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3915 - accuracy: 0.8779 - val_loss: 1.3104 - val_accuracy: 0.6721\n",
      "Epoch 3112/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3507 - accuracy: 0.8965 - val_loss: 1.3098 - val_accuracy: 0.6688\n",
      "Epoch 3113/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3980 - accuracy: 0.8701 - val_loss: 1.3160 - val_accuracy: 0.6591\n",
      "Epoch 3114/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3566 - accuracy: 0.8785 - val_loss: 1.3326 - val_accuracy: 0.6526\n",
      "Epoch 3115/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3626 - accuracy: 0.8779 - val_loss: 1.3500 - val_accuracy: 0.6461\n",
      "Epoch 3116/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4270 - accuracy: 0.8603 - val_loss: 1.3437 - val_accuracy: 0.6494\n",
      "Epoch 3117/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3909 - accuracy: 0.8520 - val_loss: 1.3362 - val_accuracy: 0.6396\n",
      "Epoch 3118/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3217 - accuracy: 0.8916 - val_loss: 1.3304 - val_accuracy: 0.6429\n",
      "Epoch 3119/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3639 - accuracy: 0.8818 - val_loss: 1.3227 - val_accuracy: 0.6461\n",
      "Epoch 3120/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4323 - accuracy: 0.8589 - val_loss: 1.3159 - val_accuracy: 0.6429\n",
      "Epoch 3121/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4179 - accuracy: 0.8617 - val_loss: 1.3175 - val_accuracy: 0.6591\n",
      "Epoch 3122/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3259 - accuracy: 0.8916 - val_loss: 1.3214 - val_accuracy: 0.6558\n",
      "Epoch 3123/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3400 - accuracy: 0.8841 - val_loss: 1.3280 - val_accuracy: 0.6558\n",
      "Epoch 3124/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3938 - accuracy: 0.8659 - val_loss: 1.3289 - val_accuracy: 0.6591\n",
      "Epoch 3125/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4044 - accuracy: 0.8701 - val_loss: 1.3233 - val_accuracy: 0.6591\n",
      "Epoch 3126/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4146 - accuracy: 0.8813 - val_loss: 1.3206 - val_accuracy: 0.6623\n",
      "Epoch 3127/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3495 - accuracy: 0.8883 - val_loss: 1.3189 - val_accuracy: 0.6623\n",
      "Epoch 3128/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3856 - accuracy: 0.8813 - val_loss: 1.3235 - val_accuracy: 0.6526\n",
      "Epoch 3129/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3782 - accuracy: 0.8715 - val_loss: 1.3307 - val_accuracy: 0.6461\n",
      "Epoch 3130/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3331 - accuracy: 0.8955 - val_loss: 1.3729 - val_accuracy: 0.6396\n",
      "Epoch 3131/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4004 - accuracy: 0.8785 - val_loss: 1.4216 - val_accuracy: 0.6104\n",
      "Epoch 3132/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3786 - accuracy: 0.8770 - val_loss: 1.4629 - val_accuracy: 0.6039\n",
      "Epoch 3133/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4080 - accuracy: 0.8673 - val_loss: 1.5047 - val_accuracy: 0.5877\n",
      "Epoch 3134/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4055 - accuracy: 0.8691 - val_loss: 1.5124 - val_accuracy: 0.5812\n",
      "Epoch 3135/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3829 - accuracy: 0.8813 - val_loss: 1.4910 - val_accuracy: 0.5877\n",
      "Epoch 3136/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4083 - accuracy: 0.8701 - val_loss: 1.4573 - val_accuracy: 0.5877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3137/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4130 - accuracy: 0.8730 - val_loss: 1.3968 - val_accuracy: 0.6039\n",
      "Epoch 3138/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4101 - accuracy: 0.8645 - val_loss: 1.3443 - val_accuracy: 0.6331\n",
      "Epoch 3139/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3759 - accuracy: 0.8841 - val_loss: 1.3137 - val_accuracy: 0.6494\n",
      "Epoch 3140/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3953 - accuracy: 0.8730 - val_loss: 1.3006 - val_accuracy: 0.6494\n",
      "Epoch 3141/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4191 - accuracy: 0.8659 - val_loss: 1.3008 - val_accuracy: 0.6591\n",
      "Epoch 3142/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3900 - accuracy: 0.8691 - val_loss: 1.2969 - val_accuracy: 0.6656\n",
      "Epoch 3143/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3651 - accuracy: 0.8906 - val_loss: 1.2839 - val_accuracy: 0.6656\n",
      "Epoch 3144/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3543 - accuracy: 0.8757 - val_loss: 1.2690 - val_accuracy: 0.6591\n",
      "Epoch 3145/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4051 - accuracy: 0.8613 - val_loss: 1.2590 - val_accuracy: 0.6494\n",
      "Epoch 3146/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4062 - accuracy: 0.8617 - val_loss: 1.2545 - val_accuracy: 0.6688\n",
      "Epoch 3147/4000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3589 - accuracy: 0.8838 - val_loss: 1.2526 - val_accuracy: 0.6721\n",
      "Epoch 3148/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3632 - accuracy: 0.8617 - val_loss: 1.2588 - val_accuracy: 0.6721\n",
      "Epoch 3149/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3474 - accuracy: 0.8945 - val_loss: 1.2671 - val_accuracy: 0.6688\n",
      "Epoch 3150/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3965 - accuracy: 0.8771 - val_loss: 1.2586 - val_accuracy: 0.6623\n",
      "Epoch 3151/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3653 - accuracy: 0.8730 - val_loss: 1.2570 - val_accuracy: 0.6656\n",
      "Epoch 3152/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4169 - accuracy: 0.8662 - val_loss: 1.2590 - val_accuracy: 0.6558\n",
      "Epoch 3153/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3662 - accuracy: 0.8867 - val_loss: 1.2558 - val_accuracy: 0.6558\n",
      "Epoch 3154/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3255 - accuracy: 0.8953 - val_loss: 1.2486 - val_accuracy: 0.6494\n",
      "Epoch 3155/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3735 - accuracy: 0.8757 - val_loss: 1.2504 - val_accuracy: 0.6526\n",
      "Epoch 3156/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3994 - accuracy: 0.8662 - val_loss: 1.2521 - val_accuracy: 0.6591\n",
      "Epoch 3157/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3657 - accuracy: 0.8857 - val_loss: 1.2589 - val_accuracy: 0.6558\n",
      "Epoch 3158/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3694 - accuracy: 0.8672 - val_loss: 1.2703 - val_accuracy: 0.6558\n",
      "Epoch 3159/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4053 - accuracy: 0.8789 - val_loss: 1.2858 - val_accuracy: 0.6461\n",
      "Epoch 3160/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3589 - accuracy: 0.8799 - val_loss: 1.3050 - val_accuracy: 0.6526\n",
      "Epoch 3161/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3832 - accuracy: 0.8721 - val_loss: 1.3195 - val_accuracy: 0.6461\n",
      "Epoch 3162/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3655 - accuracy: 0.8785 - val_loss: 1.3210 - val_accuracy: 0.6623\n",
      "Epoch 3163/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3801 - accuracy: 0.8701 - val_loss: 1.3246 - val_accuracy: 0.6526\n",
      "Epoch 3164/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4168 - accuracy: 0.8687 - val_loss: 1.3315 - val_accuracy: 0.6429\n",
      "Epoch 3165/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3701 - accuracy: 0.8827 - val_loss: 1.3339 - val_accuracy: 0.6331\n",
      "Epoch 3166/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3801 - accuracy: 0.8750 - val_loss: 1.3422 - val_accuracy: 0.6364\n",
      "Epoch 3167/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3925 - accuracy: 0.8715 - val_loss: 1.3538 - val_accuracy: 0.6299\n",
      "Epoch 3168/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3642 - accuracy: 0.8789 - val_loss: 1.3553 - val_accuracy: 0.6201\n",
      "Epoch 3169/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4339 - accuracy: 0.8574 - val_loss: 1.3524 - val_accuracy: 0.6006\n",
      "Epoch 3170/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4253 - accuracy: 0.8574 - val_loss: 1.3503 - val_accuracy: 0.6104\n",
      "Epoch 3171/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3875 - accuracy: 0.8729 - val_loss: 1.3410 - val_accuracy: 0.6266\n",
      "Epoch 3172/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3790 - accuracy: 0.8743 - val_loss: 1.3312 - val_accuracy: 0.6234\n",
      "Epoch 3173/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3843 - accuracy: 0.8757 - val_loss: 1.3159 - val_accuracy: 0.6266\n",
      "Epoch 3174/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3519 - accuracy: 0.8857 - val_loss: 1.2951 - val_accuracy: 0.6364\n",
      "Epoch 3175/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3806 - accuracy: 0.8785 - val_loss: 1.2879 - val_accuracy: 0.6266\n",
      "Epoch 3176/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3806 - accuracy: 0.8809 - val_loss: 1.2942 - val_accuracy: 0.6396\n",
      "Epoch 3177/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3494 - accuracy: 0.8785 - val_loss: 1.3080 - val_accuracy: 0.6396\n",
      "Epoch 3178/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3888 - accuracy: 0.8645 - val_loss: 1.3166 - val_accuracy: 0.6461\n",
      "Epoch 3179/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3803 - accuracy: 0.8673 - val_loss: 1.3220 - val_accuracy: 0.6299\n",
      "Epoch 3180/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4267 - accuracy: 0.8673 - val_loss: 1.3314 - val_accuracy: 0.6331\n",
      "Epoch 3181/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3626 - accuracy: 0.8813 - val_loss: 1.3395 - val_accuracy: 0.6331\n",
      "Epoch 3182/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2939 - accuracy: 0.9050 - val_loss: 1.3462 - val_accuracy: 0.6396\n",
      "Epoch 3183/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4042 - accuracy: 0.8682 - val_loss: 1.3353 - val_accuracy: 0.6429\n",
      "Epoch 3184/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3857 - accuracy: 0.8730 - val_loss: 1.3096 - val_accuracy: 0.6461\n",
      "Epoch 3185/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3651 - accuracy: 0.8779 - val_loss: 1.2824 - val_accuracy: 0.6526\n",
      "Epoch 3186/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4119 - accuracy: 0.8760 - val_loss: 1.2652 - val_accuracy: 0.6591\n",
      "Epoch 3187/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3943 - accuracy: 0.8506 - val_loss: 1.2477 - val_accuracy: 0.6656\n",
      "Epoch 3188/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3418 - accuracy: 0.8855 - val_loss: 1.2438 - val_accuracy: 0.6721\n",
      "Epoch 3189/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4199 - accuracy: 0.8603 - val_loss: 1.2574 - val_accuracy: 0.6753\n",
      "Epoch 3190/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4399 - accuracy: 0.8645 - val_loss: 1.2556 - val_accuracy: 0.6753\n",
      "Epoch 3191/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3818 - accuracy: 0.8897 - val_loss: 1.2486 - val_accuracy: 0.6753\n",
      "Epoch 3192/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4048 - accuracy: 0.8561 - val_loss: 1.2381 - val_accuracy: 0.6818\n",
      "Epoch 3193/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3902 - accuracy: 0.8771 - val_loss: 1.2338 - val_accuracy: 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3194/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3880 - accuracy: 0.8687 - val_loss: 1.2385 - val_accuracy: 0.6656\n",
      "Epoch 3195/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3722 - accuracy: 0.8857 - val_loss: 1.2492 - val_accuracy: 0.6656\n",
      "Epoch 3196/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3688 - accuracy: 0.8771 - val_loss: 1.2575 - val_accuracy: 0.6688\n",
      "Epoch 3197/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3867 - accuracy: 0.8757 - val_loss: 1.2396 - val_accuracy: 0.6753\n",
      "Epoch 3198/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3212 - accuracy: 0.9022 - val_loss: 1.2214 - val_accuracy: 0.6786\n",
      "Epoch 3199/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3929 - accuracy: 0.8721 - val_loss: 1.2139 - val_accuracy: 0.6721\n",
      "Epoch 3200/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3487 - accuracy: 0.8896 - val_loss: 1.2130 - val_accuracy: 0.6688\n",
      "Epoch 3201/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3477 - accuracy: 0.8828 - val_loss: 1.2165 - val_accuracy: 0.6721\n",
      "Epoch 3202/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3985 - accuracy: 0.8701 - val_loss: 1.2199 - val_accuracy: 0.6688\n",
      "Epoch 3203/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3244 - accuracy: 0.8966 - val_loss: 1.2228 - val_accuracy: 0.6688\n",
      "Epoch 3204/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3791 - accuracy: 0.8687 - val_loss: 1.2242 - val_accuracy: 0.6656\n",
      "Epoch 3205/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4342 - accuracy: 0.8673 - val_loss: 1.2256 - val_accuracy: 0.6591\n",
      "Epoch 3206/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3992 - accuracy: 0.8757 - val_loss: 1.2187 - val_accuracy: 0.6558\n",
      "Epoch 3207/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3684 - accuracy: 0.8818 - val_loss: 1.2133 - val_accuracy: 0.6558\n",
      "Epoch 3208/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3900 - accuracy: 0.8789 - val_loss: 1.2128 - val_accuracy: 0.6558\n",
      "Epoch 3209/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3448 - accuracy: 0.8883 - val_loss: 1.2201 - val_accuracy: 0.6526\n",
      "Epoch 3210/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3726 - accuracy: 0.8799 - val_loss: 1.2252 - val_accuracy: 0.6494\n",
      "Epoch 3211/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3786 - accuracy: 0.8682 - val_loss: 1.2306 - val_accuracy: 0.6558\n",
      "Epoch 3212/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3624 - accuracy: 0.8730 - val_loss: 1.2412 - val_accuracy: 0.6623\n",
      "Epoch 3213/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3416 - accuracy: 0.8955 - val_loss: 1.2543 - val_accuracy: 0.6558\n",
      "Epoch 3214/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3518 - accuracy: 0.8828 - val_loss: 1.2581 - val_accuracy: 0.6429\n",
      "Epoch 3215/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3391 - accuracy: 0.8841 - val_loss: 1.2584 - val_accuracy: 0.6558\n",
      "Epoch 3216/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3751 - accuracy: 0.8730 - val_loss: 1.2674 - val_accuracy: 0.6558\n",
      "Epoch 3217/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3188 - accuracy: 0.8855 - val_loss: 1.2739 - val_accuracy: 0.6591\n",
      "Epoch 3218/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3964 - accuracy: 0.8740 - val_loss: 1.2818 - val_accuracy: 0.6558\n",
      "Epoch 3219/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3635 - accuracy: 0.8770 - val_loss: 1.2884 - val_accuracy: 0.6558\n",
      "Epoch 3220/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4151 - accuracy: 0.8740 - val_loss: 1.2899 - val_accuracy: 0.6591\n",
      "Epoch 3221/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4144 - accuracy: 0.8584 - val_loss: 1.2932 - val_accuracy: 0.6688\n",
      "Epoch 3222/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4222 - accuracy: 0.8643 - val_loss: 1.2916 - val_accuracy: 0.6656\n",
      "Epoch 3223/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3480 - accuracy: 0.9050 - val_loss: 1.3003 - val_accuracy: 0.6558\n",
      "Epoch 3224/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4226 - accuracy: 0.8682 - val_loss: 1.3099 - val_accuracy: 0.6494\n",
      "Epoch 3225/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3813 - accuracy: 0.8828 - val_loss: 1.3193 - val_accuracy: 0.6494\n",
      "Epoch 3226/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3436 - accuracy: 0.8813 - val_loss: 1.3291 - val_accuracy: 0.6494\n",
      "Epoch 3227/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4018 - accuracy: 0.8631 - val_loss: 1.3398 - val_accuracy: 0.6623\n",
      "Epoch 3228/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3468 - accuracy: 0.8936 - val_loss: 1.3453 - val_accuracy: 0.6494\n",
      "Epoch 3229/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3757 - accuracy: 0.8770 - val_loss: 1.3515 - val_accuracy: 0.6558\n",
      "Epoch 3230/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4255 - accuracy: 0.8652 - val_loss: 1.3576 - val_accuracy: 0.6558\n",
      "Epoch 3231/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3892 - accuracy: 0.8740 - val_loss: 1.3683 - val_accuracy: 0.6461\n",
      "Epoch 3232/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3314 - accuracy: 0.8789 - val_loss: 1.3739 - val_accuracy: 0.6461\n",
      "Epoch 3233/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3209 - accuracy: 0.8945 - val_loss: 1.3806 - val_accuracy: 0.6429\n",
      "Epoch 3234/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3713 - accuracy: 0.8701 - val_loss: 1.3836 - val_accuracy: 0.6396\n",
      "Epoch 3235/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3206 - accuracy: 0.8877 - val_loss: 1.3902 - val_accuracy: 0.6396\n",
      "Epoch 3236/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3179 - accuracy: 0.8896 - val_loss: 1.3997 - val_accuracy: 0.6331\n",
      "Epoch 3237/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3465 - accuracy: 0.8911 - val_loss: 1.4065 - val_accuracy: 0.6299\n",
      "Epoch 3238/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3331 - accuracy: 0.8906 - val_loss: 1.4094 - val_accuracy: 0.6169\n",
      "Epoch 3239/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3848 - accuracy: 0.8750 - val_loss: 1.4087 - val_accuracy: 0.6104\n",
      "Epoch 3240/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3275 - accuracy: 0.8743 - val_loss: 1.3968 - val_accuracy: 0.6169\n",
      "Epoch 3241/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3831 - accuracy: 0.8827 - val_loss: 1.3855 - val_accuracy: 0.6136\n",
      "Epoch 3242/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3559 - accuracy: 0.8945 - val_loss: 1.3775 - val_accuracy: 0.6266\n",
      "Epoch 3243/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4081 - accuracy: 0.8760 - val_loss: 1.3740 - val_accuracy: 0.6364\n",
      "Epoch 3244/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4028 - accuracy: 0.8779 - val_loss: 1.3718 - val_accuracy: 0.6364\n",
      "Epoch 3245/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3396 - accuracy: 0.9008 - val_loss: 1.3750 - val_accuracy: 0.6331\n",
      "Epoch 3246/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3547 - accuracy: 0.8867 - val_loss: 1.3736 - val_accuracy: 0.6364\n",
      "Epoch 3247/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3404 - accuracy: 0.8857 - val_loss: 1.3538 - val_accuracy: 0.6429\n",
      "Epoch 3248/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3627 - accuracy: 0.8729 - val_loss: 1.3297 - val_accuracy: 0.6526\n",
      "Epoch 3249/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3672 - accuracy: 0.8770 - val_loss: 1.3145 - val_accuracy: 0.6461\n",
      "Epoch 3250/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4184 - accuracy: 0.8645 - val_loss: 1.2977 - val_accuracy: 0.6558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3251/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3023 - accuracy: 0.8955 - val_loss: 1.2896 - val_accuracy: 0.6656\n",
      "Epoch 3252/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3396 - accuracy: 0.8945 - val_loss: 1.2794 - val_accuracy: 0.6753\n",
      "Epoch 3253/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2475 - accuracy: 0.9162 - val_loss: 1.2735 - val_accuracy: 0.6818\n",
      "Epoch 3254/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3586 - accuracy: 0.8841 - val_loss: 1.2826 - val_accuracy: 0.6656\n",
      "Epoch 3255/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4156 - accuracy: 0.8645 - val_loss: 1.2955 - val_accuracy: 0.6494\n",
      "Epoch 3256/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3562 - accuracy: 0.8848 - val_loss: 1.3287 - val_accuracy: 0.6331\n",
      "Epoch 3257/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4006 - accuracy: 0.8750 - val_loss: 1.3619 - val_accuracy: 0.6136\n",
      "Epoch 3258/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3551 - accuracy: 0.8799 - val_loss: 1.3838 - val_accuracy: 0.6136\n",
      "Epoch 3259/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3447 - accuracy: 0.8936 - val_loss: 1.3985 - val_accuracy: 0.6071\n",
      "Epoch 3260/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3701 - accuracy: 0.8813 - val_loss: 1.4017 - val_accuracy: 0.6104\n",
      "Epoch 3261/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3962 - accuracy: 0.8869 - val_loss: 1.3965 - val_accuracy: 0.6104\n",
      "Epoch 3262/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3734 - accuracy: 0.8813 - val_loss: 1.3630 - val_accuracy: 0.6201\n",
      "Epoch 3263/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3379 - accuracy: 0.8770 - val_loss: 1.3327 - val_accuracy: 0.6039\n",
      "Epoch 3264/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3495 - accuracy: 0.8877 - val_loss: 1.3215 - val_accuracy: 0.6104\n",
      "Epoch 3265/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3881 - accuracy: 0.8673 - val_loss: 1.3190 - val_accuracy: 0.6169\n",
      "Epoch 3266/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3816 - accuracy: 0.8743 - val_loss: 1.3249 - val_accuracy: 0.6136\n",
      "Epoch 3267/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3734 - accuracy: 0.8743 - val_loss: 1.3369 - val_accuracy: 0.6104\n",
      "Epoch 3268/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3294 - accuracy: 0.8883 - val_loss: 1.3720 - val_accuracy: 0.6071\n",
      "Epoch 3269/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4105 - accuracy: 0.8770 - val_loss: 1.4287 - val_accuracy: 0.6039\n",
      "Epoch 3270/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3673 - accuracy: 0.8682 - val_loss: 1.4812 - val_accuracy: 0.5909\n",
      "Epoch 3271/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3420 - accuracy: 0.8906 - val_loss: 1.5179 - val_accuracy: 0.5877\n",
      "Epoch 3272/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3576 - accuracy: 0.8911 - val_loss: 1.5244 - val_accuracy: 0.5844\n",
      "Epoch 3273/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4256 - accuracy: 0.8631 - val_loss: 1.5249 - val_accuracy: 0.5747\n",
      "Epoch 3274/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3581 - accuracy: 0.8906 - val_loss: 1.4964 - val_accuracy: 0.6006\n",
      "Epoch 3275/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3675 - accuracy: 0.8799 - val_loss: 1.4719 - val_accuracy: 0.6039\n",
      "Epoch 3276/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4095 - accuracy: 0.8534 - val_loss: 1.4782 - val_accuracy: 0.5942\n",
      "Epoch 3277/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3075 - accuracy: 0.8877 - val_loss: 1.4748 - val_accuracy: 0.5844\n",
      "Epoch 3278/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3735 - accuracy: 0.8877 - val_loss: 1.4640 - val_accuracy: 0.5909\n",
      "Epoch 3279/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3848 - accuracy: 0.8799 - val_loss: 1.4565 - val_accuracy: 0.6104\n",
      "Epoch 3280/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3055 - accuracy: 0.9148 - val_loss: 1.4772 - val_accuracy: 0.6039\n",
      "Epoch 3281/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3506 - accuracy: 0.8925 - val_loss: 1.4838 - val_accuracy: 0.6104\n",
      "Epoch 3282/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3562 - accuracy: 0.8848 - val_loss: 1.4979 - val_accuracy: 0.6039\n",
      "Epoch 3283/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3442 - accuracy: 0.8838 - val_loss: 1.5118 - val_accuracy: 0.6071\n",
      "Epoch 3284/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3828 - accuracy: 0.8729 - val_loss: 1.5260 - val_accuracy: 0.6071\n",
      "Epoch 3285/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3700 - accuracy: 0.8691 - val_loss: 1.5400 - val_accuracy: 0.6006\n",
      "Epoch 3286/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3847 - accuracy: 0.8799 - val_loss: 1.5692 - val_accuracy: 0.5942\n",
      "Epoch 3287/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3434 - accuracy: 0.8827 - val_loss: 1.5943 - val_accuracy: 0.5844\n",
      "Epoch 3288/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3508 - accuracy: 0.8715 - val_loss: 1.6092 - val_accuracy: 0.5649\n",
      "Epoch 3289/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3316 - accuracy: 0.8771 - val_loss: 1.6186 - val_accuracy: 0.5617\n",
      "Epoch 3290/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3125 - accuracy: 0.8911 - val_loss: 1.5951 - val_accuracy: 0.5649\n",
      "Epoch 3291/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3338 - accuracy: 0.8953 - val_loss: 1.5559 - val_accuracy: 0.5714\n",
      "Epoch 3292/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3361 - accuracy: 0.9064 - val_loss: 1.5201 - val_accuracy: 0.5877\n",
      "Epoch 3293/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3387 - accuracy: 0.8809 - val_loss: 1.4984 - val_accuracy: 0.5942\n",
      "Epoch 3294/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3460 - accuracy: 0.8911 - val_loss: 1.5008 - val_accuracy: 0.5942\n",
      "Epoch 3295/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3319 - accuracy: 0.9033 - val_loss: 1.5163 - val_accuracy: 0.5909\n",
      "Epoch 3296/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3559 - accuracy: 0.8841 - val_loss: 1.5237 - val_accuracy: 0.5942\n",
      "Epoch 3297/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3580 - accuracy: 0.8867 - val_loss: 1.5196 - val_accuracy: 0.5942\n",
      "Epoch 3298/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3932 - accuracy: 0.8701 - val_loss: 1.5123 - val_accuracy: 0.6039\n",
      "Epoch 3299/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3442 - accuracy: 0.8799 - val_loss: 1.4981 - val_accuracy: 0.6071\n",
      "Epoch 3300/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3021 - accuracy: 0.8965 - val_loss: 1.4775 - val_accuracy: 0.6201\n",
      "Epoch 3301/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3426 - accuracy: 0.8799 - val_loss: 1.4533 - val_accuracy: 0.6201\n",
      "Epoch 3302/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3306 - accuracy: 0.8966 - val_loss: 1.4506 - val_accuracy: 0.6234\n",
      "Epoch 3303/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3204 - accuracy: 0.8936 - val_loss: 1.4534 - val_accuracy: 0.6299\n",
      "Epoch 3304/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3199 - accuracy: 0.9043 - val_loss: 1.4538 - val_accuracy: 0.6201\n",
      "Epoch 3305/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3682 - accuracy: 0.8818 - val_loss: 1.4526 - val_accuracy: 0.6201\n",
      "Epoch 3306/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3528 - accuracy: 0.8869 - val_loss: 1.4568 - val_accuracy: 0.6104\n",
      "Epoch 3307/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3708 - accuracy: 0.8721 - val_loss: 1.4774 - val_accuracy: 0.6039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3308/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3115 - accuracy: 0.8841 - val_loss: 1.4935 - val_accuracy: 0.6039\n",
      "Epoch 3309/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3402 - accuracy: 0.8869 - val_loss: 1.5001 - val_accuracy: 0.5974\n",
      "Epoch 3310/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3352 - accuracy: 0.8799 - val_loss: 1.4909 - val_accuracy: 0.5942\n",
      "Epoch 3311/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3906 - accuracy: 0.8757 - val_loss: 1.4666 - val_accuracy: 0.6039\n",
      "Epoch 3312/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3545 - accuracy: 0.8841 - val_loss: 1.4229 - val_accuracy: 0.6299\n",
      "Epoch 3313/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3687 - accuracy: 0.8813 - val_loss: 1.4062 - val_accuracy: 0.6429\n",
      "Epoch 3314/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3562 - accuracy: 0.8857 - val_loss: 1.4008 - val_accuracy: 0.6364\n",
      "Epoch 3315/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3484 - accuracy: 0.8838 - val_loss: 1.4074 - val_accuracy: 0.6364\n",
      "Epoch 3316/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4069 - accuracy: 0.8799 - val_loss: 1.4078 - val_accuracy: 0.6526\n",
      "Epoch 3317/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3694 - accuracy: 0.8750 - val_loss: 1.4116 - val_accuracy: 0.6429\n",
      "Epoch 3318/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3013 - accuracy: 0.8936 - val_loss: 1.4123 - val_accuracy: 0.6364\n",
      "Epoch 3319/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3510 - accuracy: 0.8897 - val_loss: 1.4151 - val_accuracy: 0.6396\n",
      "Epoch 3320/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3436 - accuracy: 0.8828 - val_loss: 1.4105 - val_accuracy: 0.6429\n",
      "Epoch 3321/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3151 - accuracy: 0.8945 - val_loss: 1.4050 - val_accuracy: 0.6429\n",
      "Epoch 3322/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4240 - accuracy: 0.8643 - val_loss: 1.3887 - val_accuracy: 0.6526\n",
      "Epoch 3323/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3457 - accuracy: 0.8953 - val_loss: 1.3708 - val_accuracy: 0.6494\n",
      "Epoch 3324/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4139 - accuracy: 0.8740 - val_loss: 1.3515 - val_accuracy: 0.6494\n",
      "Epoch 3325/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3321 - accuracy: 0.8687 - val_loss: 1.3349 - val_accuracy: 0.6526\n",
      "Epoch 3326/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3907 - accuracy: 0.8673 - val_loss: 1.3267 - val_accuracy: 0.6494\n",
      "Epoch 3327/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3485 - accuracy: 0.8906 - val_loss: 1.3169 - val_accuracy: 0.6461\n",
      "Epoch 3328/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3319 - accuracy: 0.8916 - val_loss: 1.3136 - val_accuracy: 0.6396\n",
      "Epoch 3329/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3143 - accuracy: 0.8896 - val_loss: 1.3135 - val_accuracy: 0.6461\n",
      "Epoch 3330/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3600 - accuracy: 0.8827 - val_loss: 1.3196 - val_accuracy: 0.6494\n",
      "Epoch 3331/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3689 - accuracy: 0.8799 - val_loss: 1.3214 - val_accuracy: 0.6558\n",
      "Epoch 3332/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4428 - accuracy: 0.8687 - val_loss: 1.3365 - val_accuracy: 0.6623\n",
      "Epoch 3333/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2992 - accuracy: 0.8911 - val_loss: 1.3705 - val_accuracy: 0.6623\n",
      "Epoch 3334/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3443 - accuracy: 0.8869 - val_loss: 1.3934 - val_accuracy: 0.6721\n",
      "Epoch 3335/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3351 - accuracy: 0.8887 - val_loss: 1.4084 - val_accuracy: 0.6753\n",
      "Epoch 3336/4000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3720 - accuracy: 0.8701 - val_loss: 1.4091 - val_accuracy: 0.6688\n",
      "Epoch 3337/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3640 - accuracy: 0.8809 - val_loss: 1.4051 - val_accuracy: 0.6656\n",
      "Epoch 3338/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3579 - accuracy: 0.8911 - val_loss: 1.3963 - val_accuracy: 0.6429\n",
      "Epoch 3339/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3540 - accuracy: 0.8818 - val_loss: 1.3964 - val_accuracy: 0.6494\n",
      "Epoch 3340/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3444 - accuracy: 0.8939 - val_loss: 1.4050 - val_accuracy: 0.6494\n",
      "Epoch 3341/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3389 - accuracy: 0.8994 - val_loss: 1.4196 - val_accuracy: 0.6591\n",
      "Epoch 3342/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3443 - accuracy: 0.8887 - val_loss: 1.4439 - val_accuracy: 0.6558\n",
      "Epoch 3343/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3620 - accuracy: 0.8848 - val_loss: 1.4980 - val_accuracy: 0.6266\n",
      "Epoch 3344/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3083 - accuracy: 0.8877 - val_loss: 1.5577 - val_accuracy: 0.6006\n",
      "Epoch 3345/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3640 - accuracy: 0.8691 - val_loss: 1.6231 - val_accuracy: 0.5909\n",
      "Epoch 3346/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3792 - accuracy: 0.8813 - val_loss: 1.6493 - val_accuracy: 0.5779\n",
      "Epoch 3347/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3270 - accuracy: 0.8867 - val_loss: 1.6309 - val_accuracy: 0.5844\n",
      "Epoch 3348/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3206 - accuracy: 0.9023 - val_loss: 1.5876 - val_accuracy: 0.6006\n",
      "Epoch 3349/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3393 - accuracy: 0.8916 - val_loss: 1.5558 - val_accuracy: 0.6136\n",
      "Epoch 3350/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3801 - accuracy: 0.8743 - val_loss: 1.5292 - val_accuracy: 0.6201\n",
      "Epoch 3351/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3462 - accuracy: 0.8867 - val_loss: 1.5242 - val_accuracy: 0.6266\n",
      "Epoch 3352/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3265 - accuracy: 0.8965 - val_loss: 1.5275 - val_accuracy: 0.6201\n",
      "Epoch 3353/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3081 - accuracy: 0.9008 - val_loss: 1.5332 - val_accuracy: 0.6201\n",
      "Epoch 3354/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3312 - accuracy: 0.8953 - val_loss: 1.5367 - val_accuracy: 0.6104\n",
      "Epoch 3355/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3817 - accuracy: 0.8757 - val_loss: 1.5213 - val_accuracy: 0.6136\n",
      "Epoch 3356/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3239 - accuracy: 0.9062 - val_loss: 1.5128 - val_accuracy: 0.6071\n",
      "Epoch 3357/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3723 - accuracy: 0.8848 - val_loss: 1.5082 - val_accuracy: 0.6104\n",
      "Epoch 3358/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3350 - accuracy: 0.8980 - val_loss: 1.5179 - val_accuracy: 0.6234\n",
      "Epoch 3359/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3229 - accuracy: 0.8883 - val_loss: 1.5171 - val_accuracy: 0.6201\n",
      "Epoch 3360/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3437 - accuracy: 0.8729 - val_loss: 1.5166 - val_accuracy: 0.6169\n",
      "Epoch 3361/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3262 - accuracy: 0.8980 - val_loss: 1.5086 - val_accuracy: 0.6169\n",
      "Epoch 3362/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4185 - accuracy: 0.8715 - val_loss: 1.5294 - val_accuracy: 0.6104\n",
      "Epoch 3363/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3732 - accuracy: 0.8785 - val_loss: 1.5487 - val_accuracy: 0.6039\n",
      "Epoch 3364/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3554 - accuracy: 0.8877 - val_loss: 1.5704 - val_accuracy: 0.5877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3365/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3855 - accuracy: 0.8757 - val_loss: 1.6028 - val_accuracy: 0.5909\n",
      "Epoch 3366/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3364 - accuracy: 0.8813 - val_loss: 1.6377 - val_accuracy: 0.5812\n",
      "Epoch 3367/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3679 - accuracy: 0.8799 - val_loss: 1.6663 - val_accuracy: 0.5844\n",
      "Epoch 3368/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3745 - accuracy: 0.8906 - val_loss: 1.6905 - val_accuracy: 0.5779\n",
      "Epoch 3369/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3704 - accuracy: 0.8897 - val_loss: 1.7260 - val_accuracy: 0.5714\n",
      "Epoch 3370/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2913 - accuracy: 0.9072 - val_loss: 1.7637 - val_accuracy: 0.5584\n",
      "Epoch 3371/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3195 - accuracy: 0.8936 - val_loss: 1.7769 - val_accuracy: 0.5682\n",
      "Epoch 3372/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3350 - accuracy: 0.8906 - val_loss: 1.7921 - val_accuracy: 0.5487\n",
      "Epoch 3373/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3462 - accuracy: 0.8939 - val_loss: 1.7769 - val_accuracy: 0.5617\n",
      "Epoch 3374/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3611 - accuracy: 0.8916 - val_loss: 1.7321 - val_accuracy: 0.5844\n",
      "Epoch 3375/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3424 - accuracy: 0.9064 - val_loss: 1.6745 - val_accuracy: 0.5942\n",
      "Epoch 3376/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3510 - accuracy: 0.8883 - val_loss: 1.5667 - val_accuracy: 0.6136\n",
      "Epoch 3377/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3163 - accuracy: 0.8906 - val_loss: 1.5103 - val_accuracy: 0.6331\n",
      "Epoch 3378/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3346 - accuracy: 0.8883 - val_loss: 1.4714 - val_accuracy: 0.6461\n",
      "Epoch 3379/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2953 - accuracy: 0.8939 - val_loss: 1.4613 - val_accuracy: 0.6526\n",
      "Epoch 3380/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3744 - accuracy: 0.8809 - val_loss: 1.4667 - val_accuracy: 0.6558\n",
      "Epoch 3381/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3584 - accuracy: 0.8857 - val_loss: 1.4635 - val_accuracy: 0.6494\n",
      "Epoch 3382/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2958 - accuracy: 0.9082 - val_loss: 1.4595 - val_accuracy: 0.6461\n",
      "Epoch 3383/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3401 - accuracy: 0.8906 - val_loss: 1.4480 - val_accuracy: 0.6396\n",
      "Epoch 3384/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3267 - accuracy: 0.9036 - val_loss: 1.4357 - val_accuracy: 0.6364\n",
      "Epoch 3385/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3511 - accuracy: 0.8887 - val_loss: 1.4315 - val_accuracy: 0.6364\n",
      "Epoch 3386/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3549 - accuracy: 0.8789 - val_loss: 1.4312 - val_accuracy: 0.6364\n",
      "Epoch 3387/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3554 - accuracy: 0.8799 - val_loss: 1.4341 - val_accuracy: 0.6331\n",
      "Epoch 3388/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3496 - accuracy: 0.8785 - val_loss: 1.4535 - val_accuracy: 0.6266\n",
      "Epoch 3389/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3614 - accuracy: 0.8855 - val_loss: 1.4755 - val_accuracy: 0.6201\n",
      "Epoch 3390/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3255 - accuracy: 0.8867 - val_loss: 1.4802 - val_accuracy: 0.6169\n",
      "Epoch 3391/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3728 - accuracy: 0.8770 - val_loss: 1.4705 - val_accuracy: 0.6169\n",
      "Epoch 3392/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3784 - accuracy: 0.8785 - val_loss: 1.4436 - val_accuracy: 0.6234\n",
      "Epoch 3393/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3349 - accuracy: 0.8896 - val_loss: 1.4027 - val_accuracy: 0.6429\n",
      "Epoch 3394/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3406 - accuracy: 0.8827 - val_loss: 1.3766 - val_accuracy: 0.6429\n",
      "Epoch 3395/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3288 - accuracy: 0.8980 - val_loss: 1.3623 - val_accuracy: 0.6331\n",
      "Epoch 3396/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3119 - accuracy: 0.9004 - val_loss: 1.3577 - val_accuracy: 0.6299\n",
      "Epoch 3397/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3959 - accuracy: 0.8659 - val_loss: 1.3522 - val_accuracy: 0.6331\n",
      "Epoch 3398/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3713 - accuracy: 0.8743 - val_loss: 1.3438 - val_accuracy: 0.6396\n",
      "Epoch 3399/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3375 - accuracy: 0.8682 - val_loss: 1.3361 - val_accuracy: 0.6494\n",
      "Epoch 3400/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3097 - accuracy: 0.8925 - val_loss: 1.3371 - val_accuracy: 0.6526\n",
      "Epoch 3401/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2950 - accuracy: 0.8911 - val_loss: 1.3451 - val_accuracy: 0.6591\n",
      "Epoch 3402/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3803 - accuracy: 0.8799 - val_loss: 1.3680 - val_accuracy: 0.6526\n",
      "Epoch 3403/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3429 - accuracy: 0.8939 - val_loss: 1.3867 - val_accuracy: 0.6331\n",
      "Epoch 3404/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3336 - accuracy: 0.8925 - val_loss: 1.4079 - val_accuracy: 0.6299\n",
      "Epoch 3405/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3742 - accuracy: 0.8848 - val_loss: 1.4292 - val_accuracy: 0.6396\n",
      "Epoch 3406/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4136 - accuracy: 0.8729 - val_loss: 1.4541 - val_accuracy: 0.6331\n",
      "Epoch 3407/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3270 - accuracy: 0.8936 - val_loss: 1.4792 - val_accuracy: 0.6266\n",
      "Epoch 3408/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4008 - accuracy: 0.8662 - val_loss: 1.5142 - val_accuracy: 0.6266\n",
      "Epoch 3409/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3060 - accuracy: 0.8994 - val_loss: 1.5544 - val_accuracy: 0.6234\n",
      "Epoch 3410/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3260 - accuracy: 0.8911 - val_loss: 1.6107 - val_accuracy: 0.5909\n",
      "Epoch 3411/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3367 - accuracy: 0.8729 - val_loss: 1.6822 - val_accuracy: 0.5779\n",
      "Epoch 3412/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4086 - accuracy: 0.8813 - val_loss: 1.7352 - val_accuracy: 0.5779\n",
      "Epoch 3413/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3471 - accuracy: 0.8809 - val_loss: 1.7512 - val_accuracy: 0.5519\n",
      "Epoch 3414/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3810 - accuracy: 0.8770 - val_loss: 1.7685 - val_accuracy: 0.5617\n",
      "Epoch 3415/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3123 - accuracy: 0.9078 - val_loss: 1.7764 - val_accuracy: 0.5649\n",
      "Epoch 3416/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3197 - accuracy: 0.8869 - val_loss: 1.7683 - val_accuracy: 0.5519\n",
      "Epoch 3417/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2795 - accuracy: 0.9064 - val_loss: 1.7322 - val_accuracy: 0.5649\n",
      "Epoch 3418/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3444 - accuracy: 0.8966 - val_loss: 1.7113 - val_accuracy: 0.5747\n",
      "Epoch 3419/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3117 - accuracy: 0.8867 - val_loss: 1.6752 - val_accuracy: 0.5844\n",
      "Epoch 3420/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3670 - accuracy: 0.8980 - val_loss: 1.6213 - val_accuracy: 0.5877\n",
      "Epoch 3421/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3834 - accuracy: 0.8770 - val_loss: 1.5768 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3422/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3691 - accuracy: 0.8828 - val_loss: 1.5660 - val_accuracy: 0.6104\n",
      "Epoch 3423/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3565 - accuracy: 0.8857 - val_loss: 1.5627 - val_accuracy: 0.6104\n",
      "Epoch 3424/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3330 - accuracy: 0.8966 - val_loss: 1.5472 - val_accuracy: 0.6201\n",
      "Epoch 3425/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3269 - accuracy: 0.9033 - val_loss: 1.5432 - val_accuracy: 0.6136\n",
      "Epoch 3426/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3339 - accuracy: 0.8925 - val_loss: 1.5350 - val_accuracy: 0.6071\n",
      "Epoch 3427/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3335 - accuracy: 0.8916 - val_loss: 1.5400 - val_accuracy: 0.5974\n",
      "Epoch 3428/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3345 - accuracy: 0.8966 - val_loss: 1.5286 - val_accuracy: 0.5974\n",
      "Epoch 3429/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3650 - accuracy: 0.8848 - val_loss: 1.5195 - val_accuracy: 0.5844\n",
      "Epoch 3430/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3223 - accuracy: 0.8925 - val_loss: 1.5421 - val_accuracy: 0.5812\n",
      "Epoch 3431/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3556 - accuracy: 0.8779 - val_loss: 1.5797 - val_accuracy: 0.5909\n",
      "Epoch 3432/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3213 - accuracy: 0.9036 - val_loss: 1.6185 - val_accuracy: 0.5779\n",
      "Epoch 3433/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3111 - accuracy: 0.9022 - val_loss: 1.6407 - val_accuracy: 0.5844\n",
      "Epoch 3434/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4220 - accuracy: 0.8743 - val_loss: 1.6271 - val_accuracy: 0.5844\n",
      "Epoch 3435/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3486 - accuracy: 0.8897 - val_loss: 1.6004 - val_accuracy: 0.5877\n",
      "Epoch 3436/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3953 - accuracy: 0.8750 - val_loss: 1.5563 - val_accuracy: 0.6169\n",
      "Epoch 3437/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3536 - accuracy: 0.8897 - val_loss: 1.5207 - val_accuracy: 0.6364\n",
      "Epoch 3438/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3344 - accuracy: 0.8994 - val_loss: 1.4920 - val_accuracy: 0.6396\n",
      "Epoch 3439/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2895 - accuracy: 0.9064 - val_loss: 1.4643 - val_accuracy: 0.6364\n",
      "Epoch 3440/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3426 - accuracy: 0.8883 - val_loss: 1.4307 - val_accuracy: 0.6494\n",
      "Epoch 3441/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3716 - accuracy: 0.8673 - val_loss: 1.4193 - val_accuracy: 0.6429\n",
      "Epoch 3442/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3609 - accuracy: 0.8883 - val_loss: 1.4193 - val_accuracy: 0.6558\n",
      "Epoch 3443/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3441 - accuracy: 0.8887 - val_loss: 1.4211 - val_accuracy: 0.6591\n",
      "Epoch 3444/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3620 - accuracy: 0.8721 - val_loss: 1.4381 - val_accuracy: 0.6623\n",
      "Epoch 3445/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3553 - accuracy: 0.8813 - val_loss: 1.4641 - val_accuracy: 0.6526\n",
      "Epoch 3446/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3859 - accuracy: 0.8757 - val_loss: 1.4824 - val_accuracy: 0.6299\n",
      "Epoch 3447/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3073 - accuracy: 0.8936 - val_loss: 1.5031 - val_accuracy: 0.6299\n",
      "Epoch 3448/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3610 - accuracy: 0.8939 - val_loss: 1.5039 - val_accuracy: 0.6169\n",
      "Epoch 3449/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3201 - accuracy: 0.9004 - val_loss: 1.4981 - val_accuracy: 0.6071\n",
      "Epoch 3450/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3160 - accuracy: 0.8911 - val_loss: 1.4980 - val_accuracy: 0.6104\n",
      "Epoch 3451/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3435 - accuracy: 0.8897 - val_loss: 1.5410 - val_accuracy: 0.5812\n",
      "Epoch 3452/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3381 - accuracy: 0.8848 - val_loss: 1.5705 - val_accuracy: 0.5812\n",
      "Epoch 3453/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3618 - accuracy: 0.8855 - val_loss: 1.5915 - val_accuracy: 0.5779\n",
      "Epoch 3454/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3595 - accuracy: 0.8897 - val_loss: 1.5903 - val_accuracy: 0.5779\n",
      "Epoch 3455/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3135 - accuracy: 0.8994 - val_loss: 1.6342 - val_accuracy: 0.5682\n",
      "Epoch 3456/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3416 - accuracy: 0.8855 - val_loss: 1.6752 - val_accuracy: 0.5617\n",
      "Epoch 3457/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3411 - accuracy: 0.8916 - val_loss: 1.6922 - val_accuracy: 0.5552\n",
      "Epoch 3458/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3401 - accuracy: 0.8841 - val_loss: 1.7004 - val_accuracy: 0.5552\n",
      "Epoch 3459/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3101 - accuracy: 0.9078 - val_loss: 1.6672 - val_accuracy: 0.5747\n",
      "Epoch 3460/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3813 - accuracy: 0.8771 - val_loss: 1.6440 - val_accuracy: 0.5812\n",
      "Epoch 3461/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3325 - accuracy: 0.8926 - val_loss: 1.6178 - val_accuracy: 0.5812\n",
      "Epoch 3462/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3379 - accuracy: 0.9023 - val_loss: 1.5906 - val_accuracy: 0.5779\n",
      "Epoch 3463/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3018 - accuracy: 0.8966 - val_loss: 1.5723 - val_accuracy: 0.5812\n",
      "Epoch 3464/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3558 - accuracy: 0.8916 - val_loss: 1.5355 - val_accuracy: 0.5877\n",
      "Epoch 3465/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3253 - accuracy: 0.8867 - val_loss: 1.4949 - val_accuracy: 0.6006\n",
      "Epoch 3466/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3111 - accuracy: 0.9008 - val_loss: 1.4847 - val_accuracy: 0.5942\n",
      "Epoch 3467/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3717 - accuracy: 0.8721 - val_loss: 1.4608 - val_accuracy: 0.6006\n",
      "Epoch 3468/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2933 - accuracy: 0.9062 - val_loss: 1.4485 - val_accuracy: 0.6136\n",
      "Epoch 3469/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3311 - accuracy: 0.8897 - val_loss: 1.4333 - val_accuracy: 0.6136\n",
      "Epoch 3470/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3094 - accuracy: 0.8925 - val_loss: 1.4109 - val_accuracy: 0.6234\n",
      "Epoch 3471/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3076 - accuracy: 0.9008 - val_loss: 1.3886 - val_accuracy: 0.6266\n",
      "Epoch 3472/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2991 - accuracy: 0.8955 - val_loss: 1.3684 - val_accuracy: 0.6266\n",
      "Epoch 3473/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3739 - accuracy: 0.8672 - val_loss: 1.3493 - val_accuracy: 0.6396\n",
      "Epoch 3474/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3673 - accuracy: 0.8828 - val_loss: 1.3416 - val_accuracy: 0.6461\n",
      "Epoch 3475/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3265 - accuracy: 0.8869 - val_loss: 1.3315 - val_accuracy: 0.6526\n",
      "Epoch 3476/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2793 - accuracy: 0.9189 - val_loss: 1.3275 - val_accuracy: 0.6558\n",
      "Epoch 3477/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3383 - accuracy: 0.8877 - val_loss: 1.3229 - val_accuracy: 0.6526\n",
      "Epoch 3478/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2928 - accuracy: 0.8966 - val_loss: 1.3250 - val_accuracy: 0.6526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3479/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3267 - accuracy: 0.8936 - val_loss: 1.3348 - val_accuracy: 0.6429\n",
      "Epoch 3480/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3459 - accuracy: 0.8779 - val_loss: 1.3609 - val_accuracy: 0.6396\n",
      "Epoch 3481/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3418 - accuracy: 0.8906 - val_loss: 1.3891 - val_accuracy: 0.6299\n",
      "Epoch 3482/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3428 - accuracy: 0.8916 - val_loss: 1.4194 - val_accuracy: 0.6266\n",
      "Epoch 3483/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3922 - accuracy: 0.8687 - val_loss: 1.4488 - val_accuracy: 0.6266\n",
      "Epoch 3484/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3407 - accuracy: 0.8867 - val_loss: 1.4849 - val_accuracy: 0.6169\n",
      "Epoch 3485/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3162 - accuracy: 0.8911 - val_loss: 1.5150 - val_accuracy: 0.6104\n",
      "Epoch 3486/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3097 - accuracy: 0.9008 - val_loss: 1.5253 - val_accuracy: 0.6071\n",
      "Epoch 3487/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3503 - accuracy: 0.8771 - val_loss: 1.4947 - val_accuracy: 0.6071\n",
      "Epoch 3488/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2901 - accuracy: 0.9148 - val_loss: 1.4681 - val_accuracy: 0.6234\n",
      "Epoch 3489/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3297 - accuracy: 0.8926 - val_loss: 1.4550 - val_accuracy: 0.6104\n",
      "Epoch 3490/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3718 - accuracy: 0.8828 - val_loss: 1.4531 - val_accuracy: 0.6104\n",
      "Epoch 3491/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3208 - accuracy: 0.8877 - val_loss: 1.4569 - val_accuracy: 0.6104\n",
      "Epoch 3492/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3263 - accuracy: 0.8906 - val_loss: 1.4531 - val_accuracy: 0.6136\n",
      "Epoch 3493/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3579 - accuracy: 0.8828 - val_loss: 1.4361 - val_accuracy: 0.6136\n",
      "Epoch 3494/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2910 - accuracy: 0.9008 - val_loss: 1.4161 - val_accuracy: 0.6201\n",
      "Epoch 3495/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3372 - accuracy: 0.8994 - val_loss: 1.4075 - val_accuracy: 0.6331\n",
      "Epoch 3496/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3523 - accuracy: 0.8897 - val_loss: 1.4082 - val_accuracy: 0.6299\n",
      "Epoch 3497/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3528 - accuracy: 0.8818 - val_loss: 1.4059 - val_accuracy: 0.6331\n",
      "Epoch 3498/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3263 - accuracy: 0.8953 - val_loss: 1.3995 - val_accuracy: 0.6299\n",
      "Epoch 3499/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3099 - accuracy: 0.8896 - val_loss: 1.4027 - val_accuracy: 0.6299\n",
      "Epoch 3500/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3525 - accuracy: 0.8799 - val_loss: 1.4176 - val_accuracy: 0.6266\n",
      "Epoch 3501/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3224 - accuracy: 0.8869 - val_loss: 1.4401 - val_accuracy: 0.6299\n",
      "Epoch 3502/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2984 - accuracy: 0.9050 - val_loss: 1.4742 - val_accuracy: 0.6169\n",
      "Epoch 3503/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3323 - accuracy: 0.8926 - val_loss: 1.4917 - val_accuracy: 0.5974\n",
      "Epoch 3504/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3268 - accuracy: 0.8945 - val_loss: 1.5049 - val_accuracy: 0.5974\n",
      "Epoch 3505/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3094 - accuracy: 0.8813 - val_loss: 1.5097 - val_accuracy: 0.5909\n",
      "Epoch 3506/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2889 - accuracy: 0.8939 - val_loss: 1.5387 - val_accuracy: 0.5942\n",
      "Epoch 3507/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3524 - accuracy: 0.8887 - val_loss: 1.5374 - val_accuracy: 0.5974\n",
      "Epoch 3508/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3421 - accuracy: 0.8925 - val_loss: 1.5754 - val_accuracy: 0.5779\n",
      "Epoch 3509/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3860 - accuracy: 0.8779 - val_loss: 1.6057 - val_accuracy: 0.5682\n",
      "Epoch 3510/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3570 - accuracy: 0.8809 - val_loss: 1.6308 - val_accuracy: 0.5779\n",
      "Epoch 3511/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3439 - accuracy: 0.8887 - val_loss: 1.6360 - val_accuracy: 0.5844\n",
      "Epoch 3512/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3356 - accuracy: 0.8994 - val_loss: 1.6604 - val_accuracy: 0.5779\n",
      "Epoch 3513/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2984 - accuracy: 0.9050 - val_loss: 1.6746 - val_accuracy: 0.5779\n",
      "Epoch 3514/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3406 - accuracy: 0.8883 - val_loss: 1.6540 - val_accuracy: 0.5909\n",
      "Epoch 3515/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3915 - accuracy: 0.8701 - val_loss: 1.6169 - val_accuracy: 0.6006\n",
      "Epoch 3516/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3138 - accuracy: 0.8911 - val_loss: 1.5823 - val_accuracy: 0.6039\n",
      "Epoch 3517/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2825 - accuracy: 0.9050 - val_loss: 1.5330 - val_accuracy: 0.6104\n",
      "Epoch 3518/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3062 - accuracy: 0.9023 - val_loss: 1.4800 - val_accuracy: 0.6396\n",
      "Epoch 3519/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3369 - accuracy: 0.8945 - val_loss: 1.4493 - val_accuracy: 0.6396\n",
      "Epoch 3520/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3626 - accuracy: 0.8896 - val_loss: 1.4183 - val_accuracy: 0.6461\n",
      "Epoch 3521/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3305 - accuracy: 0.8925 - val_loss: 1.3889 - val_accuracy: 0.6461\n",
      "Epoch 3522/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3033 - accuracy: 0.9022 - val_loss: 1.3747 - val_accuracy: 0.6494\n",
      "Epoch 3523/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3122 - accuracy: 0.8966 - val_loss: 1.3676 - val_accuracy: 0.6591\n",
      "Epoch 3524/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3170 - accuracy: 0.8953 - val_loss: 1.3748 - val_accuracy: 0.6558\n",
      "Epoch 3525/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3303 - accuracy: 0.8945 - val_loss: 1.4013 - val_accuracy: 0.6429\n",
      "Epoch 3526/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3279 - accuracy: 0.8953 - val_loss: 1.4364 - val_accuracy: 0.6396\n",
      "Epoch 3527/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3178 - accuracy: 0.8887 - val_loss: 1.4499 - val_accuracy: 0.6364\n",
      "Epoch 3528/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3331 - accuracy: 0.8953 - val_loss: 1.4718 - val_accuracy: 0.6396\n",
      "Epoch 3529/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3349 - accuracy: 0.8818 - val_loss: 1.4695 - val_accuracy: 0.6494\n",
      "Epoch 3530/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3146 - accuracy: 0.8818 - val_loss: 1.4666 - val_accuracy: 0.6364\n",
      "Epoch 3531/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3009 - accuracy: 0.9092 - val_loss: 1.4586 - val_accuracy: 0.6331\n",
      "Epoch 3532/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3107 - accuracy: 0.8883 - val_loss: 1.4590 - val_accuracy: 0.6331\n",
      "Epoch 3533/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3494 - accuracy: 0.8911 - val_loss: 1.4613 - val_accuracy: 0.6396\n",
      "Epoch 3534/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3715 - accuracy: 0.8869 - val_loss: 1.4661 - val_accuracy: 0.6331\n",
      "Epoch 3535/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3184 - accuracy: 0.8887 - val_loss: 1.4629 - val_accuracy: 0.6331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3536/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3390 - accuracy: 0.8906 - val_loss: 1.4586 - val_accuracy: 0.6299\n",
      "Epoch 3537/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2816 - accuracy: 0.9072 - val_loss: 1.4419 - val_accuracy: 0.6396\n",
      "Epoch 3538/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3169 - accuracy: 0.8906 - val_loss: 1.4334 - val_accuracy: 0.6364\n",
      "Epoch 3539/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3382 - accuracy: 0.8848 - val_loss: 1.4197 - val_accuracy: 0.6429\n",
      "Epoch 3540/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3168 - accuracy: 0.9014 - val_loss: 1.4154 - val_accuracy: 0.6429\n",
      "Epoch 3541/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3379 - accuracy: 0.8939 - val_loss: 1.3926 - val_accuracy: 0.6494\n",
      "Epoch 3542/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3647 - accuracy: 0.8818 - val_loss: 1.3957 - val_accuracy: 0.6429\n",
      "Epoch 3543/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3336 - accuracy: 0.8760 - val_loss: 1.3953 - val_accuracy: 0.6461\n",
      "Epoch 3544/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3061 - accuracy: 0.8945 - val_loss: 1.4023 - val_accuracy: 0.6429\n",
      "Epoch 3545/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3592 - accuracy: 0.8779 - val_loss: 1.4108 - val_accuracy: 0.6429\n",
      "Epoch 3546/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3626 - accuracy: 0.8916 - val_loss: 1.4173 - val_accuracy: 0.6331\n",
      "Epoch 3547/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2872 - accuracy: 0.9162 - val_loss: 1.4296 - val_accuracy: 0.6429\n",
      "Epoch 3548/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3339 - accuracy: 0.8926 - val_loss: 1.4339 - val_accuracy: 0.6396\n",
      "Epoch 3549/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3665 - accuracy: 0.8911 - val_loss: 1.4314 - val_accuracy: 0.6461\n",
      "Epoch 3550/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3400 - accuracy: 0.8857 - val_loss: 1.4386 - val_accuracy: 0.6494\n",
      "Epoch 3551/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3241 - accuracy: 0.8841 - val_loss: 1.4431 - val_accuracy: 0.6656\n",
      "Epoch 3552/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3215 - accuracy: 0.8953 - val_loss: 1.4561 - val_accuracy: 0.6591\n",
      "Epoch 3553/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3414 - accuracy: 0.8867 - val_loss: 1.4642 - val_accuracy: 0.6558\n",
      "Epoch 3554/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2655 - accuracy: 0.9150 - val_loss: 1.4683 - val_accuracy: 0.6558\n",
      "Epoch 3555/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2963 - accuracy: 0.9064 - val_loss: 1.4661 - val_accuracy: 0.6656\n",
      "Epoch 3556/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3277 - accuracy: 0.8975 - val_loss: 1.4561 - val_accuracy: 0.6656\n",
      "Epoch 3557/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3509 - accuracy: 0.8838 - val_loss: 1.4433 - val_accuracy: 0.6721\n",
      "Epoch 3558/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2795 - accuracy: 0.9036 - val_loss: 1.4199 - val_accuracy: 0.6721\n",
      "Epoch 3559/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3394 - accuracy: 0.8828 - val_loss: 1.4109 - val_accuracy: 0.6753\n",
      "Epoch 3560/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3284 - accuracy: 0.8975 - val_loss: 1.4037 - val_accuracy: 0.6753\n",
      "Epoch 3561/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3232 - accuracy: 0.9036 - val_loss: 1.4032 - val_accuracy: 0.6786\n",
      "Epoch 3562/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3029 - accuracy: 0.8994 - val_loss: 1.4142 - val_accuracy: 0.6656\n",
      "Epoch 3563/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3002 - accuracy: 0.8945 - val_loss: 1.4215 - val_accuracy: 0.6753\n",
      "Epoch 3564/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3112 - accuracy: 0.8925 - val_loss: 1.4241 - val_accuracy: 0.6656\n",
      "Epoch 3565/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3334 - accuracy: 0.8966 - val_loss: 1.4214 - val_accuracy: 0.6656\n",
      "Epoch 3566/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2802 - accuracy: 0.8984 - val_loss: 1.4290 - val_accuracy: 0.6591\n",
      "Epoch 3567/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3042 - accuracy: 0.9082 - val_loss: 1.4226 - val_accuracy: 0.6526\n",
      "Epoch 3568/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3161 - accuracy: 0.8936 - val_loss: 1.4341 - val_accuracy: 0.6526\n",
      "Epoch 3569/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3235 - accuracy: 0.8906 - val_loss: 1.4306 - val_accuracy: 0.6461\n",
      "Epoch 3570/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2844 - accuracy: 0.8953 - val_loss: 1.4366 - val_accuracy: 0.6558\n",
      "Epoch 3571/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3133 - accuracy: 0.9036 - val_loss: 1.4390 - val_accuracy: 0.6526\n",
      "Epoch 3572/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3287 - accuracy: 0.8994 - val_loss: 1.4481 - val_accuracy: 0.6526\n",
      "Epoch 3573/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3332 - accuracy: 0.8818 - val_loss: 1.4754 - val_accuracy: 0.6429\n",
      "Epoch 3574/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3637 - accuracy: 0.8799 - val_loss: 1.4984 - val_accuracy: 0.6429\n",
      "Epoch 3575/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2931 - accuracy: 0.9033 - val_loss: 1.5235 - val_accuracy: 0.6396\n",
      "Epoch 3576/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3015 - accuracy: 0.8984 - val_loss: 1.5387 - val_accuracy: 0.6494\n",
      "Epoch 3577/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3840 - accuracy: 0.8760 - val_loss: 1.5588 - val_accuracy: 0.6429\n",
      "Epoch 3578/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3443 - accuracy: 0.8897 - val_loss: 1.5773 - val_accuracy: 0.6169\n",
      "Epoch 3579/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3360 - accuracy: 0.8887 - val_loss: 1.5941 - val_accuracy: 0.6006\n",
      "Epoch 3580/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3382 - accuracy: 0.8887 - val_loss: 1.5942 - val_accuracy: 0.6104\n",
      "Epoch 3581/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3280 - accuracy: 0.8916 - val_loss: 1.5679 - val_accuracy: 0.6136\n",
      "Epoch 3582/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3302 - accuracy: 0.8926 - val_loss: 1.5412 - val_accuracy: 0.6169\n",
      "Epoch 3583/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3391 - accuracy: 0.8897 - val_loss: 1.5189 - val_accuracy: 0.6234\n",
      "Epoch 3584/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2992 - accuracy: 0.9092 - val_loss: 1.4965 - val_accuracy: 0.6429\n",
      "Epoch 3585/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2696 - accuracy: 0.9023 - val_loss: 1.4751 - val_accuracy: 0.6429\n",
      "Epoch 3586/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3058 - accuracy: 0.9033 - val_loss: 1.4637 - val_accuracy: 0.6461\n",
      "Epoch 3587/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3072 - accuracy: 0.9023 - val_loss: 1.4585 - val_accuracy: 0.6494\n",
      "Epoch 3588/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2970 - accuracy: 0.9008 - val_loss: 1.4619 - val_accuracy: 0.6494\n",
      "Epoch 3589/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2934 - accuracy: 0.8906 - val_loss: 1.4797 - val_accuracy: 0.6429\n",
      "Epoch 3590/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3528 - accuracy: 0.8813 - val_loss: 1.4945 - val_accuracy: 0.6331\n",
      "Epoch 3591/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2866 - accuracy: 0.9131 - val_loss: 1.5109 - val_accuracy: 0.6266\n",
      "Epoch 3592/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2975 - accuracy: 0.8939 - val_loss: 1.5334 - val_accuracy: 0.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3593/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3327 - accuracy: 0.8936 - val_loss: 1.5527 - val_accuracy: 0.6331\n",
      "Epoch 3594/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3352 - accuracy: 0.9008 - val_loss: 1.5803 - val_accuracy: 0.6169\n",
      "Epoch 3595/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3346 - accuracy: 0.8980 - val_loss: 1.5980 - val_accuracy: 0.6201\n",
      "Epoch 3596/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3490 - accuracy: 0.8789 - val_loss: 1.6323 - val_accuracy: 0.5909\n",
      "Epoch 3597/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3341 - accuracy: 0.8883 - val_loss: 1.6789 - val_accuracy: 0.5877\n",
      "Epoch 3598/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2777 - accuracy: 0.8966 - val_loss: 1.7347 - val_accuracy: 0.5812\n",
      "Epoch 3599/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3171 - accuracy: 0.8984 - val_loss: 1.7703 - val_accuracy: 0.5812\n",
      "Epoch 3600/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3579 - accuracy: 0.8848 - val_loss: 1.7885 - val_accuracy: 0.5617\n",
      "Epoch 3601/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2980 - accuracy: 0.9008 - val_loss: 1.8007 - val_accuracy: 0.5714\n",
      "Epoch 3602/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3540 - accuracy: 0.8841 - val_loss: 1.7841 - val_accuracy: 0.5649\n",
      "Epoch 3603/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2991 - accuracy: 0.9064 - val_loss: 1.7466 - val_accuracy: 0.5682\n",
      "Epoch 3604/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3292 - accuracy: 0.8841 - val_loss: 1.7058 - val_accuracy: 0.5747\n",
      "Epoch 3605/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3295 - accuracy: 0.8911 - val_loss: 1.6886 - val_accuracy: 0.5779\n",
      "Epoch 3606/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3870 - accuracy: 0.8855 - val_loss: 1.6743 - val_accuracy: 0.5877\n",
      "Epoch 3607/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3510 - accuracy: 0.8729 - val_loss: 1.6634 - val_accuracy: 0.5844\n",
      "Epoch 3608/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2933 - accuracy: 0.9120 - val_loss: 1.6531 - val_accuracy: 0.5942\n",
      "Epoch 3609/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3324 - accuracy: 0.8883 - val_loss: 1.6451 - val_accuracy: 0.5909\n",
      "Epoch 3610/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3465 - accuracy: 0.8887 - val_loss: 1.6317 - val_accuracy: 0.6006\n",
      "Epoch 3611/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3160 - accuracy: 0.8799 - val_loss: 1.5967 - val_accuracy: 0.6039\n",
      "Epoch 3612/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2948 - accuracy: 0.9014 - val_loss: 1.5664 - val_accuracy: 0.6104\n",
      "Epoch 3613/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3125 - accuracy: 0.8813 - val_loss: 1.5455 - val_accuracy: 0.6169\n",
      "Epoch 3614/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2675 - accuracy: 0.9078 - val_loss: 1.5519 - val_accuracy: 0.6104\n",
      "Epoch 3615/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3570 - accuracy: 0.8818 - val_loss: 1.5698 - val_accuracy: 0.6039\n",
      "Epoch 3616/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2726 - accuracy: 0.9120 - val_loss: 1.5699 - val_accuracy: 0.6006\n",
      "Epoch 3617/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2939 - accuracy: 0.9022 - val_loss: 1.5993 - val_accuracy: 0.5877\n",
      "Epoch 3618/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3463 - accuracy: 0.8953 - val_loss: 1.6139 - val_accuracy: 0.5942\n",
      "Epoch 3619/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2966 - accuracy: 0.9064 - val_loss: 1.6130 - val_accuracy: 0.5942\n",
      "Epoch 3620/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3444 - accuracy: 0.8896 - val_loss: 1.6059 - val_accuracy: 0.6006\n",
      "Epoch 3621/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3278 - accuracy: 0.8897 - val_loss: 1.5910 - val_accuracy: 0.6039\n",
      "Epoch 3622/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2605 - accuracy: 0.9246 - val_loss: 1.5772 - val_accuracy: 0.6039\n",
      "Epoch 3623/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3564 - accuracy: 0.8828 - val_loss: 1.5615 - val_accuracy: 0.6136\n",
      "Epoch 3624/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2851 - accuracy: 0.9078 - val_loss: 1.5528 - val_accuracy: 0.6169\n",
      "Epoch 3625/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3185 - accuracy: 0.8953 - val_loss: 1.5501 - val_accuracy: 0.6234\n",
      "Epoch 3626/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3373 - accuracy: 0.8926 - val_loss: 1.5508 - val_accuracy: 0.6299\n",
      "Epoch 3627/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3023 - accuracy: 0.8966 - val_loss: 1.5778 - val_accuracy: 0.6266\n",
      "Epoch 3628/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3399 - accuracy: 0.8906 - val_loss: 1.6094 - val_accuracy: 0.6006\n",
      "Epoch 3629/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3421 - accuracy: 0.8838 - val_loss: 1.6339 - val_accuracy: 0.5909\n",
      "Epoch 3630/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3546 - accuracy: 0.8848 - val_loss: 1.6779 - val_accuracy: 0.5844\n",
      "Epoch 3631/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3222 - accuracy: 0.9072 - val_loss: 1.7333 - val_accuracy: 0.5812\n",
      "Epoch 3632/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3092 - accuracy: 0.9050 - val_loss: 1.7952 - val_accuracy: 0.5649\n",
      "Epoch 3633/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3122 - accuracy: 0.8906 - val_loss: 1.8412 - val_accuracy: 0.5649\n",
      "Epoch 3634/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2993 - accuracy: 0.9082 - val_loss: 1.8702 - val_accuracy: 0.5519\n",
      "Epoch 3635/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3036 - accuracy: 0.9014 - val_loss: 1.8943 - val_accuracy: 0.5390\n",
      "Epoch 3636/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2568 - accuracy: 0.9120 - val_loss: 1.8924 - val_accuracy: 0.5455\n",
      "Epoch 3637/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3558 - accuracy: 0.8867 - val_loss: 1.8576 - val_accuracy: 0.5584\n",
      "Epoch 3638/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3620 - accuracy: 0.8827 - val_loss: 1.8183 - val_accuracy: 0.5617\n",
      "Epoch 3639/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3093 - accuracy: 0.9008 - val_loss: 1.7651 - val_accuracy: 0.5747\n",
      "Epoch 3640/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3411 - accuracy: 0.8887 - val_loss: 1.7066 - val_accuracy: 0.5877\n",
      "Epoch 3641/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3465 - accuracy: 0.8955 - val_loss: 1.6954 - val_accuracy: 0.5974\n",
      "Epoch 3642/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3248 - accuracy: 0.8911 - val_loss: 1.6845 - val_accuracy: 0.5974\n",
      "Epoch 3643/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2751 - accuracy: 0.9106 - val_loss: 1.6589 - val_accuracy: 0.6071\n",
      "Epoch 3644/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3024 - accuracy: 0.9120 - val_loss: 1.6477 - val_accuracy: 0.5942\n",
      "Epoch 3645/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3241 - accuracy: 0.8965 - val_loss: 1.6289 - val_accuracy: 0.6006\n",
      "Epoch 3646/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3312 - accuracy: 0.9004 - val_loss: 1.6106 - val_accuracy: 0.6071\n",
      "Epoch 3647/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3405 - accuracy: 0.8975 - val_loss: 1.6130 - val_accuracy: 0.6104\n",
      "Epoch 3648/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2971 - accuracy: 0.8925 - val_loss: 1.6107 - val_accuracy: 0.6071\n",
      "Epoch 3649/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3208 - accuracy: 0.9036 - val_loss: 1.6396 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3650/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3662 - accuracy: 0.8740 - val_loss: 1.6838 - val_accuracy: 0.5844\n",
      "Epoch 3651/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3461 - accuracy: 0.8906 - val_loss: 1.7256 - val_accuracy: 0.5747\n",
      "Epoch 3652/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3273 - accuracy: 0.8965 - val_loss: 1.7552 - val_accuracy: 0.5617\n",
      "Epoch 3653/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3054 - accuracy: 0.8925 - val_loss: 1.7665 - val_accuracy: 0.5682\n",
      "Epoch 3654/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3082 - accuracy: 0.9008 - val_loss: 1.7403 - val_accuracy: 0.5747\n",
      "Epoch 3655/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2814 - accuracy: 0.9082 - val_loss: 1.6927 - val_accuracy: 0.5974\n",
      "Epoch 3656/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3135 - accuracy: 0.8955 - val_loss: 1.6219 - val_accuracy: 0.6071\n",
      "Epoch 3657/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3634 - accuracy: 0.8855 - val_loss: 1.5823 - val_accuracy: 0.6136\n",
      "Epoch 3658/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2737 - accuracy: 0.9111 - val_loss: 1.5522 - val_accuracy: 0.6234\n",
      "Epoch 3659/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3542 - accuracy: 0.8897 - val_loss: 1.5449 - val_accuracy: 0.6396\n",
      "Epoch 3660/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3467 - accuracy: 0.8848 - val_loss: 1.5516 - val_accuracy: 0.6331\n",
      "Epoch 3661/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3009 - accuracy: 0.9036 - val_loss: 1.5684 - val_accuracy: 0.6331\n",
      "Epoch 3662/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3112 - accuracy: 0.9008 - val_loss: 1.5737 - val_accuracy: 0.6396\n",
      "Epoch 3663/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3117 - accuracy: 0.9062 - val_loss: 1.5841 - val_accuracy: 0.6396\n",
      "Epoch 3664/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3087 - accuracy: 0.8994 - val_loss: 1.5786 - val_accuracy: 0.6364\n",
      "Epoch 3665/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3061 - accuracy: 0.8994 - val_loss: 1.5503 - val_accuracy: 0.6429\n",
      "Epoch 3666/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3366 - accuracy: 0.8869 - val_loss: 1.5357 - val_accuracy: 0.6266\n",
      "Epoch 3667/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2998 - accuracy: 0.9023 - val_loss: 1.5205 - val_accuracy: 0.6266\n",
      "Epoch 3668/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3431 - accuracy: 0.8770 - val_loss: 1.4996 - val_accuracy: 0.6201\n",
      "Epoch 3669/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3217 - accuracy: 0.8897 - val_loss: 1.4749 - val_accuracy: 0.6266\n",
      "Epoch 3670/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3278 - accuracy: 0.9014 - val_loss: 1.4575 - val_accuracy: 0.6461\n",
      "Epoch 3671/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2847 - accuracy: 0.9141 - val_loss: 1.4602 - val_accuracy: 0.6558\n",
      "Epoch 3672/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3372 - accuracy: 0.8955 - val_loss: 1.4675 - val_accuracy: 0.6494\n",
      "Epoch 3673/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3009 - accuracy: 0.9004 - val_loss: 1.4898 - val_accuracy: 0.6429\n",
      "Epoch 3674/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3148 - accuracy: 0.8906 - val_loss: 1.5105 - val_accuracy: 0.6266\n",
      "Epoch 3675/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3810 - accuracy: 0.8827 - val_loss: 1.5722 - val_accuracy: 0.6234\n",
      "Epoch 3676/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3034 - accuracy: 0.9062 - val_loss: 1.6004 - val_accuracy: 0.6169\n",
      "Epoch 3677/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2916 - accuracy: 0.8984 - val_loss: 1.6376 - val_accuracy: 0.5974\n",
      "Epoch 3678/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2912 - accuracy: 0.9023 - val_loss: 1.6557 - val_accuracy: 0.5909\n",
      "Epoch 3679/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3167 - accuracy: 0.9036 - val_loss: 1.6638 - val_accuracy: 0.5779\n",
      "Epoch 3680/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3265 - accuracy: 0.8994 - val_loss: 1.6844 - val_accuracy: 0.5747\n",
      "Epoch 3681/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3581 - accuracy: 0.8789 - val_loss: 1.6740 - val_accuracy: 0.5812\n",
      "Epoch 3682/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2894 - accuracy: 0.9131 - val_loss: 1.6314 - val_accuracy: 0.5942\n",
      "Epoch 3683/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3444 - accuracy: 0.8818 - val_loss: 1.5567 - val_accuracy: 0.6169\n",
      "Epoch 3684/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3158 - accuracy: 0.8984 - val_loss: 1.5144 - val_accuracy: 0.6136\n",
      "Epoch 3685/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2889 - accuracy: 0.8994 - val_loss: 1.4903 - val_accuracy: 0.6234\n",
      "Epoch 3686/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3211 - accuracy: 0.9078 - val_loss: 1.4782 - val_accuracy: 0.6331\n",
      "Epoch 3687/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3146 - accuracy: 0.8955 - val_loss: 1.4777 - val_accuracy: 0.6331\n",
      "Epoch 3688/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2995 - accuracy: 0.9050 - val_loss: 1.4666 - val_accuracy: 0.6494\n",
      "Epoch 3689/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3050 - accuracy: 0.9022 - val_loss: 1.4656 - val_accuracy: 0.6558\n",
      "Epoch 3690/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3317 - accuracy: 0.8945 - val_loss: 1.4739 - val_accuracy: 0.6526\n",
      "Epoch 3691/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3522 - accuracy: 0.8857 - val_loss: 1.4994 - val_accuracy: 0.6429\n",
      "Epoch 3692/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2644 - accuracy: 0.9092 - val_loss: 1.5301 - val_accuracy: 0.6331\n",
      "Epoch 3693/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2991 - accuracy: 0.9121 - val_loss: 1.5388 - val_accuracy: 0.6201\n",
      "Epoch 3694/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2660 - accuracy: 0.9092 - val_loss: 1.5431 - val_accuracy: 0.6201\n",
      "Epoch 3695/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2777 - accuracy: 0.9150 - val_loss: 1.5499 - val_accuracy: 0.6201\n",
      "Epoch 3696/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3340 - accuracy: 0.8867 - val_loss: 1.5494 - val_accuracy: 0.6071\n",
      "Epoch 3697/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3482 - accuracy: 0.9022 - val_loss: 1.5260 - val_accuracy: 0.6169\n",
      "Epoch 3698/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2652 - accuracy: 0.9148 - val_loss: 1.5031 - val_accuracy: 0.6136\n",
      "Epoch 3699/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3127 - accuracy: 0.8965 - val_loss: 1.5130 - val_accuracy: 0.6266\n",
      "Epoch 3700/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3812 - accuracy: 0.8757 - val_loss: 1.5180 - val_accuracy: 0.6169\n",
      "Epoch 3701/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2901 - accuracy: 0.9078 - val_loss: 1.5139 - val_accuracy: 0.6234\n",
      "Epoch 3702/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3721 - accuracy: 0.8855 - val_loss: 1.5279 - val_accuracy: 0.6299\n",
      "Epoch 3703/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3153 - accuracy: 0.8994 - val_loss: 1.5518 - val_accuracy: 0.6169\n",
      "Epoch 3704/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3102 - accuracy: 0.9064 - val_loss: 1.5910 - val_accuracy: 0.5974\n",
      "Epoch 3705/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3243 - accuracy: 0.8906 - val_loss: 1.6392 - val_accuracy: 0.5877\n",
      "Epoch 3706/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3158 - accuracy: 0.8911 - val_loss: 1.6995 - val_accuracy: 0.5747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3707/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3371 - accuracy: 0.8936 - val_loss: 1.7426 - val_accuracy: 0.5682\n",
      "Epoch 3708/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3534 - accuracy: 0.8799 - val_loss: 1.7594 - val_accuracy: 0.5747\n",
      "Epoch 3709/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2720 - accuracy: 0.9180 - val_loss: 1.7353 - val_accuracy: 0.5779\n",
      "Epoch 3710/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3410 - accuracy: 0.9036 - val_loss: 1.6834 - val_accuracy: 0.5877\n",
      "Epoch 3711/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2432 - accuracy: 0.9189 - val_loss: 1.6406 - val_accuracy: 0.5877\n",
      "Epoch 3712/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3269 - accuracy: 0.9053 - val_loss: 1.6154 - val_accuracy: 0.5877\n",
      "Epoch 3713/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3531 - accuracy: 0.8827 - val_loss: 1.6001 - val_accuracy: 0.5942\n",
      "Epoch 3714/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3074 - accuracy: 0.9014 - val_loss: 1.5794 - val_accuracy: 0.5974\n",
      "Epoch 3715/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3740 - accuracy: 0.8740 - val_loss: 1.5717 - val_accuracy: 0.6039\n",
      "Epoch 3716/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3172 - accuracy: 0.8945 - val_loss: 1.5636 - val_accuracy: 0.6104\n",
      "Epoch 3717/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3402 - accuracy: 0.8848 - val_loss: 1.5769 - val_accuracy: 0.6234\n",
      "Epoch 3718/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2559 - accuracy: 0.9162 - val_loss: 1.5994 - val_accuracy: 0.6039\n",
      "Epoch 3719/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3179 - accuracy: 0.8925 - val_loss: 1.6022 - val_accuracy: 0.6006\n",
      "Epoch 3720/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3787 - accuracy: 0.8799 - val_loss: 1.5821 - val_accuracy: 0.6104\n",
      "Epoch 3721/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3079 - accuracy: 0.9050 - val_loss: 1.5611 - val_accuracy: 0.6234\n",
      "Epoch 3722/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3253 - accuracy: 0.8953 - val_loss: 1.5481 - val_accuracy: 0.6299\n",
      "Epoch 3723/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3394 - accuracy: 0.8936 - val_loss: 1.5289 - val_accuracy: 0.6331\n",
      "Epoch 3724/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2854 - accuracy: 0.9008 - val_loss: 1.5148 - val_accuracy: 0.6266\n",
      "Epoch 3725/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3009 - accuracy: 0.9050 - val_loss: 1.4979 - val_accuracy: 0.6234\n",
      "Epoch 3726/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3340 - accuracy: 0.8945 - val_loss: 1.4964 - val_accuracy: 0.6169\n",
      "Epoch 3727/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3244 - accuracy: 0.8994 - val_loss: 1.5088 - val_accuracy: 0.6201\n",
      "Epoch 3728/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3132 - accuracy: 0.9022 - val_loss: 1.5173 - val_accuracy: 0.6039\n",
      "Epoch 3729/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2591 - accuracy: 0.9160 - val_loss: 1.5412 - val_accuracy: 0.6071\n",
      "Epoch 3730/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3322 - accuracy: 0.8838 - val_loss: 1.5675 - val_accuracy: 0.6071\n",
      "Epoch 3731/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3140 - accuracy: 0.8994 - val_loss: 1.5822 - val_accuracy: 0.6006\n",
      "Epoch 3732/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3310 - accuracy: 0.8965 - val_loss: 1.5844 - val_accuracy: 0.6006\n",
      "Epoch 3733/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3212 - accuracy: 0.8994 - val_loss: 1.5843 - val_accuracy: 0.6136\n",
      "Epoch 3734/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2940 - accuracy: 0.9078 - val_loss: 1.5793 - val_accuracy: 0.6201\n",
      "Epoch 3735/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2915 - accuracy: 0.9043 - val_loss: 1.5628 - val_accuracy: 0.6169\n",
      "Epoch 3736/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3168 - accuracy: 0.8936 - val_loss: 1.5453 - val_accuracy: 0.6006\n",
      "Epoch 3737/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3549 - accuracy: 0.8841 - val_loss: 1.5306 - val_accuracy: 0.6071\n",
      "Epoch 3738/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3134 - accuracy: 0.8966 - val_loss: 1.5180 - val_accuracy: 0.6136\n",
      "Epoch 3739/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2505 - accuracy: 0.9092 - val_loss: 1.5029 - val_accuracy: 0.6136\n",
      "Epoch 3740/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3697 - accuracy: 0.8828 - val_loss: 1.4859 - val_accuracy: 0.6234\n",
      "Epoch 3741/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3074 - accuracy: 0.9008 - val_loss: 1.4809 - val_accuracy: 0.6234\n",
      "Epoch 3742/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3028 - accuracy: 0.9036 - val_loss: 1.4733 - val_accuracy: 0.6364\n",
      "Epoch 3743/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3931 - accuracy: 0.8743 - val_loss: 1.4724 - val_accuracy: 0.6396\n",
      "Epoch 3744/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3414 - accuracy: 0.9022 - val_loss: 1.4720 - val_accuracy: 0.6396\n",
      "Epoch 3745/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2873 - accuracy: 0.9092 - val_loss: 1.4640 - val_accuracy: 0.6494\n",
      "Epoch 3746/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2568 - accuracy: 0.9121 - val_loss: 1.4587 - val_accuracy: 0.6429\n",
      "Epoch 3747/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2757 - accuracy: 0.9033 - val_loss: 1.4519 - val_accuracy: 0.6494\n",
      "Epoch 3748/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2974 - accuracy: 0.9121 - val_loss: 1.4498 - val_accuracy: 0.6429\n",
      "Epoch 3749/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3011 - accuracy: 0.9064 - val_loss: 1.4425 - val_accuracy: 0.6429\n",
      "Epoch 3750/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2963 - accuracy: 0.9199 - val_loss: 1.4387 - val_accuracy: 0.6396\n",
      "Epoch 3751/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3065 - accuracy: 0.8965 - val_loss: 1.4526 - val_accuracy: 0.6396\n",
      "Epoch 3752/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3357 - accuracy: 0.8911 - val_loss: 1.4448 - val_accuracy: 0.6364\n",
      "Epoch 3753/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2775 - accuracy: 0.8966 - val_loss: 1.4365 - val_accuracy: 0.6364\n",
      "Epoch 3754/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2988 - accuracy: 0.8926 - val_loss: 1.4365 - val_accuracy: 0.6494\n",
      "Epoch 3755/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2482 - accuracy: 0.9078 - val_loss: 1.4374 - val_accuracy: 0.6526\n",
      "Epoch 3756/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3208 - accuracy: 0.8926 - val_loss: 1.4475 - val_accuracy: 0.6526\n",
      "Epoch 3757/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2715 - accuracy: 0.9062 - val_loss: 1.4659 - val_accuracy: 0.6591\n",
      "Epoch 3758/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3374 - accuracy: 0.8848 - val_loss: 1.4906 - val_accuracy: 0.6558\n",
      "Epoch 3759/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2498 - accuracy: 0.9160 - val_loss: 1.5187 - val_accuracy: 0.6494\n",
      "Epoch 3760/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2970 - accuracy: 0.8911 - val_loss: 1.5464 - val_accuracy: 0.6494\n",
      "Epoch 3761/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2608 - accuracy: 0.9078 - val_loss: 1.5805 - val_accuracy: 0.6429\n",
      "Epoch 3762/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3416 - accuracy: 0.8897 - val_loss: 1.6101 - val_accuracy: 0.6331\n",
      "Epoch 3763/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3147 - accuracy: 0.9036 - val_loss: 1.6325 - val_accuracy: 0.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3764/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3244 - accuracy: 0.8925 - val_loss: 1.6518 - val_accuracy: 0.6169\n",
      "Epoch 3765/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3124 - accuracy: 0.9043 - val_loss: 1.6625 - val_accuracy: 0.6136\n",
      "Epoch 3766/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3054 - accuracy: 0.9023 - val_loss: 1.6709 - val_accuracy: 0.6136\n",
      "Epoch 3767/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2934 - accuracy: 0.9050 - val_loss: 1.6593 - val_accuracy: 0.6006\n",
      "Epoch 3768/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3210 - accuracy: 0.8869 - val_loss: 1.6452 - val_accuracy: 0.5974\n",
      "Epoch 3769/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3077 - accuracy: 0.9023 - val_loss: 1.6347 - val_accuracy: 0.5974\n",
      "Epoch 3770/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3429 - accuracy: 0.8897 - val_loss: 1.6462 - val_accuracy: 0.5877\n",
      "Epoch 3771/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2751 - accuracy: 0.9232 - val_loss: 1.6347 - val_accuracy: 0.5942\n",
      "Epoch 3772/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2870 - accuracy: 0.9141 - val_loss: 1.6267 - val_accuracy: 0.5812\n",
      "Epoch 3773/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2979 - accuracy: 0.8980 - val_loss: 1.6188 - val_accuracy: 0.5812\n",
      "Epoch 3774/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3207 - accuracy: 0.9050 - val_loss: 1.6219 - val_accuracy: 0.5877\n",
      "Epoch 3775/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3219 - accuracy: 0.8926 - val_loss: 1.6408 - val_accuracy: 0.5942\n",
      "Epoch 3776/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3049 - accuracy: 0.9072 - val_loss: 1.6580 - val_accuracy: 0.5909\n",
      "Epoch 3777/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3145 - accuracy: 0.8945 - val_loss: 1.6785 - val_accuracy: 0.5877\n",
      "Epoch 3778/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3179 - accuracy: 0.9008 - val_loss: 1.6756 - val_accuracy: 0.6006\n",
      "Epoch 3779/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2736 - accuracy: 0.9036 - val_loss: 1.6794 - val_accuracy: 0.6071\n",
      "Epoch 3780/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2985 - accuracy: 0.9106 - val_loss: 1.6768 - val_accuracy: 0.6039\n",
      "Epoch 3781/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2768 - accuracy: 0.9102 - val_loss: 1.6476 - val_accuracy: 0.6071\n",
      "Epoch 3782/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3190 - accuracy: 0.9148 - val_loss: 1.6024 - val_accuracy: 0.6169\n",
      "Epoch 3783/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2879 - accuracy: 0.9043 - val_loss: 1.5601 - val_accuracy: 0.6234\n",
      "Epoch 3784/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2952 - accuracy: 0.9043 - val_loss: 1.5298 - val_accuracy: 0.6266\n",
      "Epoch 3785/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2842 - accuracy: 0.9082 - val_loss: 1.5076 - val_accuracy: 0.6299\n",
      "Epoch 3786/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3322 - accuracy: 0.8953 - val_loss: 1.4950 - val_accuracy: 0.6299\n",
      "Epoch 3787/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3589 - accuracy: 0.8877 - val_loss: 1.4851 - val_accuracy: 0.6201\n",
      "Epoch 3788/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3079 - accuracy: 0.8953 - val_loss: 1.4703 - val_accuracy: 0.6234\n",
      "Epoch 3789/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2596 - accuracy: 0.9162 - val_loss: 1.4671 - val_accuracy: 0.6266\n",
      "Epoch 3790/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3144 - accuracy: 0.9004 - val_loss: 1.4690 - val_accuracy: 0.6201\n",
      "Epoch 3791/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2702 - accuracy: 0.9092 - val_loss: 1.4691 - val_accuracy: 0.6299\n",
      "Epoch 3792/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3056 - accuracy: 0.8994 - val_loss: 1.4661 - val_accuracy: 0.6266\n",
      "Epoch 3793/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2918 - accuracy: 0.8939 - val_loss: 1.4720 - val_accuracy: 0.6331\n",
      "Epoch 3794/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2848 - accuracy: 0.8994 - val_loss: 1.4727 - val_accuracy: 0.6331\n",
      "Epoch 3795/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3076 - accuracy: 0.8975 - val_loss: 1.4708 - val_accuracy: 0.6169\n",
      "Epoch 3796/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3170 - accuracy: 0.8980 - val_loss: 1.4676 - val_accuracy: 0.6169\n",
      "Epoch 3797/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3323 - accuracy: 0.8906 - val_loss: 1.4572 - val_accuracy: 0.6331\n",
      "Epoch 3798/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2596 - accuracy: 0.9274 - val_loss: 1.4474 - val_accuracy: 0.6396\n",
      "Epoch 3799/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3038 - accuracy: 0.8994 - val_loss: 1.4358 - val_accuracy: 0.6494\n",
      "Epoch 3800/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2975 - accuracy: 0.9033 - val_loss: 1.4319 - val_accuracy: 0.6494\n",
      "Epoch 3801/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3162 - accuracy: 0.9008 - val_loss: 1.4295 - val_accuracy: 0.6494\n",
      "Epoch 3802/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2813 - accuracy: 0.9106 - val_loss: 1.4306 - val_accuracy: 0.6494\n",
      "Epoch 3803/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2899 - accuracy: 0.9176 - val_loss: 1.4310 - val_accuracy: 0.6429\n",
      "Epoch 3804/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3425 - accuracy: 0.8855 - val_loss: 1.4380 - val_accuracy: 0.6429\n",
      "Epoch 3805/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2804 - accuracy: 0.9150 - val_loss: 1.4551 - val_accuracy: 0.6494\n",
      "Epoch 3806/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2874 - accuracy: 0.9180 - val_loss: 1.4920 - val_accuracy: 0.6461\n",
      "Epoch 3807/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2901 - accuracy: 0.9111 - val_loss: 1.5490 - val_accuracy: 0.6461\n",
      "Epoch 3808/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3066 - accuracy: 0.9053 - val_loss: 1.5936 - val_accuracy: 0.6364\n",
      "Epoch 3809/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2948 - accuracy: 0.9106 - val_loss: 1.6084 - val_accuracy: 0.6299\n",
      "Epoch 3810/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3366 - accuracy: 0.8869 - val_loss: 1.5957 - val_accuracy: 0.6299\n",
      "Epoch 3811/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3239 - accuracy: 0.8966 - val_loss: 1.5633 - val_accuracy: 0.6364\n",
      "Epoch 3812/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2539 - accuracy: 0.9180 - val_loss: 1.5540 - val_accuracy: 0.6299\n",
      "Epoch 3813/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2797 - accuracy: 0.9106 - val_loss: 1.5593 - val_accuracy: 0.6429\n",
      "Epoch 3814/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2969 - accuracy: 0.8994 - val_loss: 1.5642 - val_accuracy: 0.6396\n",
      "Epoch 3815/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2733 - accuracy: 0.9218 - val_loss: 1.5592 - val_accuracy: 0.6364\n",
      "Epoch 3816/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2548 - accuracy: 0.9111 - val_loss: 1.5583 - val_accuracy: 0.6299\n",
      "Epoch 3817/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3025 - accuracy: 0.8980 - val_loss: 1.5661 - val_accuracy: 0.6364\n",
      "Epoch 3818/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3000 - accuracy: 0.8975 - val_loss: 1.5811 - val_accuracy: 0.6331\n",
      "Epoch 3819/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3198 - accuracy: 0.8926 - val_loss: 1.5763 - val_accuracy: 0.6396\n",
      "Epoch 3820/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2544 - accuracy: 0.9176 - val_loss: 1.5656 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3821/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3121 - accuracy: 0.8965 - val_loss: 1.5521 - val_accuracy: 0.6364\n",
      "Epoch 3822/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2791 - accuracy: 0.9092 - val_loss: 1.5406 - val_accuracy: 0.6396\n",
      "Epoch 3823/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2903 - accuracy: 0.9092 - val_loss: 1.5432 - val_accuracy: 0.6429\n",
      "Epoch 3824/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2944 - accuracy: 0.9148 - val_loss: 1.5430 - val_accuracy: 0.6396\n",
      "Epoch 3825/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2721 - accuracy: 0.9150 - val_loss: 1.5455 - val_accuracy: 0.6364\n",
      "Epoch 3826/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3202 - accuracy: 0.8953 - val_loss: 1.5407 - val_accuracy: 0.6396\n",
      "Epoch 3827/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3433 - accuracy: 0.9064 - val_loss: 1.5405 - val_accuracy: 0.6234\n",
      "Epoch 3828/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2645 - accuracy: 0.9134 - val_loss: 1.5314 - val_accuracy: 0.6234\n",
      "Epoch 3829/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2461 - accuracy: 0.9148 - val_loss: 1.5225 - val_accuracy: 0.6266\n",
      "Epoch 3830/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3101 - accuracy: 0.9004 - val_loss: 1.5217 - val_accuracy: 0.6266\n",
      "Epoch 3831/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3200 - accuracy: 0.8925 - val_loss: 1.5393 - val_accuracy: 0.6331\n",
      "Epoch 3832/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2962 - accuracy: 0.8994 - val_loss: 1.5802 - val_accuracy: 0.6396\n",
      "Epoch 3833/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3197 - accuracy: 0.8906 - val_loss: 1.6357 - val_accuracy: 0.6201\n",
      "Epoch 3834/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3342 - accuracy: 0.8916 - val_loss: 1.6836 - val_accuracy: 0.6136\n",
      "Epoch 3835/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2638 - accuracy: 0.9190 - val_loss: 1.7355 - val_accuracy: 0.6039\n",
      "Epoch 3836/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2741 - accuracy: 0.9082 - val_loss: 1.7705 - val_accuracy: 0.6006\n",
      "Epoch 3837/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2938 - accuracy: 0.9082 - val_loss: 1.8018 - val_accuracy: 0.5942\n",
      "Epoch 3838/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3267 - accuracy: 0.8994 - val_loss: 1.8125 - val_accuracy: 0.6006\n",
      "Epoch 3839/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3659 - accuracy: 0.8789 - val_loss: 1.7826 - val_accuracy: 0.6039\n",
      "Epoch 3840/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2874 - accuracy: 0.9078 - val_loss: 1.7416 - val_accuracy: 0.5942\n",
      "Epoch 3841/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2779 - accuracy: 0.9014 - val_loss: 1.7040 - val_accuracy: 0.5942\n",
      "Epoch 3842/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2932 - accuracy: 0.9053 - val_loss: 1.6691 - val_accuracy: 0.6169\n",
      "Epoch 3843/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2642 - accuracy: 0.9148 - val_loss: 1.6466 - val_accuracy: 0.6201\n",
      "Epoch 3844/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2799 - accuracy: 0.9053 - val_loss: 1.6318 - val_accuracy: 0.6331\n",
      "Epoch 3845/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3106 - accuracy: 0.8965 - val_loss: 1.6253 - val_accuracy: 0.6299\n",
      "Epoch 3846/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3209 - accuracy: 0.9033 - val_loss: 1.6188 - val_accuracy: 0.6266\n",
      "Epoch 3847/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2629 - accuracy: 0.9078 - val_loss: 1.6256 - val_accuracy: 0.6201\n",
      "Epoch 3848/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2652 - accuracy: 0.9082 - val_loss: 1.6381 - val_accuracy: 0.6201\n",
      "Epoch 3849/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2909 - accuracy: 0.9022 - val_loss: 1.6623 - val_accuracy: 0.6201\n",
      "Epoch 3850/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2837 - accuracy: 0.9062 - val_loss: 1.6901 - val_accuracy: 0.6006\n",
      "Epoch 3851/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3021 - accuracy: 0.8939 - val_loss: 1.7222 - val_accuracy: 0.5942\n",
      "Epoch 3852/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2634 - accuracy: 0.9120 - val_loss: 1.7647 - val_accuracy: 0.5974\n",
      "Epoch 3853/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2419 - accuracy: 0.9162 - val_loss: 1.7998 - val_accuracy: 0.5812\n",
      "Epoch 3854/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3017 - accuracy: 0.9082 - val_loss: 1.8101 - val_accuracy: 0.5779\n",
      "Epoch 3855/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2806 - accuracy: 0.9106 - val_loss: 1.7931 - val_accuracy: 0.5812\n",
      "Epoch 3856/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3024 - accuracy: 0.8980 - val_loss: 1.7537 - val_accuracy: 0.5877\n",
      "Epoch 3857/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2594 - accuracy: 0.9131 - val_loss: 1.6828 - val_accuracy: 0.6006\n",
      "Epoch 3858/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2856 - accuracy: 0.9004 - val_loss: 1.6037 - val_accuracy: 0.6136\n",
      "Epoch 3859/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2763 - accuracy: 0.9160 - val_loss: 1.5406 - val_accuracy: 0.6201\n",
      "Epoch 3860/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2684 - accuracy: 0.9170 - val_loss: 1.5055 - val_accuracy: 0.6331\n",
      "Epoch 3861/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2684 - accuracy: 0.9260 - val_loss: 1.4807 - val_accuracy: 0.6429\n",
      "Epoch 3862/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2683 - accuracy: 0.9131 - val_loss: 1.4602 - val_accuracy: 0.6494\n",
      "Epoch 3863/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3457 - accuracy: 0.8936 - val_loss: 1.4540 - val_accuracy: 0.6688\n",
      "Epoch 3864/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2921 - accuracy: 0.8966 - val_loss: 1.4521 - val_accuracy: 0.6721\n",
      "Epoch 3865/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2981 - accuracy: 0.9008 - val_loss: 1.4569 - val_accuracy: 0.6688\n",
      "Epoch 3866/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2945 - accuracy: 0.9036 - val_loss: 1.4651 - val_accuracy: 0.6591\n",
      "Epoch 3867/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2957 - accuracy: 0.8994 - val_loss: 1.4566 - val_accuracy: 0.6429\n",
      "Epoch 3868/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3285 - accuracy: 0.8896 - val_loss: 1.4457 - val_accuracy: 0.6558\n",
      "Epoch 3869/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2937 - accuracy: 0.9082 - val_loss: 1.4427 - val_accuracy: 0.6526\n",
      "Epoch 3870/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3364 - accuracy: 0.8953 - val_loss: 1.4577 - val_accuracy: 0.6526\n",
      "Epoch 3871/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2757 - accuracy: 0.9050 - val_loss: 1.4583 - val_accuracy: 0.6558\n",
      "Epoch 3872/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2838 - accuracy: 0.9062 - val_loss: 1.4612 - val_accuracy: 0.6526\n",
      "Epoch 3873/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2689 - accuracy: 0.9134 - val_loss: 1.4778 - val_accuracy: 0.6526\n",
      "Epoch 3874/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2613 - accuracy: 0.9170 - val_loss: 1.4895 - val_accuracy: 0.6461\n",
      "Epoch 3875/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3080 - accuracy: 0.8939 - val_loss: 1.5141 - val_accuracy: 0.6299\n",
      "Epoch 3876/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2799 - accuracy: 0.9004 - val_loss: 1.5442 - val_accuracy: 0.6396\n",
      "Epoch 3877/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2910 - accuracy: 0.9043 - val_loss: 1.5724 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3878/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2757 - accuracy: 0.9232 - val_loss: 1.6070 - val_accuracy: 0.6136\n",
      "Epoch 3879/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2391 - accuracy: 0.9344 - val_loss: 1.6208 - val_accuracy: 0.6104\n",
      "Epoch 3880/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3007 - accuracy: 0.9072 - val_loss: 1.6203 - val_accuracy: 0.6136\n",
      "Epoch 3881/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2739 - accuracy: 0.9111 - val_loss: 1.5833 - val_accuracy: 0.6201\n",
      "Epoch 3882/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2572 - accuracy: 0.9176 - val_loss: 1.5560 - val_accuracy: 0.6201\n",
      "Epoch 3883/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3092 - accuracy: 0.8877 - val_loss: 1.5217 - val_accuracy: 0.6169\n",
      "Epoch 3884/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2977 - accuracy: 0.9022 - val_loss: 1.4708 - val_accuracy: 0.6396\n",
      "Epoch 3885/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3180 - accuracy: 0.8906 - val_loss: 1.4248 - val_accuracy: 0.6558\n",
      "Epoch 3886/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2604 - accuracy: 0.9141 - val_loss: 1.4213 - val_accuracy: 0.6591\n",
      "Epoch 3887/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2611 - accuracy: 0.9148 - val_loss: 1.4151 - val_accuracy: 0.6656\n",
      "Epoch 3888/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4002 - accuracy: 0.8955 - val_loss: 1.4089 - val_accuracy: 0.6721\n",
      "Epoch 3889/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2882 - accuracy: 0.9111 - val_loss: 1.4315 - val_accuracy: 0.6656\n",
      "Epoch 3890/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3144 - accuracy: 0.9008 - val_loss: 1.4573 - val_accuracy: 0.6656\n",
      "Epoch 3891/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3051 - accuracy: 0.8994 - val_loss: 1.4977 - val_accuracy: 0.6526\n",
      "Epoch 3892/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2819 - accuracy: 0.9053 - val_loss: 1.5334 - val_accuracy: 0.6494\n",
      "Epoch 3893/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2658 - accuracy: 0.9219 - val_loss: 1.5625 - val_accuracy: 0.6429\n",
      "Epoch 3894/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3059 - accuracy: 0.8975 - val_loss: 1.5885 - val_accuracy: 0.6396\n",
      "Epoch 3895/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3106 - accuracy: 0.9004 - val_loss: 1.6057 - val_accuracy: 0.6364\n",
      "Epoch 3896/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3077 - accuracy: 0.9120 - val_loss: 1.6258 - val_accuracy: 0.6201\n",
      "Epoch 3897/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2856 - accuracy: 0.9078 - val_loss: 1.6275 - val_accuracy: 0.6039\n",
      "Epoch 3898/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2932 - accuracy: 0.9014 - val_loss: 1.6321 - val_accuracy: 0.6039\n",
      "Epoch 3899/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3000 - accuracy: 0.9092 - val_loss: 1.6375 - val_accuracy: 0.6169\n",
      "Epoch 3900/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2819 - accuracy: 0.9023 - val_loss: 1.6719 - val_accuracy: 0.6136\n",
      "Epoch 3901/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2801 - accuracy: 0.9064 - val_loss: 1.7098 - val_accuracy: 0.6039\n",
      "Epoch 3902/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2904 - accuracy: 0.9053 - val_loss: 1.7266 - val_accuracy: 0.6006\n",
      "Epoch 3903/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2900 - accuracy: 0.9078 - val_loss: 1.7443 - val_accuracy: 0.6104\n",
      "Epoch 3904/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3012 - accuracy: 0.9141 - val_loss: 1.7554 - val_accuracy: 0.6071\n",
      "Epoch 3905/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2728 - accuracy: 0.9148 - val_loss: 1.7630 - val_accuracy: 0.6039\n",
      "Epoch 3906/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2571 - accuracy: 0.9131 - val_loss: 1.7497 - val_accuracy: 0.6071\n",
      "Epoch 3907/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3237 - accuracy: 0.9064 - val_loss: 1.7002 - val_accuracy: 0.5974\n",
      "Epoch 3908/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3115 - accuracy: 0.8965 - val_loss: 1.6803 - val_accuracy: 0.6006\n",
      "Epoch 3909/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2999 - accuracy: 0.9004 - val_loss: 1.6459 - val_accuracy: 0.6136\n",
      "Epoch 3910/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2997 - accuracy: 0.9111 - val_loss: 1.6092 - val_accuracy: 0.6234\n",
      "Epoch 3911/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2765 - accuracy: 0.9092 - val_loss: 1.5959 - val_accuracy: 0.6266\n",
      "Epoch 3912/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2873 - accuracy: 0.9033 - val_loss: 1.5847 - val_accuracy: 0.6234\n",
      "Epoch 3913/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3136 - accuracy: 0.9008 - val_loss: 1.5696 - val_accuracy: 0.6234\n",
      "Epoch 3914/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3084 - accuracy: 0.9064 - val_loss: 1.5569 - val_accuracy: 0.6331\n",
      "Epoch 3915/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2884 - accuracy: 0.9148 - val_loss: 1.5393 - val_accuracy: 0.6299\n",
      "Epoch 3916/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3004 - accuracy: 0.9053 - val_loss: 1.5300 - val_accuracy: 0.6396\n",
      "Epoch 3917/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2716 - accuracy: 0.9092 - val_loss: 1.5286 - val_accuracy: 0.6364\n",
      "Epoch 3918/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3149 - accuracy: 0.9043 - val_loss: 1.5331 - val_accuracy: 0.6396\n",
      "Epoch 3919/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2837 - accuracy: 0.9150 - val_loss: 1.5368 - val_accuracy: 0.6396\n",
      "Epoch 3920/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2799 - accuracy: 0.9053 - val_loss: 1.5447 - val_accuracy: 0.6429\n",
      "Epoch 3921/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2710 - accuracy: 0.8994 - val_loss: 1.5453 - val_accuracy: 0.6429\n",
      "Epoch 3922/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3024 - accuracy: 0.9008 - val_loss: 1.5340 - val_accuracy: 0.6494\n",
      "Epoch 3923/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2930 - accuracy: 0.9062 - val_loss: 1.5247 - val_accuracy: 0.6364\n",
      "Epoch 3924/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2636 - accuracy: 0.9134 - val_loss: 1.5253 - val_accuracy: 0.6364\n",
      "Epoch 3925/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2687 - accuracy: 0.9131 - val_loss: 1.5359 - val_accuracy: 0.6364\n",
      "Epoch 3926/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2534 - accuracy: 0.9232 - val_loss: 1.5401 - val_accuracy: 0.6396\n",
      "Epoch 3927/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2812 - accuracy: 0.9064 - val_loss: 1.5336 - val_accuracy: 0.6461\n",
      "Epoch 3928/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2881 - accuracy: 0.9141 - val_loss: 1.5277 - val_accuracy: 0.6429\n",
      "Epoch 3929/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3074 - accuracy: 0.9062 - val_loss: 1.5248 - val_accuracy: 0.6429\n",
      "Epoch 3930/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3051 - accuracy: 0.8939 - val_loss: 1.5210 - val_accuracy: 0.6526\n",
      "Epoch 3931/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2716 - accuracy: 0.9176 - val_loss: 1.5231 - val_accuracy: 0.6526\n",
      "Epoch 3932/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2360 - accuracy: 0.9232 - val_loss: 1.5284 - val_accuracy: 0.6494\n",
      "Epoch 3933/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3783 - accuracy: 0.8841 - val_loss: 1.5213 - val_accuracy: 0.6429\n",
      "Epoch 3934/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3144 - accuracy: 0.8848 - val_loss: 1.5188 - val_accuracy: 0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3935/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2906 - accuracy: 0.9064 - val_loss: 1.5131 - val_accuracy: 0.6234\n",
      "Epoch 3936/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2726 - accuracy: 0.9102 - val_loss: 1.5055 - val_accuracy: 0.6169\n",
      "Epoch 3937/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2850 - accuracy: 0.9053 - val_loss: 1.4993 - val_accuracy: 0.6234\n",
      "Epoch 3938/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3350 - accuracy: 0.8896 - val_loss: 1.4905 - val_accuracy: 0.6234\n",
      "Epoch 3939/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2695 - accuracy: 0.9043 - val_loss: 1.4837 - val_accuracy: 0.6299\n",
      "Epoch 3940/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2886 - accuracy: 0.9033 - val_loss: 1.4828 - val_accuracy: 0.6364\n",
      "Epoch 3941/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3073 - accuracy: 0.9036 - val_loss: 1.4953 - val_accuracy: 0.6266\n",
      "Epoch 3942/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2696 - accuracy: 0.9134 - val_loss: 1.5196 - val_accuracy: 0.6299\n",
      "Epoch 3943/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2760 - accuracy: 0.9082 - val_loss: 1.5473 - val_accuracy: 0.6234\n",
      "Epoch 3944/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3256 - accuracy: 0.8897 - val_loss: 1.5748 - val_accuracy: 0.6299\n",
      "Epoch 3945/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2804 - accuracy: 0.9120 - val_loss: 1.5920 - val_accuracy: 0.6201\n",
      "Epoch 3946/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2425 - accuracy: 0.9268 - val_loss: 1.6058 - val_accuracy: 0.6136\n",
      "Epoch 3947/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2954 - accuracy: 0.9120 - val_loss: 1.5904 - val_accuracy: 0.6136\n",
      "Epoch 3948/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2937 - accuracy: 0.9092 - val_loss: 1.5540 - val_accuracy: 0.6071\n",
      "Epoch 3949/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2899 - accuracy: 0.9064 - val_loss: 1.4987 - val_accuracy: 0.6071\n",
      "Epoch 3950/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2622 - accuracy: 0.9141 - val_loss: 1.4554 - val_accuracy: 0.6136\n",
      "Epoch 3951/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2960 - accuracy: 0.8984 - val_loss: 1.4143 - val_accuracy: 0.6494\n",
      "Epoch 3952/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2897 - accuracy: 0.9148 - val_loss: 1.3876 - val_accuracy: 0.6591\n",
      "Epoch 3953/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3229 - accuracy: 0.8994 - val_loss: 1.3769 - val_accuracy: 0.6591\n",
      "Epoch 3954/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3430 - accuracy: 0.9023 - val_loss: 1.3792 - val_accuracy: 0.6623\n",
      "Epoch 3955/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2830 - accuracy: 0.9082 - val_loss: 1.3935 - val_accuracy: 0.6721\n",
      "Epoch 3956/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3180 - accuracy: 0.9053 - val_loss: 1.4060 - val_accuracy: 0.6558\n",
      "Epoch 3957/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3088 - accuracy: 0.9082 - val_loss: 1.4277 - val_accuracy: 0.6526\n",
      "Epoch 3958/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2469 - accuracy: 0.9176 - val_loss: 1.4578 - val_accuracy: 0.6461\n",
      "Epoch 3959/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2936 - accuracy: 0.9092 - val_loss: 1.4967 - val_accuracy: 0.6364\n",
      "Epoch 3960/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3159 - accuracy: 0.8966 - val_loss: 1.5348 - val_accuracy: 0.6364\n",
      "Epoch 3961/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2682 - accuracy: 0.9043 - val_loss: 1.5408 - val_accuracy: 0.6299\n",
      "Epoch 3962/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3000 - accuracy: 0.9022 - val_loss: 1.5088 - val_accuracy: 0.6429\n",
      "Epoch 3963/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2833 - accuracy: 0.9190 - val_loss: 1.4796 - val_accuracy: 0.6396\n",
      "Epoch 3964/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3324 - accuracy: 0.9023 - val_loss: 1.4538 - val_accuracy: 0.6461\n",
      "Epoch 3965/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2823 - accuracy: 0.8984 - val_loss: 1.4254 - val_accuracy: 0.6591\n",
      "Epoch 3966/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3568 - accuracy: 0.8939 - val_loss: 1.4041 - val_accuracy: 0.6688\n",
      "Epoch 3967/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3118 - accuracy: 0.9022 - val_loss: 1.3909 - val_accuracy: 0.6558\n",
      "Epoch 3968/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2297 - accuracy: 0.9204 - val_loss: 1.3966 - val_accuracy: 0.6494\n",
      "Epoch 3969/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2923 - accuracy: 0.9120 - val_loss: 1.3985 - val_accuracy: 0.6494\n",
      "Epoch 3970/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2442 - accuracy: 0.9072 - val_loss: 1.4040 - val_accuracy: 0.6623\n",
      "Epoch 3971/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2876 - accuracy: 0.9092 - val_loss: 1.4157 - val_accuracy: 0.6526\n",
      "Epoch 3972/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2761 - accuracy: 0.9199 - val_loss: 1.4322 - val_accuracy: 0.6526\n",
      "Epoch 3973/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3295 - accuracy: 0.8939 - val_loss: 1.4724 - val_accuracy: 0.6364\n",
      "Epoch 3974/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2679 - accuracy: 0.9199 - val_loss: 1.5312 - val_accuracy: 0.6266\n",
      "Epoch 3975/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2817 - accuracy: 0.9078 - val_loss: 1.5949 - val_accuracy: 0.6201\n",
      "Epoch 3976/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2829 - accuracy: 0.8984 - val_loss: 1.6126 - val_accuracy: 0.6136\n",
      "Epoch 3977/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3392 - accuracy: 0.8925 - val_loss: 1.5675 - val_accuracy: 0.6169\n",
      "Epoch 3978/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3241 - accuracy: 0.8939 - val_loss: 1.5063 - val_accuracy: 0.6299\n",
      "Epoch 3979/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3297 - accuracy: 0.8953 - val_loss: 1.4734 - val_accuracy: 0.6331\n",
      "Epoch 3980/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3077 - accuracy: 0.8945 - val_loss: 1.4473 - val_accuracy: 0.6299\n",
      "Epoch 3981/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3349 - accuracy: 0.8867 - val_loss: 1.4392 - val_accuracy: 0.6234\n",
      "Epoch 3982/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3042 - accuracy: 0.8955 - val_loss: 1.4419 - val_accuracy: 0.6364\n",
      "Epoch 3983/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2948 - accuracy: 0.9014 - val_loss: 1.4430 - val_accuracy: 0.6396\n",
      "Epoch 3984/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2881 - accuracy: 0.9064 - val_loss: 1.4547 - val_accuracy: 0.6299\n",
      "Epoch 3985/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3025 - accuracy: 0.9092 - val_loss: 1.4668 - val_accuracy: 0.6234\n",
      "Epoch 3986/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2792 - accuracy: 0.9092 - val_loss: 1.4728 - val_accuracy: 0.6396\n",
      "Epoch 3987/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2669 - accuracy: 0.9120 - val_loss: 1.4875 - val_accuracy: 0.6364\n",
      "Epoch 3988/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2657 - accuracy: 0.9111 - val_loss: 1.5096 - val_accuracy: 0.6299\n",
      "Epoch 3989/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3062 - accuracy: 0.9004 - val_loss: 1.5220 - val_accuracy: 0.6234\n",
      "Epoch 3990/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2755 - accuracy: 0.9106 - val_loss: 1.5149 - val_accuracy: 0.6331\n",
      "Epoch 3991/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2722 - accuracy: 0.9199 - val_loss: 1.5279 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3992/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2761 - accuracy: 0.9033 - val_loss: 1.5566 - val_accuracy: 0.6169\n",
      "Epoch 3993/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2464 - accuracy: 0.9036 - val_loss: 1.5567 - val_accuracy: 0.6169\n",
      "Epoch 3994/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3355 - accuracy: 0.8925 - val_loss: 1.5282 - val_accuracy: 0.6136\n",
      "Epoch 3995/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2507 - accuracy: 0.9218 - val_loss: 1.5136 - val_accuracy: 0.6201\n",
      "Epoch 3996/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3037 - accuracy: 0.8994 - val_loss: 1.5035 - val_accuracy: 0.6234\n",
      "Epoch 3997/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2772 - accuracy: 0.9218 - val_loss: 1.4810 - val_accuracy: 0.6299\n",
      "Epoch 3998/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2962 - accuracy: 0.9014 - val_loss: 1.4771 - val_accuracy: 0.6461\n",
      "Epoch 3999/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2784 - accuracy: 0.8994 - val_loss: 1.4792 - val_accuracy: 0.6429\n",
      "Epoch 4000/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2982 - accuracy: 0.9078 - val_loss: 1.4857 - val_accuracy: 0.6461\n",
      "CNN: Epochs=4000, Train accuracy=0.93436, Validation accuracy=0.69805\n"
     ]
    }
   ],
   "source": [
    "epochs = 4000\n",
    "batch_size = 1024\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold로 훈련시키기\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "epochs = 800\n",
    "batch_size = 512\n",
    "\n",
    "for k_train_index, k_valid_index in kf.split(X, y):\n",
    "    history = model.fit(\n",
    "    datagen.flow(X[k_train_index,:], y[k_train_index,:], batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=X[k_train_index,:].shape[0]//batch_size,\n",
    "    validation_data=(X[k_valid_index,:], y[k_valid_index,:]),\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2603262,
     "status": "ok",
     "timestamp": 1598167802346,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "9bcd067b-5514-491c-8c63-db77d4fc6967"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####relu 대신 leaky relu 써보자########\n",
    "#####Adam보단 RMSprop이 좋은 듯도?######\n",
    "#####후에 early stopping도 추가 ########\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1598177058256,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "pHMuMFz1DsU2"
   },
   "outputs": [],
   "source": [
    "#model_10\n",
    "from tensorflow import keras\n",
    "#model_9-3 9-2에서 optimizer만 RMSprop로 바꿔봄\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), Adagrad(lr=0.01, epsilon=None, decay=0.0), adadelta, adam\n",
    "    model.compile(optimizer=RMSprop(lr=0.001, rho=0.95, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1598177058258,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "Lmn384nZDysV",
    "outputId": "5f3b3b04-604f-410c-ac92-0ec2f300de42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1201 (Conv2D)         (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1157 (Ba (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_630 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1202 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1158 (Ba (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_631 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1203 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1159 (Ba (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_632 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1204 (Conv2D)         (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1160 (Ba (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_633 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1205 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1161 (Ba (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_634 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1206 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1162 (Ba (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_635 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1207 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1163 (Ba (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_636 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1208 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1164 (Ba (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_637 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1209 (Conv2D)         (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1165 (Ba (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_638 (LeakyReLU)  (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_31  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_639 (LeakyReLU)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 125,392\n",
      "Trainable params: 124,720\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1598177058642,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yVsg_v1KD4rr"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.975 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 858204,
     "status": "ok",
     "timestamp": 1598177916752,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "_YuoyhnFD7qj",
    "outputId": "9a9e2baa-b85e-405f-d605-310f7ff15302",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 2.4998 - accuracy: 0.1276 - val_loss: 2.2552 - val_accuracy: 0.1526\n",
      "Epoch 2/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.2659 - accuracy: 0.1593 - val_loss: 2.1527 - val_accuracy: 0.2273\n",
      "Epoch 3/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.1901 - accuracy: 0.1868 - val_loss: 2.3029 - val_accuracy: 0.1201\n",
      "Epoch 4/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.1149 - accuracy: 0.2330 - val_loss: 2.4806 - val_accuracy: 0.1039\n",
      "Epoch 5/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.0548 - accuracy: 0.2617 - val_loss: 3.0083 - val_accuracy: 0.1039\n",
      "Epoch 6/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.9871 - accuracy: 0.2875 - val_loss: 2.8759 - val_accuracy: 0.1039\n",
      "Epoch 7/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.8967 - accuracy: 0.3226 - val_loss: 2.7598 - val_accuracy: 0.1169\n",
      "Epoch 8/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.8031 - accuracy: 0.3618 - val_loss: 3.1314 - val_accuracy: 0.1234\n",
      "Epoch 9/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.7294 - accuracy: 0.3852 - val_loss: 1.8271 - val_accuracy: 0.4221\n",
      "Epoch 10/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.6769 - accuracy: 0.3958 - val_loss: 1.2876 - val_accuracy: 0.6234\n",
      "Epoch 11/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.5821 - accuracy: 0.4420 - val_loss: 1.3205 - val_accuracy: 0.5877\n",
      "Epoch 12/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.5320 - accuracy: 0.4693 - val_loss: 1.2170 - val_accuracy: 0.6136\n",
      "Epoch 13/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.4765 - accuracy: 0.4795 - val_loss: 1.2912 - val_accuracy: 0.5877\n",
      "Epoch 14/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.4124 - accuracy: 0.5146 - val_loss: 1.2951 - val_accuracy: 0.5714\n",
      "Epoch 15/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.3823 - accuracy: 0.5187 - val_loss: 1.4694 - val_accuracy: 0.5065\n",
      "Epoch 16/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.3816 - accuracy: 0.5018 - val_loss: 1.0159 - val_accuracy: 0.6688\n",
      "Epoch 17/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.2975 - accuracy: 0.5527 - val_loss: 1.0708 - val_accuracy: 0.6429\n",
      "Epoch 18/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.2263 - accuracy: 0.5796 - val_loss: 0.9438 - val_accuracy: 0.6818\n",
      "Epoch 19/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.2246 - accuracy: 0.5790 - val_loss: 1.0757 - val_accuracy: 0.6429\n",
      "Epoch 20/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.1714 - accuracy: 0.6060 - val_loss: 0.8871 - val_accuracy: 0.6883\n",
      "Epoch 21/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.1384 - accuracy: 0.6189 - val_loss: 0.8942 - val_accuracy: 0.6883\n",
      "Epoch 22/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.1424 - accuracy: 0.6171 - val_loss: 0.8996 - val_accuracy: 0.6851\n",
      "Epoch 23/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.0789 - accuracy: 0.6352 - val_loss: 0.7822 - val_accuracy: 0.7338\n",
      "Epoch 24/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.0897 - accuracy: 0.6306 - val_loss: 0.7925 - val_accuracy: 0.7338\n",
      "Epoch 25/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.0528 - accuracy: 0.6411 - val_loss: 0.7672 - val_accuracy: 0.7338\n",
      "Epoch 26/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9782 - accuracy: 0.6569 - val_loss: 0.6813 - val_accuracy: 0.7727\n",
      "Epoch 27/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9853 - accuracy: 0.6692 - val_loss: 0.7866 - val_accuracy: 0.7370\n",
      "Epoch 28/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9913 - accuracy: 0.6628 - val_loss: 0.8792 - val_accuracy: 0.7013\n",
      "Epoch 29/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9389 - accuracy: 0.6797 - val_loss: 0.7541 - val_accuracy: 0.7403\n",
      "Epoch 30/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9157 - accuracy: 0.6821 - val_loss: 0.9700 - val_accuracy: 0.6688\n",
      "Epoch 31/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9173 - accuracy: 0.6944 - val_loss: 0.6722 - val_accuracy: 0.7695\n",
      "Epoch 32/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9178 - accuracy: 0.6909 - val_loss: 0.7221 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8738 - accuracy: 0.6915 - val_loss: 0.7235 - val_accuracy: 0.7597\n",
      "Epoch 34/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8717 - accuracy: 0.7067 - val_loss: 0.6963 - val_accuracy: 0.7727\n",
      "Epoch 35/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8594 - accuracy: 0.7190 - val_loss: 0.8186 - val_accuracy: 0.7175\n",
      "Epoch 36/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8376 - accuracy: 0.7149 - val_loss: 0.6815 - val_accuracy: 0.7825\n",
      "Epoch 37/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8354 - accuracy: 0.7084 - val_loss: 0.8090 - val_accuracy: 0.7305\n",
      "Epoch 38/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8459 - accuracy: 0.7137 - val_loss: 0.6092 - val_accuracy: 0.7955\n",
      "Epoch 39/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8059 - accuracy: 0.7336 - val_loss: 0.7836 - val_accuracy: 0.7338\n",
      "Epoch 40/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8178 - accuracy: 0.7219 - val_loss: 0.6750 - val_accuracy: 0.7597\n",
      "Epoch 41/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7811 - accuracy: 0.7254 - val_loss: 0.6522 - val_accuracy: 0.7630\n",
      "Epoch 42/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7963 - accuracy: 0.7365 - val_loss: 0.7445 - val_accuracy: 0.7435\n",
      "Epoch 43/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8059 - accuracy: 0.7196 - val_loss: 0.6496 - val_accuracy: 0.7857\n",
      "Epoch 44/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8114 - accuracy: 0.7149 - val_loss: 0.7443 - val_accuracy: 0.7305\n",
      "Epoch 45/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7662 - accuracy: 0.7500 - val_loss: 0.6249 - val_accuracy: 0.7792\n",
      "Epoch 46/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7500 - accuracy: 0.7383 - val_loss: 0.6272 - val_accuracy: 0.7890\n",
      "Epoch 47/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7456 - accuracy: 0.7447 - val_loss: 0.7600 - val_accuracy: 0.7468\n",
      "Epoch 48/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7262 - accuracy: 0.7488 - val_loss: 0.5925 - val_accuracy: 0.7987\n",
      "Epoch 49/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7260 - accuracy: 0.7412 - val_loss: 0.6221 - val_accuracy: 0.8019\n",
      "Epoch 50/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7505 - accuracy: 0.7559 - val_loss: 0.7101 - val_accuracy: 0.7435\n",
      "Epoch 51/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7277 - accuracy: 0.7535 - val_loss: 0.6287 - val_accuracy: 0.7857\n",
      "Epoch 52/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7258 - accuracy: 0.7465 - val_loss: 0.5989 - val_accuracy: 0.8052\n",
      "Epoch 53/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.6988 - accuracy: 0.7652 - val_loss: 0.6240 - val_accuracy: 0.7825\n",
      "Epoch 54/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7062 - accuracy: 0.7541 - val_loss: 0.6481 - val_accuracy: 0.8019\n",
      "Epoch 55/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6977 - accuracy: 0.7711 - val_loss: 0.6163 - val_accuracy: 0.7987\n",
      "Epoch 56/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6929 - accuracy: 0.7570 - val_loss: 0.6802 - val_accuracy: 0.7792\n",
      "Epoch 57/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7194 - accuracy: 0.7529 - val_loss: 0.6242 - val_accuracy: 0.7890\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6953 - accuracy: 0.7605 - val_loss: 0.6067 - val_accuracy: 0.8019\n",
      "Epoch 59/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6613 - accuracy: 0.7758 - val_loss: 0.6572 - val_accuracy: 0.7760\n",
      "Epoch 60/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6696 - accuracy: 0.7681 - val_loss: 0.8487 - val_accuracy: 0.7273\n",
      "Epoch 61/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6757 - accuracy: 0.7646 - val_loss: 0.7014 - val_accuracy: 0.7662\n",
      "Epoch 62/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6608 - accuracy: 0.7670 - val_loss: 0.6366 - val_accuracy: 0.7857\n",
      "Epoch 63/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6320 - accuracy: 0.7881 - val_loss: 0.7097 - val_accuracy: 0.7695\n",
      "Epoch 64/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6651 - accuracy: 0.7693 - val_loss: 0.6045 - val_accuracy: 0.7987\n",
      "Epoch 65/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6655 - accuracy: 0.7641 - val_loss: 0.6040 - val_accuracy: 0.7987\n",
      "Epoch 66/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6524 - accuracy: 0.7664 - val_loss: 0.6303 - val_accuracy: 0.8052\n",
      "Epoch 67/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6729 - accuracy: 0.7810 - val_loss: 0.6506 - val_accuracy: 0.7890\n",
      "Epoch 68/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6340 - accuracy: 0.7951 - val_loss: 0.6675 - val_accuracy: 0.7565\n",
      "Epoch 69/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6644 - accuracy: 0.7752 - val_loss: 0.5886 - val_accuracy: 0.8182\n",
      "Epoch 70/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6400 - accuracy: 0.7804 - val_loss: 0.5669 - val_accuracy: 0.7955\n",
      "Epoch 71/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6376 - accuracy: 0.7822 - val_loss: 0.5742 - val_accuracy: 0.8117\n",
      "Epoch 72/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6627 - accuracy: 0.7863 - val_loss: 0.6134 - val_accuracy: 0.8182\n",
      "Epoch 73/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6027 - accuracy: 0.7986 - val_loss: 0.6403 - val_accuracy: 0.7987\n",
      "Epoch 74/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6432 - accuracy: 0.7910 - val_loss: 0.6138 - val_accuracy: 0.7922\n",
      "Epoch 75/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6152 - accuracy: 0.7957 - val_loss: 0.5987 - val_accuracy: 0.8084\n",
      "Epoch 76/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6078 - accuracy: 0.7904 - val_loss: 0.6446 - val_accuracy: 0.7857\n",
      "Epoch 77/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6203 - accuracy: 0.7810 - val_loss: 0.6096 - val_accuracy: 0.7922\n",
      "Epoch 78/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6308 - accuracy: 0.7828 - val_loss: 0.6246 - val_accuracy: 0.7987\n",
      "Epoch 79/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6240 - accuracy: 0.7822 - val_loss: 0.6460 - val_accuracy: 0.7857\n",
      "Epoch 80/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6232 - accuracy: 0.7851 - val_loss: 0.6637 - val_accuracy: 0.7825\n",
      "Epoch 81/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6052 - accuracy: 0.7945 - val_loss: 0.7033 - val_accuracy: 0.7630\n",
      "Epoch 82/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6134 - accuracy: 0.7881 - val_loss: 0.5900 - val_accuracy: 0.7792\n",
      "Epoch 83/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6014 - accuracy: 0.7910 - val_loss: 0.6836 - val_accuracy: 0.7760\n",
      "Epoch 84/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5992 - accuracy: 0.7986 - val_loss: 0.6291 - val_accuracy: 0.7955\n",
      "Epoch 85/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5965 - accuracy: 0.8015 - val_loss: 0.6344 - val_accuracy: 0.7922\n",
      "Epoch 86/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6191 - accuracy: 0.7886 - val_loss: 0.6093 - val_accuracy: 0.7890\n",
      "Epoch 87/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6049 - accuracy: 0.7933 - val_loss: 0.6477 - val_accuracy: 0.7825\n",
      "Epoch 88/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5972 - accuracy: 0.7951 - val_loss: 0.5780 - val_accuracy: 0.8182\n",
      "Epoch 89/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6217 - accuracy: 0.7904 - val_loss: 0.5783 - val_accuracy: 0.8117\n",
      "Epoch 90/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6283 - accuracy: 0.7886 - val_loss: 0.6178 - val_accuracy: 0.8019\n",
      "Epoch 91/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5556 - accuracy: 0.8085 - val_loss: 0.5905 - val_accuracy: 0.8084\n",
      "Epoch 92/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5792 - accuracy: 0.8085 - val_loss: 0.6331 - val_accuracy: 0.8019\n",
      "Epoch 93/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5812 - accuracy: 0.7904 - val_loss: 0.6477 - val_accuracy: 0.7825\n",
      "Epoch 94/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5970 - accuracy: 0.7945 - val_loss: 0.6084 - val_accuracy: 0.8019\n",
      "Epoch 95/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5827 - accuracy: 0.7998 - val_loss: 0.6296 - val_accuracy: 0.7760\n",
      "Epoch 96/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5704 - accuracy: 0.8103 - val_loss: 0.5769 - val_accuracy: 0.8052\n",
      "Epoch 97/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5970 - accuracy: 0.7904 - val_loss: 0.6054 - val_accuracy: 0.7955\n",
      "Epoch 98/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5966 - accuracy: 0.7998 - val_loss: 0.5896 - val_accuracy: 0.8019\n",
      "Epoch 99/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5565 - accuracy: 0.8050 - val_loss: 0.6189 - val_accuracy: 0.7922\n",
      "Epoch 100/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5815 - accuracy: 0.8142 - val_loss: 0.6427 - val_accuracy: 0.7890\n",
      "Epoch 101/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5558 - accuracy: 0.8091 - val_loss: 0.6597 - val_accuracy: 0.7695\n",
      "Epoch 102/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5649 - accuracy: 0.8208 - val_loss: 0.6526 - val_accuracy: 0.7760\n",
      "Epoch 103/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5582 - accuracy: 0.8080 - val_loss: 0.6199 - val_accuracy: 0.7792\n",
      "Epoch 104/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5485 - accuracy: 0.8004 - val_loss: 0.6102 - val_accuracy: 0.8052\n",
      "Epoch 105/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5762 - accuracy: 0.7992 - val_loss: 0.6148 - val_accuracy: 0.8019\n",
      "Epoch 106/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5449 - accuracy: 0.8109 - val_loss: 0.5861 - val_accuracy: 0.7987\n",
      "Epoch 107/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5728 - accuracy: 0.8068 - val_loss: 0.5534 - val_accuracy: 0.8084\n",
      "Epoch 108/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5739 - accuracy: 0.8039 - val_loss: 0.6319 - val_accuracy: 0.7825\n",
      "Epoch 109/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5926 - accuracy: 0.7968 - val_loss: 0.6230 - val_accuracy: 0.7825\n",
      "Epoch 110/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5398 - accuracy: 0.8156 - val_loss: 0.6177 - val_accuracy: 0.7922\n",
      "Epoch 111/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5507 - accuracy: 0.8121 - val_loss: 0.5872 - val_accuracy: 0.7987\n",
      "Epoch 112/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5678 - accuracy: 0.8074 - val_loss: 0.5963 - val_accuracy: 0.7955\n",
      "Epoch 113/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5877 - accuracy: 0.7869 - val_loss: 0.5938 - val_accuracy: 0.7987\n",
      "Epoch 114/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5390 - accuracy: 0.8144 - val_loss: 0.6080 - val_accuracy: 0.7922\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5488 - accuracy: 0.8021 - val_loss: 0.5931 - val_accuracy: 0.7890\n",
      "Epoch 116/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5346 - accuracy: 0.8197 - val_loss: 0.6279 - val_accuracy: 0.7955\n",
      "Epoch 117/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5494 - accuracy: 0.8138 - val_loss: 0.6057 - val_accuracy: 0.7922\n",
      "Epoch 118/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5358 - accuracy: 0.8208 - val_loss: 0.6448 - val_accuracy: 0.7857\n",
      "Epoch 119/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5234 - accuracy: 0.8185 - val_loss: 0.6424 - val_accuracy: 0.7792\n",
      "Epoch 120/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8197 - val_loss: 0.6297 - val_accuracy: 0.7825\n",
      "Epoch 121/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5419 - accuracy: 0.8050 - val_loss: 0.6185 - val_accuracy: 0.7890\n",
      "Epoch 122/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5313 - accuracy: 0.8132 - val_loss: 0.6142 - val_accuracy: 0.7922\n",
      "Epoch 123/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5291 - accuracy: 0.8074 - val_loss: 0.6259 - val_accuracy: 0.7857\n",
      "Epoch 124/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5717 - accuracy: 0.8109 - val_loss: 0.6011 - val_accuracy: 0.7955\n",
      "Epoch 125/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5470 - accuracy: 0.8068 - val_loss: 0.5836 - val_accuracy: 0.8084\n",
      "Epoch 126/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8056 - val_loss: 0.6075 - val_accuracy: 0.8019\n",
      "Epoch 127/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5169 - accuracy: 0.8279 - val_loss: 0.6067 - val_accuracy: 0.7890\n",
      "Epoch 128/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5248 - accuracy: 0.8290 - val_loss: 0.6456 - val_accuracy: 0.7825\n",
      "Epoch 129/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5331 - accuracy: 0.8214 - val_loss: 0.5859 - val_accuracy: 0.8019\n",
      "Epoch 130/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5741 - accuracy: 0.8091 - val_loss: 0.5804 - val_accuracy: 0.8214\n",
      "Epoch 131/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5071 - accuracy: 0.8349 - val_loss: 0.6237 - val_accuracy: 0.7857\n",
      "Epoch 132/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5542 - accuracy: 0.8050 - val_loss: 0.5969 - val_accuracy: 0.8052\n",
      "Epoch 133/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5382 - accuracy: 0.8138 - val_loss: 0.6054 - val_accuracy: 0.8019\n",
      "Epoch 134/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8121 - val_loss: 0.6200 - val_accuracy: 0.7922\n",
      "Epoch 135/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5653 - accuracy: 0.8103 - val_loss: 0.5936 - val_accuracy: 0.7987\n",
      "Epoch 136/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5032 - accuracy: 0.8167 - val_loss: 0.6319 - val_accuracy: 0.7857\n",
      "Epoch 137/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5513 - accuracy: 0.8115 - val_loss: 0.6192 - val_accuracy: 0.7922\n",
      "Epoch 138/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5346 - accuracy: 0.8097 - val_loss: 0.6215 - val_accuracy: 0.7955\n",
      "Epoch 139/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5496 - accuracy: 0.8144 - val_loss: 0.6068 - val_accuracy: 0.7922\n",
      "Epoch 140/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.4722 - accuracy: 0.8367 - val_loss: 0.6097 - val_accuracy: 0.7890\n",
      "Epoch 141/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5471 - accuracy: 0.8138 - val_loss: 0.6330 - val_accuracy: 0.7760\n",
      "Epoch 142/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5260 - accuracy: 0.8273 - val_loss: 0.6185 - val_accuracy: 0.7825\n",
      "Epoch 143/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5475 - accuracy: 0.8068 - val_loss: 0.6198 - val_accuracy: 0.7987\n",
      "Epoch 144/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.4780 - accuracy: 0.8367 - val_loss: 0.6033 - val_accuracy: 0.7987\n",
      "Epoch 145/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5080 - accuracy: 0.8208 - val_loss: 0.6197 - val_accuracy: 0.7890\n",
      "Epoch 146/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5259 - accuracy: 0.8132 - val_loss: 0.6196 - val_accuracy: 0.7922\n",
      "Epoch 147/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5112 - accuracy: 0.8343 - val_loss: 0.5957 - val_accuracy: 0.7987\n",
      "Epoch 148/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5390 - accuracy: 0.8285 - val_loss: 0.6055 - val_accuracy: 0.7987\n",
      "Epoch 149/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5543 - accuracy: 0.8156 - val_loss: 0.6071 - val_accuracy: 0.7922\n",
      "Epoch 150/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5114 - accuracy: 0.8249 - val_loss: 0.6284 - val_accuracy: 0.7825\n",
      "CNN: Epochs=150, Train accuracy=0.83665, Validation accuracy=0.82143\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 847482,
     "status": "ok",
     "timestamp": 1598177917190,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "ztjVtlqWD_Nb",
    "outputId": "5b0440a7-235f-4ee6-dc8a-20925a204bb5"
   },
   "outputs": [],
   "source": [
    "#9까지는 콘볼루션 층 9개에 맥스풀링과 FC 첨가해서 필터 수나 러닝 레이트만 조절해봄\n",
    "#이번 model_10은 LeNet 참고하여 비슷한 구조로 얕게 층 쌓음 - 훈련 모델에 대한 오버피팅 심함\n",
    "\n",
    "#conv 층과 maxpooling 층에 strides=2 추가해서 해봄\n",
    "\n",
    "#randomsearch로 learning rate 등 하이퍼 파라미터 조절해보기\n",
    "#차라리 learning rate 줄이고 많이 시도? 진동하는 경향이 좀 보임 epoch 75부터 계~~~~속 0.7대 유지 - epoch 161 아직도 탈출 못함\n",
    "#0.003으로 했을 때 진동하는 듯 해서 0.001로 다시 돌아옴 - 근데 학습률이 낮아도 마찬가지로 local 최적에 빠지지 않을까? - global 최적 찾을 방법은??\n",
    "#이것도 진동에 빠진다면 0.002로 시도해보기\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 167612,
     "status": "aborted",
     "timestamp": 1598169622005,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "PD-P4Jt4MoI7"
   },
   "outputs": [],
   "source": [
    "#model_11 - 모델 10에서 Leaky ReLU나 PReLU나 Maxout 시도해보기\n",
    "#아무튼 적당한 활성화 함수 찾은 후 RandomSearch로 하이퍼파라미터 최적화\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, PReLU, \n",
    "    Add, Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1597999558839,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "RkVofda0MsDp",
    "outputId": "303bc178-314a-4b69-a342-b6fb04ffc8c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1174 (Conv2D)         (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_600 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1175 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_601 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1176 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_602 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1177 (Conv2D)         (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_603 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1178 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_604 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1179 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_605 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1180 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_606 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1181 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_607 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1182 (Conv2D)         (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_608 (LeakyReLU)  (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_28  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_609 (LeakyReLU)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 124,048\n",
      "Trainable params: 124,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UJzxDuhMvcE"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.975 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "ByQCa6DAMyRv",
    "outputId": "456de1d2-61df-46d0-b582-20df15e6a5c6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 230\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11108,
     "status": "ok",
     "timestamp": 1597818952144,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "j8AWxmI1RF-1",
    "outputId": "401d75f1-e73c-47b2-9c70-e54ec1c63627"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(valid_X, valid_y, verbose=2)\n",
    "print('테스트 손실함수:', test_loss, '\\n테스트 정확도:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vr35rvIqPNUu"
   },
   "source": [
    "시도해볼 것: maxout은 dropout과 함께 쓰면 효과가 좋은 활성화함수라고 함\n",
    "    - maxout 적용 예제 / 코드 찾아서 직접 사용해보기\n",
    "    - maxout의 단점은 파라미터의 수가 두배가 된다는 점\n",
    "             maxpooling만 쓰지 말고 각 방법의 장단점 파악 후 새롭게 적용해보기\n",
    "\n",
    "Summary\n",
    "Stanford의 CS231n 강의에서는 다음과 같은 순서로 Activation function을 시도해볼 것을 권한다.\n",
    "\n",
    "(1) ReLU를 사용하자.\n",
    "\n",
    "(2) 성능이 만족스럽지 않다면, LeakyReLU, Maxout, ELU를 사용하라.\n",
    "\n",
    "(3) 그래도 만족스럽지 않다면, tanh를 사용하라. 하지만 많은 기대는 하지말자.\n",
    "\n",
    "(4) 그러나 Sigmoid는 사용하지 말라.\n",
    "\n",
    "실무적으로는 ReLU를 가장 많이 사용하며, LeakyReLU/Maxout/ELU도 좋은 선택지가 될 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XskrI2jTrcn"
   },
   "source": [
    "learning rate 점점 감소 시켰을 때: 0.7941\n",
    "\n",
    "그냥 없이 했을 때: 0.8284\n",
    "\n",
    "model_5: train - 0.87, valid - 0.82\n",
    "\n",
    "model_6: Train accuracy=0.89975, Validation accuracy=0.82195\n",
    "\n",
    "강아지 품종 분류 cnn, 데이터 부풀리기 비교 예제\n",
    "\n",
    "# https://lsjsj92.tistory.com/387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_GEq195_R9L"
   },
   "source": [
    "cnn\n",
    "# https://m.blog.naver.com/laonple/221212462034\n",
    "\n",
    "https://m.blog.naver.com/laonple/220808903260\n",
    "\n",
    "# https://buomsoo-kim.github.io/keras/2018/05/05/Easy-deep-learning-with-Keras-11.md/\n",
    "\n",
    "https://machine-geon.tistory.com/46\n",
    "\n",
    "https://excelsior-cjh.tistory.com/152\n",
    "\n",
    "cnn 정확도 높이기\n",
    "\n",
    "https://manofconcrete.blogspot.com/2019/12/mnist-hands-on-3.html\n",
    "\n",
    "randpm search vs grid search\n",
    "\n",
    "https://shwksl101.github.io/ml/dl/2019/01/30/Hyper_parameter_optimization.html\n",
    "\n",
    "케라스 튜너\n",
    "# https://github.com/keras-team/keras-tuner\n",
    "https://tykimos.github.io/2019/05/10/KerasTuner/\n",
    "\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Md1ua95yr-J"
   },
   "outputs": [],
   "source": [
    "'''def model_fn():\n",
    "    LR = Choice('learning_rate', [0.001, 0.0005, 0.0001], group='optimizer')\n",
    "    DROPOUT_RATE = Linear('dropout_rate', 0.0, 0.5, 5, group='dense')\n",
    "    NUM_DIMS = Range('num_dims', 8, 32, 8, group='dense')\n",
    "    NUM_LAYERS = Range('num_layers', 1, 3, group='dense')\n",
    "    L2_NUM_FILTERS = Range('l2_num_filters', 8, 64, 8, group='cnn')\n",
    "    L1_NUM_FILTERS = Range('l1_num_filters', 8, 64, 8, group='cnn')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(L1_NUM_FILTERS, kernel_size=(3, 3), activation='relu'), input_shape = train_X.shape[1:])\n",
    "    model.add(Conv2D(L2_NUM_FILTERS, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    for _ in range(NUM_LAYERS):\n",
    "        model.add(Dense(NUM_DIMS, activation='relu'))\n",
    "        model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(LR), metrics=['accuracy'])\n",
    "\n",
    "    return model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6uEnvE_8RF-3"
   },
   "outputs": [],
   "source": [
    "'''def create_cnn_model(train_x):\n",
    "    inputs = tf.keras.layers.Input(train_x.shape[1:])\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    conv = tf.keras.layers.Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu')(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2,2))(conv)\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(pool)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2,2))(conv)\n",
    "    \n",
    "    flatten = tf.keras.layers.Flatten()(pool)\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(flatten)\n",
    "    dense = tf.keras.layers.Dense(1000, activation='relu')(bn)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(dense)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(bn)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvsh_fosRF-5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''model = create_cnn_model(train_X)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=20)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cEvNqqJeRF-8"
   },
   "outputs": [],
   "source": [
    "'''test_loss, test_acc = model.evaluate(valid_X, valid_y, verbose=2)\n",
    "print('테스트 손실함수:', test_loss, '\\n테스트 정확도:', test_acc)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcIjWCcoRF-_"
   },
   "source": [
    "https://excelsior-cjh.tistory.com/152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8lDYw1oRF-_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "train = pd.read_csv('./data/cvision/train.csv')\n",
    "train_x = train.iloc[:,3:].values.reshape(-1,28,28)\n",
    "data = train_x[0]\n",
    "data.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZiVdnh4RF_C"
   },
   "outputs": [],
   "source": [
    "'''#상하좌우 이동\n",
    "samples = np.expand_dims(data, 0)\n",
    "\n",
    "#Generator 생성\n",
    "#range를 설정해 얼마나 움직일지 정해줌\n",
    "gen = ImageDataGenerator(width_shift_range=[-10,10])\n",
    "\n",
    "#figure 생성\n",
    "fig = plt.figure(figsize=(28,28))\n",
    "\n",
    "#it\n",
    "it = gen.flow(samples, batch_size=1)\n",
    "\n",
    "#9개 이미지 생성\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    \n",
    "    batch = it.next()\n",
    "    img = batch[0].astype('uint8')\n",
    "    \n",
    "    #plot raw pixel data\n",
    "    plt.imshow(img)\n",
    "    \n",
    "#show the figure\n",
    "plt.title('moving')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P75WrD3Zkzfb"
   },
   "outputs": [],
   "source": [
    "#ResNet - Residual Block\n",
    "\n",
    "'''\n",
    "from keras import layers\n",
    "\n",
    "def residual_block(x, filters_in, filters_out, k_size):\n",
    "    shortcut = x\n",
    "    x = layers.Conv2D(filters_in, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters_in, kernel_size=(k_size, k_size), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)    \n",
    "    \n",
    "    x = layers.Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    shortcut_channel = x.shape.as_list()[-1]\n",
    "    \n",
    "    if shortcut_channel != filters_out:\n",
    "        shortcut = layers.Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(shortcut)\n",
    "        \n",
    "    x = layers.Add()([x, shortcut])\n",
    "    return layers.LeakyReLU()(x)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
