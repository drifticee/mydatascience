{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 702,
     "status": "ok",
     "timestamp": 1598341536679,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "Vg96YzNYHFe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import History\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.datasets import cifar10\n",
    "from keras.engine import training\n",
    "from keras.layers import (Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation,\n",
    "                          Average, BatchNormalization, Flatten, Dense, Concatenate, LeakyReLU, Add)\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model, Input\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from typing import Tuple, List\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "##################################################################################################\n",
    "#데이터 로드 + augmentation\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train_img = train.iloc[:,3:].values.reshape(-1,28,28)\n",
    "test = pd.read_csv('data/test.csv')\n",
    "submission = pd.read_csv('data/submission.csv')\n",
    "y = train['digit']\n",
    "\n",
    "def data_augmentation(images, labels):\n",
    "    aug_images = []\n",
    "    aug_labels = []    \n",
    "    \n",
    "    for x, y in zip(images, labels):        \n",
    "        aug_images.append(x)\n",
    "        aug_labels.append(y)\n",
    "        \n",
    "        bg_value = np.median(x)\n",
    "        \n",
    "        for _ in range(6):\n",
    "            angle = np.random.randint(-10, 10, 1)            \n",
    "            rot_img = ndimage.rotate(x, angle[0], reshape=False, cval=bg_value)\n",
    "            \n",
    "            shift = np.random.randint(-3, 3, 2)\n",
    "            shift_img = ndimage.shift(rot_img, shift, cval=bg_value)            \n",
    "            \n",
    "            aug_images.append(shift_img)\n",
    "            aug_labels.append(y)\n",
    "            \n",
    "    aug_images = np.array(aug_images)\n",
    "    aug_labels = np.array(aug_labels)\n",
    "    \n",
    "    return aug_images, aug_labels\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_img, y, test_size = 0.2)\n",
    "train_X, train_y = data_augmentation(train_X, train_y)\n",
    "\n",
    "train_X = train_X/255.\n",
    "valid_X = valid_X/255.\n",
    "train_X = np.expand_dims(train_X, axis=-1)\n",
    "valid_X = np.expand_dims(valid_X, axis=-1)\n",
    "\n",
    "train_y = to_categorical(train_y, 10)\n",
    "valid_y = to_categorical(valid_y, 10)\n",
    "\n",
    "#input\n",
    "input_shape = train_X.shape[1:]\n",
    "model_input = Input(shape=input_shape)\n",
    "##################################################################################################\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18491,
     "status": "ok",
     "timestamp": 1598333708469,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "4J-uM_NYZaui",
    "outputId": "bb277836-c91a-4408-c9f7-5a439be7222f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2749,
     "status": "ok",
     "timestamp": 1598346055653,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "9GCffZJIRF-O",
    "outputId": "f7870203-ecd8-41f5-b6ad-b21a15753508"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/cvision_1/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-018503dcdaa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/My Drive/cvision_1/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/My Drive/cvision_1/test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/My Drive/cvision_1/submission.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/cvision_1/train.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('/content/drive/My Drive/cvision_1/train.csv')\n",
    "test = pd.read_csv('/content/drive/My Drive/cvision_1/test.csv')\n",
    "submission = pd.read_csv('/content/drive/My Drive/cvision_1/submission.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpT2mQmsHFfM",
    "outputId": "595271f5-6621-4320-d0b5-6929e0b44407"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "      <th>letter</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>2044</td>\n",
       "      <td>6</td>\n",
       "      <td>V</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>2045</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>2046</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>2047</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2048</td>\n",
       "      <td>5</td>\n",
       "      <td>Z</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows × 787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  digit letter  0  1  2  3  4  5  6  ...  774  775  776  777  778  \\\n",
       "0        1      5      L  1  1  1  4  3  0  0  ...    2    1    0    1    2   \n",
       "1        2      0      B  0  4  0  0  4  1  1  ...    0    3    0    1    4   \n",
       "2        3      4      L  1  1  2  2  1  1  1  ...    3    3    3    0    2   \n",
       "3        4      9      D  1  2  0  2  0  4  0  ...    3    3    2    0    1   \n",
       "4        5      6      A  3  0  2  4  0  3  0  ...    4    4    3    2    1   \n",
       "...    ...    ...    ... .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...   \n",
       "2043  2044      6      V  2  4  3  4  2  4  4  ...    0    2    2    0    0   \n",
       "2044  2045      1      L  3  2  2  1  1  4  0  ...    2    3    4    2    1   \n",
       "2045  2046      9      A  4  0  4  0  2  4  4  ...    2    3    1    1    3   \n",
       "2046  2047      0      Z  2  3  3  0  3  0  4  ...    2    3    1    1    0   \n",
       "2047  2048      5      Z  4  2  2  1  3  0  0  ...    4    2    4    0    4   \n",
       "\n",
       "      779  780  781  782  783  \n",
       "0       4    4    4    3    4  \n",
       "1       1    4    2    1    2  \n",
       "2       0    3    0    2    2  \n",
       "3       4    0    0    1    1  \n",
       "4       3    4    3    1    2  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "2043    1    3    1    4    0  \n",
       "2044    2    3    4    1    1  \n",
       "2045    4    2    2    0    0  \n",
       "2046    4    1    4    3    1  \n",
       "2047    3    2    4    3    4  \n",
       "\n",
       "[2048 rows x 787 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#local 연결 전용\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('data/cvision/train.csv')\n",
    "test = pd.read_csv('data/cvision/test.csv')\n",
    "submission = pd.read_csv('data/cvision/submission.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1598346059030,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "1zwkSGXiRF-S"
   },
   "outputs": [],
   "source": [
    "#X와 y 분리\n",
    "X = train.drop(['id','digit','letter'], axis=1).values\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "X = X/255.\n",
    "\n",
    "y = train['digit']\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 652,
     "status": "ok",
     "timestamp": 1598346059031,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "XrcmgXVBRF-V"
   },
   "outputs": [],
   "source": [
    "#train과 valid로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "#test\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1983,
     "status": "ok",
     "timestamp": 1598341304472,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "aqxLynpVYoEB",
    "outputId": "578660e7-867c-4bae-d6af-6391d9f485b7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#그림 시각화\n",
    "for i in range(10):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    img = train.iloc[i,3:].values.astype('int64').reshape(28,28)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('letter ' + str(train.iloc[i, 2]))\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.where(img >= 135, img, 0))\n",
    "    plt.axis('off')\n",
    "    plt.title('number ' + str(train.iloc[i, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1598342410301,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "Ec4UH2IrRF-c"
   },
   "outputs": [],
   "source": [
    "#숫자 있는 부분만 추출 (이걸로만 딥러닝해보니 성과 매우 안 좋음,\n",
    "#이 방식 적용할 거면 train, valid, test 모두 이런 형식으로 변형한 후 해야할 듯)\n",
    "\n",
    "train_X_ = np.where(train_X >= 135/255., train_X, 0)\n",
    "valid_X_ = np.where(valid_X >= 135/255., valid_X, 0)\n",
    "test_X_ = np.where(test_X >= 135/255., test_X, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1598342411073,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "7gAGejz1kYY7"
   },
   "outputs": [],
   "source": [
    "train_X_2 = np.concatenate([train_X, train_X_])\n",
    "valid_X_2 = np.concatenate([valid_X, valid_X_])\n",
    "\n",
    "train_y_2 = np.concatenate([train_y, train_y])\n",
    "valid_y_2 = np.concatenate([valid_y, valid_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqeCSgUDRF-f"
   },
   "outputs": [],
   "source": [
    "#별 거 아님 kernel 예시\n",
    "from scipy.signal import correlate2d\n",
    "\n",
    "kernel = np.array(\n",
    "[\n",
    "    [0, -100, 0],\n",
    "    [0, 255, 0],\n",
    "    [0,-100,0]\n",
    "])\n",
    "plt.imshow(correlate2d(train_X[0].reshape(28,28), kernel, mode='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1598346069043,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "fd66eFzY4Mj3"
   },
   "outputs": [],
   "source": [
    "#model_4\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout, MaxPool2D,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                            zoom_range=0.10,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=3, activation='relu', input_shape = train_X.shape[1:]))\n",
    "    model.add(Conv2D(32,kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(32,kernel_size=3, strides=2, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64,kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(64,kernel_size=3, activation='relu'))\n",
    "    model.add(Conv2D(64,kernel_size=3, strides=2, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128,kernel_size=4, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRduAyEEAZ9F"
   },
   "outputs": [],
   "source": [
    "#model_5\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.10, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1598346094045,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "wDOUiuAiRF-p",
    "outputId": "d302b390-caea-49ce-bb59-a57147f78be3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_98 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 1, 1, 128)         131200    \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,658\n",
      "Trainable params: 243,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1598346095428,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "wPbJftOsRF-s"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.975 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 619875,
     "status": "ok",
     "timestamp": 1598346717394,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "vJymm1W6RF-u",
    "outputId": "f4ad5e2d-5d08-48af-cb97-1df4c286547b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 2.2951 - accuracy: 0.1314 - val_loss: 2.2283 - val_accuracy: 0.1854\n",
      "Epoch 2/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 2.1455 - accuracy: 0.2115 - val_loss: 1.7611 - val_accuracy: 0.4878\n",
      "Epoch 3/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.9327 - accuracy: 0.3274 - val_loss: 1.4464 - val_accuracy: 0.5073\n",
      "Epoch 4/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.7993 - accuracy: 0.3876 - val_loss: 1.4248 - val_accuracy: 0.5268\n",
      "Epoch 5/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.7123 - accuracy: 0.3959 - val_loss: 1.2285 - val_accuracy: 0.6098\n",
      "Epoch 6/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.5285 - accuracy: 0.4721 - val_loss: 1.0865 - val_accuracy: 0.6585\n",
      "Epoch 7/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 1.4226 - accuracy: 0.5091 - val_loss: 1.1102 - val_accuracy: 0.6244\n",
      "Epoch 8/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.3286 - accuracy: 0.5439 - val_loss: 0.8998 - val_accuracy: 0.6732\n",
      "Epoch 9/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.2833 - accuracy: 0.5605 - val_loss: 0.8270 - val_accuracy: 0.7512\n",
      "Epoch 10/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.2326 - accuracy: 0.5809 - val_loss: 0.9370 - val_accuracy: 0.6488\n",
      "Epoch 11/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 1.1329 - accuracy: 0.6173 - val_loss: 0.8614 - val_accuracy: 0.6976\n",
      "Epoch 12/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.1034 - accuracy: 0.6256 - val_loss: 0.8238 - val_accuracy: 0.7463\n",
      "Epoch 13/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.0408 - accuracy: 0.6394 - val_loss: 0.8644 - val_accuracy: 0.6732\n",
      "Epoch 14/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.0446 - accuracy: 0.6549 - val_loss: 0.8154 - val_accuracy: 0.7024\n",
      "Epoch 15/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 1.0012 - accuracy: 0.6576 - val_loss: 0.8477 - val_accuracy: 0.7073\n",
      "Epoch 16/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.9574 - accuracy: 0.6742 - val_loss: 0.9636 - val_accuracy: 0.6780\n",
      "Epoch 17/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.9477 - accuracy: 0.6593 - val_loss: 0.7996 - val_accuracy: 0.7073\n",
      "Epoch 18/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.9194 - accuracy: 0.6792 - val_loss: 0.8402 - val_accuracy: 0.6927\n",
      "Epoch 19/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.9335 - accuracy: 0.6875 - val_loss: 0.6183 - val_accuracy: 0.7756\n",
      "Epoch 20/120\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.8771 - accuracy: 0.6869 - val_loss: 0.8499 - val_accuracy: 0.6878\n",
      "Epoch 21/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.8457 - accuracy: 0.7217 - val_loss: 0.8991 - val_accuracy: 0.6634\n",
      "Epoch 22/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.8183 - accuracy: 0.7245 - val_loss: 0.6942 - val_accuracy: 0.7463\n",
      "Epoch 23/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.8414 - accuracy: 0.7145 - val_loss: 0.6907 - val_accuracy: 0.7805\n",
      "Epoch 24/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.8053 - accuracy: 0.7211 - val_loss: 0.8330 - val_accuracy: 0.6780\n",
      "Epoch 25/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.7969 - accuracy: 0.7278 - val_loss: 0.8011 - val_accuracy: 0.7317\n",
      "Epoch 26/120\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.7826 - accuracy: 0.7338 - val_loss: 0.7136 - val_accuracy: 0.7561\n",
      "Epoch 27/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.7687 - accuracy: 0.7405 - val_loss: 0.7736 - val_accuracy: 0.7122\n",
      "Epoch 28/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.7255 - accuracy: 0.7333 - val_loss: 0.6167 - val_accuracy: 0.7805\n",
      "Epoch 29/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.7192 - accuracy: 0.7587 - val_loss: 0.6873 - val_accuracy: 0.7659\n",
      "Epoch 30/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.7275 - accuracy: 0.7620 - val_loss: 0.6293 - val_accuracy: 0.7756\n",
      "Epoch 31/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.6925 - accuracy: 0.7565 - val_loss: 0.5580 - val_accuracy: 0.8000\n",
      "Epoch 32/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.6851 - accuracy: 0.7626 - val_loss: 0.7464 - val_accuracy: 0.7415\n",
      "Epoch 33/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.7485 - accuracy: 0.7554 - val_loss: 0.5435 - val_accuracy: 0.8195\n",
      "Epoch 34/120\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.6557 - accuracy: 0.7753 - val_loss: 0.6633 - val_accuracy: 0.7707\n",
      "Epoch 35/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.6704 - accuracy: 0.7708 - val_loss: 1.0307 - val_accuracy: 0.6390\n",
      "Epoch 36/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.6147 - accuracy: 0.7846 - val_loss: 0.5286 - val_accuracy: 0.8488\n",
      "Epoch 37/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.6389 - accuracy: 0.7869 - val_loss: 0.7704 - val_accuracy: 0.7268\n",
      "Epoch 38/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.6099 - accuracy: 0.7907 - val_loss: 0.7311 - val_accuracy: 0.7610\n",
      "Epoch 39/120\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.6068 - accuracy: 0.7869 - val_loss: 0.8353 - val_accuracy: 0.7415\n",
      "Epoch 40/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.6096 - accuracy: 0.8012 - val_loss: 0.6484 - val_accuracy: 0.7659\n",
      "Epoch 41/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.6423 - accuracy: 0.7742 - val_loss: 0.5731 - val_accuracy: 0.8049\n",
      "Epoch 42/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.6199 - accuracy: 0.7858 - val_loss: 0.6189 - val_accuracy: 0.8098\n",
      "Epoch 43/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.6143 - accuracy: 0.7951 - val_loss: 0.6277 - val_accuracy: 0.8000\n",
      "Epoch 44/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.5820 - accuracy: 0.8056 - val_loss: 0.7377 - val_accuracy: 0.7610\n",
      "Epoch 45/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.5514 - accuracy: 0.8161 - val_loss: 0.5469 - val_accuracy: 0.8098\n",
      "Epoch 46/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.5780 - accuracy: 0.8189 - val_loss: 0.5167 - val_accuracy: 0.8049\n",
      "Epoch 47/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.5748 - accuracy: 0.7946 - val_loss: 0.6258 - val_accuracy: 0.7951\n",
      "Epoch 48/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.5328 - accuracy: 0.8089 - val_loss: 0.6782 - val_accuracy: 0.8098\n",
      "Epoch 49/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.5560 - accuracy: 0.8183 - val_loss: 0.5433 - val_accuracy: 0.8098\n",
      "Epoch 50/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.5415 - accuracy: 0.8134 - val_loss: 0.6208 - val_accuracy: 0.8049\n",
      "Epoch 51/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.5587 - accuracy: 0.8084 - val_loss: 0.4741 - val_accuracy: 0.8341\n",
      "Epoch 52/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.5265 - accuracy: 0.8327 - val_loss: 0.5380 - val_accuracy: 0.8195\n",
      "Epoch 53/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.5089 - accuracy: 0.8349 - val_loss: 0.6767 - val_accuracy: 0.7805\n",
      "Epoch 54/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4914 - accuracy: 0.8277 - val_loss: 0.5387 - val_accuracy: 0.8537\n",
      "Epoch 55/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4862 - accuracy: 0.8388 - val_loss: 0.6321 - val_accuracy: 0.8098\n",
      "Epoch 56/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.5015 - accuracy: 0.8239 - val_loss: 0.5905 - val_accuracy: 0.7951\n",
      "Epoch 57/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.5026 - accuracy: 0.8288 - val_loss: 0.6228 - val_accuracy: 0.8146\n",
      "Epoch 58/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.4808 - accuracy: 0.8383 - val_loss: 0.7290 - val_accuracy: 0.7902\n",
      "Epoch 59/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4854 - accuracy: 0.8360 - val_loss: 0.6225 - val_accuracy: 0.7951\n",
      "Epoch 60/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.4742 - accuracy: 0.8366 - val_loss: 0.6864 - val_accuracy: 0.8098\n",
      "Epoch 61/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4830 - accuracy: 0.8321 - val_loss: 0.6171 - val_accuracy: 0.8098\n",
      "Epoch 62/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.4554 - accuracy: 0.8321 - val_loss: 0.6485 - val_accuracy: 0.7854\n",
      "Epoch 63/120\n",
      "57/57 [==============================] - 8s 139ms/step - loss: 0.4796 - accuracy: 0.8366 - val_loss: 0.6392 - val_accuracy: 0.7805\n",
      "Epoch 64/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4724 - accuracy: 0.8421 - val_loss: 0.5261 - val_accuracy: 0.8341\n",
      "Epoch 65/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.4568 - accuracy: 0.8360 - val_loss: 0.7813 - val_accuracy: 0.7512\n",
      "Epoch 66/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4137 - accuracy: 0.8581 - val_loss: 0.6967 - val_accuracy: 0.7902\n",
      "Epoch 67/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.4374 - accuracy: 0.8504 - val_loss: 0.7268 - val_accuracy: 0.7756\n",
      "Epoch 68/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.4457 - accuracy: 0.8537 - val_loss: 0.6813 - val_accuracy: 0.8049\n",
      "Epoch 69/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.5061 - accuracy: 0.8349 - val_loss: 0.6503 - val_accuracy: 0.8049\n",
      "Epoch 70/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4501 - accuracy: 0.8454 - val_loss: 0.7851 - val_accuracy: 0.7659\n",
      "Epoch 71/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4233 - accuracy: 0.8548 - val_loss: 0.6085 - val_accuracy: 0.8049\n",
      "Epoch 72/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.4364 - accuracy: 0.8377 - val_loss: 0.6457 - val_accuracy: 0.8049\n",
      "Epoch 73/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4348 - accuracy: 0.8493 - val_loss: 0.5473 - val_accuracy: 0.8146\n",
      "Epoch 74/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.4403 - accuracy: 0.8465 - val_loss: 0.6288 - val_accuracy: 0.7951\n",
      "Epoch 75/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3982 - accuracy: 0.8620 - val_loss: 0.7626 - val_accuracy: 0.7805\n",
      "Epoch 76/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4101 - accuracy: 0.8686 - val_loss: 0.6279 - val_accuracy: 0.7951\n",
      "Epoch 77/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4333 - accuracy: 0.8493 - val_loss: 0.6301 - val_accuracy: 0.8049\n",
      "Epoch 78/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4099 - accuracy: 0.8614 - val_loss: 0.5502 - val_accuracy: 0.8634\n",
      "Epoch 79/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4178 - accuracy: 0.8548 - val_loss: 0.7486 - val_accuracy: 0.7707\n",
      "Epoch 80/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4109 - accuracy: 0.8586 - val_loss: 0.6545 - val_accuracy: 0.8098\n",
      "Epoch 81/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4139 - accuracy: 0.8603 - val_loss: 0.5584 - val_accuracy: 0.8390\n",
      "Epoch 82/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3938 - accuracy: 0.8620 - val_loss: 0.6108 - val_accuracy: 0.8390\n",
      "Epoch 83/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3893 - accuracy: 0.8581 - val_loss: 0.5122 - val_accuracy: 0.8537\n",
      "Epoch 84/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3891 - accuracy: 0.8624 - val_loss: 0.6234 - val_accuracy: 0.8000\n",
      "Epoch 85/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.4025 - accuracy: 0.8631 - val_loss: 0.5974 - val_accuracy: 0.8195\n",
      "Epoch 86/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3951 - accuracy: 0.8625 - val_loss: 0.6657 - val_accuracy: 0.7902\n",
      "Epoch 87/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3653 - accuracy: 0.8821 - val_loss: 0.6508 - val_accuracy: 0.8049\n",
      "Epoch 88/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.4835 - accuracy: 0.8426 - val_loss: 0.5619 - val_accuracy: 0.8146\n",
      "Epoch 89/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3696 - accuracy: 0.8658 - val_loss: 0.6577 - val_accuracy: 0.8049\n",
      "Epoch 90/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3914 - accuracy: 0.8658 - val_loss: 0.6501 - val_accuracy: 0.7951\n",
      "Epoch 91/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3883 - accuracy: 0.8603 - val_loss: 0.7688 - val_accuracy: 0.7610\n",
      "Epoch 92/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3925 - accuracy: 0.8597 - val_loss: 0.5104 - val_accuracy: 0.8195\n",
      "Epoch 93/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3760 - accuracy: 0.8769 - val_loss: 0.8499 - val_accuracy: 0.7610\n",
      "Epoch 94/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3862 - accuracy: 0.8686 - val_loss: 0.6642 - val_accuracy: 0.8293\n",
      "Epoch 95/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3838 - accuracy: 0.8741 - val_loss: 0.6184 - val_accuracy: 0.8293\n",
      "Epoch 96/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3228 - accuracy: 0.8929 - val_loss: 0.6284 - val_accuracy: 0.8537\n",
      "Epoch 97/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3981 - accuracy: 0.8631 - val_loss: 0.6901 - val_accuracy: 0.7854\n",
      "Epoch 98/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3527 - accuracy: 0.8791 - val_loss: 0.8570 - val_accuracy: 0.7415\n",
      "Epoch 99/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3670 - accuracy: 0.8713 - val_loss: 0.5532 - val_accuracy: 0.7951\n",
      "Epoch 100/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3599 - accuracy: 0.8758 - val_loss: 0.7251 - val_accuracy: 0.7561\n",
      "Epoch 101/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3333 - accuracy: 0.8901 - val_loss: 0.7492 - val_accuracy: 0.7805\n",
      "Epoch 102/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3577 - accuracy: 0.8907 - val_loss: 0.6396 - val_accuracy: 0.7707\n",
      "Epoch 103/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3765 - accuracy: 0.8807 - val_loss: 0.6007 - val_accuracy: 0.7805\n",
      "Epoch 104/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3304 - accuracy: 0.8835 - val_loss: 0.6114 - val_accuracy: 0.8244\n",
      "Epoch 105/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.3224 - accuracy: 0.8912 - val_loss: 0.7470 - val_accuracy: 0.8049\n",
      "Epoch 106/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3289 - accuracy: 0.8840 - val_loss: 0.6060 - val_accuracy: 0.7951\n",
      "Epoch 107/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3974 - accuracy: 0.8669 - val_loss: 0.6742 - val_accuracy: 0.7512\n",
      "Epoch 108/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.3208 - accuracy: 0.8923 - val_loss: 0.6524 - val_accuracy: 0.8293\n",
      "Epoch 109/120\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.3221 - accuracy: 0.8890 - val_loss: 0.5417 - val_accuracy: 0.8146\n",
      "Epoch 110/120\n",
      "57/57 [==============================] - 5s 94ms/step - loss: 0.3431 - accuracy: 0.8796 - val_loss: 0.6656 - val_accuracy: 0.8098\n",
      "Epoch 111/120\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.3531 - accuracy: 0.8890 - val_loss: 0.6917 - val_accuracy: 0.7902\n",
      "Epoch 112/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3295 - accuracy: 0.8901 - val_loss: 0.6772 - val_accuracy: 0.8049\n",
      "Epoch 113/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3226 - accuracy: 0.8785 - val_loss: 0.8028 - val_accuracy: 0.8098\n",
      "Epoch 114/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3346 - accuracy: 0.8890 - val_loss: 0.6229 - val_accuracy: 0.8146\n",
      "Epoch 115/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3334 - accuracy: 0.8885 - val_loss: 0.3923 - val_accuracy: 0.8634\n",
      "Epoch 116/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3263 - accuracy: 0.8874 - val_loss: 0.6834 - val_accuracy: 0.7756\n",
      "Epoch 117/120\n",
      "57/57 [==============================] - 5s 87ms/step - loss: 0.3583 - accuracy: 0.8807 - val_loss: 0.6107 - val_accuracy: 0.8146\n",
      "Epoch 118/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3388 - accuracy: 0.8868 - val_loss: 0.5205 - val_accuracy: 0.8293\n",
      "Epoch 119/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3063 - accuracy: 0.8945 - val_loss: 0.6261 - val_accuracy: 0.8195\n",
      "Epoch 120/120\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.3090 - accuracy: 0.8967 - val_loss: 0.5123 - val_accuracy: 0.8390\n",
      "CNN: Epochs=120, Train accuracy=0.89674, Validation accuracy=0.86341\n"
     ]
    }
   ],
   "source": [
    "epochs = 120\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    "    #callbacks=[annealer],\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1211,
     "status": "ok",
     "timestamp": 1598346862296,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "kB5QQWDY3yA_",
    "outputId": "79685c32-1913-43f3-c609-3bffa4d69a30"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XF1MPFKyRF-w"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'/content/drive/My Drive/cvision_1/params_4.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'/content/drive/My Drive/cvision_1/model_4.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fjm7D-7jRF-z"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "res = model.predict(test_X)\n",
    "\n",
    "#submission 파일 생성\n",
    "for i in range(len(res)):\n",
    "    submission.digit[i] = int(res[i].argmax())\n",
    "submission.to_csv('/content/drive/My Drive/cvision_1/my_subm_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9V1sl_PZkAw"
   },
   "outputs": [],
   "source": [
    "#model_6\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.10, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2J4dDK7WcMjX"
   },
   "outputs": [],
   "source": [
    "#model_6\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.1, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1598345875731,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "bG2wRBFqSufq",
    "outputId": "2c778347-c8f5-4999-ad0d-ed34a4ec96b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_75 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 133,648\n",
      "Trainable params: 133,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q73HFCn7TfqS"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WjESPwIkTb3s",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    "    #callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ppp3z5-lXawC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTtpmPijTjmk"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'/content/drive/My Drive/cvision_1/params_6.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'/content/drive/My Drive/cvision_1/model_6.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFSBLgQKTmM2"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('/content/drive/My Drive/cvision_1/my_subm_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qcD4AYCGQ9Np"
   },
   "outputs": [],
   "source": [
    "#model_8인데 데이터 부풀리기 x, 학습률 감소 x\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "'''\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.1, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "'''\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnWl2qzoURfw"
   },
   "outputs": [],
   "source": [
    "#model_8인데 데이터 부풀리기 x, 학습률 감소 x\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "'''\n",
    "datagen = ImageDataGenerator(rotation_range=10, #10도 돌림\n",
    "                            zoom_range=0.1, #10퍼센트 확대(crop?)\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "'''\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape = train_X.shape[1:], filters = 32, kernel_size = (3,3), strides = 2, padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pO2aXT2wRIxn"
   },
   "outputs": [],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nS8BcL7CRNa7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    "    #callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bseu0T8lRl3X"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2moYVE1jTLc"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'/content/drive/My Drive/cvision_1/params_9.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'/content/drive/My Drive/cvision_1/model_9.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDMU0LnTjiwo"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('/content/drive/My Drive/cvision_1/my_subm_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 934,
     "status": "ok",
     "timestamp": 1598347121753,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "sTKcFoyikcjV"
   },
   "outputs": [],
   "source": [
    "#model_9-3 9-2에서 optimizer만 RMSprop로 바꿔봄 - Adam보다 높게 나오더라\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), Adagrad(lr=0.01, epsilon=None, decay=0.0), adadelta, adam\n",
    "    model.compile(optimizer=RMSprop(lr=0.001, rho=0.95, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1598347122067,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "ySu34IFkkhNe",
    "outputId": "e3d46b6e-e956-4a26-f1bc-aa4c0e4c3b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 133,648\n",
      "Trainable params: 133,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1598347122783,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "tPFielyJ5yMH"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** x)\n",
    "\n",
    "#earlystopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537462,
     "status": "error",
     "timestamp": 1598347660504,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "012ce4a9-2ca8-41d3-d1de-9331032469e3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 2.3137 - accuracy: 0.1050 - val_loss: 2.2994 - val_accuracy: 0.1024\n",
      "Epoch 2/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 2.2979 - accuracy: 0.1190 - val_loss: 2.2992 - val_accuracy: 0.0829\n",
      "Epoch 3/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 2.2917 - accuracy: 0.1149 - val_loss: 2.2879 - val_accuracy: 0.1073\n",
      "Epoch 4/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 2.2634 - accuracy: 0.1411 - val_loss: 2.2053 - val_accuracy: 0.1317\n",
      "Epoch 5/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 2.2351 - accuracy: 0.1656 - val_loss: 2.2253 - val_accuracy: 0.2000\n",
      "Epoch 6/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 2.1605 - accuracy: 0.2169 - val_loss: 2.1426 - val_accuracy: 0.3366\n",
      "Epoch 7/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 2.1125 - accuracy: 0.2315 - val_loss: 1.9375 - val_accuracy: 0.3463\n",
      "Epoch 8/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 2.0783 - accuracy: 0.2344 - val_loss: 1.7914 - val_accuracy: 0.4049\n",
      "Epoch 9/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 2.0334 - accuracy: 0.2536 - val_loss: 1.8990 - val_accuracy: 0.4488\n",
      "Epoch 10/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.9846 - accuracy: 0.2776 - val_loss: 1.8192 - val_accuracy: 0.3854\n",
      "Epoch 11/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.9631 - accuracy: 0.2980 - val_loss: 1.7459 - val_accuracy: 0.5171\n",
      "Epoch 12/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.8743 - accuracy: 0.3306 - val_loss: 1.6804 - val_accuracy: 0.4390\n",
      "Epoch 13/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.9031 - accuracy: 0.3259 - val_loss: 1.5386 - val_accuracy: 0.5366\n",
      "Epoch 14/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.8519 - accuracy: 0.3449 - val_loss: 1.6745 - val_accuracy: 0.4976\n",
      "Epoch 15/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.8122 - accuracy: 0.3580 - val_loss: 1.7570 - val_accuracy: 0.4732\n",
      "Epoch 16/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.8115 - accuracy: 0.3621 - val_loss: 1.5626 - val_accuracy: 0.5756\n",
      "Epoch 17/2000\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 1.7353 - accuracy: 0.4070 - val_loss: 1.6524 - val_accuracy: 0.5024\n",
      "Epoch 18/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.7391 - accuracy: 0.3784 - val_loss: 1.3797 - val_accuracy: 0.6000\n",
      "Epoch 19/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.7041 - accuracy: 0.4041 - val_loss: 1.3833 - val_accuracy: 0.6000\n",
      "Epoch 20/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.6650 - accuracy: 0.4332 - val_loss: 1.4773 - val_accuracy: 0.5707\n",
      "Epoch 21/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.6948 - accuracy: 0.4175 - val_loss: 1.3674 - val_accuracy: 0.5707\n",
      "Epoch 22/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.6400 - accuracy: 0.4315 - val_loss: 1.4132 - val_accuracy: 0.5756\n",
      "Epoch 23/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.5886 - accuracy: 0.4472 - val_loss: 1.4005 - val_accuracy: 0.5171\n",
      "Epoch 24/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.6244 - accuracy: 0.4513 - val_loss: 1.2447 - val_accuracy: 0.6000\n",
      "Epoch 25/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.5549 - accuracy: 0.4601 - val_loss: 1.2125 - val_accuracy: 0.6146\n",
      "Epoch 26/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.5409 - accuracy: 0.4706 - val_loss: 1.1969 - val_accuracy: 0.6195\n",
      "Epoch 27/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.5288 - accuracy: 0.4752 - val_loss: 1.2017 - val_accuracy: 0.6537\n",
      "Epoch 28/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.4815 - accuracy: 0.4886 - val_loss: 1.1513 - val_accuracy: 0.6098\n",
      "Epoch 29/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.5217 - accuracy: 0.4898 - val_loss: 1.2059 - val_accuracy: 0.6439\n",
      "Epoch 30/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.4624 - accuracy: 0.5073 - val_loss: 1.2834 - val_accuracy: 0.6390\n",
      "Epoch 31/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.4406 - accuracy: 0.5085 - val_loss: 1.4618 - val_accuracy: 0.5756\n",
      "Epoch 32/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.4337 - accuracy: 0.5160 - val_loss: 1.2435 - val_accuracy: 0.5512\n",
      "Epoch 33/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.4281 - accuracy: 0.4997 - val_loss: 1.1841 - val_accuracy: 0.6829\n",
      "Epoch 34/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 1.4177 - accuracy: 0.5236 - val_loss: 1.2278 - val_accuracy: 0.6000\n",
      "Epoch 35/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.3310 - accuracy: 0.5464 - val_loss: 1.0392 - val_accuracy: 0.6585\n",
      "Epoch 36/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.3752 - accuracy: 0.5353 - val_loss: 1.0386 - val_accuracy: 0.7122\n",
      "Epoch 37/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.3087 - accuracy: 0.5551 - val_loss: 1.1950 - val_accuracy: 0.5951\n",
      "Epoch 38/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.3335 - accuracy: 0.5487 - val_loss: 1.1840 - val_accuracy: 0.6146\n",
      "Epoch 39/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.2943 - accuracy: 0.5726 - val_loss: 1.0413 - val_accuracy: 0.6683\n",
      "Epoch 40/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.3015 - accuracy: 0.5569 - val_loss: 1.1696 - val_accuracy: 0.6293\n",
      "Epoch 41/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.2630 - accuracy: 0.5528 - val_loss: 1.1251 - val_accuracy: 0.6390\n",
      "Epoch 42/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.2691 - accuracy: 0.5633 - val_loss: 1.0323 - val_accuracy: 0.7073\n",
      "Epoch 43/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.2314 - accuracy: 0.5825 - val_loss: 1.0410 - val_accuracy: 0.6927\n",
      "Epoch 44/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.1781 - accuracy: 0.5960 - val_loss: 0.9626 - val_accuracy: 0.6976\n",
      "Epoch 45/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.2428 - accuracy: 0.5778 - val_loss: 1.0101 - val_accuracy: 0.6683\n",
      "Epoch 46/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.2050 - accuracy: 0.5819 - val_loss: 0.9217 - val_accuracy: 0.7122\n",
      "Epoch 47/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.1894 - accuracy: 0.5930 - val_loss: 1.0405 - val_accuracy: 0.6927\n",
      "Epoch 48/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.1784 - accuracy: 0.6117 - val_loss: 0.9913 - val_accuracy: 0.6634\n",
      "Epoch 49/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.1850 - accuracy: 0.6076 - val_loss: 0.8585 - val_accuracy: 0.7463\n",
      "Epoch 50/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.1622 - accuracy: 0.5918 - val_loss: 0.9009 - val_accuracy: 0.7073\n",
      "Epoch 51/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.1472 - accuracy: 0.5936 - val_loss: 0.9652 - val_accuracy: 0.6878\n",
      "Epoch 52/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.1393 - accuracy: 0.6058 - val_loss: 0.9623 - val_accuracy: 0.6976\n",
      "Epoch 53/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.1472 - accuracy: 0.6082 - val_loss: 0.8001 - val_accuracy: 0.7463\n",
      "Epoch 54/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.1248 - accuracy: 0.6157 - val_loss: 0.8392 - val_accuracy: 0.7463\n",
      "Epoch 55/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.0758 - accuracy: 0.6338 - val_loss: 0.9767 - val_accuracy: 0.7171\n",
      "Epoch 56/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.0931 - accuracy: 0.6350 - val_loss: 1.0289 - val_accuracy: 0.6780\n",
      "Epoch 57/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.0596 - accuracy: 0.6542 - val_loss: 0.9533 - val_accuracy: 0.7171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.0952 - accuracy: 0.6245 - val_loss: 0.7775 - val_accuracy: 0.7756\n",
      "Epoch 59/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.0050 - accuracy: 0.6612 - val_loss: 0.8179 - val_accuracy: 0.7220\n",
      "Epoch 60/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.0570 - accuracy: 0.6397 - val_loss: 0.8520 - val_accuracy: 0.7171\n",
      "Epoch 61/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.0098 - accuracy: 0.6612 - val_loss: 0.8856 - val_accuracy: 0.7561\n",
      "Epoch 62/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.0176 - accuracy: 0.6490 - val_loss: 0.7301 - val_accuracy: 0.8049\n",
      "Epoch 63/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.9999 - accuracy: 0.6548 - val_loss: 0.8837 - val_accuracy: 0.7561\n",
      "Epoch 64/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.0305 - accuracy: 0.6519 - val_loss: 0.8437 - val_accuracy: 0.7561\n",
      "Epoch 65/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.9990 - accuracy: 0.6379 - val_loss: 0.8740 - val_accuracy: 0.7171\n",
      "Epoch 66/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.0010 - accuracy: 0.6554 - val_loss: 0.7478 - val_accuracy: 0.7805\n",
      "Epoch 67/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.9725 - accuracy: 0.6758 - val_loss: 1.0031 - val_accuracy: 0.7024\n",
      "Epoch 68/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.9704 - accuracy: 0.6797 - val_loss: 1.1076 - val_accuracy: 0.6293\n",
      "Epoch 69/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.9501 - accuracy: 0.6857 - val_loss: 0.6888 - val_accuracy: 0.8098\n",
      "Epoch 70/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.9670 - accuracy: 0.6758 - val_loss: 0.7598 - val_accuracy: 0.8000\n",
      "Epoch 71/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.9369 - accuracy: 0.6700 - val_loss: 0.7456 - val_accuracy: 0.7951\n",
      "Epoch 72/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.9540 - accuracy: 0.6810 - val_loss: 0.6785 - val_accuracy: 0.8146\n",
      "Epoch 73/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.9302 - accuracy: 0.6816 - val_loss: 0.7724 - val_accuracy: 0.7610\n",
      "Epoch 74/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.9083 - accuracy: 0.6968 - val_loss: 0.7161 - val_accuracy: 0.7951\n",
      "Epoch 75/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.9073 - accuracy: 0.6945 - val_loss: 0.7624 - val_accuracy: 0.7854\n",
      "Epoch 76/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.8738 - accuracy: 0.6974 - val_loss: 0.7006 - val_accuracy: 0.7951\n",
      "Epoch 77/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.9157 - accuracy: 0.7020 - val_loss: 0.6790 - val_accuracy: 0.8000\n",
      "Epoch 78/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.8777 - accuracy: 0.7020 - val_loss: 0.7533 - val_accuracy: 0.7805\n",
      "Epoch 79/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.9001 - accuracy: 0.6945 - val_loss: 0.6703 - val_accuracy: 0.8293\n",
      "Epoch 80/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.8808 - accuracy: 0.7026 - val_loss: 0.7521 - val_accuracy: 0.8000\n",
      "Epoch 81/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.8605 - accuracy: 0.7131 - val_loss: 0.6670 - val_accuracy: 0.8390\n",
      "Epoch 82/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.8643 - accuracy: 0.7009 - val_loss: 0.6388 - val_accuracy: 0.8195\n",
      "Epoch 83/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.8503 - accuracy: 0.7079 - val_loss: 0.6703 - val_accuracy: 0.8098\n",
      "Epoch 84/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.8548 - accuracy: 0.7038 - val_loss: 0.8067 - val_accuracy: 0.7512\n",
      "Epoch 85/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.8498 - accuracy: 0.7096 - val_loss: 1.1198 - val_accuracy: 0.6293\n",
      "Epoch 86/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.8238 - accuracy: 0.7289 - val_loss: 0.6997 - val_accuracy: 0.7951\n",
      "Epoch 87/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.8355 - accuracy: 0.7160 - val_loss: 0.6511 - val_accuracy: 0.8146\n",
      "Epoch 88/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.8203 - accuracy: 0.7085 - val_loss: 0.9584 - val_accuracy: 0.7024\n",
      "Epoch 89/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7789 - accuracy: 0.7300 - val_loss: 0.7337 - val_accuracy: 0.7756\n",
      "Epoch 90/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7945 - accuracy: 0.7248 - val_loss: 0.5618 - val_accuracy: 0.8244\n",
      "Epoch 91/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7694 - accuracy: 0.7300 - val_loss: 0.5087 - val_accuracy: 0.8293\n",
      "Epoch 92/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7969 - accuracy: 0.7289 - val_loss: 0.7531 - val_accuracy: 0.7610\n",
      "Epoch 93/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7866 - accuracy: 0.7347 - val_loss: 0.6092 - val_accuracy: 0.8195\n",
      "Epoch 94/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.8279 - accuracy: 0.7195 - val_loss: 0.6353 - val_accuracy: 0.8000\n",
      "Epoch 95/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.8162 - accuracy: 0.7248 - val_loss: 0.6623 - val_accuracy: 0.7951\n",
      "Epoch 96/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7849 - accuracy: 0.7405 - val_loss: 0.5537 - val_accuracy: 0.8195\n",
      "Epoch 97/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7967 - accuracy: 0.7329 - val_loss: 0.7493 - val_accuracy: 0.7463\n",
      "Epoch 98/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7308 - accuracy: 0.7405 - val_loss: 0.6243 - val_accuracy: 0.7902\n",
      "Epoch 99/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.8073 - accuracy: 0.7149 - val_loss: 0.7571 - val_accuracy: 0.7707\n",
      "Epoch 100/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7684 - accuracy: 0.7341 - val_loss: 0.7345 - val_accuracy: 0.7756\n",
      "Epoch 101/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.8066 - accuracy: 0.7370 - val_loss: 0.6663 - val_accuracy: 0.7902\n",
      "Epoch 102/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7278 - accuracy: 0.7528 - val_loss: 0.8144 - val_accuracy: 0.7366\n",
      "Epoch 103/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7431 - accuracy: 0.7545 - val_loss: 0.6772 - val_accuracy: 0.7512\n",
      "Epoch 104/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7485 - accuracy: 0.7469 - val_loss: 0.6889 - val_accuracy: 0.7756\n",
      "Epoch 105/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7203 - accuracy: 0.7499 - val_loss: 0.5121 - val_accuracy: 0.8537\n",
      "Epoch 106/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7964 - accuracy: 0.7254 - val_loss: 0.5688 - val_accuracy: 0.8390\n",
      "Epoch 107/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7126 - accuracy: 0.7592 - val_loss: 0.6368 - val_accuracy: 0.8049\n",
      "Epoch 108/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6885 - accuracy: 0.7638 - val_loss: 0.6485 - val_accuracy: 0.7854\n",
      "Epoch 109/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.6934 - accuracy: 0.7545 - val_loss: 0.8360 - val_accuracy: 0.7463\n",
      "Epoch 110/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.7239 - accuracy: 0.7522 - val_loss: 0.5662 - val_accuracy: 0.8195\n",
      "Epoch 111/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6952 - accuracy: 0.7633 - val_loss: 0.5763 - val_accuracy: 0.8195\n",
      "Epoch 112/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7722 - accuracy: 0.7364 - val_loss: 0.7476 - val_accuracy: 0.7415\n",
      "Epoch 113/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6661 - accuracy: 0.7732 - val_loss: 0.5701 - val_accuracy: 0.8195\n",
      "Epoch 114/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7135 - accuracy: 0.7493 - val_loss: 0.5367 - val_accuracy: 0.8488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.6840 - accuracy: 0.7621 - val_loss: 0.6113 - val_accuracy: 0.8195\n",
      "Epoch 116/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6871 - accuracy: 0.7718 - val_loss: 0.6718 - val_accuracy: 0.7610\n",
      "Epoch 117/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7128 - accuracy: 0.7475 - val_loss: 0.5297 - val_accuracy: 0.8341\n",
      "Epoch 118/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6597 - accuracy: 0.7673 - val_loss: 0.5080 - val_accuracy: 0.8439\n",
      "Epoch 119/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6871 - accuracy: 0.7685 - val_loss: 0.7296 - val_accuracy: 0.7756\n",
      "Epoch 120/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.6709 - accuracy: 0.7697 - val_loss: 0.5698 - val_accuracy: 0.8439\n",
      "Epoch 121/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.7042 - accuracy: 0.7522 - val_loss: 0.5200 - val_accuracy: 0.8293\n",
      "Epoch 122/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6723 - accuracy: 0.7656 - val_loss: 0.5157 - val_accuracy: 0.8244\n",
      "Epoch 123/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6452 - accuracy: 0.7825 - val_loss: 0.5669 - val_accuracy: 0.8195\n",
      "Epoch 124/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6607 - accuracy: 0.7690 - val_loss: 0.5126 - val_accuracy: 0.8341\n",
      "Epoch 125/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6444 - accuracy: 0.7866 - val_loss: 0.6149 - val_accuracy: 0.7951\n",
      "Epoch 126/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.6852 - accuracy: 0.7720 - val_loss: 0.4743 - val_accuracy: 0.8341\n",
      "Epoch 127/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.7062 - accuracy: 0.7668 - val_loss: 0.5455 - val_accuracy: 0.8390\n",
      "Epoch 128/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6220 - accuracy: 0.7854 - val_loss: 0.5132 - val_accuracy: 0.8439\n",
      "Epoch 129/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6098 - accuracy: 0.7980 - val_loss: 0.5831 - val_accuracy: 0.8049\n",
      "Epoch 130/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6695 - accuracy: 0.7714 - val_loss: 0.5324 - val_accuracy: 0.8390\n",
      "Epoch 131/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6447 - accuracy: 0.7720 - val_loss: 0.5086 - val_accuracy: 0.8293\n",
      "Epoch 132/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6112 - accuracy: 0.7924 - val_loss: 0.4766 - val_accuracy: 0.8341\n",
      "Epoch 133/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6088 - accuracy: 0.7840 - val_loss: 0.5797 - val_accuracy: 0.8000\n",
      "Epoch 134/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.6384 - accuracy: 0.7802 - val_loss: 0.4498 - val_accuracy: 0.8341\n",
      "Epoch 135/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6476 - accuracy: 0.7860 - val_loss: 0.4474 - val_accuracy: 0.8439\n",
      "Epoch 136/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6360 - accuracy: 0.7854 - val_loss: 0.6465 - val_accuracy: 0.7854\n",
      "Epoch 137/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6342 - accuracy: 0.7778 - val_loss: 0.5811 - val_accuracy: 0.8195\n",
      "Epoch 138/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6033 - accuracy: 0.7983 - val_loss: 0.5461 - val_accuracy: 0.8146\n",
      "Epoch 139/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6174 - accuracy: 0.7930 - val_loss: 0.4568 - val_accuracy: 0.8537\n",
      "Epoch 140/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5964 - accuracy: 0.7959 - val_loss: 0.5764 - val_accuracy: 0.8390\n",
      "Epoch 141/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6102 - accuracy: 0.7930 - val_loss: 0.5265 - val_accuracy: 0.8341\n",
      "Epoch 142/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.6207 - accuracy: 0.7854 - val_loss: 0.5383 - val_accuracy: 0.8244\n",
      "Epoch 143/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.6089 - accuracy: 0.7942 - val_loss: 0.4857 - val_accuracy: 0.8439\n",
      "Epoch 144/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5975 - accuracy: 0.7901 - val_loss: 0.4632 - val_accuracy: 0.8439\n",
      "Epoch 145/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5991 - accuracy: 0.7971 - val_loss: 0.4616 - val_accuracy: 0.8439\n",
      "Epoch 146/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5775 - accuracy: 0.7991 - val_loss: 0.5449 - val_accuracy: 0.8244\n",
      "Epoch 147/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5795 - accuracy: 0.8017 - val_loss: 0.5106 - val_accuracy: 0.8293\n",
      "Epoch 148/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5724 - accuracy: 0.7988 - val_loss: 0.5553 - val_accuracy: 0.8244\n",
      "Epoch 149/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5797 - accuracy: 0.8000 - val_loss: 0.5606 - val_accuracy: 0.8146\n",
      "Epoch 150/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5888 - accuracy: 0.7895 - val_loss: 0.4858 - val_accuracy: 0.8341\n",
      "Epoch 151/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5884 - accuracy: 0.7930 - val_loss: 0.5430 - val_accuracy: 0.8244\n",
      "Epoch 152/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5795 - accuracy: 0.7924 - val_loss: 0.5005 - val_accuracy: 0.8439\n",
      "Epoch 153/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5835 - accuracy: 0.8058 - val_loss: 0.4669 - val_accuracy: 0.8537\n",
      "Epoch 154/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5604 - accuracy: 0.8093 - val_loss: 0.5022 - val_accuracy: 0.8341\n",
      "Epoch 155/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5259 - accuracy: 0.8175 - val_loss: 0.4711 - val_accuracy: 0.8439\n",
      "Epoch 156/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5273 - accuracy: 0.8204 - val_loss: 0.5836 - val_accuracy: 0.8049\n",
      "Epoch 157/2000\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.5745 - accuracy: 0.7895 - val_loss: 0.5848 - val_accuracy: 0.8098\n",
      "Epoch 158/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5705 - accuracy: 0.8023 - val_loss: 0.4608 - val_accuracy: 0.8537\n",
      "Epoch 159/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5581 - accuracy: 0.8128 - val_loss: 0.4569 - val_accuracy: 0.8634\n",
      "Epoch 160/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5188 - accuracy: 0.8245 - val_loss: 0.4762 - val_accuracy: 0.8488\n",
      "Epoch 161/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5362 - accuracy: 0.8140 - val_loss: 0.5325 - val_accuracy: 0.8341\n",
      "Epoch 162/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5446 - accuracy: 0.8082 - val_loss: 0.5009 - val_accuracy: 0.8146\n",
      "Epoch 163/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5554 - accuracy: 0.8041 - val_loss: 0.5371 - val_accuracy: 0.8390\n",
      "Epoch 164/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5386 - accuracy: 0.8122 - val_loss: 0.4548 - val_accuracy: 0.8390\n",
      "Epoch 165/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5191 - accuracy: 0.8140 - val_loss: 0.6731 - val_accuracy: 0.7756\n",
      "Epoch 166/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5208 - accuracy: 0.8210 - val_loss: 0.4133 - val_accuracy: 0.8585\n",
      "Epoch 167/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5612 - accuracy: 0.8070 - val_loss: 0.4904 - val_accuracy: 0.8341\n",
      "Epoch 168/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5270 - accuracy: 0.8157 - val_loss: 0.4645 - val_accuracy: 0.8439\n",
      "Epoch 169/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5567 - accuracy: 0.8047 - val_loss: 0.5745 - val_accuracy: 0.8049\n",
      "Epoch 170/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5239 - accuracy: 0.8251 - val_loss: 0.4666 - val_accuracy: 0.8585\n",
      "Epoch 171/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4986 - accuracy: 0.8262 - val_loss: 0.5148 - val_accuracy: 0.8098\n",
      "Epoch 172/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5161 - accuracy: 0.8087 - val_loss: 0.4259 - val_accuracy: 0.8390\n",
      "Epoch 173/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4924 - accuracy: 0.8402 - val_loss: 0.4922 - val_accuracy: 0.8390\n",
      "Epoch 174/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4953 - accuracy: 0.8344 - val_loss: 0.5280 - val_accuracy: 0.8341\n",
      "Epoch 175/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4973 - accuracy: 0.8222 - val_loss: 0.4266 - val_accuracy: 0.8585\n",
      "Epoch 176/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5192 - accuracy: 0.8093 - val_loss: 0.5707 - val_accuracy: 0.8146\n",
      "Epoch 177/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5189 - accuracy: 0.8292 - val_loss: 0.4590 - val_accuracy: 0.8488\n",
      "Epoch 178/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5273 - accuracy: 0.8210 - val_loss: 0.5633 - val_accuracy: 0.8098\n",
      "Epoch 179/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5122 - accuracy: 0.8239 - val_loss: 0.5722 - val_accuracy: 0.8341\n",
      "Epoch 180/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4778 - accuracy: 0.8348 - val_loss: 0.5026 - val_accuracy: 0.8341\n",
      "Epoch 181/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4565 - accuracy: 0.8385 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 182/2000\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.4880 - accuracy: 0.8303 - val_loss: 0.4852 - val_accuracy: 0.8244\n",
      "Epoch 183/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.5332 - accuracy: 0.8163 - val_loss: 0.5084 - val_accuracy: 0.8244\n",
      "Epoch 184/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5070 - accuracy: 0.8280 - val_loss: 0.4590 - val_accuracy: 0.8341\n",
      "Epoch 185/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4889 - accuracy: 0.8362 - val_loss: 0.4390 - val_accuracy: 0.8439\n",
      "Epoch 186/2000\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.4866 - accuracy: 0.8350 - val_loss: 0.6588 - val_accuracy: 0.7610\n",
      "Epoch 187/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4665 - accuracy: 0.8391 - val_loss: 0.5379 - val_accuracy: 0.8146\n",
      "Epoch 188/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5096 - accuracy: 0.8253 - val_loss: 0.5010 - val_accuracy: 0.8049\n",
      "Epoch 189/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4955 - accuracy: 0.8210 - val_loss: 0.4613 - val_accuracy: 0.8341\n",
      "Epoch 190/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4895 - accuracy: 0.8356 - val_loss: 0.5363 - val_accuracy: 0.8195\n",
      "Epoch 191/2000\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4942 - accuracy: 0.8227 - val_loss: 0.4927 - val_accuracy: 0.8341\n",
      "Epoch 192/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4729 - accuracy: 0.8332 - val_loss: 0.4587 - val_accuracy: 0.8488\n",
      "Epoch 193/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.5112 - accuracy: 0.8175 - val_loss: 0.4780 - val_accuracy: 0.8244\n",
      "Epoch 194/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4805 - accuracy: 0.8344 - val_loss: 0.5292 - val_accuracy: 0.8098\n",
      "Epoch 195/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4666 - accuracy: 0.8385 - val_loss: 0.4407 - val_accuracy: 0.8634\n",
      "Epoch 196/2000\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4866 - accuracy: 0.8385 - val_loss: 0.4912 - val_accuracy: 0.8341\n",
      "Epoch 197/2000\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4599 - accuracy: 0.8420 - val_loss: 0.4252 - val_accuracy: 0.8585\n",
      "Epoch 198/2000\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4979 - accuracy: 0.8309 - val_loss: 0.4971 - val_accuracy: 0.8146\n",
      "Epoch 199/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4833 - accuracy: 0.8356 - val_loss: 0.5474 - val_accuracy: 0.8000\n",
      "Epoch 200/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4599 - accuracy: 0.8315 - val_loss: 0.8842 - val_accuracy: 0.7122\n",
      "Epoch 201/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4850 - accuracy: 0.8280 - val_loss: 0.5354 - val_accuracy: 0.8293\n",
      "Epoch 202/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4359 - accuracy: 0.8426 - val_loss: 0.4999 - val_accuracy: 0.8341\n",
      "Epoch 203/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4662 - accuracy: 0.8431 - val_loss: 0.4768 - val_accuracy: 0.8488\n",
      "Epoch 204/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4348 - accuracy: 0.8519 - val_loss: 0.4616 - val_accuracy: 0.8585\n",
      "Epoch 205/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4679 - accuracy: 0.8391 - val_loss: 0.4999 - val_accuracy: 0.8390\n",
      "Epoch 206/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4651 - accuracy: 0.8391 - val_loss: 0.6559 - val_accuracy: 0.7854\n",
      "Epoch 207/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4862 - accuracy: 0.8420 - val_loss: 0.4862 - val_accuracy: 0.8585\n",
      "Epoch 208/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4712 - accuracy: 0.8338 - val_loss: 0.5174 - val_accuracy: 0.8341\n",
      "Epoch 209/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4075 - accuracy: 0.8525 - val_loss: 0.5091 - val_accuracy: 0.8439\n",
      "Epoch 210/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4380 - accuracy: 0.8402 - val_loss: 0.4828 - val_accuracy: 0.8488\n",
      "Epoch 211/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4445 - accuracy: 0.8414 - val_loss: 0.4719 - val_accuracy: 0.8439\n",
      "Epoch 212/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4492 - accuracy: 0.8437 - val_loss: 0.4759 - val_accuracy: 0.8439\n",
      "Epoch 213/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4491 - accuracy: 0.8385 - val_loss: 0.4942 - val_accuracy: 0.8341\n",
      "Epoch 214/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4418 - accuracy: 0.8466 - val_loss: 0.4686 - val_accuracy: 0.8439\n",
      "Epoch 215/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4197 - accuracy: 0.8560 - val_loss: 0.4097 - val_accuracy: 0.8537\n",
      "Epoch 216/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4193 - accuracy: 0.8595 - val_loss: 0.5501 - val_accuracy: 0.8146\n",
      "Epoch 217/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4563 - accuracy: 0.8385 - val_loss: 0.4357 - val_accuracy: 0.8439\n",
      "Epoch 218/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4258 - accuracy: 0.8583 - val_loss: 0.4974 - val_accuracy: 0.8439\n",
      "Epoch 219/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4054 - accuracy: 0.8595 - val_loss: 0.4737 - val_accuracy: 0.8439\n",
      "Epoch 220/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3875 - accuracy: 0.8700 - val_loss: 0.4807 - val_accuracy: 0.8439\n",
      "Epoch 221/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4351 - accuracy: 0.8536 - val_loss: 0.4578 - val_accuracy: 0.8390\n",
      "Epoch 222/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4386 - accuracy: 0.8490 - val_loss: 0.5594 - val_accuracy: 0.8000\n",
      "Epoch 223/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4303 - accuracy: 0.8577 - val_loss: 0.4683 - val_accuracy: 0.8488\n",
      "Epoch 224/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4695 - accuracy: 0.8385 - val_loss: 0.4698 - val_accuracy: 0.8585\n",
      "Epoch 225/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4003 - accuracy: 0.8566 - val_loss: 0.4212 - val_accuracy: 0.8537\n",
      "Epoch 226/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4539 - accuracy: 0.8443 - val_loss: 0.4103 - val_accuracy: 0.8537\n",
      "Epoch 227/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4502 - accuracy: 0.8431 - val_loss: 0.4726 - val_accuracy: 0.8439\n",
      "Epoch 228/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3993 - accuracy: 0.8577 - val_loss: 0.5526 - val_accuracy: 0.8293\n",
      "Epoch 229/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4472 - accuracy: 0.8449 - val_loss: 0.4715 - val_accuracy: 0.8341\n",
      "Epoch 230/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4177 - accuracy: 0.8612 - val_loss: 0.4843 - val_accuracy: 0.8537\n",
      "Epoch 231/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4523 - accuracy: 0.8484 - val_loss: 0.6254 - val_accuracy: 0.7854\n",
      "Epoch 232/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4148 - accuracy: 0.8548 - val_loss: 0.4734 - val_accuracy: 0.8683\n",
      "Epoch 233/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3949 - accuracy: 0.8606 - val_loss: 0.4445 - val_accuracy: 0.8537\n",
      "Epoch 234/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4327 - accuracy: 0.8455 - val_loss: 0.4424 - val_accuracy: 0.8537\n",
      "Epoch 235/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3702 - accuracy: 0.8706 - val_loss: 0.4028 - val_accuracy: 0.8780\n",
      "Epoch 236/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4271 - accuracy: 0.8461 - val_loss: 0.4698 - val_accuracy: 0.8585\n",
      "Epoch 237/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4457 - accuracy: 0.8449 - val_loss: 0.4951 - val_accuracy: 0.8341\n",
      "Epoch 238/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4279 - accuracy: 0.8513 - val_loss: 0.5233 - val_accuracy: 0.8390\n",
      "Epoch 239/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3914 - accuracy: 0.8606 - val_loss: 0.5864 - val_accuracy: 0.8000\n",
      "Epoch 240/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4111 - accuracy: 0.8595 - val_loss: 0.4637 - val_accuracy: 0.8341\n",
      "Epoch 241/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4141 - accuracy: 0.8571 - val_loss: 0.4969 - val_accuracy: 0.8049\n",
      "Epoch 242/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3948 - accuracy: 0.8618 - val_loss: 0.4840 - val_accuracy: 0.8293\n",
      "Epoch 243/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4015 - accuracy: 0.8618 - val_loss: 0.5050 - val_accuracy: 0.8390\n",
      "Epoch 244/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3884 - accuracy: 0.8671 - val_loss: 0.4802 - val_accuracy: 0.8244\n",
      "Epoch 245/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4237 - accuracy: 0.8490 - val_loss: 0.4139 - val_accuracy: 0.8634\n",
      "Epoch 246/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4124 - accuracy: 0.8577 - val_loss: 0.4735 - val_accuracy: 0.8537\n",
      "Epoch 247/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3648 - accuracy: 0.8741 - val_loss: 0.5269 - val_accuracy: 0.8439\n",
      "Epoch 248/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4036 - accuracy: 0.8641 - val_loss: 0.5246 - val_accuracy: 0.8244\n",
      "Epoch 249/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3845 - accuracy: 0.8676 - val_loss: 0.5113 - val_accuracy: 0.8537\n",
      "Epoch 250/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3748 - accuracy: 0.8671 - val_loss: 0.4668 - val_accuracy: 0.8439\n",
      "Epoch 251/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3977 - accuracy: 0.8630 - val_loss: 0.4549 - val_accuracy: 0.8390\n",
      "Epoch 252/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3800 - accuracy: 0.8618 - val_loss: 0.4478 - val_accuracy: 0.8634\n",
      "Epoch 253/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3861 - accuracy: 0.8723 - val_loss: 0.4760 - val_accuracy: 0.8439\n",
      "Epoch 254/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3244 - accuracy: 0.8840 - val_loss: 0.4588 - val_accuracy: 0.8390\n",
      "Epoch 255/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3391 - accuracy: 0.8787 - val_loss: 0.4246 - val_accuracy: 0.8488\n",
      "Epoch 256/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3668 - accuracy: 0.8700 - val_loss: 0.4460 - val_accuracy: 0.8927\n",
      "Epoch 257/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3952 - accuracy: 0.8694 - val_loss: 0.6944 - val_accuracy: 0.7854\n",
      "Epoch 258/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3577 - accuracy: 0.8688 - val_loss: 0.5049 - val_accuracy: 0.8488\n",
      "Epoch 259/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3650 - accuracy: 0.8659 - val_loss: 0.4610 - val_accuracy: 0.8537\n",
      "Epoch 260/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3721 - accuracy: 0.8653 - val_loss: 0.4645 - val_accuracy: 0.8537\n",
      "Epoch 261/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3884 - accuracy: 0.8688 - val_loss: 0.4370 - val_accuracy: 0.8585\n",
      "Epoch 262/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3664 - accuracy: 0.8653 - val_loss: 0.4505 - val_accuracy: 0.8390\n",
      "Epoch 263/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3612 - accuracy: 0.8776 - val_loss: 0.4442 - val_accuracy: 0.8488\n",
      "Epoch 264/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3938 - accuracy: 0.8531 - val_loss: 0.6142 - val_accuracy: 0.7951\n",
      "Epoch 265/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3433 - accuracy: 0.8892 - val_loss: 0.4245 - val_accuracy: 0.8585\n",
      "Epoch 266/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3677 - accuracy: 0.8799 - val_loss: 0.4642 - val_accuracy: 0.8439\n",
      "Epoch 267/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3640 - accuracy: 0.8723 - val_loss: 0.4886 - val_accuracy: 0.8390\n",
      "Epoch 268/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3773 - accuracy: 0.8571 - val_loss: 0.4370 - val_accuracy: 0.8634\n",
      "Epoch 269/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3445 - accuracy: 0.8840 - val_loss: 0.5640 - val_accuracy: 0.8244\n",
      "Epoch 270/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3531 - accuracy: 0.8787 - val_loss: 0.4183 - val_accuracy: 0.8683\n",
      "Epoch 271/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3658 - accuracy: 0.8776 - val_loss: 0.4219 - val_accuracy: 0.8732\n",
      "Epoch 272/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3836 - accuracy: 0.8653 - val_loss: 0.4384 - val_accuracy: 0.8829\n",
      "Epoch 273/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3446 - accuracy: 0.8776 - val_loss: 0.5174 - val_accuracy: 0.8341\n",
      "Epoch 274/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3310 - accuracy: 0.8805 - val_loss: 0.4334 - val_accuracy: 0.8585\n",
      "Epoch 275/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3699 - accuracy: 0.8746 - val_loss: 0.4998 - val_accuracy: 0.8390\n",
      "Epoch 276/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3658 - accuracy: 0.8752 - val_loss: 0.4266 - val_accuracy: 0.8537\n",
      "Epoch 277/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3662 - accuracy: 0.8787 - val_loss: 0.4245 - val_accuracy: 0.8585\n",
      "Epoch 278/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3684 - accuracy: 0.8612 - val_loss: 0.3909 - val_accuracy: 0.8537\n",
      "Epoch 279/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3367 - accuracy: 0.8880 - val_loss: 0.3999 - val_accuracy: 0.8732\n",
      "Epoch 280/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3486 - accuracy: 0.8781 - val_loss: 0.5016 - val_accuracy: 0.8634\n",
      "Epoch 281/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3584 - accuracy: 0.8741 - val_loss: 0.4730 - val_accuracy: 0.8341\n",
      "Epoch 282/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3717 - accuracy: 0.8706 - val_loss: 0.4656 - val_accuracy: 0.8537\n",
      "Epoch 283/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3369 - accuracy: 0.8857 - val_loss: 0.4944 - val_accuracy: 0.8390\n",
      "Epoch 284/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3566 - accuracy: 0.8834 - val_loss: 0.4633 - val_accuracy: 0.8341\n",
      "Epoch 285/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3509 - accuracy: 0.8741 - val_loss: 0.4328 - val_accuracy: 0.8732\n",
      "Epoch 286/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3703 - accuracy: 0.8758 - val_loss: 0.4814 - val_accuracy: 0.8488\n",
      "Epoch 287/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3477 - accuracy: 0.8711 - val_loss: 0.4584 - val_accuracy: 0.8537\n",
      "Epoch 288/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3534 - accuracy: 0.8776 - val_loss: 0.4404 - val_accuracy: 0.8585\n",
      "Epoch 289/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3427 - accuracy: 0.8752 - val_loss: 0.4622 - val_accuracy: 0.8634\n",
      "Epoch 290/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3463 - accuracy: 0.8845 - val_loss: 0.4076 - val_accuracy: 0.8732\n",
      "Epoch 291/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3545 - accuracy: 0.8746 - val_loss: 0.4636 - val_accuracy: 0.8634\n",
      "Epoch 292/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3343 - accuracy: 0.8787 - val_loss: 0.4704 - val_accuracy: 0.8537\n",
      "Epoch 293/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3428 - accuracy: 0.8857 - val_loss: 0.4825 - val_accuracy: 0.8537\n",
      "Epoch 294/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3173 - accuracy: 0.8892 - val_loss: 0.5250 - val_accuracy: 0.8146\n",
      "Epoch 295/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3458 - accuracy: 0.8776 - val_loss: 0.4693 - val_accuracy: 0.8634\n",
      "Epoch 296/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3441 - accuracy: 0.8863 - val_loss: 0.4291 - val_accuracy: 0.8537\n",
      "Epoch 297/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3344 - accuracy: 0.8799 - val_loss: 0.4641 - val_accuracy: 0.8634\n",
      "Epoch 298/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3081 - accuracy: 0.8886 - val_loss: 0.4838 - val_accuracy: 0.8439\n",
      "Epoch 299/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3181 - accuracy: 0.8834 - val_loss: 0.4557 - val_accuracy: 0.8683\n",
      "Epoch 300/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3319 - accuracy: 0.8857 - val_loss: 0.4408 - val_accuracy: 0.8439\n",
      "Epoch 301/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3170 - accuracy: 0.8962 - val_loss: 0.4753 - val_accuracy: 0.8634\n",
      "Epoch 302/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3252 - accuracy: 0.8856 - val_loss: 0.5378 - val_accuracy: 0.8244\n",
      "Epoch 303/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3563 - accuracy: 0.8793 - val_loss: 0.4821 - val_accuracy: 0.8439\n",
      "Epoch 304/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3116 - accuracy: 0.8892 - val_loss: 0.4735 - val_accuracy: 0.8341\n",
      "Epoch 305/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3247 - accuracy: 0.8828 - val_loss: 0.4681 - val_accuracy: 0.8585\n",
      "Epoch 306/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3200 - accuracy: 0.8880 - val_loss: 0.4004 - val_accuracy: 0.8780\n",
      "Epoch 307/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3278 - accuracy: 0.8851 - val_loss: 0.5283 - val_accuracy: 0.8293\n",
      "Epoch 308/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3395 - accuracy: 0.8810 - val_loss: 0.6286 - val_accuracy: 0.7951\n",
      "Epoch 309/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3237 - accuracy: 0.8845 - val_loss: 0.4253 - val_accuracy: 0.8634\n",
      "Epoch 310/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2876 - accuracy: 0.8974 - val_loss: 0.4571 - val_accuracy: 0.8585\n",
      "Epoch 311/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3081 - accuracy: 0.8991 - val_loss: 0.3861 - val_accuracy: 0.8683\n",
      "Epoch 312/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3072 - accuracy: 0.8939 - val_loss: 0.4515 - val_accuracy: 0.8585\n",
      "Epoch 313/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3198 - accuracy: 0.8776 - val_loss: 0.4226 - val_accuracy: 0.8780\n",
      "Epoch 314/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3339 - accuracy: 0.8851 - val_loss: 0.4510 - val_accuracy: 0.8732\n",
      "Epoch 315/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3311 - accuracy: 0.8898 - val_loss: 0.4836 - val_accuracy: 0.8439\n",
      "Epoch 316/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2959 - accuracy: 0.9038 - val_loss: 0.4751 - val_accuracy: 0.8488\n",
      "Epoch 317/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3197 - accuracy: 0.8875 - val_loss: 0.4482 - val_accuracy: 0.8780\n",
      "Epoch 318/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3463 - accuracy: 0.8828 - val_loss: 0.3753 - val_accuracy: 0.8927\n",
      "Epoch 319/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2922 - accuracy: 0.8915 - val_loss: 0.4005 - val_accuracy: 0.8829\n",
      "Epoch 320/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3394 - accuracy: 0.8869 - val_loss: 0.4223 - val_accuracy: 0.8585\n",
      "Epoch 321/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3163 - accuracy: 0.8840 - val_loss: 0.4068 - val_accuracy: 0.8927\n",
      "Epoch 322/2000\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3275 - accuracy: 0.8840 - val_loss: 0.4882 - val_accuracy: 0.8488\n",
      "Epoch 323/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3240 - accuracy: 0.8910 - val_loss: 0.4145 - val_accuracy: 0.8634\n",
      "Epoch 324/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3192 - accuracy: 0.8869 - val_loss: 0.4395 - val_accuracy: 0.8732\n",
      "Epoch 325/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3137 - accuracy: 0.8950 - val_loss: 0.4489 - val_accuracy: 0.8537\n",
      "Epoch 326/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3064 - accuracy: 0.8956 - val_loss: 0.4454 - val_accuracy: 0.8780\n",
      "Epoch 327/2000\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3198 - accuracy: 0.8851 - val_loss: 0.4462 - val_accuracy: 0.8780\n",
      "Epoch 328/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3080 - accuracy: 0.8974 - val_loss: 0.4813 - val_accuracy: 0.8439\n",
      "Epoch 329/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3512 - accuracy: 0.8845 - val_loss: 0.4911 - val_accuracy: 0.8341\n",
      "Epoch 330/2000\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2937 - accuracy: 0.8997 - val_loss: 0.4621 - val_accuracy: 0.8439\n",
      "Epoch 331/2000\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2783 - accuracy: 0.9026 - val_loss: 0.4660 - val_accuracy: 0.8634\n",
      "Epoch 00331: early stopping\n",
      "CNN: Epochs=2000, Train accuracy=0.90379, Validation accuracy=0.89268\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "batch_size = 128\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1598336814187,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "30b0e4a2-9738-4989-eb06-1c54ecef6b41"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#맥스풀링 마지막에만 하고 FC두번 거쳐서 하니 느리지만 꾸준히 정확도 증가 80에서 거의 멈춤 - 해결 방안?\n",
    "#epoch 180정도로 한 결과 = model_9\n",
    "#model_9는 0.89166, 0.87805\n",
    "#model_9-2를 eopch 230, relu 대신 leaky relu\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EQCvPGZks9v"
   },
   "outputs": [],
   "source": [
    "#Parameter 저장\n",
    "model.save_weights(f'data/cvision/params_9-5.h5')\n",
    "\n",
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'data/cvision/model_9-5.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-8nb5jokyny"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-40-dbea146f3fce>:6: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('data/cvision/my_subm_9-5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_279 (Conv2D)          (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_222 (Bat (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_280 (Conv2D)          (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_223 (Bat (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_281 (Conv2D)          (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_224 (Bat (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_282 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_225 (Bat (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_283 (Conv2D)          (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_226 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_284 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_227 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_285 (Conv2D)          (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_228 (Bat (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_286 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 50)                313650    \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 609,512\n",
      "Trainable params: 608,452\n",
      "Non-trainable params: 1,060\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model_9-6: \n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Conv2D(128, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), Adam(0.001)\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537462,
     "status": "error",
     "timestamp": 1598347660504,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "012ce4a9-2ca8-41d3-d1de-9331032469e3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "359/359 [==============================] - 7s 18ms/step - loss: 1.8772 - accuracy: 0.3564 - val_loss: 4.1103 - val_accuracy: 0.1122\n",
      "Epoch 2/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 1.2489 - accuracy: 0.5842 - val_loss: 1.5237 - val_accuracy: 0.5293\n",
      "Epoch 3/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.9815 - accuracy: 0.6760 - val_loss: 0.8388 - val_accuracy: 0.7463\n",
      "Epoch 4/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.8160 - accuracy: 0.7318 - val_loss: 0.7002 - val_accuracy: 0.7561\n",
      "Epoch 5/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.7293 - accuracy: 0.7585 - val_loss: 0.6685 - val_accuracy: 0.7951\n",
      "Epoch 6/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.6461 - accuracy: 0.7841 - val_loss: 0.5892 - val_accuracy: 0.8024\n",
      "Epoch 7/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.5905 - accuracy: 0.8012 - val_loss: 0.4901 - val_accuracy: 0.8390\n",
      "Epoch 8/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.5310 - accuracy: 0.8227 - val_loss: 0.4620 - val_accuracy: 0.8390\n",
      "Epoch 9/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.4840 - accuracy: 0.8414 - val_loss: 0.5633 - val_accuracy: 0.8098\n",
      "Epoch 10/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.4545 - accuracy: 0.8485 - val_loss: 0.4004 - val_accuracy: 0.8683\n",
      "Epoch 11/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.4055 - accuracy: 0.8619 - val_loss: 0.4800 - val_accuracy: 0.8268\n",
      "Epoch 12/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.3752 - accuracy: 0.8731 - val_loss: 0.3984 - val_accuracy: 0.8683\n",
      "Epoch 13/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.3650 - accuracy: 0.8769 - val_loss: 0.3934 - val_accuracy: 0.8610\n",
      "Epoch 14/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.3392 - accuracy: 0.8864 - val_loss: 0.3738 - val_accuracy: 0.8805\n",
      "Epoch 15/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.3054 - accuracy: 0.8994 - val_loss: 0.3737 - val_accuracy: 0.8805\n",
      "Epoch 16/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.2934 - accuracy: 0.9014 - val_loss: 0.3738 - val_accuracy: 0.8756\n",
      "Epoch 17/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.2800 - accuracy: 0.9054 - val_loss: 0.3888 - val_accuracy: 0.8854\n",
      "Epoch 18/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.2616 - accuracy: 0.9127 - val_loss: 0.4044 - val_accuracy: 0.8902\n",
      "Epoch 19/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.2485 - accuracy: 0.9155 - val_loss: 0.3691 - val_accuracy: 0.8927\n",
      "Epoch 20/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.2370 - accuracy: 0.9205 - val_loss: 0.3652 - val_accuracy: 0.9024\n",
      "Epoch 21/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.2179 - accuracy: 0.9247 - val_loss: 0.3453 - val_accuracy: 0.8927\n",
      "Epoch 22/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.2201 - accuracy: 0.9260 - val_loss: 0.3925 - val_accuracy: 0.8780\n",
      "Epoch 23/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.1958 - accuracy: 0.9326 - val_loss: 0.3870 - val_accuracy: 0.8829\n",
      "Epoch 24/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.1891 - accuracy: 0.9337 - val_loss: 0.3784 - val_accuracy: 0.8902\n",
      "Epoch 25/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.1958 - accuracy: 0.9359 - val_loss: 0.3616 - val_accuracy: 0.8829\n",
      "Epoch 26/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.1741 - accuracy: 0.9405 - val_loss: 0.4769 - val_accuracy: 0.8780\n",
      "Epoch 27/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.1676 - accuracy: 0.9436 - val_loss: 0.3855 - val_accuracy: 0.8951\n",
      "Epoch 28/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.1577 - accuracy: 0.9454 - val_loss: 0.3281 - val_accuracy: 0.8927\n",
      "Epoch 29/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.1609 - accuracy: 0.9445 - val_loss: 0.3651 - val_accuracy: 0.8854\n",
      "Epoch 30/100\n",
      "359/359 [==============================] - 7s 18ms/step - loss: 0.1506 - accuracy: 0.9503 - val_loss: 0.3776 - val_accuracy: 0.8780\n",
      "Epoch 31/100\n",
      "359/359 [==============================] - 8s 21ms/step - loss: 0.1423 - accuracy: 0.9520 - val_loss: 0.4199 - val_accuracy: 0.8951\n",
      "Epoch 32/100\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 0.1396 - accuracy: 0.9526 - val_loss: 0.3596 - val_accuracy: 0.8805\n",
      "Epoch 33/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.1397 - accuracy: 0.9531 - val_loss: 0.3235 - val_accuracy: 0.9024\n",
      "Epoch 34/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.1333 - accuracy: 0.9531 - val_loss: 0.4916 - val_accuracy: 0.8780\n",
      "Epoch 35/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.1264 - accuracy: 0.9572 - val_loss: 0.4178 - val_accuracy: 0.8805\n",
      "Epoch 36/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.1262 - accuracy: 0.9581 - val_loss: 0.3929 - val_accuracy: 0.8951\n",
      "Epoch 37/100\n",
      "359/359 [==============================] - 7s 20ms/step - loss: 0.1156 - accuracy: 0.9599 - val_loss: 0.4554 - val_accuracy: 0.8683\n",
      "Epoch 38/100\n",
      "359/359 [==============================] - 8s 22ms/step - loss: 0.1207 - accuracy: 0.9591 - val_loss: 0.4310 - val_accuracy: 0.8951\n",
      "Epoch 39/100\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 0.1196 - accuracy: 0.9622 - val_loss: 0.4829 - val_accuracy: 0.8854\n",
      "Epoch 40/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.1061 - accuracy: 0.9657 - val_loss: 0.4276 - val_accuracy: 0.8829\n",
      "Epoch 41/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.0984 - accuracy: 0.9666 - val_loss: 0.4550 - val_accuracy: 0.8854\n",
      "Epoch 42/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.1039 - accuracy: 0.9668 - val_loss: 0.4728 - val_accuracy: 0.8805\n",
      "Epoch 43/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.0923 - accuracy: 0.9680 - val_loss: 0.4232 - val_accuracy: 0.8878\n",
      "Epoch 44/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.0984 - accuracy: 0.9659 - val_loss: 0.4507 - val_accuracy: 0.8902\n",
      "Epoch 45/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.0923 - accuracy: 0.9693 - val_loss: 0.4429 - val_accuracy: 0.8829\n",
      "Epoch 46/100\n",
      "359/359 [==============================] - 7s 18ms/step - loss: 0.0960 - accuracy: 0.9671 - val_loss: 0.3992 - val_accuracy: 0.9073\n",
      "Epoch 47/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.1001 - accuracy: 0.9656 - val_loss: 0.4142 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.0898 - accuracy: 0.9696 - val_loss: 0.4068 - val_accuracy: 0.8878\n",
      "Epoch 49/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.0864 - accuracy: 0.9693 - val_loss: 0.4119 - val_accuracy: 0.8829\n",
      "Epoch 50/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.0793 - accuracy: 0.9726 - val_loss: 0.3471 - val_accuracy: 0.9073\n",
      "Epoch 51/100\n",
      "359/359 [==============================] - 6s 17ms/step - loss: 0.0839 - accuracy: 0.9709 - val_loss: 0.4558 - val_accuracy: 0.8927\n",
      "Epoch 52/100\n",
      "359/359 [==============================] - 7s 18ms/step - loss: 0.0740 - accuracy: 0.9738 - val_loss: 0.4497 - val_accuracy: 0.8780\n",
      "Epoch 53/100\n",
      "359/359 [==============================] - 6s 18ms/step - loss: 0.0793 - accuracy: 0.9741 - val_loss: 0.4096 - val_accuracy: 0.8951\n",
      "Epoch 00053: early stopping\n",
      "CNN: Epochs=100, Train accuracy=0.97410, Validation accuracy=0.90732\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "lrs = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** x)\n",
    "\n",
    "#earlystopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "#modelcheckpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "model_num = 'model_9-6'\n",
    "MODEL_SAVE_FOLDER_PATH = './data/cvision/' + model_num + '/'\n",
    "\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "    \n",
    "model_path = MODEL_SAVE_FOLDER_PATH + model_num +'vl{val_loss:.4f}-va{val_accuracy:.4f}-ep{epoch:02d}.hdf5'\n",
    "\n",
    "cp = ModelCheckpoint(filepath=model_path, monitor='val_loss',\n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_X, y=train_y,\n",
    "    epochs = epochs,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[es, cp, lrs]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1598336814187,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "30b0e4a2-9738-4989-eb06-1c54ecef6b41"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3wUZf7A8c9sS3aTTQ/pCQFCC70LUkUFFNt5eqfe7xR7QU89z+55ttOzn4qIyKmnZy+gVFukKKFKLwkE0kN62yTb5vfHJIGQSkhI+75fr31tMvPMzLMD2e88XVFVFSGEEEJ0HF1HZ0AIIYTo6SQYCyGEEB1MgrEQQgjRwSQYCyGEEB1MgrEQQgjRwSQYCyGEEB2s2WCsKMoSRVGOKYqyu5H9iqIo/1YUJVlRlJ2Kooxq+2wKIYQQ3VdLSsbvArOa2D8biKt+3QS8efrZEkIIIXqOZoOxqqprgYImklwMvK9qNgJ+iqKEtVUGhRBCiO6uLdqMI4C0E35Pr94mhBBCiBYwtME5lAa2NTjHpqIoN6FVZWM2m0dHRUW1weU1brcbne7Uni1KXCUUuYpwV0YQZNbhbWzoo3R/rbl3Qu5ba8l9ax25b63T2e7bwYMH81RVDT55e1sE43TgxKgaCWQ2lFBV1UXAIoAxY8aoW7ZsaYPLaxISEpg2bdopHfPhvg95dtOzlB58lPtmjuL26f3aLD9dSWvunZD71lpy31pH7lvrdLb7pijK0Ya2t8XjwjLg/6p7VU8AilVVzWqD87Y7s8EMgI9ZJbu4soNzI4QQoqdqtmSsKMpHwDQgSFGUdODvgBFAVdWFwApgDpAM2IDr2iuzba0mGAdZFbJLJBgLIYToGM0GY1VV/9jMfhW4vc1ydAZ56j0BCLRCVnFFB+dGCCFET9V5WrU7gNlYXTL2UTiaZ0PWdhZCCNER2qIDV5dVU00d6qejtMpJZnElEX7mDs6VEEKIJtltUJIBxemgusHTV3t5+GjvRs+66R2VUJYNpdlQkqm9l2ZBeS64HNo5VFf1uwrump/dcMX7YLK0+0eSYAz08tWGNB3MLpVgLIToXpx2LaicHKCaO6YkA4rToDgDFAUsgWAOAIu/9rOHj7b9VKkqlOVAwWEoSNGCJAooOtDptXdFB4peO7+9XAu6J+anoql5qAC9SQvKJm8mleZBQmkDaTzAOwQMphOu2cBLdZ36Z2yFnh2M9Vrg9ffS/kPtzy5l+sBeHZklIURPYbdpQaY4FYrSoKoEnFXVr8q6764q4o/lQNYiQD1eglPd2u9uFzgqwFGunddhq34vB7dTu57BUwumZn+wVL/X/Ox2VQe6dO1Vmk0j00UcpzNUnyOgulRqPeHlc/xnvUk7d8FhKDyivTtsp3avPHzBN1J7RY7V3n0iwTdCy0dlCVQWQ2WRdh8ri7VXVSnHCsqJGDAGrKHgEwbW6pfZv3UPE+2kZwfj6jZjRWcn1MeHgzkNPD0JIcSpcru00l9JplaiK8nUglxRqhaYitLAltfwsYoODGYweBx/6T0wV1RCUVl1AKkuSSrK8RKc0awFGJMFjBYweVW/W7T9FUVaibKiCGwFkHdQe68o1PbXBLu+54Bf1PHffaunkbAVaMfb8rWfbfnVvxdUB8Ai7bNVlWove9nxz6Q3gX8sBPSB2Cnae0Csts0nXPs86glVw27X8YcNgwd4+rT6nyIpIYGIqdNaffyZ0rODcXU1dYWzggGhVg5kSzAWotuyFWgBw1mllSKdldrLUXn858qSuiWr2hJWiVZdqjNq1Zp6jxPePbRgo7qqg291m+TJ1ZsGsxbc/KIgdFh1wIuufo/SAqnBE/QNfy1vaa/JK2o6rjZXSgzse2rndbu0gOyoBK8grQpaNKpHB+OaoU01wfjXw/k4XW4M+h7dyVyIrstWoFWD5h+qbpM8dPznyqKWn8doqdshyBIIftFagKmuNsZp10qATrv2u6LTqj9jp2qlPZ/w6urUcPCJ6HTVorXaK086/fGOVaJZPToY63V6TDoTFa4KBoRYsTvdHMm30a+Xd0dnTYiux2mH3P1a9ezJpcqaNr2qUoblZUOKFdwOrT3TddJ7zcvlqE7jOr7vlDrTKFqpM6APDPmd9m4J1DoyGU54nfi7h49WJao3ttttEqIhPToYg9ZuXOGoYECUFYAD2aUSjIVojtMOufsg8zfI3A5Zv0HOHnDZ66fVGU4oZfqgd1UC3lrw0xm0wHfiu86oVdXW/mzUSlk64/F20sZ4+GjVqQF9wT9Gq0IWoguQYGwwU+GsoF8vb3QKHMgp5QJkOWbRjbic2vCRkiwozYTSHK3Ktqb3acUJP1cWa9WwNW2hBs+6HYkMnlp7aM7u44HXwxfChsH4WyB8hNb+WWfMp7lOAN3eySbuF6IzkGBcHYw9jXp6B3pxUDpxia5GVbUAmXcAcg9CfpI2FrO0ujNR2TEaHKZi9Drepmf209o1e8VrQddlrzvMxlXdPlqWq6UdfzOEj4SwEVqP2E60RJ0QXVGPD8aeek8qXdoiEf1DrByQ4U2is3E5tVJr7ZCSPK1DUu7B4wG4qvh4epNVayu1hkFIPFjDj3cosoZp4y09/bTewEKITqHHB+OakjHAgFArq/dmU+lw4WmUbviiHVQUQtomyE/WJj5wVByfpMFRcfy9svj4mM7K4obP5dULggfA0Mu19+ABEDRAC7adsdeuEKJREoyNZoqrv+wGhFpRVUjKKWNopHTHF6dJVaEwBVITIW2j9p67r24aRV89OYO5+mXR3j2sWgckc4DWA9hS/V4zY5JfjPYuhOgWenwwthgsZDuzAa2aGrROXBKMRYNcDm0WpYIUgo9thO3px6cdrC3h2rR22rRNUH5MO87DF6LGwdDfQdQErfrYwypDaIQQgATjOm3GvQMtmAw6mRazp6uZyD4vSatOzk/WJo7IT9ZKutVz/cYD7D3pWGP1VIRmP+g7HaLGQ/QECB4knZyEEI3q8cH4xDZjg15Hv2Bv9kuP6p6jokibqCJnDxzbV/3ao7Xt1jB4auNWew2CwRdBYD/wj2XT7iTGTZx6fA7gk4bwCCFES0kwPiEYAwwMtfLLofwOzJFoE6qqdXwqy9GG/ZTl1P25NFvrkVyScfwYk7U64F6slWSDB2iB1yeiwVKtLaVKa9cVQojTJMHYqAVjt+pGp+joH2rly+0ZFNsc+FqkPa9LKUqDI+sgZR2krIWS9PppDJ7aGqbWUIiZBCGDoVf1yzdSSrZCiA7R44NxzWIRVa4qzAYzA0KPd+IaFyu9VTu10pzq4LtWexWmaNvNAdD7bBh/kzbG1hoC3qHae2sXRBdC1OO22yn66CN0Vh+8xo/DGBFxxq6tqirFX32NzuyJ9fzzUbp4n4weH4xPXEbRbDAzIESCcaehqto424LD1a+U4z8Xpmj7QOup3HuSNitU78laKfc0/jBVVcV+5AiGoCD0VmsbfRhxutxVVbjy8zGGh3d0VgTgLCgg/Y75VGzbVrvNGBmJZfw4vCZMwDJuPMaQXu1ybdVuJ+uJJyj+/AsAPOL6EXTHfKznzuyyQVmC8QnBGCDM1xOrp4ED2SUdma3uz+WAAyuh8IjWWaqisHqe5MLjL1tB3QXKa1bh8Y+FQRdBUBzETNTWhm2DtVKrkpIoWbmSkpWrsKekoBiNeE2Zgs+sWVhnTEfn5XXa1xCtU3XoEOl33oX96FHCHv87fpdf3tFZ6tGqDh0i7ZZbcR47RsTLL2Hq2xdb4ibKEzdS+v0PFH/xJQCm3r2xnDUBv8suwzx0aJtc21VcTPqdd2FLTCTw1lvwjIsj9/U3yLjrLjwGDiR4/h14z5iB0sVqwCQYG6uDsUMLxoqiMCDEysHssqYOE61VUQRb34XEt7S5k0Fbncfsr03RaPbXqpSDB1VPbhGtLX0X0Ef7uY1X4alKSaFk5UpKV66kKikZdDos48bhf83VOFJTKVm1mrIffkDx8MB76lR85szGe+pUdGZzm+bjTFGdTir37UPn5YUhIACdj88ZK0moqoojLQ2czlM6rvjb5WQ99hg6sxnLiBFkPfIo9iNHCL7nnjbLu6qq2A8dwtS7N4rh1L8WVbsdR3Y2xqioLhcETlX5L7+QftdfUDw8iHn/PczDhwPg2b8/AX+6BtXlonL/fmyJm7AlJlL89VKKPvoYz+HDCLj6aqyzZqEztW4qVvvRo6TdciuO9HTCn3sW34svBsB6/vmULF9O7htvkH77HXjGxxN853y8pkxp9ed0V1VhS0zE+zTOcSokGOu1L9WascYA/UOtLN+Zhaqq3f4P64wpPAob34Tt/9VKu7FTYO6rEHMWmLzbrR3XXVGBq6AAZ0EBzvx8XPkFuAoLcOblU56YSNU+bUYs85jRhDz6CD7nnYchOLj2+F7330/Ftm2UrFhJyZo1lK5Zg2KxYJ02DcOwtnnSP1PKN20i58mnqEpKOr7RYEDv74chIBBDYAD6gECM4eFYxo7FMmpkm9UG2I8eJfuZZyj/eS1BgYEUFZfge/FFTQY+t93OsWefpfB/H2EePZqIl17EEBhI9lNPkb/4HexHjxL+3HPoLJbTylv5xkRyX3uNiq1b8Z4+nYiXX0Ln6dni411FRaTefDOVO3ZijI7GZ9YsfObMxmPAgG73/VH4yadkP/EEHn37EvXmggbbiBW9HnN8POb4eALnXYertJTir76m8MMPyfzb/ej/9Tz+V/wevyv/cErV2LYtW0i//Q5QFKL/swTLmDF1rul70UX4zJlD8dJl5C1YQNrNt2AePhzT1KmoU6ee0r9F6U8/kfPMP3FkZNB3zWpMkZEtPra1FFVtYDWXM2DMmDHqli1b2ux8Ca1clm1T1iauX3M9S85fwtjQsQC8/+sRHlu6h40PnkOob8v/KLuq1t67FknfCr++BnuXamvRDvkdnHU7hA1vs0uoLheO9HSqkpOpSkqi6mASVcnJ2NPTUW22Bo9RPDzwHDgQnzmzsc6ahTEkpEXXsW3erAXm1atxFxfjPX06wXfOx3PQoNP6DK7iYmybN1OeuAnbpk2g0+E1biyW8eOxjBmD3sen1ed25ORw7F/PU7J8OYbwMIJvvx3F5KE9lOQX4CrIr37XHlocmZla6dVgwDx0qNYGOH485pEjTylIAbhtNvIWLaLgnSUoJhP+11xD9sqVGFNTMcZEE3z77fhccAGKvm4zgz09g4y//IXK3bsJmDePXnf/BcWojW5QVZXC998n59nn8Bw8mMgFC1rVNmnbto3cV/+NLTERQ3Aw3jNmUPTpp1jGjCHyzQXovZtf19xx7Bhp19+A/cgRAm+6iYrffqN840ZwuTDFxuIze7YWmPv1O+X8nay1f6fOvDwq9+3THkYLCuv9e7vy89F5WbQHsHHjsYwfh8Hfv845VJeLY8+/QMG77+I1ZTIRL73UovtT5xxuN+UbfqHwww8p+/ln0OuxnjsT/9//Hs/4ePS+jc96WLx0KZmPPIopMpKotxZiio5u+lp2O0VffU3ewoU4s7IwjxlN8Pw78Ro/rsnj7Kmp5DzzT8oSEjD16UPoIw/jNXHiKX3O5iiKslVV1TH1tvf0YLwrdxdXrbiKN855gymRWnXExsP5/GHRRt6bN46p/YObOUPX1+bBuCgN9n4Nu7+EzG1aB6sx18K4m8H39HtbusvLKU1IoHztOi34Hj6MWnm8ZsMYHo4prh+mmBgMgUG1JT7tPQBDQACKxXJapRZXWRnbnngCn4SfcZeUYD33XILm34Fn//4tPt62ZUttVV7lvn2gqiienlhGjURVVSq2bUetqgKdDs9Bg7BMGK8FxVGj0Xs3X2JV7XYK/vtf8t5YgOp0EnjD9QTeeGOzVexumw3btu3YEhMp35RI5e494HKhGI2YR4zAMn48XuPH4Tl8eKPVjaqqUrp6DTnPPYczKwvfiy8i+N57MfbqRcJPPzHa7Sb3369RdeAApj59CL7jdqyzZqHodJT+9BOZDzwIbjfh/3wG68yZDV6j9MefyPjrX9FbrUQtfLPFD0QVO3eS++/XKF+/Hn1gIEE33YjflVei8/Sk+NvlZD7wAJ4DBxL19qJ6QelE9vR0Uq+bhzM/n6gFb+A1YQKgdWwqXfMdJStXag9WqopHXByWCRMwBAaiDwzAEBiIIUD7/6gPCETnZQFVxVVcrAXJ6sDpLKiuzSkuJrW8jEHnn49HvziM4WGNVtE7Cwuxbd6MbaP272dPPlRnv2I0oq+5fmAghgB/nAWF2LZurX149RgwoPYhzDM+nuwnnqTsxx/xv+YaQh64v1VV+XXuXWoqhR99TNEXX+Au0frnGHr1wiMuDo9+/fDoH4dHXBymPn3Jf2cx+W8uxDJhApGvvtJk0D6Z225n8zPPEPDDjzhzc7FMmEDwnfOxjBpVN11FhfbQuPgdFKORoDvuIOCaq1FaWZ3eFAnGjUguTObSZZfy/NTnmdV7FgCF5XZGPvkdD80ZyE1T+rZZHjurNgnGRWla6Xfv15C+GQCH9xDs/lOg30xtdqoGGELDMEVHNfvH7a6spCzhZ0pWrqTs559RKyvRBwTgOWjQ8T/efv0w9e3XokDVFhISEpg8ahQF775HwXvv4bbZ8Jk9i6A77sCjTx+gutSelkZlUhJVSUnYa0rvh1PqBrjqQOs5bFhtgHPb7VT89lttwLbt2AEOB+j1ePTpo31xxfWr/QIzRkXVljDLNmwg56mnsaek4D19OiEPPtBsaaIxrrIyKrZupXxjYoMPDpZx4/GaMB7PIUNQDAaqDh0i+6mnsP26EY+BAwl99BEso0fXuW/Tpk1DdbspXfMdua+/hj35EB5xcZhHjqTo00/xGDyIyFdeaTbPlfv2kXbrbbhKSoh44QWsM6bX2a+63VqAKyzEkZlF4QcfUJaQgN7Pj8Abb8D/j3+sV81dmpBAxl1/wRgZSfSSdxqsNalKSiJ13vWodjtRby/CPGxYg/lz5uZSsnoNJStXUrVvH+7GampMJlSXC1yuBvfrvLxwl5cf/91iwRTXT/u/HxeHsVcvKnbsoDxxE1UHDmj/PhYLllGjsIwfh2XECAy9eqEPCEDn7d3gg6jqcFCxe7f2EJaYePxhEECnI+Shhwi45uoG89dabpsN2+bN2t9EUnKDD9cAfr+/nNDHHqutHTkVCQkJTJkwgaJPPiFv0du48vPxOvtsrUZr6FBKv/uOnGefxZmZhc9Fc+n1179i7NU+vcBBgnGj0kvTmf3lbJ6c9CSX9Lukdvu4p79nclwwL17RdtWpndUp3ztV1Xo7Fx6B1F9hz9eQvknbFzoMddDFFOxWyH3rfVS7vdnTKUYjpr59a79YaoKMITiY8g0bKFmxktKffkK12dAHBuJz/nn4zJ6NefToDh3GcOJ9cxUVkb/kPxR88AFqZSVeEyfiLMjHfujw8S80tKEfHnFxeA4aiGXcOMwjRrS46tddUUHF9u2Ub9pE1f4DVCUl4cg4PoOY4uGBqW8f9F7e2DZvxhgdTchDD2Jt4yYIV3Exti1baoNz1cGDgBYgPOPjsW3fjs5iIfgvd+F/xRX1HrRO/v+mulyUrFxF3uuvYz9yBL8rriDk4YfQebSss57j2DHSb72Nyr178Z4xA7etHFd+Ac7CAlwFhXUCnM7Xl8DrrsP/mmuafGgr37SJ9FtvQ+/nR/SSdzDFHJ9prWLXLtJuuBHFZCLqncUtrg0B7aFSK/kW1G0mKChAMRoxBARqtTc1tTkB/uj9/VEMBn5evpyxYWG1zTBVSdq7K18b4qd4eGAeORKv8eOwjJ+AeeiQVgWv2rza7VTu2IFt6zbMo0biNa7pKt62cnKzkzE8HJ+5c1tdk3Xi/ze3zUbhRx+R//ZiXEVFmGJisB89iseAAdpD45h6MbLNSTBuRH5FPtM+ncZD4x/ijwP/WLv9T+8kUmRz8M38s9ssj51Vo/euqkwLtgUpUHRUC76FR7Wfq04Y+hU6FOIvhcGXYLeZyHzwQSq2bMV7xgwCrv1zvfbAGqrLhSMjk6rkpNovFmdmVr10el9frOedh8+c2VjGjj3tKrK20tB9cxYUkP/OO5T98CPGqKgTHjD64dGnT5sPj3KXl1N16FCdkoUjMxPfiy8i4LrrWhzQToezoADbpk21pSnzsGEE3/0XDAENj9Nv7P+b6nRiT03Do0/sKefBbbOR/Y8nsG3ffkL1a0C9wOY5bFiL2zordu8h7YYbwGAg+p3FeA4YQPnGRNJvuw19QADR/1mCKSrqlPPaWo3dN2dBAc7sbEx9+56Rf++upqH75iorp/CDDyj9/nt8L7kE/z9ceca+VxoLxp3jW60DnTzOuMaAECv/3XgUl1tFr+tePSKbpKqQsQ22vQe7vzg+ztdg1uZh9ovRxvb6x4B/b22CjYBYVFWl6JNPyPnX8yg6HWH//Ce+l1x8yk+zrrIyrSq3ugOWZfRovCZMOK0n/DPJEBBAyH33EXLffWfkejovL8zDhjVaTXomGAICtB7Es2ad1nkUg6FVgRi0Unn4c8+e1vVPZh4ST8yHH5A673qO/un/CLzhBvJefx1TTDRRi99ptwktTpWhuh+EaDm9txdBt9xM0C03d3RWavX4YOxp0KoITw7G/UOtVDndpBbYiA3qmpM9uMvLSb3hRvwu/x1+v/td04ltBbDzE9j2PhzbC0YLxY6JHPsuA8+hQ/GaOBnLhAl4xMXVC7COrCyyHnmU8g0b8Jo4kbCnn8IYFtaqPOu9vTGPGIF5xIhWHS9EW/Lo25eYDz8kdd48cl96Cc+hQ4la9FaTHbuEaI0eH4x1ik5b09hZt8NA7bSY2SVdNhgXfvwJFdu3U7l3L+YRI/Doe1JnNFWFwwkM3vMCrNsELjtEjIYLX8HufxbZV1yDPiiQquQjlCWsB0AfEIBl3LjadqmKnTvIefoZVJeL0Mf/jt+VV3a7sZWiZzNFRtD7ww8o/uZb/K644ox1EBQ9S48PxlB/GUWAuBBvFAUOZJcxa0gHZew0uCsqyF+yBPOIEdiPHiXzvr/R++OPtK76Lifs+RLWvwLH9uBvsMKY62HUnyAkHtXlIuvP1wIQ/c4STJERODIytDGwiRspT9xE6apVtdcyjx5N+D+faXVvXSE6O0NwMIHzruvobIhuTIIxDQdji8lAdICFgzmlHZSr01P02We48vPp9eorOAsLyZh/J7mv/5teZ/vCL/+GolQIHgiXvMmv+UFMOee82mML3n0P25YthD3zDKZIbVywMSICv8suxe+yS7VpDVNTKU9MRDGa8L1obqOdtIQQQjRPgjENB2PQqqr3d8EFI9xVVeS/vRjLuHFaV/2KQsrOiiP/7cVYD+dhHjESZv8L4s4HnQ53QkLtsZUHDpL7yit4zzwH30svafD8iqJgiompM9xDCCFE63XNtabamKfBs+FgHGrlSL6NSkfDA/E7q6IvvsCZm0vQ3DGw4j54eQgh4Wsx+pjI2BuP+49fw4DZ9ZYZdNvtZN5/PzofH8KeeELafoUQ4gyRYEzjJeP+IVZcbpVDuV1gBSdbAez7Bvc395H/0tOYg+xYdj+irZA0YDb6+esJe20xjqxccl54ocFT5L32OlX79xP25JMyVEIIIc4gqaZGC8b5lfn1tg8M1XpUH8wpJT685fOhnjGOStjwqjYF5bG9ABSn+OIs8yJs3hyU2VdA5JjaqSi9QiHguusoWLIE6/TpdZYGs23dSv7ixfj9/vJ6UwoKIYRoXxKM0YKxzVF/ztjeQV4Y9QoH2nFt44L//Y9j/3wW1eFoNI3n4MHa2MagoOMbUzfC0jsgP0lbjnDGI6gRE8i/6XE8hwXhdeu/G1yWMPiuOylft47Mhx+mz7JlGPz9USoryXzqaYwREfS6/4H2+JhCCCGaIMEYiLJG8WPqj1S5qvDQH59OzqjX0TfYmwPt1ImrfNMmcp5+Bsvo0Y3Oiao6nRS8/z6p111H9HvvYfAywY9PQuJb4BsFf/oK+s4AoPiLL3FkZBLy6KONtvfqPDwIf/5fpPz+CrIf/wcRr7yM92ef48jIIOaD/8oYSiGE6AASjIEhQUNwqk72F+xneHDdhSEGhFrZcqSwza/pyMkh4+57MEVHE7ngjSbny/WaeBZpN99C6tVXED01G0NlGoy7Cc75O3hox6lOJ3mL3sJz8GC8p05t8tqeAwcSPH8+uS+9RNbDj2DZsIHAG2+os7KOEEKIM0c6cKEFY4Ddebvr7esfYiWjqIKSysarkU+VareTcedduCsqiHzt381OXO81fCCR1wzCfjSd1G/duC7/AuY8XxuIAUpWrMBxNJWg225tUS/owOvnYR41iuIvv8QRGUnQ/Pmn/bmEEEK0jgRjIMQSQqBnIHvy9tTbV9OJK6kNJ//IefZZKnbsIPyZp/Ho16/pxEnfw4IJeNtWEXnTFOzFBlL/sQhX6fH8qC4XeQvfwqN/f7xnzGhRHhS9nvB/PYf3OedQPG9eo4vECyGEaH8SjNEmsRgSNITd+Q2XjIE268RV9PXXFP7vIwLmzWt6lRuXA9Y8Ch/+Dsz+cMMPeP9lERGvvkrl/v2k3XAjrjItT6WrV2M/fFgrFZ/C+r6myEii3ngdV3jrFnUQQgjRNiQYV4sPiudI8RHK7HWDbqS/GS+Tvk1m4qrcu5fsvz+OZfx4et1zd+MJi9LgP3O0aSvHzIMbf4SIUQBYZ0wn4qUXqdi9m7SbbsZVVkbemwsx9e2L9bzzGj+nEEKITkuCcbUhgUNQUdmbv7fOdkVRGBXjz7qkPFRVbfX5XUVFpN95F3p/fyJeerHxhawPrISFZ8OxfXD5Erjw5dpxwjV8zj2XiBdfoGLHDlIuuZSqpCSCbrnllErFQgghOo8WfXsrijJLUZQDiqIkK4pSbyCqoii+iqJ8oyjKDkVR9iiK0uWWN6ntxNVAVfXsIWGk5JWzL6t17caqy0XGfX/DmZND5KuvYAgMrJ/IaYfVD8NHfwC/aLj5ZxjS+BrEPrNmEf7cczgyMzH17o3PnNmtypsQQoiO1+zQJkVR9MAbwLlAOrBZUZRlqqqeWIS8HdirqupcRVGCgQOKonyoqqq9XXLdDvw9/YnwjmiwR/X58SE88vUuVuzKYnC4zymfO++NBZSvW0fo449jHj68fj4lHbYAACAASURBVILCo/D5PMjYAmNvhPOeAqNns+f1vfACjGGh6P39ZdUkIYTowloyzngckKyq6mEARVE+Bi4GTgzGKmBVtDE13kAB4GzjvLa7+MD4BoNxoLcHE/oEsmJXFvee17/ZoUOu4mJsmzdXr/+bSNXBg/heeil+V15RN6Gqwo6PYdX92s+/fw/iG14pqTEyNlgIIbo+pbl2UEVRLgdmqap6Q/XvfwLGq6p6xwlprMAyYCBgBa5UVXV5A+e6CbgJICQkZPTHH3/cVp+DsrIyvJsZr9uc74u/Z2nRUp6JfAar3lpn34+pDt7fa+fJSWairHVr95XKSoxJSZgOHMR08ACGtHQUVUU1GrH37Yt98CBs06eD0Vh7jFdZCv0PvoVvyT6KfQawb9DdVJo7pldzW9y7nkjuW+vIfWsduW+t09nu2/Tp07eqqlpvysWWlIwbKgaeHMHPB34DZgB9ge8URVmnqmqdLsiqqi4CFgGMGTNGnTZtWgsu3zIJCQmc7vm8sr1YunopvgN8mRI5pc6+IWVVfLDve3I9IvjTtAG12+1Hj3LkiitxFRejGI2YR4zAcvHFeI0fj+ewYfXH71YUwU/PwNa3tSFLF72G74hrmNCBna/a4t71RHLfWkfuW+vIfWudrnLfWhKM04GoE36PBDJPSnMd8KyqFbOTFUVJQSslb2qTXJ4hgwMHo6CwJ29PvWAc5O3B+NhAlu/K4u5ztapqt91Oxt33oAJRixdjGTManWcjbb1uN+z4CL7/O9jytSFL0x8GiyxVKIQQPV1LimObgThFUWIVRTEBf0Crkj5RKnAOgKIoIcAA4HBbZvRM8DJ6Eesb22CPaoA5w8I4lFvOwRxtLHLuiy9SuXcv4f98Bu+zJzUeiLN2wJLzYelt4B8LNyXABS9KIBZCCAG0IBirquoE7gBWA/uAT1VV3aMoyi2KotxSnexJYKKiKLuAH4D7VVXNa69Mt6chQUPYnbe7wTHFs+JDURRYviuL0h9/ouC99/H/05+wNjUF5aa3YdE0KDgMFy+AeashrIEe1UIIIXqsFq3apKrqCmDFSdsWnvBzJtAtpn+KD4xn2aFlZJdnE+Zdt0NVsNWDcb0D+OXXvVy4/Fk8Bg+i131/bfhEqgo//APWvwz9Z8OlC8HsdwY+gRBCiK5GllA8ydCgoYA2+cfJwRjggvheeL7/JC67nZgXX2x4gQWnHZbNh50fw+hrYc6LoJdbLYQQomEyf+JJBgQMwKAzNDjeGGDKxmUMzU9h5+9vwSM2tn6CqlL43xVaIJ7+CFz4igRiIYQQTZJgfBKT3kR///4NLqdYvjGRinfeZvvgSbxjHlD/4NJsbYGHlLVw8Rsw9T5owdrCQgghejYJxg0YEjiEPfl7cKvu2m3OggIy77sPU+/euO64l4M5ZSQfO2Gu6rwkeOdcyE+Gqz6Bkdd0QM6FEEJ0RRKMGzAkaAhljjKOlBwBQHW7yXzgAVzFxUS89CLnjYnVelXvzNYOSNukBWJHBVy7HOLO7bjMCyGE6HIkGDcgPigegD15e3CVlpL7yquUr11Hr/v/huegQYT4eDImxp8Vu7Lg4Bp47yJtNq3r19SuOyyEEEK0lPQsakBvQyjT9xvwWv0aSbsfQbXbsc6ehf9VV9WmmTM0jO3LF6N+vBAlJB6u/gK8gzsw10IIIboqCcbV3BUVlP28lpKVKyn7+WduraykxCcbvz/8AZ/ZszEPH15ntabLXKv5s/ENMqwjifzzUvA89aUVhRBCCJBgDEDhZ5+R889nUW029IGB+F12Gd/2KeQt9Wd+ufo+jLrjqy2hqrDuBXx/fIrNHuN5kvtYJoFYCCHEaZBgDJSsWIEhIICwBW9gGTsWRa8n/PAKKtd9R3JhMoMCB2kJVRXWPAK/vg7DrmR30F/ZuSKJw7ll9AnuPEt0CSGE6FqkAxfgSEvHPHw4XhMmoOj1gNajGji+aITLCcvu0ALxuJvhkoXMGq4tZrViV1aH5FsIIUT30OODsep04sjKwhgVWWd7lDUKH5OPNvmHswo+vxa2fwBTH4DZz4FOR5ivmVHRfizfld0xmRdCCNEt9Phg7MjOBpcLU1RUne2KohAfGK9Ni/n5PNj3Dcx6FqY/WGdWrTlDw9iXVUJKXvmZzroQQohuQoJxWhoAxsioevuGBA0huTCJigPL4Zy/w4Rb66WZM1RbTGL5zsz2zagQQohuq8cHY3t1MDadVE0N2nKKLtwc8AuDCbc1eHy4n5nRMf58u1PajYUQQrROjw/GjrR0MBoxhITU2zektBCA3QPOAaNno+e4aHg4+7NLOZhT2mgaIYQQojE9Phjb09MwhofV9qKupaqEbHiNYDfsNluaPMecoWHoFPhmh1RVCyGEOHU9Phg70tIxNdBezP7lkPUb8X792FOwr8lzBFs9mNg3iG92ZKKqajvlVAghRHclwTg9vd6wJtxu+OkZCOzHkNjzOFJyhBJ7SZPnmTs8jCP5NnZlFLdjboUQQnRHPToYu0pLcRUV1RvWxN6v4NgemPYgQ4KHaZvy9zZ5rlnxYRj1ilRVCyGEOGU9Ohg70tOBk4Y1uZzw0z+h12CIv4z4QG05xd15u5s8l6/FyNT+wXy7Mwu3W6qqhRBCtFyPDsYNDmva9RnkJ8H0h0Cnw8/Tj1jfWL44+AX5FflNnm/u8HCyiivZcrSwPbMthBCim+nRwdiRVlMyrg7GLgck/BPChsPAC2vTPTHxCfIq8rjth9sodzQ+09bMQSF4GnVSVS2EEOKU9OhgbE9PQ+fri96negnE7R9A0VGY/kidKS9H9BrBi9Ne5EDBAf7y019wuBwNns/Lw8A5g0JYsSsLp8t9Jj6CEEKIbqBHB2NtWFN1qdhRCWufh8hxEHduvbRTIqfw+MTH2Zi1kYc3PIxbbTjYzh0WTn65nV8ONV2lLYQQQtTo4cE4DWNNT+pt70FJBsx4uE6p+ESX9LuEu0bdxcqUlTy/+fkGxxRPGxCM1cMgVdVCCCFarMcGY9XlwpGZqXXesttg7QvQezLETm3yuOuHXM81g67hg30fsGT3knr7PY16zosPZdWebKqcrvbKvhBCiG6kxwZj57FjqA6HNqxp82IoPwbTGy8V11AUhfvG3sfs3rN5ZdsrfJ38db00c4eHUVrp5OcDue2VfSGEEN1Ijw3GdYY17fgIos+CmLNadKxO0fHU2U8xIWwCj//yOGvT19bZP6lfEAFeJr6RlZyEEEK0QI8NxrXDmrzccGwvDL74lI436U28Mv0VBgQM4N6Ee+vM0GXU65g9JJTv9+ZgszvbNN9CCCG6nx4bjO3paaDTYSzeom0YMOeUz+Fl9GLBOQsw6U28u/vdOvvmDg+nwuHih33H2iC3QgghurMeG4wdaekYw8JQkldB6FDwj2nVeQLNgcyOnc2PaT9SZi+r3T6udwAhPh4sk17VQgghmtGDg3EaxvAQSN1YZ7at1riwz4VUuar4PvX72m06ncKFw8L5+UAuxRUNTxIihBBCQA8OxvaMDExeLkCFgRec1rmGBw8nyhrFt4e+rbN97vBw7C43a/Zkn9b5hRBCdG89Mhi7bTZceXkYlWzwi4aQIad1PkVRuLDPhWzK3kR2+fHAOzzSl+gAi1RVCyGEaFKPDMb26qUTTfZkrYq6mbHFLXFBnwtQUVl+eHntNkVRmDs8jF8O5ZNXVnXa1xBCCNE99chgXLuOsaXytKuoa8T4xDAseBjfHv62zjSZl46MwOVWeXfDkTa5jhBCiO6nZwbj6gk/jEFWiJrQZued22cuyUXJHCg8ULutXy8rFwwLY8mGFPKldCyEEKIBPTIY21NT0RlV9MNmgd7QZued1XsWBsXAN4e+qbP97pn9qXS4eDPhUJtdSwghRPfRI4Ox4+BOjF5OlEGnN6TpZH6efpwdeTYrUlbgch9fJKJfL28uHRnJfzceJbu4sk2vKYQQouvrkcHYnnoEk1WFPtPb/Nxz+8wlryKPxKzEOtvvOicOl1vljZ+S2/yaQgghurYeF4xVtxtHXhnGyEgwWdr8/FOjpmI1WvnmcN2q6uhAC1eMjeLjzamkFdja/LpCCCG6rh4XjJ27f0J1gXHgqHY5v4feg/N6n8cPqT9gc9QNuvNn9ENRFF77Maldri2EEKJr6nHB2LFxKQCmUTPb7RoX9rmQCmcFP6T+UGd7mK+Za8bH8MW2DA7nljVytBBCiJ6m5wXjXesBMPYd3G7XGBUyinCvcL49/G29fbdO64tJr+OV76V0LIQQQtOiYKwoyixFUQ4oipKsKMoDjaSZpijKb4qi7FEU5ee2zWYbyT+EPSsHFDBGhLfbZXSKjgv6XMDGrI3k2nLr7Au2enDtpN58szOT/dkl7ZYHIYQQXUezwVhRFD3wBjAbGAz8UVGUwSel8QMWABepqhoP/L4d8nr69i/HUWbAEByEzsOjXS91Yd8LcatuVqSsqLfv5il98DYZePm7g+2aByGEEF1DS0rG44BkVVUPq6pqBz4GLj4pzVXAl6qqpgKoqnqsbbPZRvYvx273wRTdu90v1ce3D/GB8Q1WVftZTNwwuQ+r9+SwM72o3fMihBCic2tJMI4A0k74Pb1624n6A/6KoiQoirJVUZT/a6sMtpmyY5CWiKPchDEq6oxccm7fuewv2E9SYf324Xln98bPYuTFNVI6FkKInq4lc0E2tKSRetLvBmA0cA5gBn5VFGWjqqp1Io2iKDcBNwGEhISQkJBwyhluTFlZWZPnC8tcQ5xLxVlsI8Pp4GAbXrsxPi4fdOhYkLCAi/1PrkyA8yLh04O5LPrqB/r769s9P41p7t6Jhsl9ax25b60j9611usp9a0kwTgdOLEpGAicv0JsO5KmqWg6UK4qyFhgO1AnGqqouAhYBjBkzRp02bVors11fQkICTZ7vwwVU6aIBJ/0nT8a3Da/dlJXfr2RX4S5enPoiOqVuRcS4iU5+/FcCPxyzcOMlE1DaYCnH1mj23okGyX1rHblvrSP3rXW6yn1rSTX1ZiBOUZRYRVFMwB+AZSelWQpMVhTFoCiKBRgP7GvbrJ6GqlI4nIDDdywAxsgzU00NWlV1ji2HrTlb6+2zmAzcNq0viSkFJKYUnLE8CSGE6FyaDcaqqjqBO4DVaAH2U1VV9yiKcouiKLdUp9kHrAJ2ApuAxaqq7m6/bJ+i5B/AVYXdEAuAKSryjF16SuQUDDoD69LXNbj/qvHRBHmbZM5qIYTowVo0zlhV1RWqqvZXVbWvqqpPV29bqKrqwhPSPK+q6mBVVYeoqvpKe2W4VbJ2gM6Ao0yP4umJPijojF3ay+jF6JDRrMtoOBh7GvXcMLkP65Ly+C1NelYLIURP1DNm4CpKBd9I7BmZmKIiz3jb7OSIySQXJZNZdnJTu+aaCTH4mo28/qOUjoUQoifqIcH4KPhF40hLO6PtxTUmR04GYH3G+gb3e3sYuG5Sb77fl8O+LJmVSwghepoeEoxTUX2jcKSna0snnmGxPrFEeEc02m4McO3E3nh7GKTtWAgheqDuH4wdFVCWg8sQittmO6Odt2ooisLkiMkkZidS5apqMI2fxcQ1E2JYviuLQ7KikxBC9CjdPxgXpwPgqPQCzuywphNNjpxMhbOCLdlbGk1zw+RYPAw63kw41OLz3vL9Lfxr87/aIotCCCE6SPcPxoVHAbCXaR+1I0rGAGNDx+Kh92i0VzVAkLcHfxgbzVfbM0grsDV7zryKPDZkbODXzF/bMqtCCCHOsO4fjIu0YOwocgB0SJsxgNlgZmzo2CbbjQFuntoHnQJvrW2+dPxL5i8AHCk+gsPlaJN8CiGEOPN6QDBOBZ0R+7Fi9MFB6MzmDsvK5IjJpJamcrTkaKNpwnzNXD46ik83p5NTUtnk+dana72znaqTw8WH2zSvQgghzpyeEYz9tJ7Upg5qL65RM8SpudLxrVP74lJV3l7beIB1uV38kvULgwO1paWTiuqvDCWEEKJr6AHBWBtjbE9P67Aq6hpR1ihifWObbDcGiA60cPHwcD5MTKWg3N5gmt35uymuKuaaQddg0BkaXKZRCCFE19ADgnEqqncUzuycDuu8daLJEZPZnL0Zm6PpDlq3Te9LpdPFkvUpDe5fn7EenaJjcsRkYn1jJRgLIUQX1r2Dsd0G5bk43AHgdnfYsKYTTY6cjMPtYFP2pibT9etlZfaQUN775QjFFfU7Z23I2MCQoCH4efoR5xcn1dRCCNGFde9gXJQKgL1C67TVGUrGo3qNwmKwNNtuDHDbtH6UVjn5769H6mwvqCxgd95uzo44G4D+/v3JLs+mxC5TaQohRFfUI4Kxo1T71RjV8SVjk97EhLAJrMtYh6qqTaYdEuHLjIG9WLT2MHllx2fu+jXzV1RUJkdoHcLi/OMApKpaCCG6qG4ejLUhRM4KbZUmwxlcOrEpkyMnk1WeRXJR8/NQPzRnIDa7i2dX7q/dtj5jPf4e/rU9qfv79wckGAshRFfVzYNxKug9cFW40Hl7oxgMHZ0jgNrq5eZ6VYPWdnzjlD58vjWdTSkFuFU3v2T+wsSIiegU7Z8vxBKC1WiVYCyEEF1UNw/GR8EvCldJMXpf347OTa1Qr1D6+/dvUbsxwJ0z4ojwM/PI17vYlbuHgsoCJoVPqt2vKApx/tKJSwghuqpuHoxTwS8aV3HnCsYAUyKnsP3Ydkrtpc2mNZv0PH5RPAdzynjt129QUJgUMalOmjj/OJILk5tthxZCCNH59IBgHIO7uASdr09H56aOyRGTcamuFi/ycO7gEGYOCmFj1i/E+Q0iwDOgzv44vzhKHaVkl2e3R3aFEEK0o+4bjKvKwJZ/QsnYr6NzVMew4GFYTdYWtRvXuOf8CPBMxVbUr96+2h7VUlUthBBdTvcNxtXDmvCLxlVS0umqqQ06A5PCJ7E+Yz1u1d2iY1IrdqAoKgeORPDj/pw6+2qC8cHCg22eVyGEEO2r2wdj1S9GKxn7dK5qatCGOOVV5LG/YH/zidGGNPmYfIi1DuLvy/ZQ6XDV7rOarIR5hUkwFkKILqjbB2O3KRicTvR+natkDNT2iG5Jr2q36mZD5gYmhk/kqYuHkVZQwRs/1R2nHOcfJ8ObhBCiC+rGwfgoGDxxO40A6DphyTjQHMiQwCEtajc+UHCAvIo8JkVM4qy+gVw6MoK3fj7Modyy2jRxfnEcKT6Cw1V/LmshurvN2ZtZm762o7MhRKt072Bc3V4MdLo24xpTIqewM3cnP6T+0GS6DZkbgOMThjw0ZxAeRh2PLd1dO5wpzj8Op+okpaThlZ6E6M5e2vISD657kCpXVfOJhehkunEw1oY1uYqLATpdb+oa1wy+hqFBQ/lrwl9ZfWR1o+nWpa9jUMAggszalJ7BVg/+dv4ANiTns/S3TEDmqBY9l1t1c6j4ECX2En442vSDbUdwuBzNLpsqerZuHoyjcRXXlIw7XzU1aB2v3jr3LYYGD+Vva//G8sPL66UptZeyI3dHvYk+rhofw8hoP+7/Yie/HMoj1icWg2JocTB2q26+P/o9LtXVfGIhOrGMsgwqnBUAfJn8ZQfnpi5VVbnxuxu5esXVON3Ojs6O6KS6ZzCuLIGKwupgXAR03mpqAG+TNwtnLmR0yGgeXPcgS5OX1tm/MWsjLtVVW0VdQ69TeOfPY4kJtHD9u1v4La2U3r69WzzW+Puj33N3wt0kliW22WcRHcvldvHenvcoriru6KycUYeKDgHaZDqJWYmklaZ1cI6O++7od2zN2UpyUTLfHPqmo7MjOqnuGYxPGGPs7uRtxjUsRgtvnPMG48PG8+iGR/n84Oe1+9ZnrMfb6M2w4GH1jgvwMvHhDRMI8/Pkuv9sJsjUu8Ul428Oa18MW8q3tM2HEB1uS84WXtjyAp8c+KSjs3JG1ayAdu+Ye9EpOr5K+qqDc6RxuBy8vPVl+vn1Y0jgEN7c8SZ2l71Nr1FUWcS3h7/F4ZaOm11Z9w7G/tVtxkYjitncsXlqAbPBzOvnvM6kiEn849d/8PH+j1FVlfUZ6zkr/CyMOmODxwVbPfjoxgkEeZvYuN9EVnlWs3NeF1YWsj59PVaTleSqZHLKc5pML7qGzdmbAZrtENjdJBUmEeYVRl+/vkwKn8TSQ0s7RZXwxwc+Jr0snXvH3Mv8UfPJKs+q86B9OlRV5evkr5n79VweXPcg/9v3vzY5r+gY3TsY+8XgKtIWiVAUpWPz1EIeeg9enf4q06Km8XTi0zyd+DTHbMfqVVGfLMTHk//dOAGLEgnAd0m/NZl+zZE1OFUnj531GCoqq46sarPPIDpOTTDem7+3R81TnlyUTD8/bZrY38X9jmO2Y/yS+UuH5qm4qpi3dr7FWWFnMSl8EmeFncWYkDG8vevt2vbt1jpUdIjrVl/HoxseJdY3ltEho1m4YyF5FXltlHtxpnXTYHwUjBawBGpTYXbCMcZNMelNvDT1Jc6NObe2unFi+MRmjwv3M7Pg8gsA+MeaHziY03jp+JvD39DPrx/nx5xPlCmKFSkr2ibzosNUOivZlbeLaZHTAPgx9ceOzdAZ4nQ7SSlOqQ3GU6KmEOAZwBcHv+jQfC3etZiSqhLuHXMviqKgKAp3jrqTvIo8Ptr/UavOWeGs4NVtr3L5sstJLkrmHxP/wbuz3uXvZ/2dSmclr29/vY0/hThTumkw1npSoyidcvnEljDqjfxryr/4XdzvODfmXEK9Qlt03KiIWLwM3iimbK56O7HOpCA10krS2JG7gwv7XIiiKIzxGsPe/L2kFMv45K5sZ+5OHG4Hvx/we/r49ukxwTi1NBWH20E/fy0YG3VGLu57MWvT13ZYSTG9NJ0P933Ixf0uZkDAgNrtI3uN5OyIs1mye0mLlk890Z6KPVy69FIW71rMBX0uYNkly7gs7jJ0io5Y31iuGnQVXyZ9yd78vW39ccQZ0E2D8VHwiwHossEYtMUkHp/4OC9Ne6nFxyiKQv+AOPpHlQEqV729kbSCuuMbv035FgWFC/popehRllEoKKxMWdmW2Rdn2OaczegUHSN7jWRG9Ay25GzpEb2qkwu1zls1JWOAS+Iuwak6WXZoWZtcI7s8m8c2PEZqSWqL0v97+7/RK3ruGHFHvX13jLyD4qpi/rv3vy06l81h468//5WFxxbiofdgyflLeOrsp+oto3rz8Jvx9/TnuU3PybrmgMPtYP6P81mcu5glu5ewOXsz5Y7yjs5Wo7ppMK4uGQPu4uJOO8a4vcT5xZFedpgPrh9Phd3FA1/urP3jVFWVbw99y9jQsbWlbT+DH2NDx7IiZYX8EXdhm7M3MyhgEFaTlXOiz8Gluvg5/eeOzla7O1R0CAWFWN/Y2m19fPswqtcovkr6qk3+Ty/csZCvkr/iqhVXsTVna5Npd+XuYmXKSv4v/v8I8Qqptz8+MJ6Z0TN5f+/7FFUWNXmuUnspN393M98d/Y4LfC/g87mfMzZ0bINpfUw+zB85n23Htp1SH5CkwiS+Pfxtt+vEuSdvDwlpCRyuPMzLW19m3up5TPxoIpcuvZTHNjzGpwc+rX2Q6wy6XzCuKILK4tpg7CouRtdFS8atFecfR6mjFD8fG3+tnqVr9R7tD21X3i5SS1O5sM+FdY6ZEzuHoyVHpYqri6p0VrIzdydjQsYAMDhwML0svXpEVXVSURJR1ijMhrojJi6Nu5QjJUfYdmzbaZ0/ryKPZYeWMSNqBv4e/tyw5oZGxwurqsoLW14gwDOAeUPmNXrO20fcjs1hY8nuJY2mKaos4oY1N7A7fzcvTH2BWX6zMOobHlFR49J+lzIoYBAvbnmxRZ3ENmRs4KrlV/HgugeZ+flMLvn6Ep7b9Bxr09d2+RnDfs36FQWFh8MfZt2V61hwzgJuGXYLYV5h/JT2E09ufJJLl13aZrUnp6v7BeMThjWpDgfu8vIuW03dWieubXzVuGgGhlp5avleKh0uvj38LR56D2bGzKxzzMyYmRh0Bpan1J8BTHR+u/J24XA7aktNOkXHjKgZbMjYcNo9dzu7E3tSn+i8mPPwMnrxZdLpzcj14b4Pcbqd3DvmXj6Y8wGjeo3iofUP8dr21+qtRf5T2k9sO7aN20fcjpfRq9Fz9vPvxwV9LuCj/R+Ra8uttz+vIo/rVl9HcmEyr05/lXNjzm1RXvU6PfePu58cWw7/2f2fJtP+mPoj83+cT4xPDO/Neo97R99LL0svPjv4Gbf/cDuTPp7EvNXzWLxrcZfspb0xcyODAwfjpffCz9OPyZGTuXXErSyYuYC1V65lxWUrGB0ymqc3Pt3i5of21H2DsV80rlKtg4Tep2cF45ovpqTCJAx6HX+fG096YQULfz7IqpRVTIuahtVkrXOMr4cvkyMmsyplFS63TI/Z1WzOrm4vDhlZu21G9AwqXZX8mvlrB+asfdlddlJLUms7b53IYrQwJ3YOa46sOeXOUjXKHeV8cuATZsbMJNonGl8PXxbOXMhlcZexaOci7l97P5XOSkBro3x568vE+sZyWdxlzZ77tuG34XQ7eXvX23W2Z5dnc+2qa8koy2DBzAVMiZxySnkeHTKaWb1nsWT3ErLKshpMsyplFfck3MPAgIG8c/47jAoZxbVDrmXReYtY/4f1LDp3EX8a9CdK7aW8uu1Vbv7u5i61GpzNYWNn3k4mhE1ocL+iKERZo3h28rPodXoeWPdAh0+a0o2DsTbGGOiUaxm3J18PX0K9QmunxTyrbyAXDAvjrc0rKKwqrFdFXWNOnznkVuSyJUdm5OpqNmdvZmDAQHxMx/tHjAkdg9Vk7dYTgKQUp+BSXQ2WjAEui7uMSldlqzsnfnHwC0rtpVwbf23tNqPeyONnPc7do+9m1ZFVXL/mevIq8vj84OccKTnCvaPvxaAzNHvuKJ8oLom7hM8OfkZmmbbYS1pJGn9e+WfyK/JZdO4ixoeNb1W+7xl9DwAvba3f+fPr5K+5f939DA8eMrqucAAAIABJREFUzqJzF+HrUff70dPgyVnhZ3HPmHv4bO5nvDr9VQ4WHuSd3e+0Ki8dYWvOVpxuZ7P3L9QrlMfPepxdebt487c3z1DuGtYNg/FRMHmD2R93SXUw7mLjjNtCnF8cBwsP1v7+0JxB6KzbMeDNpPBJDR4zLXIaFoNFxhx3MVWuqjrtxTWMOiNTI6fyc/rPnWI2qvZQMw1mY8E4PjCe/v79W1VV7XA7+O++/zImZEy9qWgVRWHekHm8PO1lDhYc5OrlV/Pmb28yNnTsKZVkbx52Mzp0LNyxkMPFh7l21bWUO8tZfP5iRvQaccp5rhHmHca8IfNYdWRVnQ5nH+//mEc3PMr40PEsPHch3ibvZs81I3oGs2Nn89bOt7rMinAbszZi0pkY2Wtks2nP630el8VdxuJdi2snzekI3TAYa0sn1owxhs4/L3V7iPOPI6U4pbbqxdfiwmjdh61gKFuOlDR4jKfBk5kxM/nuyHdtPn+uaD87c3did9sb7GU7I3oGxVXFbMs5vU5MnVVyUTIGxUBvn94N7lcUhcviLmNP/h72F+w/pXOvSllFdnk21w25rtE0M2Nm8u6sd7G77RRWFdZO8NFSoV6hXDHgCpYeWsq1K6/FpbpYcv4S4gPjTymvDbluyHWEeoXy3KbnahcQeTrxaaZFTuO1c16r1+GtKQ+OexAfkw+PbXisSzzYJWYlMjLk/9u77/CoivWB49/Zzab3XkkBQihJKKG3AApIFQRFkKbixSvWn4oFBRuKqNgLFxG4gMilqBRBkCrSmwQCIYSShBDSC+mb8/tjkxggZdOTzXyeJ0+S3VPmTDb77syZeacTpkamem0/u+tsWli34NX9rzbYdEADDcb/jKQGmt1oatAF44LCAq6kXQF0K8doycO2sAdvbTpLgbawzP2G+Q4jIz+D/bH767G0Uk0cu3EMgaCzS+e7nuvt3hsTtQm7og1zVHVkaiTe1t4VjjIe4TcCY5VxlVrHiqLww9kfaGXbqtJUtO0d27N2xNpqB9HHAh/DRG2CsdqYZUOX4W/nX+VjlMXMyIz/6/J/hCeH86+d/+KjYx8xxGcInwz4BBO1SZWOZWdqx6vdXyUsKUzv+dENJSk7iQspF8q9X1wWc405C/otICknibcOvtUgUzwNKxgrCqRcLRWMm8aKTXWhta1uRHVxt9KWqC20sGrBvMFDOX8jg9VHyh492N2tO/am9myNkl3VTcXR+LvvFxcz15jT060nu67tahRzyGu7VRWZElnm4K3SbExsGNRiEJujNpcMtqrMgesHuJhykWntp6ESlb9NOpk7lTv/tzKOZo78NOIn1o5ci4+NT7WOUZ4hPkPo7NyZw3GHGdVyFAv6Lih3wZlKj+U9hEEtBvHlyS8bdba+IzeOAFQpGIPulsYznZ5hx9UdbIys/1W/DCsYZ6dAXsZdLePmeM/Yz8YPI2HExdSL3Lh1gyM3jjDCbwRDO7jRu5UDH/8eQfKtu7uijVRGDPEZwt6YvWTm3Z1KU2pccrW5nL55mhDXkHK3GdhiIHG34ghPDq/Hkt3tbNJZ+v/Un5O3TtbK8bLys4jJjCn3fnFpY/3HkpGXwfYr2/U69rKwZTibOzPMd1hNi6kXXxvfuzJq1QYhBB/0/YC3e73NO73fQa1S1+hYr3d/HRMjE+b9Ne+uaV2NxeG4w1gZW9HWvm2V953afird3brzwZEP6v0Dh2EF41JzjAG06WmoLC0RRpWPbDQ0GrUGHxvd2sZbL29FQWG433CEEMwd2Z7M3AI+/v1CmfsO8x1GrjbXYLs2DcmZhDO6+8Uu5bfK+nv1RyVUDZoAJFeby+v7Xyc9L50tqVtq5Y28+M2yuBeoIt1cu9HarjXvHHqHHVd3VLjt2cSzHL5xmMltJ1eaZKMpcLN0Y0zrMXq18CvjZO7E7K6zOXHzBGvOr6l0+6vpV/nP3/9h97Xd1Z5eVhWKonDw+kG6uXar1gcPlVDxXu/3MFGb6KY71eN0Lr3+OkKIoUKIC0KISCHEKxVs11UIoRVCjKu9IlZBqTnGUJQKsxm2iou1tm1dkuouyCmIFta6evF3sWJKT29WH7nG2et3D1YIdgrGw9JDdlU3AUfjj5Z7v7iYvak9nZ07N+gUp69OfsWltEs80PoB4gvia+WDQfHUvZa2LSvdViVULBm8hAD7AP5vz/+x/Ozycrvtfzj7A5YaS8b5N8zbWGM3quUoenv05tMTnxKTEVPmNjdu3WDeX/MY/fNoPj/5Oc/sfoY+a/owcctEPj3+KQevH7wrGY2iKMTfiufP2D9ZGraUV/e/ygO/PsAr+8sNOXeJyYjh+q3rVe6iLs3FwoW3er3FuaRzfHHqi2ofp6oqDcZCCDXwFXAf0A54WAjRrpztFgD69QPVhdSruu/F3dSpaaia2Rzj0vzt/bl+6zoXUy7eNbf4uXv8sTM35q1fz931piSEYJjvMA7FHWqSmXeak2M3jhFgH3DXXNE7DWwxkMjUyAbJNHTq5imWnV3GOP9xvNHjDZyMnPjPmf/U+B52ZEokxipjvKy89Nre3tSeJYOXcI/3PXx07CPmH55/1z3s6Ixodlzdwfg24/Wa9tMcCSGY22MuKqFi3sF5t/0dk3OSWXh0IcM3DOeXS7/wUJuH2P7AdpYOWcoTQU9gpDJi+dnlPLHjCXr/2Jvp26bz9sG3mb5tOn1/6ss96+7hyZ1Psuj4Io7e0H3Q3BK1hbOJZ/Uq28E4XYKbmgRj0P2/POj/ICvOriA6I7pGx9KXPi3jbkCkoihRiqLkAWuA0WVs9zSwHrhZi+WrmtRrYGIDZnYARWsZN99gXNx9ZySMGOoz9LbnbMw0vDykDUeuJLMp6u6umGG+w9AqWn6/8nu9lLU2xd+K562Db/HCnhfI1eY2dHHqTJ42j9MJp+ni0qXSbQe2GAjU/xrHWflZvP7n67hbuvNiyIuoVWrusb6Hc0nnapwZLDItkpa2LavUHWlqZMpH/T9ievvprLmwhud2P3dbDuYVZ1egEioeaftIjcpm6Nws3XihywscjjvMhosbyMzL5KtTX3Hf+vtYGb6S+3zvY/OYzbza/VXcLd3p6tqVpzo+xYr7VnDg4QN8c883TGo7iVv5t9h2eRv5hfnc630vr3V/jR+G/MCfE/5k5/idLBu6DAuNBSvOrdCrXIfjDuNi7oK3tXeNr/HFri+yZPASvT/s1ZQ+N1M9gNIfDWKA29KaCCE8gDHAQKB6QwprQ6lpTaAbwGXSuvL7SYaqOEd1H48+2Jna3fX8gyFeHL6czIaTsQQeuMz03v+setPKrhX+dv5surSJUS1HNYlWQkZeBkvDlrLy3EoKlAIKCgswMzLj3d7vVmnuZ1NxJvEMudpcvUbxelh6EGAfwK7oXUzrMK3uC1fk0xOfci3jGkuHLC3J1dzVsit/5PzBkrAl9PLoVe1jR6ZEVmsEs0qoeCHkBdwt3Xn/yPtM2zaNrwZ9hZHKiJ8jf2ak30iczZ2rXa7mYpz/OLZf2c7CYwv59MSnpOamcq/3vczqOAs/W79y9zPXmNPHo0+lU8YALI0tGdt6LD+G/8jzXZ6vcF33QqWQwzcOE+oZWiv/72ZGZhUOjKxt+gTjsq7qzv6lT4HZiqJoK6oEIcQTwBMALi4u7NmzR89iVi4zM5PM2HByTF0JKzquY2IiqR7uRNbieZoSRVEYYDWALgVdyq3rEU4KUQ4Kb206R/TlSPp5/jNgpT3t2Zi0kZ4/9sRebY+bsRvuGnfcNG64G7vjrHFGIxp+gEu+ks/+jP1sT9tOVmEWIeYhDLcdzpFbR/j10q8YJRsxwHpArZ83MzOzVl/DVbUtdRsCQfbFbPZEVV4OP60fvyX/xq9//Iq1uu7HUlzIvsCPN38k1CqUW+dvsee8roy5t3LpY9KHDTc2sHTbUvxMy3/jLk9WYRbxWfGoklXV/hu44soMxxn8kPgDD2x4gNamrcnR5tAuq12D/l3L09Cvt7IMVQ0lTBuGq9qVGa4zaEELrp26xjVq73ZIy4KWaBUtC35fwGi7sjpldaJzo0nLTcMm1ea2emqM9VYWfYJxDFC6ne4JXL9jmxBgTVEgdgSGCSEKFEX5ufRGiqIsBhYDhISEKKGhodUs9t327N6NZV4ilh2GERoaiqIonM/OxisgAOdaPE9TM4DKg1Ahu1lx2ZxlZxPpHNSeEUHuAPRX+nNP7D1EpEQQkRJBZGoku9N2l9xnUws1XVy6MKfHnNvWkq0vhUohWy9v5cuTXxKbGUtPt5483+V52jropjSMVcaStyePn6N/ZmjIUHq696zV8+/Zs4eyXsPXM6+z/OxyvK29aevQljZ2bTDXmNfquQFWbl9JG3Ubhg8artf2bslubN20lTyvPEL9Q2u9PKVl5mUy/9f5eFt78+HID2/L9rRnzx5m957NrvW7OKE5waOh5S81WJ6TN09CNAzpMqTKCymUFkooA5IGMOuPWRy5dYRQz1AmDJpQ7ePVpfJebw1tnDKuznueDuw5wKG4Q7zX+71y/5d+CPsBbsC0gdNwMncqebyx1tud9AnGR4HWQghfIBaYAEwsvYGiKCXvxEKIZcDmOwNxXdPkZ0D+rZJpTUpWFuTnN8uEH1WlUQkWTw5hytLDPLfmFObGagYGuCCEoJ9nv9ve7PK1+VxNv8rF1ItEpETwv4j/8eCmB3muy3M8HPBwrUyfqIyiKBy4foDPTnzG+eTztLVvy5v3vkkv99u7PFVCxfw+85m0dRIv7n2RH4f/WDKivC7LNvevuRyKO1TymEDoArN9WwIcAgiwD6C9Q/tKB11VJE+bx6mEU4z3H6/3Pv52/nhYevDHtT/qfKTwwmMLic+KZ/nQ5WWmXTTXmPNI20f48tSXXEi+QBv7NlU6fmU5qauivUN7Vg9bzWcnP+PxDo/X+HjNTX3cAprSbgo7ru7gl0u/8HDAw2VucyjuEK1sW90WiJuSSt85FUUpAGahGyUdDqxVFOWsEGKmEGJmXRdQX6Y58bofikdSp+uybzXHVJjVYWas5vtpXWnrZs3MlSf461LZo6g1ag2t7Fpxn+99PNv5WTaO2kg3t258cOQDZvw+o2T1mbpyPP4407ZN48mdT5KRl8EHfT9gzYg1dwXiYuYacz4f+DlCCJ7Z9Qy38m/Vafm2X93OobhDvNLtFXaM28EXA7/gyY5P4mfjx+mE0yw6voh/7fgX/X7qx5TfprDkzBIiUyKrPLK4+H5xVe5pCSEY1GIQh+MOk55Xdn7y2rAvZh8bLm5gevvpFS52MCFgAhYaC74/U/XVgCJTIjE3MsfNwq0mRS3hZunGB30/qDSbl9QwOjp3JMgxiJXnVpa5xGueNo8T8SdqPIq6IenVjFEUZauiKP6KorRUFOW9ose+VRTl2zK2naYoyrraLmhlTHOKBnHflX1LBmN9WZtqWPFoN3wczHl8+TFOXEupdB8ncye+HPglb/V6i7DEMMb+OpaNFzfWeurFs0lnmblzJtO2TSM6I5o53eew6f5NDPcbXmlr3MvKi4/7f8yV9Cu8uv/VOsscdCv/FguPLKStfVsmtJmAq4UroV6hPBn8JJ8N/Izt47bz54Q/WTJ4CU8EPUFOQQ6fnfiMMb+O4b4N9/H+4ff5K/YvvRbpKM5HfedKTZUZ4TeC/MJ8vRI2VEdabhrz/ppHK9tW/Lvjvyvc1sbEhgfbPMj2q9u5mn61SueJTI2klW0rgxyYJ5VtcvvJXMu4xt6YvXc9dzrhNDnanGovOdkYGEwGrrtaxqnNd8WmmrCzMGblY91xsjJh2tIjZSYFuVPxyjgbRm/QdRn/9SZP73q6VuYoR6VG8cKeF5iweQJhiWG80OUFtozdwkMBD1UpO1J3t+681PUldkfv5utTX9e4XGX5+tTXJGQnMKfHnHKn29iY2NDdrTtPdXyKtSPXsnPcTt7s+SatbVuz4eIG/rXzX/Rd05d5f82rsP6Oxh/F386/yl3dbR3aEuoZyvKzy2s93enNrJvMOTCHlJwU3uvzHsZq40r3mdJuCkbCSHe/rwoiUyvPSS0Zlnta3IObhVuZC1UcvH4QtVBX+cNpY2IweSJNc26CqS2Y6t6ctMVrGds03wxc1eVsbcqqx7sz/tuDPLz4EA908eT+jh4EedpU2BLxsPTg+yHfsyp8FZ+d+Iz7f7mfkX4jS1quAlGyvyg1SF8pGpxf3Jou/j0+K54dV3dgqjZlZvBMprSbgpWxVbWva2LARC4kX+C7v7/D386fwT6Dq32sO11IvsCq8FU84P/AXWvfVsTFwoXx/uMZ7z+e7IJsjt44yh/X/uCXS7+w/cp2ZgbPZGLAxNs+eORp8zh98zQP+D9QrbLO7DiTCZsnsPr8ap4IeqJaxyjtTMIZ/hv+X3Zc2YFW0fJ/If9HO4e78gKVydHMkTGtx7D+4npmBs+scOpKsaTsJJJzkmlpU3nmLclwGKmMmNR2Eh8d+4hzSedue40djjtMoGNgk5iCWR7DCsZ3zDEG2TKuLk87c36c0YP3fwtn1aFr/HDgCn6OFozu6MH9ndzxdrAocz+VUDG53WR6e/Tmrb/eYsPFDSXBtVjpoFsclO8M8gKBRq1hctvJPBr4aK0k0RdCMKfHHC6nXWbOgTmYa8zp4NABG5OKP2RUplAp5N1D72JtbM2znZ6t9nHMjMxKBsxNbz+dBUcX8NGxj1h/cT2vdH2lZE5uWGIYOdqcCvNRV6S9Q/uS1vHEgInVegPLL8xn59WdrAxfyd8Jf2OpsWRCwAQmBkzEy7pqSRKmd5jOuoh1rDi3gpe7vlzp9pdSLwHIlnEzNLb1WL4+9TX/Pfdf3u/7PqDLLxCWFMaMwBkNXLqaMaBgHA+lBosUpjff5RNri4+jBd9NDiEtK5/fwuL4+VQsi3ZGsGhnBB29bBnTyYORwe7YW9zdHeln48fy+5Y3QKkrZqw2ZtGARUzYPIEndz4JgJXGCk8rT7ysvEq+t7BqQbBzsF7rvv4S+QunEk7xdq+3sTW1rZVy+tj48M0937AvZh8LjizgXzv/RahXKC+HvMyx+GMAemXeKk91W8dpuWmsvbCWNRfWcDPrJi2sWvBKt1e4v9X9JUk9qsrD0oPhfsNZF7GOGYEzykxQU1rxSGp9FoiQDIuVsRVjW49lzfk1PNf5OVwsXDh64yiFSmGTHrwFhhKMFaWoZfxPCjRtahoYGSHMa39+Z3NjY65hQrcWTOjWguup2fx6+jo/n4xl7q9nWbQzgu+ndqWLd8VvoI2Jo5kj60au4+TNk0RnROu+MqO5kHKBXdG7SuZR+9n4Mb/v/AoXjE/LTWPR8UV0dOrI6FblJySorn6e/ejh1oOV4Sv57vR3jP5lNDYmNvjb+dco8FendZyZl8kjWx/hSvoVerr1ZG7PufTx6FMr09ke6/AYmy5tYlX4KmZ1mlXhtpGpkVgbW+No5ljj80pNz8S2E1kVvoo1F9bwbOdnORR3CDMjM4Kdghu6aDViGAO4biWiLswrmWMMum5qtU3Nuh+lu7nbmjGzf0u2PdePzU/3wdZMw6Qlh9hxLr6hi1Yltqa2DGgxgCntp/B6j9f59p5v2TxmM8cmHWP7A9v5qP9HuuCz5REW/734rgUFin124jPS89KZ02NOnc2xNlYb82iHR9k0ZhNDfYaSmJ1Y7lSuqpjZcSbpeemsPr+60m0VReGNA28QnRHN4nsXs3jwYvp59qu1a/az9WNgi4GsPr+a1JzUCreVI6mbNy8rLwa1GMTaC2vJys/icNxhOrt0bvLLXRpGML5j6UQoWiRCdlHXqQ4eNqx7shdtXKz413+P8eOR+l8RqLapVWrcLd0Z4jOEDaM3cK/3vXxx8gumbZt214pHV3KvsC5iHRPbTqxy0orqcDZ3Zn7f+Wwds7XSaUP6KN06rmxk9YpzK9h5bSfPd3m+1jOZFXsy+ElyCnKYvX92mXNJQfehIDIlsiTvutQ8TW43mfS8dJacWUJUWhQ93ermNVmfDCMYq9QkOnQFh3/+QbVpqc16LeP64mhpwuoZPejn78SrG87w6c6IWp9j3FBsTGz4sP+HLOi7gKi0KMZtGsf/Iv6HoihoC7WsTV6Lk5kT/w6ueWCsCi9rrzKzWlWHPq3jYzeOsej4Iu71vpcp7abUynnL0sa+Da91f42/rv/Fl6e+LHObm1k3ycjPqJXMW1LT1cm5Ex0cOvB9mC5hTFOeX1zMMIKxe0fCAueA4z//oMXd1FLdszAx4j9TQhjXxZNPd17ktY1nKNDWTWKNhjDMbxgbRm0gyCmItw++zaxds1j892Ki86J5qdtLTXo6RWWt44SsBF7c+yJeVl683evtOu8aHuc/jgdaP8CSM0vYcXXHXc8XD95qaSunNTVnQggmt5tMoVKInYkd/nb+DV2kGjOMYFyGwrR01LYyGNcXjVrFwnFBzBrQih+PRDNz5Qmy88ruamyKXC1cWXzvYl7p9gqH4w7z9emvaWPahiHeQxq6aDVWXus4vzCfF/e+SFZBFotCF9Xbh47Xur9GkGMQr//5OpEpkbc9V5s5qaWm7V6fe/Gw9KCvZ996yYlf15r+FZRDm5aGSqbCrFdCCF4c0oa3R7fnj/PxTFpyiJRblad2bCpUQsWktpNYO2ItY1uPZYL9BIMYRFRe6/jT459y4uYJ5vacW69zeo3VxnwS+gnmRuY8t+e52/JoR6ZG4mjmWOn0J8nwaVQafhrxE2/0eKOhi1IrDDIYKwUFFGZmym7qBjKlpw9fT+xM2PV0Ji89TFZe2SORmyo/Wz/e6vUWjhrDmVpzZ+t4+5XtrDi3gocDHma4n35LNNYmFwsXPg79mNiMWF7b/1pJPvHIlEjZRS2VsDGxwdTItKGLUSsMMhhrMzIA5ACuBnRfoBvfPdKFc9fTeW7NKQoLDWNQl6Eq3To+k3CGNw+8SZBTEC+FvNRgZeri0oWXur7E3pi9fHv6WwqVQi6lXZLJPiSDZJjBOFU3T1HeM25YAwKceXNEO34/F8+CbecbujhSJYpbx1O3TcXUyJSP+3/c4HM3Hw54mFEtR/HN6W9YHb6a7IJseb9YMkgGGYxlKszGY1pvX6b09Oa7fVGsMYB5yIasuHWsVbQs6LdAr0Ub6poQgjd6vEFb+7YsOLoAkDmpJcNkkMG4eJEIleymbhTeHNGO/v5OzPk5jAORNV9WUao78/vO58fhPzaqPL+mRqZ8OuBT7Ex0g7bkak2SITLQYFzcMq6dpP1SzRipVXwxsRN+ThY8ufI4kTdrdx1dqfZYGVvpvfxhfXK3dOerQV/xYsiLTXpetySVx0CDcdHyifKecaNhbarh+6ldMTZS8djyoyQb0JQnqX4EOgUytf3Uhi6GJNUJAw3GRQO4rKq/EL1U+7zszVk8JYS4tBxm/vc4uQWGkxREkiSpJhrVEor5+fnExMSQk5NT5X1tbGwIDw8HQNulC4Vff8X5yMhK9pLg9rorzdTUFE9PTzSa2htR27mFHR+PD+bpH0/y6oYzfDw+2CASZ0iSJNVEowrGMTExWFlZ4ePjU+U36IyMDKyKWsJ5MTEU3rqFaZu6X0nHEJSuu2KKopCUlERMTAy+vr61er6Rwe5cTrzFJzsiSMrMY1pvH/q3dkKlkkFZkqTmqVEF45ycnGoF4rtotQi1unYK1UwJIXBwcCAhIaFOjv/0wFZo1CqWHrjM9B+O4u1gziPdvRkf4omtuXGdnFOSJKmxanT3jGujy1LRakEG4xqry+5jIQRPhrbkwOyBfPFwJ1ysTHlvazjd5//BS/87zZmYtDo7tyRJUmPTqFrGtUXRalGZmFRrX0tLSzIz5dSb+mJspGJksDsjg90Jj0tnxcGr/Hwylv8dj6Gjly0z+voxtIMratmFLUmSAWt0LeNaIVvGTVJbN2veHxvIodcG8eaIdqRm5fHU6hMM+ngPqw5fJSdfjr6WJMkwGVwwVhQFpRbuGSuKwksvvUSHDh0IDAzkp59+AiAuLo5+/frRsWNHOnTowP79+9FqtUybNq1k20WLFtXGpTRbNmYaHu3jyx//F8rXkzpjbabh9Y1h9Fmwm692R5KWnd/QRZQkSapVjbab+q1NZzl3Pb3yDYtotVrUajWgUHgrC2GchNBcvm2bdu7WzB3ZXq/jbdiwgVOnTnH69GkSExPp2rUr/fr1Y/Xq1QwZMoTXX38drVZLVlYWp06dIjY2lrCwMABSixaqkGpGrRIMC3Tjvg6uHIxK4tu9USzcfoFv9lxiYvcWPNbHFxdrw1g+TZKk5q3RBuNqK16pr4aDj/78808efvhh1Go1Li4u9O/fn6NHj9K1a1ceffRR8vPzuf/+++nYsSN+fn5ERUXx9NNPM3z4cAYPHlzz65BKCCHo1dKRXi0dOXs9je/2RrFkfxTL/rrCs4Na80Q/PzRqg+vkkSSpGWm0wVjfFmyx4rmyhTk55EZGYuzlVaNVmxSl7PV3+/Xrx759+9iyZQuTJ0/mpZdeYsqUKZw+fZrt27fz1VdfsXbtWpYuXVrtc0vla+9uw+cPd+KlIW14/7dwFm6/wOa/41jwQCBBnjIXuSRJTZPBNSeU4hSLNbxn3K9fP3766Se0Wi0JCQns27ePbt26cfXqVZydnZkxYwaPPfYYJ06cIDExkcLCQh544AHeeecdTpw4UQtXIlXEy96cryd14bvJXUjKzOX+rw4wf2s42XlykJckSU1Po20ZV1uh7s24pgO4xowZw8GDBwkO1qVr/PDDD3F1dWX58uUsXLgQjUaDpaUlK1asIDY2lunTp1NYWAjA+++/X+PLkPQzpL0rPfwc+OC38yzeF8W2sBu8PzaQ3q0cG7pokiRJejO4YKwUFOh+qGYwLp5jLIRg4cKFLFy48Lbnp06dytSpd68cI1vDDcfGTMP7YwMZ3dGdVzecYdKSwzwY4snrw9phY157ebUlSZLqisF1U6PVtU5lOszmp4efA78Z7TpcAAAgAElEQVQ925cnQ1uy/kQs/T/azce/XyAhI7ehiyZJklQhgwvGilarG0mtMrhLk/RgqlEze2gAv87qTTcfe77cHUnvBbt4dcPfRN6UmdUkSWqcDK+bWqtFqNRyWb5mrr27DYunhBCVkMmSPy+z/ngMPx6J5p62zjzRryVdfezka0SSpEbD8JqPhTIVpvQPPydL5o8J5MArA3l2UGuOX03hwe8Ocv/Xf/HLqVhyC+Toa0mSGp5htoxlAgjpDo6WJjx/rz8z+7dk/YkYluyP4tk1p7C3MGZcF08e7tYCX0eLhi6mJEnNlMEFYwq0oDG8y5Jqh5mxmkd6eDOxWwv+jExk9eFrfP/nZRbvi6KnnwMTu7dgcHsXTIxk74okSfXH4KKWotWiMq3e8olS86FSCfr5O9HP34mb6Tn873gMPx65xtM/nsTewpjxXTx5VOa+liSpnhhef27RAK7GrqB4PrTU4JytTXlqQCv2vTSA5Y92o6uPHUv+vMy9n+xl3fGYclOjSpIk1RaDCsaKoqDUwgCu+++/ny5dutC+fXsWL14MwLZt2+jcuTPBwcEMGjQI0CUImT59OoGBgQQFBbF+/XoALC0tS461bt06pk2bBsC0adN44YUXGDBgALNnz+bIkSP06tWLTp060atXLy5cuADoVqB68cUXS477xRdf8McffzBmzJiS4+7YsYOxY8fW6Dql26lUgv7+Tnw3OYSdL/SnjasVL/7vNI8uO8qNtJyGLp4kSQas8XZT//YK3Dij9+Zm2gJQqTHOykJlbAyaMjIvuQbCfR9UeqylS5dib29PdnY2Xbt2ZfTo0cyYMYN9+/bh6+tLcnIyAO+88w42NjacOaMrZ0pKSqXHjoiIYOfOnajVatLT09m3bx9GRkbs3LmT1157jfXr17N48WIuX77MyZMnMTIyIjk5GTs7O5566ikSEhJwcnLihx9+YPr06XrXj1Q1vo4W/PRET5YfvMKCbee5d9Fe3hjRjvFdPOWUKEmSal3jDcbVUtSdWMM3y88//5yNGzcCEB0dzeLFi+nXrx++vr4A2NvbA7Bz507WrFlTsp+dnV2lxx4/fnzRusuQlpbG1KlTuXjxIkII8vPzS447c+ZMjIyMbjvf5MmTWblyJdOnT+fgwYOsWLGiRtcpVUylEkzv7cuANs68vP5vXl73N1v+juODBwJxszFr6OJJkmRAGm8w1qMFW1p2RgYWajV5UVEYe3ujtrKq1mn37NnDzp07OXjwIObm5oSGhhIcHFzShVyaoihltpJKP5aTc3v3poXFP9Nn3njjDQYMGMDGjRu5cuUKoaGhFR53+vTpjBw5ElNTU8aPH18SrKW65eNowZoZPVhx8AoLtl1g8Cf7mH1fAOlJWm79HUdKVh6pWXmkZuWTkpVPalYeGrWK14a1pYWDeUMXX5KkJsCw7hlrixI41GAAV1paGnZ2dpibm3P+/HkOHTpEbm4ue/fu5fLlywAl3dSDBw/myy+/LNm3uJvaxcWF8PBwCgsLS1rY5Z3Lw8MDgGXLlpU8PnjwYL799tuSQV7F53N3d8fd3Z1333235D60VD9UKsG03r5se64v7dytmfNzGB8ezeGp1SeY83MYH/0ewarD1zh4KZG4tBwOXErk/q8PcOxKckMXXZKkJsCgmlbFwVjUYI7o0KFD+fbbbwkKCqJNmzb06NEDJycnFi9ezNixYyksLMTZ2ZkdO3YwZ84cnnrqKTp06IBarWbu3LmMHTuWDz74gBEjRuDl5UWHDh1KVoK608svv8zUqVP55JNPGDhwYMnjjz/+OBEREQQFBaHRaJgxYwazZs0CYNKkSSQkJNCuXbtqX6NUfd4OFvw4oweHLidx+tRpQnt1xc7cGFtzDaaaf153UQmZPLb8GBP/c5gF4wIZ08mzAUstSVJjJ/SZtiGEGAp8BqiBJYqifHDH85OA2UW/ZgJPKopyuqJjhoSEKMeOHbvtsfDwcNq2bat/6UvJyMjALC+P/Lg4TAMCEAbahTtr1iw6derEY489VmvHzMjIwKqcbv2a/E0M3Z49e0puLZQlNSuPmSuPcygqmVkDWvHCvf6oVHLwV2X1JpVN1lv1NLZ6E0IcVxQl5M7HK+2mFkKoga+A+4B2wMNCiDubZZeB/oqiBAHvAItrXuSq+6eb2qB630t06dKFv//+m0ceeaShiyLpwdbcmBWPduehEC++3B3J0z+eJDtP5sKWJOlu+jQfuwGRiqJEAQgh1gCjgXPFGyiK8lep7Q8BDdMnp9UiVCqEgQbj48ePN3QRpCoyNlLxwQOBtHK2ZP5v4cSkZPGfKSE4y8xekiSVUmk3tRBiHDBUUZTHi36fDHRXFGVWOdu/CAQUb3/Hc08ATwC4uLh0KT0tCMDGxoZWrVpV5zrQarVoUlJQ5eRS4OlRrWM0V1qttmS61Z0iIyNJS0ur5xI1DZmZmbcleKnMifgCvv07F0uN4OlOJvjaVG9sQ0aegoUGVE10vnNV603SkfVWPY2t3gYMGFBmN7U+LeOy/uPLjOBCiAHAY0Cfsp5XFGUxRV3YISEhyp39+OHh4eXeu6xMRkYGGpUKRWNU7WM0VxXdMzY1NaVTp071XKKmoar3okKBwX3SeHz5Md46mIO7jSkhPvZ09bEjxMeeNi5Wd91TLixUiLiZwdErKRy7ksyxKynEpmYT7GnDlxM742Xf9KZONbZ7eE2FrLfqaSr1pk8wjgG8Sv3uCVy/cyMhRBCwBLhPUZSk2ile1ShauZax1Lh18LBh8zN92HT6OseupnAoKolfT+v+naxMjQjx1gVmgKNXkjl+NYWMHN0UN2crE7r62PNAF09+OHCZ4Z/v56PxwQxu79pg1yNJUu3QJxgfBVoLIXyBWGACMLH0BkKIFsAGYLKiKBG1Xko9KVotKhO5YpPUuDlamjC9ty/Te/uiKAoxKdkcvZLM0SspHL2SzO6iBDP+LpaMDHYnxNuOrj72eNqZlSSDGdfZk6dWn+CJ/x7n8T6+zL4vAI1cx1uSmqxKg7GiKAVCiFnAdnRTm5YqinJWCDGz6PlvgTcBB+DrojeLgrL6xOucbBlLTYwQAi97c7zszRnbWTfuMeVWHkLoRmOXp4WDOeue7Mn8LeEs+fMyx6+l8OXEznjYyjSdktQU6fVRWlGUrYqi+CuK0lJRlPeKHvu2KBCjKMrjiqLYKYrSseir/gOxoqBotYh6DMYVDQq4cuUKHTp0qLeySIbDzsK4wkBczMRIzVujO/DVxM5cjM9k+Of72XU+vh5KKElSbTOcfi1F0X3JlrHUzAwPcmPT031wtzHj0WXHeP+3cBIzcxu6WJIkVUGjTVO14MgCzief13t7bUEBIjcXccWk3OxbAfYBzO42u8znAGbPno23tzf//ve/AZg3bx5CCPbt20dKSgr5+fm8++67jB49ukrXkpOTw5NPPsmxY8cwMjLik08+YcCAAZw9e5bp06eTl5dHYWEh69evx93dnQcffJCYmBi0Wi1vvPEGDz30UJXOJzU/vo4WbPh3L97efI7v9kbx3d4ofBzM6extRxdvO0K87WntbCkzgElSI9Vog3GV6ZHWszITJkzgueeeKwnGa9euZdu2bTz//PNYW1uTmJhIjx49GDVqVJXWtP3qq68AOHPmDOfPn2fw4MFERETw7bff8uyzzzJp0iTy8vLQarVs3boVd3d3tmzZAiDn+Ep6M9WomT8mkAldvTgUlcSxKynsi0hgw4lYQDdau1MLO7p623FfoCutnOUUQElqLBptMK6oBVuWzIQE1PHxGPv4oK7mBO9OnTpx8+ZNrl+/TkJCAnZ2dri5ufH888+zb98+VCoVsbGxxMfH4+qq/3SSP//8k6effhqAgIAAvL29iYiIoGfPnrz33nvExMQwduxYWrduTWBgIC+++CKzZ89mxIgR9O3bt1rXIjVfQZ62BHna8kQ/3XKc15KzOH41hWNXUzhxNYVPdkbw8Y4IAlytGBnszsggd7nUoyQ1sEYbjKussBCgxgO4xo0bx7p167hx4wYTJkxg1apVJCQkcPz4cTQaDT4+PnetUVyZ8rKcTZw4ke7du7NlyxaGDBnCkiVLGDhwIMePH2fr1q28+uqrDB48mDfffLNG1yQ1X0IIvB0s8HawKBmtfTM9hy1n4th0+joLt19g4fYLdPSyZWSwO8MD3XC1MUVRFNKy84lLyyEuLZvrqTncSMshLi0HB0tjRgW7097duko9RJIklc/ggnFNB3BNmDCBGTNmkJiYyN69e1m7di3Ozs5oNBp2797N1atXq3zMfv36sWrVKgYOHEhERATXrl2jTZs2REVF4efnxzPPPENUVBR///03AQEB2Nvb88gjj2BpaXnbOseSVBucrU1L5jlHJ2eVBOZ3Np/j3S3n8LQzIzEjj+z82xe1UKsEzlYmJGbmsnhfFK2dLbm/kwejO7rjaSdb1pJUEwYTjEUttYzbt29PRkYGHh4euLm5MWnSJEaOHElISAgdO3YkICCgysf897//zcyZMwkMDMTIyIhly5ZhYmLCTz/9xMqVK9FoNLi6uvLmm29y9OhRXnrpJVQqFRqNhm+++aZG1yNJFfGyN2dm/5bM7N+SSwmZbDp9ncibmbham+JqY4q7rRluNqa42ZjhZGWCWiVIzcpjy5k4fj4ZW9Ky7uZrz5hOHgzr4IaNuaahL0uSmhy91jOuC7W9nvGta9Go0tMxbd9Odp1VkVzPuHqaSs7buhSdnMUvp2LZcDKWqIRbGKtV9GrlwIA2zgxo41zmvWhZb9Uj6616Glu9lbeescG0jCnUItQqGYglqR552Zsza2BrnhrQirDYdH4+Fcuu8zeZ++tZ5nIWP0cLQts4MyDAiW6+9pgYyTwAklQWgwnGorCwQRJ+nDlzhsmTJ9/2mImJCYcPH673skhSQxFCEOhpQ6CnDW+MaMflxFvsuXCT3RcSWHn4KksPXMbcWE1PPweMcnKJUF3CycoEZyvTou8m2Jhp5IdpqdkymGBMYWG9psIsFhgYyKlTp+r9vJLUmPk6WuDrqBsklp2n5WBUIrvPJ3DgUiLRSQVsv3J3Qh+NWmBvYYxAoKBQqBSnDyj+WcHCxIhgL1u6tLCjs7cd7dysMTYynESCUvNlUMEY48rz+UqSVL/MjNUMDHBhYIALALt37yakZx9uZuSSUPRV/HPKrTwAhNB9gUBV9LNAkJyVx8mrKWz5Ow4AEyMVQZ42dPa2o3MLXbYxR0u5cpvU9BhUMBZqw7kcSTJUQgisTDVYmWpo6VS9BD1xadmcuJrKiWspnLiWwtI/L/OdNgoAP0cLuvrY09XXnm4+9njZm8nub6nRM5joJRqom1qSpPrnZmPG8CAzhge5AZCTryUsNo1jV1M4ejmZ38Li+OlYNAAu1iaE+OgCs6uNKSqha22rhEAI3fxplRAYqXT3vc2NDeZtUWpCDOJVpyiKrptaLq4uSc2SqUZNiI89IT72zOzfksJChYibGRy9nMzRKykcvZJc0rVdEQtjNcMC3Rjb2ZPuvvZyYQ2p3hhEMEaryxRU3y1jS0tLMjMz6/WckiRVTqUSBLhaE+BqzeSePiiKwvW0HFKz8lAUKFR0g8IKFQWl6OeMnHy2hd1g65kb/O94DJ52Zozt5MGYzp74OlrcdnxFUbiRnsP5uAzCb6RzPi6DG+k5mGrUmGlUmGnUmBmri35XY26sprWLFfe0dUEtA7xUBoMIxkpRMG6uaxkXFBRgVM6ykZIk6e5Te9ia4WFrVuF2AwNceGtUB34/d4N1x2P4cnckn++KpIu3HYPaOhOflkP4jQzOx6WTnlNQsl/xsdOy84lP05Kdr/vKydOSla9FW6hLruTnaMHM/i25v5OHHAUu3abRvoPfmD+f3HD91jNWCgspzM5GZWpaYevYpG0Arq+9Vu7ztbmecWZmJqNHjy5zvxUrVvDRRx8hhCAoKIj//ve/xMfHM3PmTKKidINQvvnmG9zd3RkxYgRhYWEAfPTRR2RmZjJv3jxCQ0Pp1asXBw4cYNSoUfj7+/Puu++Sl5eHg4MDq1atwsXFhczMTJ5++mmOHTuGEIK5c+eSmppKWFgYixYtAmDZsmVcvnyZTz75RK/6liRDZmasZnRHD0Z39OBGWg4/n4pl/fEYPtx2AQtjNW1crRgR7E5bVysC3Kzxd7HCxqziFKC5BVp2nrvJ13sieXn933yyI4LH+/rycLcWWJg02rdhqR4ZxqugOKVnDUdM1uZ6xqampmzcuPGu/c6dO8d7773HgQMHcHR0JDk5GYBnnnmG/v37s3HjRrRaLZmZmaSkpFR4jtTUVPbu3QtASkoKhw4dQgjBkiVL+PDDD/n444955513sLGx4cyZMyXbGRsbExQUxIcffohGo2HlypUsWbKkRnUnSYbI1caUmf1b8q9+fiTfysPO3Lha95FNjNQMD3JjWKAr+y4m8vXuSN7dEs6XuyOZ2tOHab18sLOQUzObs0YbjCtqwd5JURQy09OxtLJCqKrf9VOb6xkrisJrr7121367du1i3LhxODo6AmBvbw/Arl27WLFiBQBqtRobG5tKg/FDDz1U8nNMTAwPPfQQcXFx5OXl4evrC8DOnTtZs2ZNyXZ2dnYADBw4kM2bN9O2bVvy8/MJDAysYm1JUvMhhMChFuYvCyHo7+9Ef38njl9N4Zs9kXz2x0X+sz+KIe1d6dPKkT6tHXGxNtX7mDn5WuLTc2hhby6ncDVhjTYYV4UQAlSqGgXiYrW1nnF5+ymKovc/jJGREYXFS0PCXee1sPhnUMnTTz/NCy+8wKhRo9izZw/z5s0DKPd8jz/+OPPnzycgIIBHHnlEr/JIklR7unjbsWRqVy7cyOA/+6PYdf4mG0/GAuDvYknvVo70be1Id1+Hkq7stOx8zl1P5+z1NM4Wfb+UcAttoUJrZ0smdm/B2E6ejWblrKy8ApIy8/C0k3O9K2MQwbg21dZ6xmlpaWXuN2jQIMaMGcPzzz+Pg4MDycnJ2NvbM2jQIL755huee+45tFott27dwsXFhZs3b5KUlISlpSWbN29m6NCh5Z7Pw8MDgOXLl5c8PnjwYL788ks+/fRTQNdNbWdnR/fu3YmOjubEiRMcOHCgJlUmSVINtHG14qPxwRQWKpyLS+fPyEQORCay+vA1fjhwpWT+c0xCFgnbfi/Zz8XahPbuNgxp74q9hTE/n4zlrU3nWLDtPCOC3JnYvQWdvGzLDILaQoVLCZmcik7ldHQq+dpCgjxt6ehlSxtXKzRVmCaak68lOjmLy4m3uJx4iytJRd8Ts7iRrmtA+DiYc38nD+7v6IHPHSPTJR0ZjO9QW+sZl7df+/btef311+nfvz9qtZpOnTqxbNkyPvvsM5544gm+//571Go133zzDT179uTNN9+ke/fu+Pr6VnjuefPmMX78eDw8POjRoweXL18GYM6cOTz11FN06NABtVrN3LlzGTt2LAAPPvggp06dKum6liSp4ahUgg4eNnTwsGFm/5bk5Gs5fjWF/RcTOX41GR8bFdP6taK9uzXt3W1wsrq923x6b1/CYtNYdfgav56KZd3xGNq6WTOxewv6tHLkwo10TkWncTo6lTOxaWTm6kaDW5kYoTFSsfZYDKBLMRroYUOwly44d/SyRQiITs4mOiWLmOQsolOyiU7OIjoli/j03NvKYW9hjI+DOb1aOeDrYIGlqRG/n43nsz8u8unOi3RqYcuYTh4MD3Srla5/Q2Ew6xlXtCavVLYRI0bw/PPP061bN7mecTU0tnVSmwpZb9VTlXrLzC3gl1OxrD58jbPX00se16gF7dysCfayJdjTlmAvW/wcLRACYlKyORWdWtJaPhObRm5B4V3HFgLcrE3xtDfHy84cL3szfBws8HG0wNfBotwu8uup2fx6+jo/n4zl/I0MjFSCfv5ODO3giq+jBR62ZjhbmWBUy8mbGtvrzfDXM5b0lpqaSrdu3QgODmbQoEFkZGQ0dJEkSapFliZGTOruzcRuLTgdk8bZ62m0c7OmrZs1ppqyp3962ZvjZW/OyGB3APK1hVy4kcHpmFQEAi97M7zszHG3NavWHGl3WzNm9m/JzP4tCY/TrX39y8nr7Dp/s2QbtUrgam2qm7dtZ4a7rSmtnC3p5utQ6Rzxpk4G4xpqiusZ29raEhER0dDFkCSpjgkhSrqaq0qjVpV0m9e2tkUfDGYPCSAqMZOYlGyup+YQm5ql+56SzZHLydxIzylJmOJlb0Z3Xwd6+DnQ3dceL3vz246pKAoJGblE3swkMiGTyJuZXEnKwjI/D2f/dNq6WTXqQWQyGNeQXM9YkiSpelQqQStnK1o5l32brEBbSER8Joeikjh8OYmd4fGsO667t+1ha0Z3P3uMVIKLN3XBN6NUVjQrEyM87Mz4Mz6frZ/vp6WTBaOCPRgZ7IZfBauF5RZouRifSXhcOpEJmbwyNKBegrgMxpIkSVKjZKRW0c7dmnbu1jzax7dkAZDDUckcikpiX0QCIGjlbMHoju60crKklbMVrV0scbYyQQjBr7/vJt3aj02nr/PpHxEs2hlBBw9rRga561Kcpudy7no64XHpnItLJ/JmJgVFrXEzjZrH+vjibKX/vO9qX2udn0GSJEmSakHpBUCm9vLRax9rY8GoHt480sObuLRstvwdx6bT13n/t/O8/9s/KZddrE1o52bNwABn2rnrutF9HCzqbWEPGYwlSZKkZsHNxozH+/rxeF8/ribd4uClJDztzGnrZtXg06xkML6DXBZRkiTJ8Hk7WODt0HgSkMg1vPSgLV6iUZIkSZLqgAzG5dizZw8DBgxg4sSJchEFSZIkqU412m7q/WsjSIzWv7tYq9WirmAtYwBHL0v6Puiv9zGPHDlCWFhYyQpIkiRJklQXZMu4At26dZOBWJIkSapzjbZlXJUWLNRNburSSxRKkiRJUl2RLWNJkiRJamAyGEuSJElSA2u03dQNpXiOcWhoaKNadkuSJEkyXLJlLEmSJEkNTAZjSZIkSWpgMhhLkiRJUgNrdMFYUZSGLoJURP4tJEmS6kejCsampqYkJSXJINAIKIpCUlISpqZ1v46nJElSc9eoRlN7enoSExNDQkJClffNycmRgaOayqs7U1NTPD09G6BEkiRJzYtewVgIMRT4DFADSxRF+eCO50XR88OALGCaoignqloYjUZT7fSTe/bsoVOnTtXat7mTdSdJktSwKu2mFkKoga+A+4B2wMNCiHZ3bHYf0Lro6wngm1oupyRJkiQZLH1axt2ASEVRogCEEGuA0cC5UtuMBlYoupu9h4QQtkIIN0VR4mq9xGXIzS4gK1HhRlRazQ4karJrJTvX4NgAoob7VyQ7WSHhWkbdHLzOr7v6J6hpneakKiTF6r+y2N0FqOipmlZcDXevw9dbbrpCyo1bFZy7Dk9emQatt4p3zstUSEvIrqNz11Adn7smr4n8WwoZyTnV3t/S1gShqvvK1ScYewDRpX6PAbrrsY0HUC/BOOFqOpd3Klzeebw+TmeQon4/2tBFaJIubTvS0EVokiK3Hm7oIjRJFzcfbOgiNEkRm/6q9r6PL+qHiVndD6/S5wxlfSS4c7izPtsghHgCXTc2QKYQ4oIe59eXI5BYi8drTmTdVY+st+qR9VY9st6qp0b1Nuu7WiyJjndZD+oTjGMAr1K/ewLXq7ENiqIsBhbrcc4qE0IcUxQlpC6Obehk3VWPrLfqkfVWPbLeqqep1Js+84yPAq2FEL5CCGNgAvDrHdv8CkwROj2AtPq6XyxJkiRJTV2lLWNFUQqEELOA7eimNi1VFOWsEGJm0fPfAlvRTWuKRDe1aXrdFVmSJEmSDIted6UVRdmKLuCWfuzbUj8rwFO1W7Qqq5Pu72ZC1l31yHqrHllv1SPrrXqaRL0JmXpSkiRJkhpWo8pNLUmSJEnNkUEEYyHEUCHEBSFEpBDilYYuT2MlhFgqhLgphAgr9Zi9EGKHEOJi0Xe7hixjYySE8BJC7BZChAshzgohni16XNZdBYQQpkKII0KI00X19lbR47Le9CCEUAshTgohNhf9LuutEkKIK0KIM0KIU0KIY0WPNYl6a/LBWM90nZLOMmDoHY+9AvyhKEpr4I+i36XbFQD/pyhKW6AH8FTRa0zWXcVygYGKogQDHYGhRbMtZL3p51kgvNTvst70M0BRlI6lpjM1iXpr8sGYUuk6FUXJA4rTdUp3UBRlH5B8x8OjgeVFPy8H7q/XQjUBiqLEFS98oihKBro3SA9k3VVI0SnOF6op+lKQ9VYpIYQnMBxYUuphWW/V0yTqzRCCcXmpOCX9uBTPCS/67tzA5WnUhBA+QCfgMLLuKlXU1XoKuAnsUBRF1pt+PgVeBgpLPSbrrXIK8LsQ4nhRxkdoIvXWqNYzria9UnFKUk0JISyB9cBziqKkN+iCBk2EoihaoKMQwhbYKITo0NBlauyEECOAm4qiHBdChDZ0eZqY3oqiXBdCOAM7hBDnG7pA+jKElrFeqTilcsULIdwAir7fbODyNEpCCA26QLxKUZQNRQ/LutOToiipwB50YxZkvVWsNzBKCHEF3W23gUKIlch6q5SiKNeLvt8ENqK7jdkk6s0QgrE+6Tql8v0KTC36eSrwSwOWpVESuibw90C4oiiflHpK1l0FhBBORS1ihBBmwD3AeWS9VUhRlFcVRfFUFMUH3fvZLkVRHkHWW4WEEBZCCKvin4HBQBhNpN4MIumHEGIYunssxek632vgIjVKQogfgVB0q5jEA3OBn4G1QAvgGjBeUZQ7B3k1a0KIPsB+4Az/3MN7Dd19Y1l35RBCBKEbMKNG98F/raIobwshHJD1ppeibuoXFUUZIeutYkIIP3StYdDdgl2tKMp7TaXeDCIYS5IkSVJTZgjd1JIkSZLUpMlgLEmSJEkNTAZjSZIkSWpgMhhLkiRJUgOTwViSJEmSGpgMxpIkSZLUwHEgjvIAAAAXSURBVGQwliRJkqQGJoOxJEmSJDWw/wemSLpxnMsaJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_9-6vl0.3235-va0.9024-ep33.hdf5\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3235 - accuracy: 0.9024\n",
      "loss= 0.3234768807888031\n",
      "accuracy= 0.9024389982223511\n"
     ]
    }
   ],
   "source": [
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'data/cvision/' + model_num + 'auged' + '.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#모델 불러와서 정확도 확인 및 예측\n",
    "file_path = './data/cvision/' + model_num\n",
    "files = os.listdir('./data/cvision/' + model_num)\n",
    "hdf5_file = files[0] #폴더 맨 앞의 val_loss 가장 작은 파일 불러옴\n",
    "print(hdf5_file)\n",
    "\n",
    "model.load_weights(file_path + '/' + hdf5_file)\n",
    "\n",
    "score = model.evaluate(valid_X, valid_y)\n",
    "print('loss=', score[0])        # val_loss\n",
    "print('accuracy=', score[1])    # val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-8nb5jokyny"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('data/cvision/my_subm_9-6_auged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_92 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 50)                57650     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 353,512\n",
      "Trainable params: 352,452\n",
      "Non-trainable params: 1,060\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model_9-7: \n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), Adam(0.001)\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1598347122783,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "tPFielyJ5yMH"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "lrs = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** x)\n",
    "\n",
    "#earlystopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "\n",
    "#modelcheckpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "model_num = 'model_9-7'\n",
    "MODEL_SAVE_FOLDER_PATH = './data/cvision/' + model_num + '/'\n",
    "\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "    \n",
    "model_path = MODEL_SAVE_FOLDER_PATH + model_num +'vl{val_loss:.4f}-va{val_accuracy:.4f}-ep{epoch:02d}.hdf5'\n",
    "\n",
    "cp = ModelCheckpoint(filepath=model_path, monitor='val_loss',\n",
    "                               verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537462,
     "status": "error",
     "timestamp": 1598347660504,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "012ce4a9-2ca8-41d3-d1de-9331032469e3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 1.8879 - accuracy: 0.3443 - val_loss: 2.4309 - val_accuracy: 0.1976\n",
      "Epoch 2/100\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 1.1899 - accuracy: 0.6035 - val_loss: 0.8678 - val_accuracy: 0.7122\n",
      "Epoch 3/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.8625 - accuracy: 0.7156 - val_loss: 0.5976 - val_accuracy: 0.8098\n",
      "Epoch 4/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.6809 - accuracy: 0.7747 - val_loss: 0.5806 - val_accuracy: 0.8195\n",
      "Epoch 5/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.5697 - accuracy: 0.8143 - val_loss: 0.5001 - val_accuracy: 0.8341\n",
      "Epoch 6/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.4876 - accuracy: 0.8400 - val_loss: 0.5116 - val_accuracy: 0.8439\n",
      "Epoch 7/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.4150 - accuracy: 0.8598 - val_loss: 0.4442 - val_accuracy: 0.8537\n",
      "Epoch 8/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.3691 - accuracy: 0.8770 - val_loss: 0.4714 - val_accuracy: 0.8537\n",
      "Epoch 9/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.3353 - accuracy: 0.8859 - val_loss: 0.7055 - val_accuracy: 0.7683\n",
      "Epoch 10/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.2941 - accuracy: 0.9007 - val_loss: 0.3848 - val_accuracy: 0.8829\n",
      "Epoch 11/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.2639 - accuracy: 0.9143 - val_loss: 0.3750 - val_accuracy: 0.8927\n",
      "Epoch 12/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.2392 - accuracy: 0.9199 - val_loss: 0.3656 - val_accuracy: 0.8854\n",
      "Epoch 13/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.2205 - accuracy: 0.9249 - val_loss: 0.4208 - val_accuracy: 0.8659\n",
      "Epoch 14/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.2020 - accuracy: 0.9311 - val_loss: 0.4281 - val_accuracy: 0.8683\n",
      "Epoch 15/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.1853 - accuracy: 0.9355 - val_loss: 0.3960 - val_accuracy: 0.8780\n",
      "Epoch 16/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.1706 - accuracy: 0.9424 - val_loss: 0.3236 - val_accuracy: 0.9073\n",
      "Epoch 17/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.1466 - accuracy: 0.9516 - val_loss: 0.3653 - val_accuracy: 0.9049\n",
      "Epoch 18/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.1438 - accuracy: 0.9514 - val_loss: 0.3869 - val_accuracy: 0.8854\n",
      "Epoch 19/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.1356 - accuracy: 0.9541 - val_loss: 0.4745 - val_accuracy: 0.8659\n",
      "Epoch 20/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.1326 - accuracy: 0.9549 - val_loss: 0.3665 - val_accuracy: 0.8976\n",
      "Epoch 21/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.1280 - accuracy: 0.9573 - val_loss: 0.3765 - val_accuracy: 0.9122\n",
      "Epoch 22/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.1112 - accuracy: 0.9635 - val_loss: 0.4406 - val_accuracy: 0.8780\n",
      "Epoch 23/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.1035 - accuracy: 0.9646 - val_loss: 0.4009 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.1081 - accuracy: 0.9639 - val_loss: 0.4476 - val_accuracy: 0.8878\n",
      "Epoch 25/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0986 - accuracy: 0.9668 - val_loss: 0.4552 - val_accuracy: 0.8805\n",
      "Epoch 26/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0830 - accuracy: 0.9724 - val_loss: 0.5662 - val_accuracy: 0.8683\n",
      "Epoch 27/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0971 - accuracy: 0.9696 - val_loss: 0.4474 - val_accuracy: 0.8829\n",
      "Epoch 28/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0800 - accuracy: 0.9744 - val_loss: 0.4356 - val_accuracy: 0.8976\n",
      "Epoch 29/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0731 - accuracy: 0.9774 - val_loss: 0.4343 - val_accuracy: 0.9024\n",
      "Epoch 30/100\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0716 - accuracy: 0.9764 - val_loss: 0.5828 - val_accuracy: 0.8561\n",
      "Epoch 31/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0764 - accuracy: 0.9749 - val_loss: 0.4712 - val_accuracy: 0.8756\n",
      "Epoch 32/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0668 - accuracy: 0.9793 - val_loss: 0.4625 - val_accuracy: 0.9122\n",
      "Epoch 33/100\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0588 - accuracy: 0.9801 - val_loss: 0.5301 - val_accuracy: 0.8756\n",
      "Epoch 34/100\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0639 - accuracy: 0.9796 - val_loss: 0.5161 - val_accuracy: 0.8780\n",
      "Epoch 35/100\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0585 - accuracy: 0.9798 - val_loss: 0.4829 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0556 - accuracy: 0.9829 - val_loss: 0.4622 - val_accuracy: 0.8902\n",
      "Epoch 00036: early stopping\n",
      "CNN: Epochs=100, Train accuracy=0.98291, Validation accuracy=0.91220\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_X, y=train_y,\n",
    "    epochs = epochs,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[es, cp, lrs]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1598336814187,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "30b0e4a2-9738-4989-eb06-1c54ecef6b41"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUZfq/7zMtmUkmk94DSehFIaGpSBEEpIhgwd5dZS2Luutadtey7tf1t6u7iro2RLEgIggoBOwoWClBegqEkEpIZjLpyZTz++OkQsqkTcq893XNNWfOec85zwkhn3mf9ymSLMsIBAKBQCDoOVQ9bYBAIBAIBJ6OEGOBQCAQCHoYIcYCgUAgEPQwQowFAoFAIOhhhBgLBAKBQNDDCDEWCAQCgaCHaVOMJUlaKUlSgSRJB1s4LkmStFySpHRJkvZLkpTY9WYKBAKBQNB/cWVm/A5wSSvH5wJDal93Aq923iyBQCAQCDyHNsVYluXvAXMrQy4D3pUVfgb8JUmK6CoDBQKBQCDo73TFmnEUkNXoc3btPoFAIBAIBC6g6YJrSM3sa7bGpiRJd6K4stHr9eNiYmK64PYKTqcTlart7xZF9iKq5WoitZHNHs8qdaLXSATrm3usnsfV5+zriOfsX4jn7F+I5+w4qamphbIsh5y5vyvEOBtorKrRQG5zA2VZfgN4A2D8+PHy7t27u+D2Ctu3b2f69OltjnvixyfYmb2Tr5d83ezxJa//hCzLfLz0gi6zrStx9Tn7OuI5+xfiOfsX4jk7jiRJmc3t7wrJ/xS4qTaq+jzAKstyXhdct1vQqrTUOGtaPD4g0ECWudKNFgkEAoHA02lzZixJ0ofAdCBYkqRs4AlACyDL8mtAEjAPSAcqgFu7y9iuQKfWUeNoWYxjAgzkl1RRZXPgrVW70TKBQCAQ9ApkGWrK8KoqULal7l+2bFOMZVm+to3jMnBPl1nUzehUulZnxjGBegByiisZFOLrLrMEAoGg/+F0QHkhVJeC0w5OGzhsyv76bXvDq+6zpAKVGiR10/fm9klSbZSSrAin7GzYbu69qgQqzVBhbvRuUV51+yot4KjhfICL5oKXsdt/VF2xZtyn0Kl12J12nLITlXS2l35AoAGALHOFEGOBQNA7cTqh2lorHsW1YnKGqNirQK2rfWlB46W8q3WgbrytA40ONN7KGI0etN5N3zVeoNUrY+tmiVUlUJoPpblQkqe8l+ZDSS6U5tUeywfZ0bM/q9ZQ60AfCIZA0AdA0CAwTKjfd/TkaYar3COTHinGADanDS+111nHYxqJsUAgELiEwwbWbPysKVAQBt7+oPdXBKw9OB21gpajvKx179mKwNXP3IppIWlFwcukCKmjdvbpqAFHdaceUUECrZ4pDgdsb+Z6XibwiwBjOAQPq92OAG9T7cxWq3wJUGmUV/22FtSahv2yU/lZyI7a99rPTnujfQ7lS4nsrP2CICkzaqnWzvp9Z7x7GWvFNxB0Pq26oPNt2xne3n/DDuJxYqxVaQGocdQ0K8Yhvl7oNCqyLCKISyAQ1CLLiru1OBMsJ8CSAZba7eJMRTRlB4kAyY3OU3spQqT3bxBob1PDtq2ykejWzijPnElqfcAUBX6R4D9AERF9gPIyNNrWByjHvE2KsDX3DE57rTDXgL2mYdtRo8ykbVVgr2zjvYrcrExiho9XbDLWCq5fhCJugg7hcWJcNzNuKYhLpZKICdCLmbFA0BtxOmvXGhuJidNWu8ZYO8NSqRtmWCpNw7piY2xVUFXn3i2u3a79XLddd9yarQivrbzpNXxCIWAgxEyCcwZCQCz7M05x7rC4hvOrrE23ywqgMFXZrrIqblK/SPCLgrgpyrspSnmv2/b275oAIkmqdU1rgc6J5rHt24m5cHrnbRLU43lirGpwU7dETKCBk0KMBYLup7oMzMegKB2Kjte+pyuuWIcN7NW1Mzdbg/B2BEnd4BJ12pVZYMuDwduvYfYaEAvx08FfEVwCBioz1GZmgeaS7TB6ums2OWvdq26I1BX0fjxPjNuYGYOS3rQ30+IukwSC/oksK6JXXYqh/CQc3dIgtnXCW5bf9By/aCWIJiC2NuCoUQCSWndGEFLtS6UB5EZRuo2ic5t8rj0uSYpLt95t7F/r4q3drlvf7G48oIKVwHU8Toy16oY145YYEGigpMqOtcKGyaB1l2kCgfuozaNscKNaoab87HQTh612XyNBqzteU66krDR5ldS+ShvSWYCJALtq7+0TAoGDYPDFivAGDYKgwRAQBzpDT/1EBIIexePEuM5N7UqucZalApPB5Ba7BIIWKS+CnN2Qs0dZc2wpSvTMd1CEsW59sv5VrKSldDblROOtRKbWv/wUV26TfcrrcEYeIy+cr4iw3r9z9xUI+iGeJ8YuuKmjAxrSm0ZHCTEWuBFbFeQfUMQ3e7fybjmhHJNUYAhStpstbkDTz6CIobdJefmGQvCQBlds45feH3S+jdJNagOh6rbV2mZSU1x35RZUbGdk1Lgu+zEJBP0NzxNjFwK4BgTVirFFBHEJuhGnE31FDvz2UYP45h9oCFIyRkL0OBh3K0SPh4ix4CUK0QgE/RHPE2MXZsZ+3lpMeq2IqBZ0DQ67kpd6+mjtK1V5L0xjkr02n13rA5EJcP7dEDVeEV+/5tt8CgSC/ofHibErAVygrBuL7k0Cl3E6lXScklwlVed0Sq3wpihRw41/30wxEDIMYqdw1CIx/KJrIXSEeyJ4BQJBr8TjxNiVAC5QIqqP5pe6wyRBb0aWlSCo+pq7+Y3q7jaqv1uad0YOrKSk54QMgyGzIGS4sh08tEnR+fzt2xkePtrtjyUQCHoXnifGLripQck1/upwAU6njEolkvL7PVVWKDoG5rrCE8dqi1EcU6KPz8TLT6m/a4yAgRc0bBvDITBeCZRyU01bgUDQ9/E8MXYhgAuUKlw1DicFpdWEm7zdYZqgO3E6obxAKW1YfFIRXfNxRWyL0qGisNFgCUzRiqiOvlyZ4RojG4re+4aJQCqBQNCleJwYu75m3BBRLcS4D1BdqgitNRusWUrh/cafS3LPLqVojFDyXofPU96DBinvgXFiVisQCNyKx4mx625q5Y/xyaIKJsQGdrtdgjZw2KEku7ZjTjOvyjPKl0rq2kL70RAzUXk3RSvBU35RiuCKDjMCgaCX4Hli7GIAV1SAHkkSucZuR5Yhfz8xJz+BzzY0iG1xVtOKUSqtUqw/IBYiE5XtOrE1RStrtyI6WSAQ9BE8T4xrZ8Y2R+trxl4aNeF+3iK9yR04HZD1KxzdDEc+heKTDAIwBCtiGzUeRl9Z2zGn9uUXKcS2lyPbbJT//DMlW5II2L+fCj8/DImJPW2WwI04SkrI+8tfUAcGEfaXx1DpdD1tUq/F48RYJanQSJo2Z8agRFSLvsbdhL0GTnwPRzYr3XzKC5QOPPEXwdSH+KHQj8mzF/W0ld1KTWYmvhs3cnr/AVRGI2qjLypfX1S+Z29Lej1SH2i1JzscVOzaTUlSEqVffIGjuFh5No2GzJtvIfwvfyHgmqt72kyBG6jJzibrrqXUZGaC3U7NsWNEv/wSan9Rm7w5PE6MQQniamvNGJQgrh+PFbY5TuAiNRVw7Gs48hmkbINqq1J5auhsGL4AhsxW+sgCtu3be9bWbkSWZYrXrOHUv/6NoaqKQllu+yS1GpWvL94jRhB4y834Tp2K1Eta8MlOJ5X7fqNk61ZKtm3FcboQyWDAOGMGfvPm4XPhZHZ89RVxmzaR/+STVB06RNjf/ipmSd2Eo6wce14u6sBANEFBPWJD5b59ZN19D7LDwYCVb2EvOE3eo49y4upriHnjdXQDB/aIXb0ZjxRjnVrnohjryU+uotruwEsjXKIdwlYJqdvg4HpI+wrslUrv2BGXwogFStN2D4pctp06Rd5f/kr5zp34TJ7MiQULmLLwUpwVFThLS3GUluEsL2vYLivDWVaKo6wMZ0kJpd98S/bS3+M1ZDCBt96GacF8pB4QNVmWqTp8mJKkJEq2bsWem4ek0+E7bRp+8+fhO20aKn3Dv6tsMBDzv/9x+qWXKHrtdapTU4lavhxtWGin7KjJysK66VO84uPwmTwZtal/N3Zx1tRgz8/HlpuHLT9P2c7Lx5aXiz0vH1t+Ps5SpViRymBgwKpV6M9xb1GZkm3byH34ETRhYcS89hpe8XEAaCMjyL77Hk5cfQ3Rr7yMYZx7G4fYCwspXrcelZ8RQ2IiXkOGIKl7z991zxRjla7NPGNQ3NSyDDmWSuJDRF6py9hr4Ng3igCnJCl9c33DIOEGRYQHTga1Z/3qybJMyeYt5D/9NLLNRvgTj+N/zTUc/+47JLUatdGI2mikre7ZYY8+SsnWrRSteIu8xx7j9AsvEHjTjfhffTVqo7GNs7uGqtRUcv/8MNVHj4JGg+/kyfgtW4bvzJmofVv+fyKp1YTefz/eI0eS+8ijZFx5BdEvLseQmNBuG2x5eRS++hrFn3wCdqVnMioV+jFj8J06BZ+pU/EeMaLXeA86iuxwULF7DyVJSZRt34791KmzxqgDA9GGh6MdMADDxIloIyPQhIRw+sXlZN15JwM/+KBeELvVVlmm6I03Of3f/6JPTCT6lZfRBATUHzckJhL70Rqy7lrKyVtuJeKZZzBduqDb7bJbLJhXvo35/feRKxtigFQ+PujHjEGfmIg+YSz6MWNR+/ZchoVn/UWsxdWZcUP3JiHGbeJ0wImdcHAdHP5UqVrl7Q+jr1BesRe2GXAlO53UZGRQmZyM73ffYc7NxXvIELyGDOnT60x2i4X8p/5O6bZt6MeOJfL/PdthN52k1WJauBC/Sy+lfOcPFK18i4Lnnqfw1dfwX7KEwJtvQhse3sVPoCDLMsXr1nHqH/+Hymgk/KmnMM6e1eQPriv4zZ6NV1wcWffeS+bNN7drHdlWUEDRG29S/NFHyEDAkiUE/e4ObHn5lO34nvLvd3D6xeWcfnE56uBgfC+8UBHnPjRrlmWZyn37KEnaSum2bdhPn0bS6/GdNg2voUPQhkegjYxAGx6OJjwclXfzdRD0557Lietv4OTttxO7+gO0ERHdZ7PNRt6TT2Jd/wl+8+cT8cz/ofLyOmucbuBAYtd8SPa995H70EPUZJ0k+Pe/75Z4CEdpKeZ3VmF+5x2cFRX4zZ9P8D13I2m1VO7dS0VyMpV7kyl85RUli0OlwmvYMAwJY9EnJKJPSKhtR+oePFKMtSqtywFcgAjiaglZhuxdygz40AYoO6X0xB0+XxHg+ItA07IL1VlZSeWBA1Qm76Ny714q9+3DYbUCYFCpOPXlV/VjNSEheNUKs9fQ2vdBg1D59O5c4dJvvyXvb4/jsFoJefBBgm6/rUtcY5Ik4TvlQnynXEjloUPKN/9338X83nuY5s8n8Lbb8B42tAueQMFRVkb+E09SsmULPhecT+S//oUmOLjD1/MaMoS4tWvJeeghl9aR7RYLRStWYPlgNbLNhv/liwleuhRtVBQA2ogIZYa9bBn2wkLKdu6k/PsdlH77LdaNG5VZ89ixijCfdx5eQ4b0qt8dWZapPnJEcfsnbcWWm1vr9p+K37xat7/B0K5r6mJjGfDmG2TedDMn7/gdA99/r91fnFzBUVJC9h+WUfHzzwTf/XuC77uvVXFV+/sTs/It8v/2NwqXv4Qt8yThT/+9y2IInOXlmD9YTdFbb+G0WjHOmkXwfffiPbTh/4MuOhrTwoWK/WVlVO77jcrkZCqT92LduAnL6g8BCDaZsH32KdrQzi2nuIJHirGrM+NQoxc6jUqIcR0OGxQchpy9kLsXjm0H60lQeylBWKOvVIKwdM3/0bCdKqAyeS+VyclU7E2m6siRehejbtAgfGddjKH2G+lPJzKYPHIk1WlpVKemKe9paVg++gi5qqr+mtroaLwGD8YwaRL+V17hNldtWzjKyjj17LNY163Ha9gwBqx4E+/hw7vlXvpRo4h6/jlCHngA87urKF63HuumTfhMmULQ7bdhmDSpUzOPqsOHyX7gAWxZ2YTcv4ygO+/sEvev2mQi5tVXOb38JYpef53qtDSiXnyxyTqyo6SEorffxrLqXZyVlZgWXkrw3Xe36lnQBAfjv2gR/osWIdvtVO4/0DBrfuFFTvMi0PC70/gLni4+3q2BZdXp6YoAb0lSoo41GnwuOJ/gP9yHcebMTv8+e48cSfT/XiHrjt+RdddSBr69sku/hNRHTJ88ScSz/8R/kWsZECqdjohnn0U7cKAiyDk5nY60dlZVYVmzhqI33sRhNuM7bRrBf7gP/ahRrZ6n9vXF98LJ+F44GVCWBqpTU6nYu5cT33yDJiSkwza1B88UY5XOpZmxSiURHaD3zMIfTqdSuzl3ryK+OXsgfz/Ya4VQHwAxk+Cix5SZcG0UdHPIskzW0qWUf/c9AJKXF/pzziHottuUtZqxY8/+xn4yU1kHCw/Hd8qUhms5HNhycurFuTo1jarUFMq2b6fwlVcUV+1NN3abq9YVyn/9lbxHH8OWl0fQ735H8H33uuUPvC46ivDHHiPk7ruxrFmD+b33OXnLrXiPHEng7bfhN2cOksb1//KyLGNZvZqCZ/8f6sBABr67CsP48V1qs6RWE/pA7Tryow3ryF5Dh2J5/z2KVr6Ns6QE4yWXEHLvPXgNHty+62s0GBITmsyaK5KTqUlPpzotneq0NMp27mxYd1ar0Q0c2OCFGTIEQ2JCl/5Brjl5kpKkrZQkJVGdmgqShGHSJAJvvw3jrPa7/dvCZ+JEol74L9n3/YHs+/5A9GuvdsnvY5OI6RUr8Jk0sV3nS5JEyN13o4sZQN5jj3HimmuJef21di/hyDU1FK9fT+Grr2EvKFC+zNx3H4aE9scigPI76T1iBN4jRrA/KsptKYWeKcZqXZtFP+pQco09oPCHw6YEXWX9oghvbrLSyQhAa4CIMTDhDohMgKhxSuENF39Jq/bvp/y77/G/9hr8Fy/Ge/jwDkcAS2o1ugED0A0YgHHmzPr9lYcOYX5rJeZVqxq5am9t4prqTmwFBVTuTaZs5w6s6z9BGxPDwPff71BwUmdR+/sTvHQpgbfeinXTJswr3yb3j3/i9H/+S+DNN+N/5RVtujyVYg1/pfTLL/GZNpXIZ5/tFhdnHX5zZqOLiyX73vvIvPlm1D4+OIqL8Z0xg5D77sV7xIguuY8mOBi/WbNg1qz6fXJNDTWZmVSnpVFV+yWv6ugRSr/4on7N0GvkCHynTMV36hT0Y8a060sNKAFnJVu3UZKURNXBgwDoExIIe+wxjJfM6XY3qHHGDCKefpq8xx4j988PE/X8c51aLvHas4fMd99DExpKzOuvdypAzHTpAiXS+p576yOt9QkJOMvLlayCstqsgrrt2owDR2kpztIyyr79FltuLvpx44j897/b/aWgt+CRYqxVa6m2V7s0NiZQz76sZlro9ReKT8KeVZD8nrLmq9JA6EgYdTlEJSqlJkOGdyr6uXjjRiQvL0IffLDb3Mj6UaOI+s/zhGQ/iHnVKorXrcO6cSM+U6cQdNvtGCZN7LJvuLLDQXV6uhIEsjeZyuRkbNnZAEg6HQHXXkPoH//Y42uSKi8vApYswf/KKyn79luK3lrJqWee4fQrrxBw7TUE3nBDs+u+lfv3k/PAg9hOnSL0z38m8Jab3RKV7D10KHEfryXvr3/DWVNNyD33oD/33G6/r6TT1c+CG/t3nJWVVKenU/7jT5Tt+J6iFSsoev11VH5++Ey+QBHnKRe2OGu2FxZS8vnnlCRtpXLPHuUZR40i9KGH8Jt7CdrIyG5/tsb4X74YR3ExBf/6F/kmE+FPPtHu/xNVR49StHIl/p9+hndCghIxHdj52v2GceOIXfMhWXctJfOGG10LnFKpUPn64jV4MOFPPYXPhZP7RGGclvBIMdapdJQ6S10aOyDQgLXSRkmVDT/vthJP+ghOB6R9AbvfVt4lSVnrHXcrxE/r0rxfZ00NJUlbMV58sVvWc3XRUYT/5TGC7/49xWvWYH7/A07ecgveo0YRdPttGGfPbvesxlFWTtX+3+qFt/K333CWlQGgDgnGkJBIwPXXY0hMUNJpelkxC0mlwjhzJsaZM6lITsa8ciVFr7+BeeXbmC67jMBbb8UrPg5ZljG/s4qC559HGxpK7PvvoR871q22qk0mol9a7tZ7toRKr0d/zjnozzmH4LvuxFFSQvmPP1L2/Q7Kd+ygdOs2oHbWPHWqUoiltBTLxx9TkpRExS+/gtOJ15DBhCz7A35z56KLje3RZwq67VYcFgtFb76JOjCA0GXL2jxHlmUqfvqJordWUv7DD0gGA+UXX8yw559rNmK6o+hiYxm45kMs738AsozKaETl64PaaETl46tUpTMaUfn6ovb1RTIY+rT4nolnirGLAVzQNKJ6VGTfSI1okZJc2Pse7H1X6YDkGw5TH4LEm8A/pltuWfbNtzitVkyLF3fL9VtCExBA8O9/T+Btt2HduAnz22+T8+Af0UZHE3jjDWhCQmqLajRyfZWW4ig/e9tRXKysoUsSXkOH4nfpAgwJCegTE9G6cU2pKzAkJGB46SWqMzIwv/0O1o0bKV63Dt8ZM5DtNsq/+x7jrIuJ+Mc/+kwqkLtQ+/nhd8kl+F1yiRL9fPQoZd/voOz77yl6cwVFr71OKJAPaAcOIOiuO/GbO9dtSyWuEvLgAziKLRS9+hqagAACb7qp2XGyzUbJts8pWrmS6iNHUIcEE/LAAwRcczU7kpO7VIjr0AQEEHLfvV1+3b6AR4pxsD6YX/N+RZblNv+Q1vc17qti7HTC8W+UWXDKVqXz0aAZMPdZGHoJqLt3tm/dsAFNWBg+55/XrfdpCZWXFwFXL8H/qisp++YbxVX7z2fPGKSq/7at8lW+fWtCQtDFxaEy+qIJDkE/diz6sWNaLWrRl/CKiyPi708R8of7MH/wAcWrP8RZUUHYX/9KwPXX9akvGD2BJEn1QT6NZ80p33zD6JtuxnvUyF77M5QkifAnnsBRbOXUM/9E7e9fn+YDSmpQ8bp1FK1ahT03D118PBH/eBq/hQtFCdNuxCPFOM4UR6mtlKKqIoL1redK1hX+SC8oc4dpXUdVCex5B3atgOJMpQPSBffBuJshMN4tJtTlewbddmuPl52TVCqMF1+M8eKLqT6eAU6H0sCgH7q72oMmOJjQZcsIvvNO5JoaMRvuIHWz5nJvb/SjW0+l6Q1IGg2Rz/2brLuWkvvoY6j8/NCPGoX5vfexrFmDs6QE/fhxhP/1b/hOn9bnK5n1BTxWjAEyrBltirGft5Yhob7szrS0Oq7XUJoPP78Ku1dCdYlSenLm40oZSk3Xu5Vaw/rZZnA4MLmYe+gu3FEasK+h0utB7zk1wgWK1yj65Zc5efPN5PxhGcgyst2OcdYsgm6/Df2YMT1tokfhkWIcb1JmhseLjzMhfEKb48fHBrJ5fy4Op4xa1UtnUIVpyDtfpPr7dVQUqKisiaeyQIW9KBv4e+2rDTQaIv/1/5TUj04iyzLWDRvwPvdcvAYN6vT1BAJB16P29SHmzTfI/dOf0A4cSNAtt4iOSj2ER4pxmCEMvUZPRkmGS+MnxgXw4a8nST1VyoiIlotbuBtHWTmVX62lcuu7VB7NpNKsw2lTckHVIRKGhAR0AwcArn2BKPnic07/578YZ8zotFu5+sgRqlNTCXv8b526jkAg6F40gYEMWLmyp83weDxSjCVJIs4Ux/Hi4y6NHz9QyaPbfcLcY2IsyzK2nFy8f/mV/O++o+Ln76k+kQsygIxXVBh+C6dhmHRBh6N8vUePJmfZMkqStna6m0rxxo1KU4N58zp1HYFAIPAEPFKMQVk33nNqj0tjowP0hPt5s+uEhRvPj+1ew2qRbTaqjhypr+NcmZyMvaAAE2DVgj6wGmOCN/oZC9Evuh91cOfLPxpnXYzX0KEU/u9/+M2b2+HZsWyzUbJ5C74zZvTpbksCgUDgLjxWjONN8Ww5voUKWwUGbeulASVJYnxsALtOmF1Kh+oIjuJipaVXXQejgwfrGyJoIyMxjIpHP6ocgy4Dr6HDkKbcD6MWd2lqkqRSEXzPPZ2eHZft2IHDbMa06LIus00gEAj6Mx4rxvUR1SUZjApqOxVhQmwgm/fnkVNcSXRA+1qZNYfscFCxZw+l27ZR/suv1Bw7phzQaPAeMYKAq5egT0hAP3QA2v2vwL73wS+KQ9EPMuqqx1yuC91eumJ2bN2wAXVQEL4XXtgNFgoEAkH/w2PFuC6iOsPquhgD7D5h6bAYy7JM1f79Ssu0rduwFxQg6fX4TJyIaeFCpYPROecoaSZOB+x5G9beCTXlMPl+mPoQp3/a3W1CDJ2fHdstFkq3f0fgddchaftJ+VCBQCDoZjxWjGOMMagltctBXMPCjRi9NOw6YWZRQpTL96krm1ffNDwnB0mnw2fqFEzz5uE7ffrZHXSy98CWByFvH8ROgfnPQ8iw9jxep+jM7LhkSxLYbJgud2/5S4FAIOjLeKwY69Q6oo3RnCg54dJ4tUoicWAAu0+4Vvyj+tix+p6lNRkZDU3D77u35abhFWb46kmldrRvGFzxFoy+oltnws3RmdmxdcMGvEaMwHuY+748CAQCQV/HY8UYaFd6E8CE2ACe+yIVa4UNk6GpC9ZuNisdfZKTKdv5A9VHjypNwydOJPCWWzDObqVpuNMJye8qQlxVAuffA9MfAa/u73LUEsZZF+M1ZEi7ZsfVaWlUHTpE2KOPuMFCgUAg6D94vBjvzNmJ3WlHo2r7RzG+bt04o5ALdWVK9HNt2lFNZiYAklaL97nnEvaXv2CcM7vtpuF5v8HmByBnj1K6ct5zEDay08/WWepnx/ff7/LsuHjjRtBo8FvQuRxlgUAg8DQ8WozjTfHYnXZyynIY6NdyCThnRQWV+w8Qu2cPT//0JcGfZ3G8shwAdUAA+sRE/K+6En1iIt6jRrneWuxoEnx8C3ibYPEbcO4St7ukW8M4e5bLs2PZbqfk08/wnToVTVCQG60UCASCvo9LYixJ0iXAi4AaWCHL8rNnHDcB7wMDaq/5nCzLb3exrV1OXXrT8eLjLYqxvaiI45ctwlFYCEBMYCS/DWuN4hQAACAASURBVBrHwusuwZCYgHbgwI7lHe/7EDbdA5Fj4bqPwaf3CViT2fHWbZgWzG9xbPmPP2I/fVrkFgsEAkEHaLMvliRJauAVYC4wErhWkqQz/aj3AIdlWR4DTAeelySp1ze+bJxr3BKWjz7CUVhI1H+eZ+jPP/HTX1/mH8MW4X3pQnSxsR0T4p9fhY1LIfZCuGlTrxTiOhrPjmWHo8Vx1o0bUZtM+E6f7j7jBAKBoJ/gSpPKiUC6LMvHZVmuAdYAZ05/ZMAoKcrkC5gBe5da2g346fwI1ge3GMTlrKnB8uGH+Eydgt+8eaj9/RkfG0iNw8mBHGv7byjL8O0zsO0RGL4Arv+4R4O0XKFudlxz/DglW7c1O8ZRUkLpV1/jN3++aD4uEAgEHcAVN3UUkNXoczYw6YwxLwOfArmAEbhalmXnmReSJOlO4E6AsLAwtm/f3gGTm6esrKxD1wtwBvBb1m/Nnuv98y+YTheSfc1Yjtcer6qRAfjom92Ux7dDeGQng9NXEJ2zhbzwmaSG3oa886d229vR5+wUOi2BkZGcfO45igx6OKPRuH7HDvxqakgfOICjXWRbjzxnDyCes38hnrN/4dbnlGW51RdwFco6cd3nG4GXzhhzJfBflF59g4EMwK+1644bN07uSr799tsOnff0T0/L568+X3Y6nU32O51O+djixXL6vPlnHZv5/Hb5lpW/uH4Te40sr7tDlp/wk+Vtj8nyGddrDx19zs5i3bpNPjxsuFz82eazjmVcfY2cPv/sn1Nn6KnndDfiOfsX4jn7F93xnMBuuRlNdMVNnQ3ENPocjTIDbsytwCe190qvFePhHf2C4E7iTHGU1pRSVFXUZH/lnj1UHz5C4I03nrUuPCE2kN2ZFpxOue0b2CphzfVwYC3MfBxm/6NXRUy7Sktrx9UZGVTu24f/okXd0kBDIBAIPAFXxHgXMESSpLjaoKxrUFzSjTkJzASQJCkMGAa4Xk2jB6kP4rI2DeIyr3oXlcmE6bKFZ50zITaA0io7qQWlrV+8ygrvXQ5pX8D8/8CUP/ZJIYaW146tmzaBSoXfpWf/nAQCgUDgGm2KsSzLduBe4HPgCLBWluVDkiQtlSRpae2wp4ELJEk6AHwNPCzLcmF3Gd2V1DWMaBzEVZOdQ+nXXxOwZInStOEM6ppG7GqtNGbZaXhnAWT/Cle+BRNu71rDe4AzZ8ey04l106f4TJ6MNqyN4iYCgUAgaBGX8oxlWU4Cks7Y91qj7Vxgdtea5h7CDGHoNfom6U2WDz4ASSLg+uuaPSc6QE+Ynxe7T5i58bxm8pOLT8J7i8GaA9eugSGzust8t3Jm3rEmKBB7Xh6hf/pjT5smEAgEfRqPrsAFIEkScaa4eje1o6yc4nXr8JszB214eIvnjI8NbL5pRNExWHUpVJfBTRthwHndab7baTw79h41CpXRiHHmzJ42SyAQCPo0rqwZ93viTHEctypuauvGjThLSwm8+aZWz5kwMICc4kpyiisbdtqq4KMblaCtW7f0OyGGM9aOP/sMv7lzUXl797RZAoFA0KcRYoyybpxfnk95dRnm995FP2YM+jFjWj1nQlxt04gT5oadXz4OBYdg8esQfk53mtyj1M2OAUyLFvWwNQKBQND3EWJMQ0T1ic/XY8s82easGGB4uB++Xhp21Ylx6ufw6+sw6fcwtE8un7uMpFIR/sTjBNx4I/qEsT1tjkAgEPR5PH7NGBoiqqtWr8MvPBzjrLYDrtQqicSBAcq6cWk+bPw9hJ0Ds57qbnN7BYbx4zGMH9/TZggEAkG/QMyMgQHGAcSeljDsSyfg+uuQtFqXzpswMIDUU1Zs6+6EmgolhUnjYvtEgUAgEAhqETNjQKvWcuU+PXatg4CrrnL5vPGxgdyuSkKb+R0seAFChnWjlQKBQCDor4iZMWA3m0ncV8aeRD/U/v4un5egOcFDmo9ICZwO427pNvsEAoFA0L8RYgwUf/QRGruTdWMqsDtd7PxYXYb3pt9Rog7gWc3dfbbMpUAgEAh6Ho8XY7mmBvPq1ZQnDiEzyElOWY5rJ259GMzH2Tb07/yQ46TK5mj7HIFAIBAImsHjxbjk889xnC5Ed90VQNMa1S1ycD3sex+m/onQc2ZS43ByMMfazZYKBAKBoL/i0WIsyzLmVe+ii49n4MWXATSpUd0slkz47H6IngDTHmbcwACgjaYRAoFAIBC0gkeLcWVyMlUHDxJ4042YvP0J1gef1UqxCQ47fPI7ZfuKFaDWEuTrxaAQn6aVuAQCgUAgaAceLcb1PYsXKr14G9eobpbv/wVZv8CC/0JAbP3uiXGB7M604HTK3WyxQCAQCPojHivGtpwcSr/8koAlV6EyGAClEleGNQNZbkZUM3+E7/8NY66Dc65scmj8wECslTbSCsrcYbpAIBAI+hkeK8bmD1YrPYuva+hZHGeKo7SmlKKqoqaDKy2w/nfKbHjev8661oRYpWnELuGqFggEAkEH8EgxdpaXU/zxx/jNmY02IqJ+f13DiCbrxrKsBGyV5SvrxF7Gs64XE6gn1Ogl1o0FAoFA0CE8UoyL63oW39S0O1Ndw4gm6U15++DwRpj2CESNa/Z6kiQxITZQRFQLBAKBoEN4pBiX//gTuthY9GObtv8LM4Sh1+ibpjclvw8ab5j4u1avOT42gJziSnKLK7vDZIFAIBD0YzxSjB1FRWgiws/aL0kScaa4Bje1rQoOfAwjLgV96zWrPW3d+FDhIZbvXd7TZggEAkG/wCPF2G4xowkIbPZYk/SmlC1QZYWx17d5zeHhRny9NEp/Yw/g49SPefPAm1irReUxgUAg6CweKcaOIjPqoKBmj8Wb4skvz6fCVqG4qE0xEDetzWtq1CoSBvh7zMw4zZIGQHZZdg9bIhAIBH0fjxNjZ00NzrIyNIEBzR6vj6jO/QWOfQtjrwOVaz+mCbGBpJwqxVpp6zJ7eyMOp4O04loxLhViLBAIBJ3F48TYYVHcyOoW3NR1EdUZB9cCsiLGLjI+NgBZhr0n+7erOqs0i0q7EqgmxFggEAg6j+eJsVlxI6tbmBkPMA5ALanJyN4JsVOalL1si4SYADQqqd/nG6daUuu3hZtaIBAIOo/HibG9SBFKTQtrxlq1lhjvIDIcFZBwQ7uurdepGR1lYldG/54Zp1hSUEtqhgYMFTNjgUAg6AI8TowdltqZcQtuaoBYm50MnReMWNju60+IDWBfdjHl1fYO29jbSbWkEusXyyDTICHGAoFA0AV4nhjXuqlbCuCiupQ4SzYntBrsGl27rz9nVDg1didJB/I6Y2avJtWcytCAoUQbo8krz8Pu7L9fPAQCgcAdeJwY280WUKtR+fk1P+DQBuKrKrEjk1OW0+7rjxsYQHywDx/v7p8zxpKaEnLLcxkaqIixQ3aQX57f02YJBAJBn8bjxNhhLkIdEIDUUrpS8gfEGZTmEU0aRriIJElcNT6GX0+YOX66/7VUrMsvHhYwjBhjDCCCuAQCgaCzeJwY280WNIEtrBcXpkHWz8SNvhqgoRJXO7kiMQq1SuLjPf1PpFLMKQCKm9o3GhDpTQKBQNBZPE6MHWYz6pbEeN8HIKnxS7iZYH1wh2bGAKF+3kwfGsL6PdnYHc5OWNv7SLWk4u/lT6ghlFBDKBqVRoixQCAQdBKPFONmg7ccdtj3IQyZDcYw4k3xHZ4ZA1w1PoaC0mq+TzvdCWt7H6mWVIYFDEOSJNQqNVG+UcJNLRAIBJ3E48TYbrE0n9Z07Bsoy4cEpSlEXfcmWZY7dJ8Zw0MJ8tGxdlf/ESqH00GaJY0hAUPq90X7RouZsUAgEHQSjxJjuaYGZ0kJ6qBmxHjf+2AIhiFzAEWMS2tKKaoq6tC9dBoVlydG8dWRUxSVVXfG7F7DydKTVDmqGBY4rH5ftDFazIwFAoGgk3iUGNstxQBnB3CVF8HRJDj3aqjNLa5vGNHBdWNQXNV2p8yG5PanSPVG6spgDg0YWr8v2jcaa7WVkpqSnjJLIBAI+jweJcYtVt868DE4bU3KX9Y3jOiEGA8NMzI2xp+1u7M67O7uTaSYlTKYg/wH1e+LNioR1Tml/eMLh0AgEPQEniXGLVXfSn4fIhMgbGT9rjBDGHqNvlNBXABLxseQeqqM37KtnbpObyDNkkacKQ4vtVf9vjoxFq5qgUAg6DgeJcZ1TSKapDbl/QanDsDY65uMlSSpPoirMywYE4G3VsXa3Vmduk5vIMWS0iR4CyDKNwpQ2ioKBAKBoGN4lBjXu6kbi3Hy+6D2gnOuPGt8Z9ObAPy8tcwbHcFn+3KprHF06lo9ibXaSl55HsMChjXZb9QZ8ffyFxHVAoFA0Ak8SoztZjOo1ahNJmWHrQr2r4URC0B/du5xnCmO/PJ8KmwVnbrvVeNjKK22s+1Q320eUV8GM3DYWcdEepNAIBB0Do8SY4fZgtrfv6EudUoSVBW32Le4LqL6RMmJTt13UlwgAwINfTrnOMXSUAbzTER6k0AgEHQOzxJjyxnVt/Z9AH7REDet2fF1EdWddVWrVBJLxkfz0/EiThZ1bpbdU6RaUgnwCiBEH3LWsWhjNHllopWiQCAQdBSPEmN7kRl1YJDywZqjVN0aex2o1M2OH2AcgFpSdzqIC+CKcdFIEqzb0zcDnVLNqQwNHIokSWcdi/aNxi7bOVVxqgcsEwgEgr6PR4mx0iSidmb824cgOxUxbgGtWkuMMaZLxDjCpGfqkBA+3pONw9m3co4dTgfpxenNuqihUXqTWDcWCASCDuGSGEuSdIkkSSmSJKVLkvRIC2OmS5K0T5KkQ5Ikfde1ZnYNdosFTUAgyLLioo6dAoFxrZ4Ta4rtEjEGJec4z1rFzvTCLrmeu8gszVTKYAacHbwFQowFAoGgs7QpxpIkqYFXgLnASOBaSZJGnjHGH/gfsFCW5VHAVd1ga6eQbTacVquS1nTyJzAfPyu3uDniTHFklmR2yXroxSND8Tdo+1zOcV0ZzOYiqQHCDeFoJI0I4hIIBIIO4srMeCKQLsvycVmWa4A1wGVnjLkO+ESW5ZMAsiwXdK2ZncdusQCgCQqE/R+BzggjF7Z5XrwpHpvTRk5Z58s9emnULBobxZeHTmEpr+n09dxFqjkVjaSpD2g7E7VKTaRvpJgZCwQCQQdxRYyjgMZTuezafY0ZCgRIkrRdkqQ9kiTd1FUGdhWOWjFWBwRCbjLETACdT5vn1aU3HTEf6RI7loyPocbhZNO+vlPLOdWSSqwpFp1a1+KYaKPINRYIBIKOonFhzNnhs3BmBJIGGAfMBPTAT5Ik/SzLcmqTC0nSncCdAGFhYWzfvr3dBrdEWVlZq9fTHT1KAHAg8wTnnTpCbuQcjrlw/ypnFQaVgT9/92fe/uVtLjBewGj9aNRS8xHYrjDQT8XK7UeJtWW2+9y2nrM72J+3n0Feg1q9r6pERUZFRpfZ1hPP2ROI5+xfiOfsX7jzOV0R42wgptHnaCC3mTGFsiyXA+WSJH0PjAGaiLEsy28AbwCMHz9enj59egfNPpvt27fT2vWs5eXkAuMnDEf9aQ0xCbOIGefa/ceWj2V92no+SfuEFadXEKIPYdHgRVwx9Ir62szt4Q6vE/xt0yGChyQwOsrUrnPbes6uxlptxbLGwpQRU5g+uuX7ZhzMYOeenYy7YBxGnbHT93X3c/YU4jn7F+I5+xfufE5X3NS7gCGSJMVJkqQDrgE+PWPMJmCKJEkaSZIMwCSga/y6XYTDXOumdtRGMocMd/nccJ9w7hl7D59f8TnLL1rOiKARrDiwgrnr57L0q6V8nfk1NqfN5estHBOFTtM3mkfUB2+1EEldR30rxS5YWxcIBAJPo00xlmXZDtwLfI4isGtlWT4kSdJSSZKW1o45AmwD9gO/AitkWT7YfWa3H7u5CFQq1FUnlR0hzefMtoZGpeGiARfxysxX+PyKz7lrzF2kWdK4f/v9zFk3h+V7l7skRiaDlktGhbMxOYcqW+9uHlEnxi3lGNcR7SvSmwSCvsrBwoOU28p72gyPxqU8Y1mWk2RZHirL8iBZlv+vdt9rsiy/1mjMv2VZHinL8mhZll/oLoM7Sn1d6qI08A1vtjFEe4jwjaifLb804yVGBo3krYNvMXf9XB7c/mCbqVBLxsdQUmXni8O9u2pVijmFQO9AgvXBrY4TucYCQd/EXGXmhqQbeGFPr/uz7VF4TAWu+upbBUcgpHWXa3vQqDRMj5nOyzNfZtvl27hx5I18mfklnx4705PflAsGBRHlr+fjXu6qTrWkMjSg+TKYjTHqjJi8TCLXWCDoY/yQ8wMO2cGWjC1U2at62hyPxWPE2G4xK9W3Tqe0a724PUT4RvCn8X/i3OBz+d++/1HtqG5xrEolceW4aHamF5Jt6Z3NI+xOe6tlMM9EtFIUCPoeO3J2oJbUlNaU8s3Jb3raHI/FY8TYUWRG7acHW3mXzozPRJIk7h93P6cqTrHm6JpWx145TnHtrt3dOwXsZOlJqh3VLVbeOpNoYzRZpb17pi8QCBpwOB38mPsj8+LmEekTyYb0DT1tksfiOWJsNqPxqk2P7qaZcR0TwidwQeQFrDiwgtKa0hbHxQQamDk8lHd+yMBa6Xo0trtINbsWSV1HtG80uWW5OJy9OyhNIOgODpw+wCunXqHC1js9Xc1xoPAA1morU6OnsmjwIn7J+4XcsjMzVwXuwCPEWLbbcVitqDW16yGhI7r9nn9I/APF1cWsOrSq1XEPzBpKSZWdFTs61zO5O0ixpKCRNPVVyNoi2ihaKQo8l5UHV3K06ihfnfyqp01xmZ05O1FJKs6PPJ/LBitVjjcd29TDVnkmHiHGjuJiANSSFXxCwBDY7fccFTSKObFzePfwuxRWttylaVSkifnnRvDWzgwKy1peY+4JUi2pxPnHtVoGszEiolrgqZirzGzP2g7A5mObe9aYdrAjZwdjQsZg8jIR6RvJxIiJbErfhFN29rRpHodHiLG9yAyAxlHY7S7qxtw79l5qHDWsOLCi1XEPXDyUKpuDV7cfc5NlrpFiTnE5eAsa5RqLiGqBh7H52Gbssp2xhrH8kv8LBRW9rlfOWRRWFnK46DBToqbU71s8eDE5ZTnsyt/Vg5Z5Jh4hxg6LIsZqW063Bm+dSawplkWDF/FRyketFgMZHOrL5YnRvPdzJnnWSrfZ1xrWaiunKk65vF4MSqUytaQWM2OBRyHLMhvSN3Bu8Lks8F+AU3ayNWNrT5vVJj/k/ADAhVEX1u+bOWAmRq1RBHL1AJ4hxubambGq1K0zY4ClY5ailtT8b9//Wh23bOYQZFnmpW/S3WRZ67haBrMxGpWGCJ8IIcYCj+Jg4UHSi9NZNGQRYdowRgeNZsvxLT1tVpvsyNlBiD6E4YENfxO9Nd7Mi5/HV5lfUVJT0oPWeR4eIcb2urrUXk63zoxBmS1eN/w6Pjv2GWmWtBbHxQQauGbCANbuyuJkUc9HY6aYUwAYGti+sqExxhjhphZ4FBvSN+Ct9mZu7FwAFgxawBHzEdItveOLdXPYnXZ+zP2RyVGTzyros3jwYqod1WzL2NZD1nkmHiHGDrMZJFDrnG6fGQPcfs7t+Gp9WZ68vNVx984YjFol8cJXqa2OcwcpFtfKYJ6J6Gss8CQq7ZVszdjK7NjZ+Op8AZgTOwe1pGZLRu+dHe8/vZ/SmtIm68V1jAwayZCAIWxIE65qd+IRYmw3F6E2aJF8ApRoajdj8jJxy+hb2J61nX0F+1ocF+bnzc0XxLJhXw5pp1rOT3YHqZbUdrmo64g2RmOptlBWU9YNVgkEvYuvMr+izFbGosGL6vcF64M5L/I8thzf0mujknfm7EQtqTkv8ryzjkmSxOLBizlYdLB+uUrQ/XiEGDvMFtTeQMgIaKPGcndxw4gbCPIO4oW9LyDLcovjlk4bhI9Ow3++7Ln/BHannXSL62UwG1MXUS1aKQo8gQ3pGxhgHMD4sPFN9i+IX0BeeR57T+3tIctaZ0fODsaGjsVP59fs8fnx89GoNGxM3+hmyzwXDxFjMxpNldvXixtj0Bq4a8xd7Dm1hx9yf2hxXKCPjtsvjGPrwXwO5ljdaGEDJ0tOUuOscbkMZmNErrHAU8gqyWJX/i4WDV501rrrjJgZ6DV6Nh/vfTnHBRUFHDUfbdZFXUegdyAXxVzE5mObsTncVx1wX8E+Jn4wkVu33crqI6v7RIpYV+ERYmwvOo1aW9Mj68WNuXLIlUT5RvHi3hdbdV/dMSUOf4OW575IcaN1DaRYaoO3OjIzNopcY4FnsCF9AypJxcJBC886ZtAamDlgJl9kfkGNo6YHrGuZ5lKammPR4EVYqi18n/29O8yixlHDEz8+gY/WB0uVhX/++k8u/vhibtp6E+8dfo/88ny32NFTeIQYO4oKUXu7P5L6TLRqLfeMvYej5qN8ceKLFscZvbUsnTaI7Smn2XXC7EYLFVLMKWhUGuJN8e0+10/nh5/OTzSMEPRrHE4Hm45tYnLkZMJ8wpodsyB+AaU1pezI3uFm61pnR84OQg2hbX7ZviDyAkL0IW7LOV55cCXHrcd56oKn2LhoIxsv28jdY++m3FbOv3b9i1nrZnF90vWsOrSqXy6D9Xsxlh0OHKXlaLx6JpL6TObFzWNIwBBeSn4Jm7Nl98/N58cSYvTi35+ntLrG3B2kWlKJN8WjVWs7dH60MVrMjAX9mh9zf6SgooDFQxa3OGZSxCSCvIN6lava5rTxU+5PTIma0maPco1Kw8JBC9mRs6Pb3cUZ1gze2P8Gc2LnMDV6KgCD/AexdMxS1i9cz2eLPmNZ4jJsDhvP7X6OS9ZfwjWbr+GtA2+RV5bXrba5i34vxo7iYpBB7aMDY3hPm4NapWZZwjJOlp5sNXVAr1Nz70WD+TXDzI60lmtbdwcplpQORVLXEe0bTU5p//vmKhDUsSF9AwFeAUyPnt7iGI1Kw9y4uXyX/R3W6p6J/ziTfQX7KLOVtbpe3JhFgxfhlJ18duyzbrNJlmWe/vlpvNXePDLxkWbHxJpiueOcO1h76VqSLk/iwXEPopJUvLD3BS7bdBlJx5O6zT530f/FuK76VmhEj0VSn8nU6KkkhCbw2m+vUWlvufzlNRNjiPTX8Y+vN/Ny8stcn3Q9D2c9zMHCg91mW3FVMQUVBR1aL64j2hhNTlmOaKUo6JdYqix8m/UtCwYtaNN7tGDQAmxOG19mfukm61pnZ85ONJKGSRGTXBofa4olMTSRjekbu81DtzF9I7vyd/Hg+AddqmsQY4zh1tG3snr+apIuT2JE4Age3vEw//zln24NNutq+r0Y11ffioztWUMaIUkSyxKXcbryNKuPrG5yTJZljhcf54MjH/DH75ZRHfUX8gz/4Y39byozfNQ8+eOTrbq4O0NdXmF7K281JtoYjc1p43Tl6a4ySyDoNWw+vhm7087iwS27qOsYGTiSOFNcr3FV78jZQWJYYn2BEldYNHgRJ0pOsO90yzUSOkpRZRHP7X6OxNBELh9yebvPjzHGsGLOCm4aeROrj67m1s9v5VR532zh2u/F2JF7AgB1TM8Gb53JuLBxTImawlsH3+KE9QRbjm/hrzv/ysXrLuayTZfx7K/Pctx6nIWDFuBnvZ0wy//j3bnvc3XQ1aRYUnjv8HvdYldnIqnrqMs1FkFcgv5GXVOIc4LPYUjAkDbHS5LE/Lj57Dm1h9yyXDdY2DL55fmkWdLajKI+kzmxc9Br9N1Skevfu/9Nhb2CJ85/ApXUMTnSqrQ8NOEhnpv2HGmWNJZsXsKveb92saXdT78XY3uWIi6a2NE9bMnZLEtcRmlNKZduvJRHdjzC9uztjA0ZyxPnP8HWy7eSdHkST1zwOA9PW0JavoPN+3MZYxjDjJgZvLrvVbJKul7sUswpBHkHtbsMZmNErrGgv3K46DBplrQmFbfaYl78PACSMnp2XXNnzk4Al9eL6zBoDVwSewnbTmyjwtZ1dfN/yPmBLce3cMc5dxDv3/7MjTOZEzuHD+d/iL+XP7/78nesPLjS7cGvnaHfi7EjLwMAdfy4HrbkbIYFDuPx8x9nWeIy1sxfw3dLvuP56c9z5dAr6wUNYME5EQwPN/LfL1OxO2UenfQoapWap39+ust/2VItqR0q9tGYulaKYmYs6G98kvaJ0hQibq7L58QYY0gITeCzY5/1qDjszNlJuE84g/wHtfvcxUMWU2mv5PMTn3eJLZX2Sp7++Wli/ZTArK4i3j+e1fNXc/GAi/nvnv/ywPYHKK3p2dLCrtL/xbggD7XOiRQ4oKdNaZarhl7FHefcwajgUahV6mbHqFQSf5o9jBNFFfyQYyfcJ5xlicv4Ke+nLl2LsjvtHCs+1ikXNShuo3CfcJHeJOhXVNorScpIYtbAWRh1xnaduyB+AcetxzlqPtpN1rWOzeF6SlNzjA0ZS6xfbJeVx3ztt9fIKcvh8fMfx0vt1SXXrMNH68Nz057jzxP+zHdZ33Htlmtb7ZjXW+j3YmwvOo3aR9trIqk7yswRoYyN8WfTMRtVNgdLhi7h3JBz+feuf2OpsnTJPTJLMqlx1nRajKE2olqkNwn6EV+f/JoyW1mrucUtMXvgbDQqTY/1OU4uSKbCXtFuF3UdkiSxaPAi9hbs5YT1RKdsSTGnsOrQKi4fcjkTwid06lotIUkSN468kbfmvEW5rZzrk67vNUF0LdHvxdhRXIba5HrkYG9FkiT+PGcY5iqZlT9koFapeeL8JyitKeW53c91yT3qehh31k0NShCXmBkL+hMb0jYQ7RvNuLD2L3n5e/szJWoKSRlJPZLytyNnB1qV1uWUpua4dNClqCQVm45t6vA1HE4HT/30FCYvEw+Oe7DD13GVxLBE1i5Yy4jAETy641Ge+eWZXleetI7+LcYVZuwVdjSBgT1tSZdwweBgEkPVvPxNOvnWKoYGDOXW0bfy6bFP+Tnv505fv3K0GgAAIABJREFUP8WilMGM84vr9LVijDGYq8yU28o7fS2BoKfJKs3i1/xfWTxkcYejfhfEL+B05Wl+zXd/pO+O7B2MCxuHQWvo8DVCDaFcGHUhn6Z/ikPu2BeKNSlrOFB4gIcnPIzJy9RhW9pDiCGEFXNWcPPIm/nw6IfM+2QeHxz5gCp7lVvu7yr9W4wLU3FUq1CHRvS0JV3GtcN12J0y/9x6BIC7xtzFQL+B/P2nv3f6lyvVksog06AOl8FsjIioFvQnNqVvQkJqtimEq0yLmYav1tft7tLcslyOWY+1O6WpORYPXkxBZQFHq9q/9p1fns/yvcuZHDW5XQFwXYFWpeVPE/7EitkriPKN4tlfn+WS9ZfwzsF3ujRCvDP0azGWTx1WxDh8YE+b0mWEGFQsnRrPpn257DphxkvtxePnPU5WaRav/fZap66dau58JHUdontT32Jtylru+OKOVruJeSoOp4ON6Ru5IOoCwn06XlLXS+3F7NjZfJX5VauV97qa+pSm6I6tFzdmWvQ0ArwC+Lms/Z64Z355Bqfs5K+T/tqhILKuYFLEJFbNXcXbc95maMBQnt/zPLPXz+b1317v8ajrfi3GjsyDgIQmsvNu197E76cPJtLkzRObDuFwykyMmMiiwYt459A79eu+7cHmtPHm/jcpqCzoVE3qxtQV/hAz495Pha2C5cnL+SXvly5Z7uhv/Jz3M6cqTnH54PZXiDqT+XHzqbBXsD1re+cNc5EdOTuI8o3qkuUnrVrLgkEL+K3iN6789Eqe/PFJ1qas5XDR4VarAn6d+TXfZn3LPWPvaZK22VOMDx/PG7Pf4P157zM2ZCwv73uZOevm8FLySxRXFfeITf1bjE8qrhR1UP9YM65Dr1Pzl/kjOZxXwoe/ngTgj+P+iMnLxFM/PdWuAJH9p/dz9earWZ68nFkDZ3WoJF1zmLxMGHVGIcZ9gI9SPsJabUWv0bM+dX1Pm9Pr2JC+AX8vf6bHTO/0tcaHjyfMEOY2V3WNo4Zf8n7hwqgLu2w2eveYu5ljmkOQPogvM7/k6Z+f5urNV3PeB+dx3Zbr+L+f/49N6ZtIt6TjcDoorSnlmV+eYXjgcG4YeUOX2NBVjAkZw8szX2btgrWcF3keb+x/g9nrZ/Of3f+hsNK9DXo0br2bm7HnKgU/+ksAV2PmnRPOefGBPPdFCgvOjcDf4M+fJ/yZR3Y8wpqUNVw/4vpWzy+3lfNS8kusPrKaEEMIL170IjMGzOhSG0VEde+n0l7JO4fe4fyI8xkcMJgPj36IucpMoHf/+z/TEYqrivnm5DdcPexqdGpdp6+nklTMi5/Hu4fedcvPec+pPVTaKzuc0tQcvjpf5vvPZ/r06ciyTHZZNocKD3Gw8CCHig7x6bFPWZOyBgC9Rk+QdxCFVYW8OONFNKreKTkjgkbwn+n/Id2SzoqDK1h1eBWrj67mPMN5JFQnuCXYrP/OjKusOCxKxyZ1PxRjSZJ4cuEoSiptPP+F0txhXtw8JkdOZvne5eSX57d47vfZ37No0yJWH1nN1cOuZtNlm7pciKG2r7GYGfdqPkn7BHOVmf/f3p2HRVm1Dxz/nplh3xfZUVBQVBBxwTXTLLe0ck0rU9PM0hZ7s362mu37pq+pmWbZq5ZZblmZmmXugCvuCwIqKLusM3N+fwySKSrLwMB4Ptc1F/DMs9yHR7nnnOcsj0Q/wpDwIeiNelYcXWHpsOqM1SdWU2IsqdLY4mvp37g/Bmlg7Ym1ZjvntfyZ8ie2GtsaHc8b7BJMn9A+PNP+Geb3mc/fI/7mp7t/4o2ub3BP2D14OXgxqfUkIr3r3pTEVwrzCOPtW95mxT0r6Bfaj7iLcWhF+ZMxmVvd/JhiDumH0ReaPmtoPTwsHEzNiPBzZWTHRny99RQjYhvSIsCVFzu+yMCfBvLG1jf49LZP/9U0db7gPO9sf4e1J9fSxK0JC/supLVP6xqLL8gliI2nN2KUxioPB1FqTrGhmC/3fUlb37ZlY2djfGJYdmQZo1qOslgnG0uSUnK+4DxHMo9wOPMwiw8tpqVXS7NMhHNJU4+mNPVoyuoTq7mv+X1mO295/kr5i3Z+7ao1pKmytBotjd0b09i9cbV6n1tSI9dGTO8ynS5FXSq1wlV1WHEyPoihyJQAdFaajAGevqMZK3anMm3lfpaM70iQSxATW0/kg10fsC5pHXc0ugMpJT8e/ZH3d75Pgb6Aia0nMjZyrFmGMF1PkLNpKcW0/LRq9UJVasaPR38kLT+N17u8XrZtcPhgXtz8IjvP7ayx2lRdUaAv4FjWsbLEezjzMEcyj5BZ9M+Mdj6OPkyKmWT2a/dv3J8Pd31IUk4SDV1rZqre5NxkTmSfYFjTYTVy/puBnca8U3Vej3Un42JbNK6uCJuaTTqW5OZow5TeETy/fC8r95zhrugAHmjxAKtPrOatbW8R4BTAh7s+ZPvZ7bTxacMrnV+hsVv1V0ipiMvHGqtkXLeUGEuYt3cerRq0oqN/x7LtvUJ68c72d1h2ZJlVJuNd53axKHERRzKPcCrnFBLTwg0OOgfC3MO4reFthHuE09SjKeHu4bjbu9dIHH1D+/LRro/4fPfnPBL9CA1dGpq9JeLSkCZzjC9Wap4VJ+ND6KWrVXbeutK97YP5dvsp3lydyO3NfXC01TGt0zTuW3Mfw1cPx9nGmZc6vsSQpkNqtbk42DkYMI01bke7WruucmOrjq0i9WIqL3R84V9JwEHnQL/G/Vh+ZDlTY6fW2ixJtWFP+h4eXfcoTjZOtG7Qmn6h/UxJ1yOcIJegWv2/4efkx4AmA1hxbAUrj68k0DmQzgGd6RLQhVj/2EovRFGeP1P+JNglmEau1jPPgjWz6mRs0DtaZeetK2k1gmkDWjLk8y38d8MxnundjJbeLXm67dMczjzMk22exMfRp9bj8nP2QyM0ainFOkZv1PPF3i9o7tm83F62Q5oOYcmhJaw6vuqGvfJrwneHv0Nv1DO82XCz1RaPZx1n4u8T8bL34ut+X1drvW5zeaPrG0xoNYHNqZvZnGpa2/e7w9+hFVqiG0TTOaAznQM608KrxTVXdLuWIkMR289sZ1D4oJvy2X99ZJ3JuCgPspMwFLXA1srGGF9LuxBPBsYEMmfTcYa2C6KRlxOjWo6yaEw2Ghv8nfxVj+o65peTv5CUm8TH3T8u9w91hGcELb1a8v3h77kv4r5a/WMenxbPa1teQyJJykliSvsp1a6xnr14lkfWPYJWaJlzx5w6kYgvCXYNZrjrcIZHDKfEUMLu9N38nfo3m1M3MyNhBjMSZuBm50Yn/0508O+Ah70Hdlo7bDW22GpLXxpb7LR22GhtTO9pbdl1bheFhkLVRF2PWGcyPm8a6qO/qMfB4+ZIxgD/1zeCX/ef5bVViXwxqm40C6uxxnWLURqZu2cuYe5h9GjY45r7DW46mOlbprPn/B6iG0TXSmwF+gJe2vwS/k7+dAvqxjeJ35BbnMu0ztOqPD41qzCLR357hLziPOb3mU+wa7CZozYfG60N7fza0c6vHU+0eYKMwgy2pm5lc+pmtqRuYe3Jyg2FstPaWeVzf2tlnck4/SBSgiEvH62n9fakvpKvqz2P9wzn7Z8PsvFQGt2b1X7T9JWCXILYcHqDpcOokiJDESeyT6ATOsI8wiwdjlmsO7WOY9nHeLfbu9etcfYL7cd7O95j2eFltZaMZ8TP4FTOKb7o9QWxfrF4OXgxM2EmucW5vHvru5VehD6/JJ+Jv08kOTeZz+/4nAjPiBqKvGZ42nvSr3E/+jXuh5SS07mnuVhykWJjMcUG06vIUESxsZgSQ4np+9LtxcZiwtzDsNfZW7oYSgVZbTI26G3BYLwpOnBdbkyXEJbsOM30VQfo3MQbW51lx/cGuQSRUZhBfkl+rY51rIwSQwknc05yLOsYR7OOcjTrKMeyjpGUm1S2cMLYyLFMiplUZ2cQqggpJXP2zCHENYRejXpdd18nGyf6hvbl5xM/82z7Z2t8rGV8WjxfH/iae5vdW7bm7oToCbjYuvD29rd5bN1jfHrbpzjZOFXofCWGEp7e+DT7Luzjw+4f1vsaohCixoZAKXVD/f3Lcj3phzA4hAK5aG+iZmoAO52Wl/u3YMyCHSz4+wTjuzWxaDxlC0bkJZt14oTq+Dv1b3an7zYl38yjnMo5hV7qAdN0hQ1dGhLmHkbvkN6EuYex9cxW5u2bR3xaPO92exdfJ18Ll6Bq/kj+g0OZh3i9y+sV6hA0OHwwPxz5gTUn1jCsWc2NVS3UF5Y1T09uO/lf793f/H5cbV15afNLjPtlHLNun3XD4UZGaeTFzS+yOXUzr3Z+lZ4Ne9ZY7IpiLlaajA9isAsDDqC7STpwXa5HhA89I3z4ZN0R7mkdiI+r5Zqqgl1Khzfl1o1k/MORH3jl71cQCAKdAwnzMD07beLehHD3cELcQq5qDu0T2od2fu2YvmU6Q1cO5c1b3qx3HWOklMzePZtA50D6Ne5XoWOivKMI9whn2ZFlNZqMP4v/rKx5urya74AmA3CxdeE/G//D6LWjmX3H7Gt+IJJS8t6O91hzYg1PtnnSbAufKEpNs745CovzIfMUeq3peenNMLSpPC/1b0GJQfLqqgNIKS0Wx+UTf1jagQsHeGPrG3T078jW+7by8+Cf+ey2z3iyzZP0b9yfZp7Nrvlcsn/j/izuvxgvBy8eXfcon8Z9it6or+USVN2W1C3su7CPsVFjsdFUbBIcIQSDwwdz4MIBEi8k1khcCWkJfH3ga4Y1HVbWPF2e7sHd+fyOzzmbf5YHf36QpJykcvebt28e3yR+wwPNH2Bs5NgaiVlRakKFkrEQoo8Q4pAQ4qgQ4v+us197IYRBCDHEfCFW0oUjgMSAqSnrZmumviTE24knbw9n9Z4zvL32oMXicLV1xcXGxeI9qrOLsnl649N42HvwTrd3qvT8urFbY76981sGhw9m7t65jP1lLOcunquBaM1LSsnsPbPxdfTl7iZ3V+rY/o37Y6e1Y9kR8y+teHnz9NPtnr7h/u392jOv9zwK9AU8+PODV63dvezwMj6J+4Q7G9/JlPZT1PhapV65YTIWQmiBmUBfoAUwQgjR4hr7vQP8Yu4gKyXd9B9Urzc1zeo8amY6u/rgse5NGNmxEbP/OM6sjccsEoMQwuKrNxmlkRf+eoFz+ef4oPsH1Vq2zkHnwLTO03iz65skZiQybNUw/k7524zRmt/OczuJS4vjociHKr0MoJudG3c0uoPVx1eTX5Jv1rg+i/+Mkzknmd5leoU7ZrX0asmCvgvQaXSMWTuG+LR4wLR4/fSt0+ka2JXXurymFiZR6p2K/IuNBY5KKY9LKYuBxUB5H68fB5YBaWaMr/LSD4JGh6EQ07zUttVfg7S+EkLw6l0tubt1AO+sPci328pv2qtpQS6WHWs8b+88/kj+gyntpphtmM6AJgNY3H8xnvaeTFg3oU43W8/eMxsve68qPz8dHD6YvJI8fj31q9liqmjzdHkauzVmYd+FeDp4Mv7X8czdM5dnNz1LpHckH9z6QYWb4RWlLqlIMg4ELp/PMLl0WxkhRCAwEPjcfKFVUdpB8GyCISvbqldrqiiNRvD+0Ghui/DhhR/3snJ3aq3HEOQcREpuStkwodq0JXULMxJm0De0LyMiRpj13JearQeGD2Tu3rmM+3UcafmW/Sx6pYS0BLad2caYyDFVHnPa1rctIa4hLDtsnqbqyjZPlyfAOYCv+nxFiFsIn8Z/SrBLMP/t+d86O3xOUW5E3KhzjxBiKNBbSjmu9OeRQKyU8vHL9vkO+EBKuVUIsQBYJaX8vpxzjQfGA/j6+rZdvHix2QqSl5eHs7Mzsdse5aJTI1J+s0eUlJD57BSzXaMuuFTOyioySD7YWcixLCNPtbEjqkHtdaT/K/cvlmQs4bXA13DXVeyxQVXLeblMfSbvnnkXZ60zz/g9U6PLoW3L28bSjKXYClvG+4wn1C60QseZo5zXMyttFqeKTvFq4KvVKv/v2b/zY9aPPO//PP62/pU+/vJyLs9czvqc9UzymUQzh2ZVjgmgwFjAHzl/0NG5Y4X/bdWkmr6fdYUqZ9X16NFjl5Ty6ikSpZTXfQGdgF8u+3kqMPWKfU4AJ0tfeZiaqu+53nnbtm0rzWnDhg1SFhdIOc1dyt9fl8f6D5BJj0006zXqgg0bNlT52OyCYtn3400y4sWf5c6TF8wX1A1sTt4sIxdEyp1nd1b4mOqUU0opi/XF8r7V98nYb2Llsaxj1TpXRR3LPCZ7f99b9l3WVxbqCyt0THXLeT37zu+TkQsi5Zzdc6p9rgsFF2Trha3l29vertLxl8oZfy5eRi2IktP/nl7tmOqimryfdYkqZ9UBO2U5ObEizdQ7gHAhRKgQwhYYDqy4IqGHSilDpJQhwPfAY1LKHyv/maGaLhwFaQSfCPSZmehuoqkwK8LV3oaFY2Pxd7NnzPwdJJ7JqZXrWmJ40/s732dP+h6md5lea+s3N3ZvzMudXuZ07mkW7l9YK9e8njm75+Bi62KW5nlPe09uC76NlcdXUmQoqtI5zNE8rSjW6obJWEqpByZh6iWdCCyVUu4XQkwQQkyo6QArJd00hEd6NcWQmYnW08vCAdU93s52LBwbi5OdjpHztnPy/MUav6a/kz8aoTHNAJVxCIPRUKPX+/nEz3x78FseaP4AvUN61+i1rtQ5oDM9G/Zk7t65nL14tlavfcnxrOM8+8ezrD+9ngeaP2C2qSyHNB1CdlE2v5/6vUrHz4ifwcmck7za5dUK955WlJtFhfr/SynXSCmbSimbSCnfKN32uZTyqg5bUsrRspznxbUi/RAIDUZbXzAYVM34GoI8HPl6bAeMUvLAvG2czS6s0evZaG1o79ue3079xpCVQ+i6uCuP/PYIs3bPYuuZrWYdMnMs6xiv/P0KMT4xFqt9TWk/BaM08uHOD2v1uiezT/J/f/4f9/x0DxuTNzIuahxjo8w38UUH/w4EOgdWaczx8cLjLDywkKFNh9LRv6PZYlIUa2Fd02GmHwTPxuizTbW9m3X2rYoI83HmqzGxjJi7lZHztrH0kU54ONXcMLC5veaSkpdCfFo8CWkJxKfHMythFhKJVmhp5tmMGJ8YWvu0JqZBTJWucbHkIpM3TsZB58B73d6z2BCXQOdAHop8iFm7ZzG02dAaX6QgKSeJ2Xtms+r4Kuy0doyOHM3olqOrNZ66PBqhYXD4YD6N/5SknKQKL1xw9uJZFl1YhJ+TH/9p9x+zxqQo1sLKkvEhaBCBIeMCcPPOvlVRUUFuzH2wHaPmb2f0gh18O64DTnY180/i0uQfQS5BDGgyAICc4hz2pO8h7lwcCekJLDu8jEWJiwDw1HrS4Y8OtGrQilYNWhHhGXHdCSuklLzy9yucyjnF3DvmWnwxh4ciH+Knoz/x1va3WNp/aY2s9pScm8ycPXNYcWwFOo2Okc1HMiZyDF4ONfd45p6we5iZMJNlR5ZdtagDmO7D8ezjxKXFEX8unri0OFLyUhAIZveYrZqnFeUarCYZC2MJZByD5v3RZ2QA3JSLRFRWpyZezLyvDRO+2cX4r3cyb1R77G1uvKKPObjautI1sGvZogslxhIOZRwiPi2eX/f/Snx6PD+f/BkAG40Nzb2a08q7FdENomnVoBX+Tv5lUx4uSlzELyd/4ak2TxHrH1sr8V+Pvc6eKe2nMHnjZJYeWsp9ze8z27lT81KZs2cOPx39CY3QMCJiBA9FPkQDxwZmu8a1NHBsQLegbvx49EcmtZ4EwIGMA8Sfi2dX2i4S0hLIKsoCTJ2+2vq25f7m96NL1tEpoFONx6co9ZXVJGOHgjNg1JtqxgcyAdVMXVF3tPDl3cGt+M93uxkxdyuz7m+Ln1vtr/Rko7Eh0juSSO9IgtOC6d69O+cunmPv+b3sSd/D7vTdfH/4e75J/AYAbwdvWnm3orF7YxbsW0CP4B48FPlQrcd9LT0b9qSDfwdmJMygT2ifajcbp+WnMXv3bH44+gMCwdBmQxkbObbWWwGGNB3ChtMbGLF6BKdyTlFoMPU5aOTaiO7B3Wnj04Y2vm1o6NKw7MPSxrSNtRqjotQ3VpOMnS6WThLWoBmGTNNcwVo1A1eFDW4bhKOtlv98t5v+n/3Ff+9vQ2yo5T/M+Dr54uvky+2NbgdMtecjmUfYk77H9Dq/h/Wn19PQpSGvd329Ti0OIIRgauxUhqwYwqdxnzKt87Qqn+tY1jHG/TqOrKIsBocPZlzUOPyc/MwXbCV0CehCjE8MRYYihjQdQhvfNsT4xODt4G2ReBTFGlhNMnbMPw0I8G6K/sIqNM7OaG7ieamrom+UP2E+zoz/ehf3zd3KC3c2Z3TnkDqV4Gw0NrTwakELrxYMjxgOQFZhFjZamzr5PLKJexNGNB/BNwe+YWjTobT0blnpcxzOPMzDvz6MRmj4rv93hHmE1UCkFafVaFnY1/LjqBXFmljN0iZOF5PAIwRsHDBkZKgm6ioK93Xhp0ld6N6sAa+uPMB/lu6moLhmxwVXl7u9e51MxJc8Gv0onvaevLn9zUrPz30w4yBjfxmLTqNjfu/5Fk/EiqLUDKtJxo75ydAgAgB9ZgY6lYyrzNXehjkj2/H0HU1ZnpDC4Fl/czrDvMvn3UxcbF14qu1T7Enfw8pjKyt83P7z+xn7y1gcdA4s6L2AELeQmgtSURSLso5kbNDjmJ8CDUyTzhsyMlXNuJo0GsETPcP5clR7TmfmM2DGX2w6nG7psOqtu5rcRasGrfho10fkFufecP/d6bsZ9+s4XGxdmN9nPsGuwbUQpaIolmIdyTjzBBqpL6sZm5qpVectc+gR4cPKSV3xdbFn9Pzt/Hfj0UuLgyiVoBEapsZOJaMwg9m7Z19337hzcTzy2yN42HuwoM8CAp0Dr7u/oij1n3Uk4+xkDBpbaNAMKaVpkQg14YfZhHg78cNjnekb5c+7aw/x6Ddx5BXpLR1WvRPpHcnA8IEsSlzE8azj5e6z4+wOJqybQAOHBszvPd9iPaYVRald1pGMm/Tgz1sWg39rjDk5oNejVRN+mJWTnY4ZI2J4vl8Evx44yz0zN3MsPc/SYdU7T8Q8gYPOgbe3v31VC8OW1C08tu4xApwCmN9nvsVnEVMUpfZYRzIGEFrQaP6ZfUs9MzY7IQTjuzXhm7EdyLhYzD0zN7PrVKalw6pXvBy8mBgzkS1ntrA+aX3Z9r9S/mLS75No6NqQL/t8qcbsKspNxnqScSlDZunsW6qZusZ0DvPmp4ld8HKy5cF529h2/IKlQ6pX7m12L2HuYby38z2KjcVsPL2RJ9Y/QRP3JszrNc/sCzwoilL3WV0y1l8oXSRCdeCqUcGejix5pBN+bvaMmr+dP4+ontYVpdPoeL7D86TkpfDl+S+ZvGEyzTyaMbfXXNzt3S0dnqIoFmB1ydiQYaoZq2bqmufras+SRzoR4uXE2K928nviOUuHVG+092tP75De7C/YT0vvlszpNQc3OzdLh6UoioVYXzLOND0zVuOMa4e3sx2Lx3ckws+FR77exc97z1g6pHpjauxUBrgPYPYds3GxdbF0OIqiWJDVJWN9RgYaJyc0dnaWDuWm4e5oyzfjOhAd7M6k/8XzU0KKpUOqF7wcvOjl1qtOT+WpKErtsLpkrGbfsgxXexsWPhRL+xAPnlqSwNIdpy0dkqIoSr1Rp1ZtKikpITk5mcLCwkof6+bmRmJiIvp77oa7BpCYmFgDEVrepXLWBnt7e4KCgrCxsanQ/k52OuaPjuWRb3bx7LI9FOoNPNgppGaDVBRFsQJ1KhknJyfj4uJCSEjll+3Lzc3FxcWFoqNHETY22DZqVENRWtalctY0KSUXLlwgOTmZ0NDQCh/nYKtl7oNtmbgonpd/2k9RiZGHuzWuwUgVRVHqvzrVTF1YWIiXl1e11s+Vej3o6tRnjHpJCIGXl1eVWinsdFpmPdCGO6P8eWNNIp/9fqQGIlQURbEedS5rVSsRS4k0GBBarRkjunlV517YaDV8Mrw1djoNH/x2mEK9gWd6NavWORVFUaxVnUvG1WI0gpSIatSMnZ2dyctTcy6bg06r4f2h0djZaJi54RjpuUVMu6sljrbW9c9OURSluqzqr6LUl64kpJqp6wyNRvDmwCi8nOyYufEoO09m8vHw1rQKUjNNKYqiXFKnnhlXl9QbAMzSTC2lZMqUKURGRhIVFcWSJUsAOHPmDN26daN169ZERkby559/YjAYGD16dNm+H330UbWvb02EEDzTuxmLxnWgoMTAoP/+zcwNRzEY1brIiqIoUIdrxq+u3M+B1JwK728wGNACxsJCNA7ZoLn6c0aLAFdeGdCyQuf74YcfSEhIYPfu3Zw/f5727dvTrVs3vv32W3r37s0LL7yAwWAgPz+fhIQEUlJS2LdvHwBZWVkVjvtm0rmJN2uf7MbzP+7lvV8O8cfhdD4cFk2Qh6OlQ1MURbEo66oZX1of1gydhP766y9GjBiBVqvF19eXW2+9lR07dtC+fXvmz5/PtGnT2Lt3Ly4uLjRu3Jjjx4/z+OOPs3btWlxdXat9fWvl5mjDjBExfDA0mv0p2fT95E81Y5eiKDe9OlszrmgN9pLc3FzsCwrRp53DvkULRDk148q4cuH3S7p168amTZtYvXo1I0eOZMqUKTz44IPs3r2bX375hZkzZ7J06VK+/PLLal3fmgkhGNw2iPYhnjy1JJ4nFyew4WAa0++JxNW+YhOMKIqiWBOrqhlj0CM0mmonYjAl3SVLlmAwGEhPT2fTpk3ExsZy6tQpfHx8ePjhhxk7dixxcXGcP38eo9HI4MGDee2114iLizNDYaxfQy9Hlj7Sicm3N2XlnjP0/fhPtp/IsHRYiqIota7O1oyrQuoNoDVPkQYOHMiWLVuIjo5GCMG7776Ln58fX331Fe+99x42NjaztCVNAAAgAElEQVQ4OzuzcOFCUlJSGDNmDEajEYC33nrLLDHcDHRaDU/eHs4tTb15anECw+ds4bHuYbS2UZ27FEW5eVhXMjboEbrq9aS+NMZYCMF7773He++996/3R40axahRo646TtWGq6dNQw/WPHkLr67Yz4wNRwl10+DXLJvIQLXGr6Io1s+6mqn1+mpN+KFYlrOdjveGRvPf+9twvsDIgBl/8X/L9nA+r8jSoSmKotQoq8pcUm9A2DtYOgylmvpF+SPPOhJf5MuCv0+yes8ZnugZzqjOIdjqrOvzo6IoClhTzVhKszRTK3WDk43gxf4t+GVyN9qFePDGmkT6fLyJDQfTLB2aoiiK2VlVMkZKhJk6cCl1Q5MGzswfE8v80e1BwJgFOxg9fztH09T84YqiWA/rScYG01SYqJqxVeoR4cPaJ7vx4p3N2XUykz4fb+K1VQfILiixdGiKoijVZjXJWJQOK1IduKyXrU7DuFsas2FKd4a2C+bLzSfo8f5Gvt2WpOa5VhSlXrOaZHypZqyaqa2ft7Mdbw2KYuWkroQ1cOb55Xvp/fEmvt2WRGGJwdLhKYqiVJr1JOPSmnF9aabWX1ruUamyyEA3ljzSkZn3tcFOp+H55Xvp9NbvvP/LIc7lFFo6PEVRlAqzmmQsLtWMzdBMfc8999C2bVtatmzJnDlzAFi7di1t2rQhOjqanj17AqYJQsaMGUNUVBStWrVi2bJlADg7O5ed6/vvv2f06NEAjB49mqeffpoePXrw3HPPsX37djp37kxMTAydO3fm0KFDgGkFqmeeeabsvJ999hm///47AwcOLDvvb7/9xqBBg6pd1vpOCMGdrfxZ9XhXlozvSPsQT2ZuPErXd9YzeUkCe5OzLR2ioijKDdXdNt2f/w/O7q3w7vZFhWAwIHY4XXsnvyjo+/YNz/Xll1/i6elJQUEB7du35+677+bhhx9m06ZNhIaGkpFhmj/5tddew83Njb17TXFmZmbe8NyHDx9m3bp1aLVacnJy2LRpEzqdjnXr1vH888+zbNky5syZw4kTJ4iPj0en05GRkYGHhwcTJ07k/PnzuLi4MH/+fMaMGVOxX85NQAhBh8ZedGjsxakLF5m/+STf7TzN8vgUYkM8eahrKHe08EWrqf6KXoqiKOZWd5NxZUmJMMPSiQCffvopy5cvB+D06dPMmTOHbt26ERoaCoCnpycA69atY/HixWXHeXh43PDcQ4cORas1NaVnZ2czatQojhw5ghCCkpKSsvNOmDABXWkt/9L1Ro4cyeLFi3n00UfZsmULCxcuNEt5rU0jLyem3dWSp3s1ZemO08zffJIJ3+wi2NOB0Z1DGdYuCBe1OpSiKHVI3U3GFajBXq7o6FG0QmDXpEm1Lrtx40bWrVvHli1bcHR0pHv37kRHR5c1IV9OXuMDwOXbCgv//ezSyemfmvtLL71Ejx49WL58OSdPnqR79+7XPe+YMWO48847cXd3Z+jQoWXJWimfq70N425pzOjOIfx24Bzz/jrBa6sO8NFvhxnaLojRnUNo5HWdlhRFUZRaYjXPjDEawQzJKTs7Gw8PDxwdHTl48CBbt26lqKiIP/74gxMnTgCUNVP36tWLGTNmlB17qZna19eXxMREjEZjWQ37WtcKDAwEYMGCBWXbe/Xqxeeff17WyevS9QICAvDz8+P1118vew6t3JhOq6FvlD/fP9qZnyZ2oWdzH77ecoru729k3Fc72Hz0/DXXr1YURakNVpOMhcGA0Fa/J3WfPn3Q6/W0atWKl156iY4dO9KgQQPmzJnDoEGDiI6O5t577wXgxRdfJDMzk8jISKKjo9mwYQMAb7/9Nv379+e2227D39//mtd69tlnmTp1Kl26dMFg+GdIzrhx42jYsCGtWrUiOjqab7/9tuy9YcOGERwcTIsWLapd1ptRdLA7nwyPYfP/3cakHmHEJ2Vx/xfb6PPxn/xvexIFxWpolKIotU9UpEYghOgDfAJogS+klG9f8f79wHOlP+YBj0opd1/vnO3atZM7d+7817bExESaN29e8ehLSSkpPHAAnZcXNn5+lT6+Phk/fjwdOnRg7NixtXK9qt6T6tq4cWNZs31NKiwxsGJ3KvM3nyTxTA7ujjaMiG3IyI6NCHCv+UVHaquclqbKaV1UOatOCLFLStnuyu03bNcVQmiBmcAdQDKwQwixQkp54LLdTgC3SikzhRB9gTlAB/OEXgFGY+m81PVjjHFVtW3bFnt7ez777DNLh2I17G20DGsXzNC2QWw/kcH8zSeZ/ccx5mw6Tp9IP8Z0DqFtIw+zdQ5UFEUpT0UessYCR6WUxwGEEIuBu4GyZCyl/Puy/bcCQeYM8kZk2bzU1t2hadeuXeTm5mJnZ2fpUKzO5UOjTmfk8/XWUyzensTqPWeIDHRlRGxD7ooOUL2wFUWpETdsphZCDAH6SCnHlf48EuggpZx0jf2fASIu7X/Fe+OB8QC+vr5tLx8WBODm5kZYWFjlC1FUhPbsWQwNGiAdHSt9fH1iMBjKhkbVhqNHj5KdXfsTZ+Tl5f1r8hRLKNJLNqfqWZ9UQnKexFYLsX46bg3SEeauMUttuS6UszaocloXVc6q69GjR9WaqYHy/uKUm8GFED2AsUDX8t6XUs7B1IRNu3bt5JVt8YmJibi4uFQgpH8zaDQU6XQ4urqicaj553yWlJubW6XfUVXZ29sTExNTa9e7pK48k+oNvCole5KzWbzjNCsSUvgrpZAmDZwY3r4hg9oE4uVc9ZaKulLOmqbKaV1UOc2vIsk4GQi+7OcgIPXKnYQQrYAvgL5SygvmCa9itE5OGAIDrT4RK5YhhCA62J3oYHdevLM5q/eeYcmO07yxJpF3fznIHS18Gd6+IV3DvNGoGb4URamCiiTjHUC4ECIUSAGGA/ddvoMQoiHwAzBSSnnY7FEqSh3hZKdjWLtghrUL5si5XJbsOM2yuGTW7D1LoLsDw9oFM6hNIMGe1v24RFEU87phMpZS6oUQk4BfMA1t+lJKuV8IMaH0/c+BlwEv4L+lz9H05bWJK4o1Cfd14cX+LZjSpxm/HTjHkh2n+WjdYT5ad5iYhu4MaBVA/1b++LjaWzpURVHquAp1P5ZSrgHWXLHt88u+Hwdc1WHL2jk7O5OXl1fueydPnqR///7s27evlqNSapudTkv/VgH0bxVAcmY+K3efYeXuVKavOsBrqw/QMdSLAdEB9I30w8PJ1tLhKopSB1n3WCBFqWVBHo482r0Jj3ZvwtG0PFbuTmXl7lSeX76Xl3/axy3h3gyIDuCOFr5qmJSiKGXqbDJ+Z/s7HMw4WOH9KzLkJ8Izgudin7vm+8899xyNGjXiscceA2DatGkIIdi0aROZmZmUlJTw+uuvc/fdd1c4LjAtFvHoo4+yc+dOdDodH374IT169GD//v2MGTOG4uJijEYjy5YtIyAggGHDhpGcnIzBYOCll14qm35TqV/CfJyZfEdTnro9nANncspqzE8v3Y2tTsNtzXwIs9Fzi1GqpR0V5SZXZ5OxJQwfPpynnnqqLBkvXbqUtWvXMnnyZFxdXTl//jwdO3bkrrvuqtQY05kzZwKwd+9eDh48SK9evTh8+DCff/45Tz75JPfffz/FxcUYDAbWrFlDQEAAq1evBrDIGF/FvIQQtAxwo2WAG8/1aUZcUhYrd6eyeu8Z1uYWsf7cX7x4Z3M6h3lbOlRFUSykzibj69Vgy2OO8bcxMTGkpaWRmppKeno6Hh4e+Pv7M3nyZDZt2oRGoyElJYVz587hV4k5sP/66y8ef/xxACIiImjUqBGHDx+mU6dOvPHGGyQnJzNo0CDCw8OJiorimWee4bnnnqN///7ccsst1SqTUrcIIWjbyIO2jTx4qX8L3lvyOytPlXDfF9u4vbkvU/tF0KSB9U+moCjKv1nNqk3mMmTIEL7//nuWLFnC8OHDWbRoEenp6ezatYuEhAR8fX2vWqP4Rq41y9l9993HihUrcHBwoHfv3qxfv56mTZuya9cuoqKimDp1KtOnTzdHsZQ6SKsRdPTX8ft/buW5PhFsPX6B3h9tYtqK/WReLLZ0eIqi1CKVjK8wfPhwFi9ezPfff8+QIUPIzs7Gx8cHGxsbNmzYwKlTpyp9zm7durFo0SIADh8+TFJSEs2aNeP48eM0btyYJ554grvuuos9e/aQmpqKo6MjDzzwAM888wxxcXHmLqJSx9jbaHm0exM2TunOve2DWbjlJLe+t4G5m45TpFdLOirKzaDONlNbSsuWLcnNzSUwMBB/f3/uv/9+BgwYQLt27WjdujURERGVPudjjz3GhAkTiIqKQqfTsWDBAuzs7FiyZAnffPMNNjY2+Pn58fLLL7Njxw6mTJmCRqPBxsaGWbNm1UAplbrI29mONwZGMapzCG+uSeSNNYl8vfUUU/tG0CfST60cpShWTCXjcuzdu7fse29vb7Zs2VLuftcaYwwQEhJSNsbY3t6eBQsWXLXP1KlTmTp16r+29e7dm969e1chasVaNPV1YcGYWP44nM6bqxN5dFEc7UM8ePHOFkQHu1s6PEVRaoBKxopSR93atAFdmnjx3a5kPvj1EHfP3Ex0kBseTra4Odhc++Vo+uruYIuDrXWv8a0o1kIl42rau3cvI0eO/Nc2Ozs7tm3bZqGIFGui02oYEduQAdEBzNl0nPikTDIuFnM8/SLZBSXkFJZwvVVQA90daBngWjq0ypWWga74udqrJm9FqWNUMq6mqKgoEhISLB2GYuWc7XQ8fUfTq7YbjZLcIj05BSVkl76y8k1fMy4WcehcHvtTs/kt8VxZ0vZ0sqVlgCst/F1pUZqoQ72d1MQjimJBKhkrSj2m0Yiy5ung6+x3sUjPwbM57E/NYX9KDvvPZDN/80mKDUYAHG21hHo74elki7ujLe4ONrg72lz9vaMN7qXX02nVYAxFMReVjBXlJuBkp6NtI0/aNvIs21asN3I0zVRz3p+aw8kLF8nKLyE5s4Cs/GKyC0owXqcJ3MvJFj83e/xc7fFzs8ffzR5fV3v83RxM293scbZTf2IUpSLU/xRFuUnZ6jS0CDA1VQ8t532jUZJbqCczv5isghKy8ovJyjd9zcwvIS23iLPZBaRmFxKXlElmfslV53Cx0+HnZo+jLCTbPYXeLf2wt1GdyhTlSioZK4pSLo1GmHpmO1ZsdanCEgPncgo5k11Y9vVs6Wvn8Ys8uTgBd0cbBsYEMrx9Q5r5VW/6WkWxJioZV8P11jNWlJuNvY2WRl5ONPJyuuq99Rs2YBccxf+2J7FoaxLzN58kpqE7I9o3pH+0P4626k+RcnNT/wOsgF6vR6dTt1KpuzRC0CXMmy5h3mRcLOaHuGT+tz2JZ5ftYfqqAwyIDmBEbDBRgW5q2JVyU6qzf8HPvvkmRYkVX89YbzCQcYP1jO2aR+D3/PPXfN+c6xnn5eVx9913l3vcwoULef/99xFC0KpVK77++mvOnTvHhAkTOH78OACzZs0iICCA/v37l83k9f7773PhwgXeeustunfvTufOndm8eTN33XUXTZs25fXXX6e4uBgvLy8WLVqEr68veXl5PP744+zcuRMhBK+88gpZWVns27ePjz76CIC5c+eSmJjIhx9+eONftKJUk6eTLeNuaczYrqHsOpXJ/7afZnm8KTm38HdlRGwwfSL9aeBiZ+lQFaXW1NlkbAnmXM/Y3t6e5cuXX3XcgQMHeOONN9i8eTPe3t5kZGQA8MQTT3DrrbeyfPlyDAYDeXl5ZGZmXvcaWVlZ/PHHHwBkZmaydetWhBB88cUXvPvuu3zwwQe89tpruLm5lU3xmZmZia2tLa1ateLdd9/FxsaG+fPnM3v27Or++hSlUoQQtAvxpF2IJy8PaMGKhBT+t/00L/20n5d+2o+3sx3N/V1o7u9KhJ8LEX6uhPk4Y6ur/JCq3MISzmabnmMbpSQ6yB0PJ9saKJWiVE2dTcbXq8GWp66tZyyl5Pnnn7/quPXr1zNkyBC8vU0LyXt6moaarF+/noULFwKg1Wpxc3O7YTK+9957y75PTk7m3nvv5cyZMxQXFxMaGgrAunXrWLx4cdl+Hh4eANx2222sWrWK5s2bU1JSQlRUVCV/W4piPm4ONozsFMLITiHsS8lm6/ELHDyby8GzOSz4+yTFetN4aJ1GEObjbErOpUk6zMeZ3EJ9WbI9m11g+npZJ7K8Iv1V12zcwIk2DT1Mr0buhPu4qIlPFIups8nYUi6tZ3z27Nmr1jO2sbEhJCSkQusZX+s4KWWFn4npdDqMRmPZz1de18npn44yjz/+OE8//TR33XUXGzduZNq0aQDXvN64ceN48803iYiIYMyYMRWKR1FqQ2SgG5GBbmU/6w1GTpy/SOLZXA6eyeHg2Vy2ncjgx4TUco/XCPBxMY1zDvdx5pZwb/zd7PFzc8DfzZ4Sg5H4pCzikzJZfzCN73clA6ZZzloHu9OmoTsxjTxoE+xR4Z7kilJdKhlfYfjw4Tz88MOcP3+eP/74g6VLl1ZpPeNrrYPcs2dPBg4cyOTJk/Hy8iIjIwNPT0969uzJrFmzeOqppzAYDFy8eBFfX1/S0tK4cOECzs7OrFq1ih49elzzeoGBgQB89dVXZdt79erFjBkz+PjjjwFTM7WHhwcdOnTg9OnTxMXFsWfPnur8yhSlRum0GsJ9XQj3deGu6ICy7Vn5xRw8m8vx9Iu4O9qUTTzSwNnuhrODdW5iapmSUnLyQj5xpzKJS8okLimLGRuOlk12EubjTM8IHwa1CTLrUCyjUZKQnIWTrU4N8VIAlYyvYq71jK91XMuWLXnhhRe49dZb0Wq1xMTEsGDBAj755BPGjx/PvHnz0Gq1zJo1i06dOvHyyy/ToUMHQkNDr3vtadOmMXToUAIDA+nYsSMnTpwA4MUXX2TixIlERkai1Wp55ZVXGDRoEADDhg0jISGhrOlaUeoTd0dbOjb2omNjryqfQwhBqLcTod5ODG4bBEBekZ49p7OIS8pk+8lM5v11gtmbjtMywJWBMYHc3TqwSp3LDEbJzpMZ/LzvLD/vO8O5nCIAWge7c1+HhvRvpYZ43cyEvN6SLzWoXbt2cufOnf/alpiYSPPmzat0PnM8M64PzFnO/v37M3nyZHr27HnNfapzT6pj48aNdO/evdavW9tUOeu+C3lFrNydyg/xKexJzkarEXQL92ZQmyDuaOH7rxnFriynwSjZfiKDNXvPsHb/WdJzi7DTaejerAH9ovy5kFfMt9uTOJqWh4udjntiAhkR25AWAa4WKGnF1ef7WRk1UU4hxC4pZbsrt6uPYTehrKwsYmNjiY6Ovm4iVhQFvJztGN0llNFdQjmalssPcSksj0/h8f/F42Kno1+UP4PaBNI+xNQZU28wsq00Af+y/yzn84qxt9FwW4QPfSP9uS3CB6fL5uwe0yWEnacy+d+2JJbsPM3XW0+ZasuxakKUm4m6y9VUH9czdnd35/Dhw5YOQ1HqnTAfF57tE8EzvZqx9fgFfohPYdWeVJbsPE2guwPBDsX858/fuXCxGAcbLbc19+HOKH+6N2twzaQqhKB9iCftS4d4/RCXwrelE6K8tupAvaktK9WjknE1qfWMFeXmo9EIOod50znMm+l3t+TX/ef4IT6F+BPp9GjhS78oP25t6oODbeUWxXB3tOWhrqHl1pajg9xo08iDcB8Xwn2dCWvgrMZKWxGVjBVFUarB0db0rPeemMDSZ4wx1T5nebXlFbtTWbz9NAUlhrL9vJ1tCfNxJtzHpfSrM2G+zjRwtqv2tKJSSrLyS0jNLuBMViFnSsdvn8kuJCm1kH3GI7Rp5EHrYHfVlG4G6jeoKIpSh12qLT/UNRSjUZKaXcCRtDyOnsvjaFoeR9Jy+TEhhdzCfyY2cbXXEeThiL2NBnsbbelLg71Oi52NBjvdP9vsdFrsdBoy84tJzSrkbI4p+aZmF1BYYvxXLDqNwNfVHkOxkfd/NT3q0moEzf1daNvQgzaNPGjbyINAdwc1x3glqWSsKIpST2g0giAPR4I8HOnRzKdsu5SStNwiU3I+l8uRtDzOZhdSqDdQWGIkp7CEwhIjhSUGivSlX0uMFBv+SbaXJkvxd7enub8rt0X44O/uQICbPf7upglTvJ3t0GoEGzduJCa2C3GnM4k7lcmuU5l8tyuZr7aY5lPwdbWjbSPT7GZtG3nQIsAVO51ax/p6VDK+gloWUVGU+kYIU43V19WeLmHeFT7OYJQU640U6Q042+luOFnK5dwcbejRzKfsQ4HeYOTg2VzikkzJedepTNbsPQv8M41piwBXWviXvgJccXes2jPvYr2Rs9mFJGflozdIgjwcCHB3+Ncws/pGJeMKMBgMaG+wIpSiKEp9o9UIHGy1le5oVh6dVlM2lemDnUIAOJdTSNypTPalZnMgNYfNR8/zQ1xK2TEBbvb/JOgAV1r4uxHs6cDFYgMpmQWkZOWTklVY+n0BKZn5pGYVci63kPKmyPBxsSPIw4EgD0eCPR1KWxFMXwPc7et07Vwl42vYuHEjr776Kv7+/iQkJHDgwAFLh6QoilKv+Lra0zfKn75R/mXbzucVkXgmhwOpORwo/br+YFrZFKS2Ws2/ms8BbLQCfzcHAt0d6BruTaC76ftADwdstBpSsvI5nVFAcmY+yZkFJJzOYs3eM+iN/2RsIUzJ2svJDjcHG9wdbXBzKH2Vfu/uYPuv9/JLZKXWE6iOOpuM/1x6mPOnK95cXJHaq3ewM7cMa1rhc27fvp19+/aVrYCkKIqiVI+3sx23hDfglvAGZdsKSwwcOpvLgTM5HE/Pw9PJjkAPU8IN8nCggbMdmuuuqOV51Ra9wci53CKSM/I5nflPos68WEx2QQlH0vLILighO7/kquR/ufjOJbUyhKzOJuO6IDY2ViViRVGUGmZvoyU62J3oYHeznVOn1ZTVoDtcZz8pJYUlRlNiLighK9+UrLMKSojbexBXh9pZuavOJuPK1GChZuamvnyJQkVRFMX6CPHPc3M/N/t/veeTd6zW1riueNc5RVEURVFqhErGiqIoimJhdbaZ2lIujTHu3r37TbFEmKIoimJ5qmasKIqiKBamkrGiKIqiWJhKxoqiKIpiYXUuGcvy5jhTLELdC0VRlNpRp5Kxvb09Fy5cUEmgDpBScuHCBezt7W+8s6IoilItdao3dVBQEMnJyaSnp1f62MLCwpsicdRmOe3t7QkKCqqVaymKotzMKpSMhRB9gE8ALfCFlPLtK94Xpe/3A/KB0VLKuMoGY2NjU+XpJzdu3EhMTEyVjq1PbpZyKoqi3Exu2EwthNACM4G+QAtghBCixRW79QXCS1/jgVlmjlNRFEVRrFZFasaxwFEp5XEAIcRi4G7g8jUF7wYWStPD3q1CCHchhL+U8ozZIy5HUYGe/POSs8eza+4iNTg9qajEyfMvSM6dzKm5WGpnGtYbKsiQpCflWjqMf9TQ76UgU3I+ubLlrLmbVFP3vzBLciGl4quwVVol467M/7nKKMyWZJy5WCPnhrrz/7MoR5J5tuLlrI0lCGtCUa7EaJQ3WDHKPCqSjAOB05f9nAxXLYJR3j6BQK0k4/RTOZxYJzmxbldtXM7iTvy209Ih1Irjv+6wdAi14vgvN0c5j63dbukQasWxn7dZOoRacXTNzVHO7rcbsHOo+e5VFblCeR8JruzuXJF9EEKMx9SMDZAnhDhUgetXlDdw3oznq6tUOa2LKqd1UeW0Lt6TZpu9nI3K21iRZJwMBF/2cxCQWoV9kFLOAeZU4JqVJoTYKaVsVxPnrktUOa2LKqd1UeW0LrVZzoqMM94BhAshQoUQtsBwYMUV+6wAHhQmHYHs2nperCiKoij13Q1rxlJKvRBiEvALpqFNX0op9wshJpS+/zmwBtOwpqOYhjaNqbmQFUVRFMW6VOiptJRyDaaEe/m2zy/7XgITzRtapdVI83cdpMppXVQ5rYsqp3WptXIKNfWkoiiKolhWnZqbWlEURVFuRlaRjIUQfYQQh4QQR4UQ/2fpeGqKEOKkEGKvECJBCGE1g42FEF8KIdKEEPsu2+YphPhNCHGk9KuHJWM0h2uUc5oQIqX0niYIIfpZMkZzEEIECyE2CCEShRD7hRBPlm63qnt6nXJa1T0VQtgLIbYLIXaXlvPV0u3Wdj+vVc5auZ/1vpm6dLrOw8AdmIZY7QBGSCkPXPfAekgIcRJoJ6W0qvF9QohuQB6mWdwiS7e9C2RIKd8u/YDlIaV8zpJxVtc1yjkNyJNSvm/J2MxJCOEP+Esp44QQLsAu4B5gNFZ0T69TzmFY0T0tXXvASUqZJ4SwAf4CngQGYV3381rl7EMt3E9rqBmXTdcppSwGLk3XqdQTUspNQMYVm+8Gvir9/itMf+TqtWuU0+pIKc9cWihGSpkLJGKakc+q7ul1ymlVpMmluUxtSl8S67uf1ypnrbCGZHytqTitkQR+FULsKp3NzJr5XhqrXvrVx8Lx1KRJQog9pc3Y9bqp70pCiBAgBtiGFd/TK8oJVnZPhRBaIUQCkAb8JqW0yvt5jXJCLdxPa0jGFZqK00p0kVK2wbRK1sTSZk+lfpsFNAFaY5rL/QPLhmM+QghnYBnwlJSy5lY3sbByyml191RKaZBStsY0u2KsECLS0jHVhGuUs1bupzUk4wpNxWkNpJSppV/TgOWYmuit1bnSZ3KXns2lWTieGiGlPFf6B8AIzMVK7mnpM7dlwCIp5Q+lm63unpZXTmu9pwBSyixgI6bnqFZ3Py+5vJy1dT+tIRlXZLrOek8I4VTaSQQhhBPQC9h3/aPqtRXAqNLvRwE/WTCWGnPpj1mpgVjBPS3tCDMPSJRSfnjZW1Z1T69VTmu7p0KIBkII99LvHYDbgYNY3/0st5y1dT/rfW9qgNKu5h/zz3Sdb1g4JLMTQjTGVBsG08xp31pLOYUQ/wO6Y1oJ5tmiYDAAAACpSURBVBzwCvAjsBRoCCQBQ6WU9brz0zXK2R1T85cETgKP1Pd53YUQXYE/gb2AsXTz85iep1rNPb1OOUdgRfdUCNEKUwctLaYK3FIp5XQhhBfWdT+vVc6vqYX7aRXJWFEURVHqM2toplYURVGUek0lY0VRFEWxMJWMFUVRFMXCVDJWFEVRFAtTyVhRFEVRLEwlY0VRFEWxMJWMFUVRFMXCVDJWFEVRFAv7f7jH25loVT3rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EQCvPGZks9v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_9-7vl0.3236-va0.9073-ep16.hdf5\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.9073\n",
      "loss= 0.3236319124698639\n",
      "accuracy= 0.9073171019554138\n"
     ]
    }
   ],
   "source": [
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'data/cvision/' + model_num + 'auged' + '.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#모델 불러와서 정확도 확인 및 예측\n",
    "file_path = './data/cvision/' + model_num\n",
    "files = os.listdir('./data/cvision/' + model_num)\n",
    "hdf5_file = files[0] #폴더 맨 앞의 val_loss 가장 작은 파일 불러옴\n",
    "print(hdf5_file)\n",
    "\n",
    "model.load_weights(file_path + '/' + hdf5_file)\n",
    "\n",
    "score = model.evaluate(valid_X, valid_y)\n",
    "print('loss=', score[0])        # val_loss\n",
    "print('accuracy=', score[1])    # val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-53-f24fe59b5315>:6: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('data/cvision/my_subm_9-7_auged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_271 (Conv2D)          (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_213 (Bat (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_272 (Conv2D)          (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_214 (Bat (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_273 (Conv2D)          (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_215 (Bat (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_274 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_216 (Bat (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_275 (Conv2D)          (None, 28, 28, 48)        13872     \n",
      "_________________________________________________________________\n",
      "batch_normalization_217 (Bat (None, 28, 28, 48)        192       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 28, 28, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_276 (Conv2D)          (None, 28, 28, 48)        20784     \n",
      "_________________________________________________________________\n",
      "batch_normalization_218 (Bat (None, 28, 28, 48)        192       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 28, 28, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 14, 14, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 14, 14, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_277 (Conv2D)          (None, 14, 14, 64)        27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_219 (Bat (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_278 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_220 (Bat (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 50)                156850    \n",
      "_________________________________________________________________\n",
      "batch_normalization_221 (Bat (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 274,504\n",
      "Trainable params: 273,764\n",
      "Non-trainable params: 740\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model_9-8: \n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(48, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Conv2D(48, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), Adam(0.001)\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1598347122783,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "tPFielyJ5yMH"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "lrs = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** x)\n",
    "\n",
    "#earlystopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "\n",
    "#modelcheckpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "model_num = 'model_9-8'\n",
    "MODEL_SAVE_FOLDER_PATH = './data/cvision/' + model_num + '/'\n",
    "\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "    \n",
    "model_path = MODEL_SAVE_FOLDER_PATH + model_num +'vl{val_loss:.4f}-va{val_accuracy:.4f}-ep{epoch:02d}.hdf5'\n",
    "\n",
    "cp = ModelCheckpoint(filepath=model_path, monitor='val_loss',\n",
    "                               verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537462,
     "status": "error",
     "timestamp": 1598347660504,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "012ce4a9-2ca8-41d3-d1de-9331032469e3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "359/359 [==============================] - 6s 16ms/step - loss: 1.9664 - accuracy: 0.3157 - val_loss: 3.1764 - val_accuracy: 0.1171\n",
      "Epoch 2/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 1.4070 - accuracy: 0.5241 - val_loss: 1.3264 - val_accuracy: 0.5683\n",
      "Epoch 3/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 1.1061 - accuracy: 0.6313 - val_loss: 0.9735 - val_accuracy: 0.6829\n",
      "Epoch 4/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.9412 - accuracy: 0.6902 - val_loss: 0.7436 - val_accuracy: 0.7488\n",
      "Epoch 5/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.8196 - accuracy: 0.7231 - val_loss: 0.7072 - val_accuracy: 0.7561\n",
      "Epoch 6/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.7310 - accuracy: 0.7595 - val_loss: 0.5563 - val_accuracy: 0.8146\n",
      "Epoch 7/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.6858 - accuracy: 0.7711 - val_loss: 0.6297 - val_accuracy: 0.7927\n",
      "Epoch 8/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.6188 - accuracy: 0.7929 - val_loss: 0.5235 - val_accuracy: 0.8220\n",
      "Epoch 9/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.5610 - accuracy: 0.8109 - val_loss: 0.4306 - val_accuracy: 0.8634\n",
      "Epoch 10/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.5292 - accuracy: 0.8243 - val_loss: 0.5769 - val_accuracy: 0.8122\n",
      "Epoch 11/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.4820 - accuracy: 0.8390 - val_loss: 0.4757 - val_accuracy: 0.8439\n",
      "Epoch 12/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.4599 - accuracy: 0.8467 - val_loss: 0.3688 - val_accuracy: 0.8780\n",
      "Epoch 13/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.4381 - accuracy: 0.8521 - val_loss: 0.4391 - val_accuracy: 0.8659\n",
      "Epoch 14/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.4200 - accuracy: 0.8591 - val_loss: 0.4123 - val_accuracy: 0.8732\n",
      "Epoch 15/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.3804 - accuracy: 0.8704 - val_loss: 0.5170 - val_accuracy: 0.8463\n",
      "Epoch 16/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.3654 - accuracy: 0.8777 - val_loss: 0.4838 - val_accuracy: 0.8268\n",
      "Epoch 17/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.3400 - accuracy: 0.8862 - val_loss: 0.4062 - val_accuracy: 0.8610\n",
      "Epoch 18/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.3526 - accuracy: 0.8804 - val_loss: 0.3818 - val_accuracy: 0.8585\n",
      "Epoch 19/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.3134 - accuracy: 0.8941 - val_loss: 0.3674 - val_accuracy: 0.8683\n",
      "Epoch 20/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.3037 - accuracy: 0.8957 - val_loss: 0.3334 - val_accuracy: 0.8976\n",
      "Epoch 21/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.2902 - accuracy: 0.9022 - val_loss: 0.3957 - val_accuracy: 0.8829\n",
      "Epoch 22/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.2778 - accuracy: 0.9062 - val_loss: 0.3168 - val_accuracy: 0.8805\n",
      "Epoch 23/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.2804 - accuracy: 0.9031 - val_loss: 0.3693 - val_accuracy: 0.8659\n",
      "Epoch 24/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.2516 - accuracy: 0.9134 - val_loss: 0.3916 - val_accuracy: 0.8707\n",
      "Epoch 25/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.2578 - accuracy: 0.9120 - val_loss: 0.3579 - val_accuracy: 0.8805\n",
      "Epoch 26/100\n",
      "359/359 [==============================] - 6s 16ms/step - loss: 0.2484 - accuracy: 0.9135 - val_loss: 0.4005 - val_accuracy: 0.8805\n",
      "Epoch 27/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.2404 - accuracy: 0.9171 - val_loss: 0.4172 - val_accuracy: 0.8659\n",
      "Epoch 28/100\n",
      "359/359 [==============================] - 5s 15ms/step - loss: 0.2151 - accuracy: 0.9269 - val_loss: 0.5212 - val_accuracy: 0.8561\n",
      "Epoch 29/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.2240 - accuracy: 0.9235 - val_loss: 0.3467 - val_accuracy: 0.9122\n",
      "Epoch 30/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.2093 - accuracy: 0.9296 - val_loss: 0.3579 - val_accuracy: 0.8878\n",
      "Epoch 31/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.2035 - accuracy: 0.9318 - val_loss: 0.3799 - val_accuracy: 0.8756\n",
      "Epoch 32/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1986 - accuracy: 0.9273 - val_loss: 0.3642 - val_accuracy: 0.9024\n",
      "Epoch 33/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1852 - accuracy: 0.9355 - val_loss: 0.3537 - val_accuracy: 0.8976\n",
      "Epoch 34/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1914 - accuracy: 0.9337 - val_loss: 0.3744 - val_accuracy: 0.8683\n",
      "Epoch 35/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1835 - accuracy: 0.9388 - val_loss: 0.3146 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1732 - accuracy: 0.9428 - val_loss: 0.4641 - val_accuracy: 0.8610\n",
      "Epoch 37/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1774 - accuracy: 0.9407 - val_loss: 0.4094 - val_accuracy: 0.8854\n",
      "Epoch 38/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1734 - accuracy: 0.9407 - val_loss: 0.3992 - val_accuracy: 0.8927\n",
      "Epoch 39/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1679 - accuracy: 0.9415 - val_loss: 0.3764 - val_accuracy: 0.8756\n",
      "Epoch 40/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1653 - accuracy: 0.9459 - val_loss: 0.3806 - val_accuracy: 0.8927\n",
      "Epoch 41/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1695 - accuracy: 0.9417 - val_loss: 0.3791 - val_accuracy: 0.8878\n",
      "Epoch 42/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1549 - accuracy: 0.9471 - val_loss: 0.3377 - val_accuracy: 0.9049\n",
      "Epoch 43/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1513 - accuracy: 0.9508 - val_loss: 0.3927 - val_accuracy: 0.8585\n",
      "Epoch 44/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1533 - accuracy: 0.9496 - val_loss: 0.4809 - val_accuracy: 0.8732\n",
      "Epoch 45/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1548 - accuracy: 0.9480 - val_loss: 0.3557 - val_accuracy: 0.8976\n",
      "Epoch 46/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1282 - accuracy: 0.9549 - val_loss: 0.4210 - val_accuracy: 0.8854\n",
      "Epoch 47/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1457 - accuracy: 0.9512 - val_loss: 0.4747 - val_accuracy: 0.8902\n",
      "Epoch 48/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1378 - accuracy: 0.9538 - val_loss: 0.3889 - val_accuracy: 0.8976\n",
      "Epoch 49/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1375 - accuracy: 0.9533 - val_loss: 0.4478 - val_accuracy: 0.8780\n",
      "Epoch 50/100\n",
      "359/359 [==============================] - 5s 15ms/step - loss: 0.1359 - accuracy: 0.9527 - val_loss: 0.4627 - val_accuracy: 0.8829\n",
      "Epoch 51/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1349 - accuracy: 0.9543 - val_loss: 0.3986 - val_accuracy: 0.8878\n",
      "Epoch 52/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1344 - accuracy: 0.9527 - val_loss: 0.4296 - val_accuracy: 0.8976\n",
      "Epoch 53/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1312 - accuracy: 0.9570 - val_loss: 0.3905 - val_accuracy: 0.8902\n",
      "Epoch 54/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1240 - accuracy: 0.9579 - val_loss: 0.4373 - val_accuracy: 0.8732\n",
      "Epoch 55/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1260 - accuracy: 0.9571 - val_loss: 0.4459 - val_accuracy: 0.8902\n",
      "Epoch 56/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1281 - accuracy: 0.9583 - val_loss: 0.4006 - val_accuracy: 0.8902\n",
      "Epoch 57/100\n",
      "359/359 [==============================] - 5s 15ms/step - loss: 0.1045 - accuracy: 0.9628 - val_loss: 0.3577 - val_accuracy: 0.9049\n",
      "Epoch 58/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1207 - accuracy: 0.9585 - val_loss: 0.3962 - val_accuracy: 0.8951\n",
      "Epoch 59/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1158 - accuracy: 0.9608 - val_loss: 0.4307 - val_accuracy: 0.8951\n",
      "Epoch 60/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1095 - accuracy: 0.9628 - val_loss: 0.4585 - val_accuracy: 0.8927\n",
      "Epoch 61/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1038 - accuracy: 0.9649 - val_loss: 0.4581 - val_accuracy: 0.8732\n",
      "Epoch 62/100\n",
      "359/359 [==============================] - 5s 15ms/step - loss: 0.1106 - accuracy: 0.9629 - val_loss: 0.4056 - val_accuracy: 0.8902\n",
      "Epoch 63/100\n",
      "359/359 [==============================] - 5s 15ms/step - loss: 0.1107 - accuracy: 0.9634 - val_loss: 0.4398 - val_accuracy: 0.8829\n",
      "Epoch 64/100\n",
      "359/359 [==============================] - 5s 15ms/step - loss: 0.1112 - accuracy: 0.9631 - val_loss: 0.4752 - val_accuracy: 0.8902\n",
      "Epoch 65/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.1047 - accuracy: 0.9636 - val_loss: 0.4611 - val_accuracy: 0.8780\n",
      "Epoch 66/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0959 - accuracy: 0.9675 - val_loss: 0.4301 - val_accuracy: 0.8951\n",
      "Epoch 67/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0991 - accuracy: 0.9659 - val_loss: 0.4003 - val_accuracy: 0.9073\n",
      "Epoch 68/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0993 - accuracy: 0.9675 - val_loss: 0.4326 - val_accuracy: 0.8976\n",
      "Epoch 69/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0966 - accuracy: 0.9662 - val_loss: 0.4668 - val_accuracy: 0.8829\n",
      "Epoch 70/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0933 - accuracy: 0.9684 - val_loss: 0.4699 - val_accuracy: 0.8878\n",
      "Epoch 71/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0951 - accuracy: 0.9664 - val_loss: 0.4297 - val_accuracy: 0.9073\n",
      "Epoch 72/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0951 - accuracy: 0.9685 - val_loss: 0.4438 - val_accuracy: 0.8878\n",
      "Epoch 73/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0942 - accuracy: 0.9690 - val_loss: 0.4504 - val_accuracy: 0.9024\n",
      "Epoch 74/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0950 - accuracy: 0.9685 - val_loss: 0.4598 - val_accuracy: 0.8707\n",
      "Epoch 75/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0930 - accuracy: 0.9710 - val_loss: 0.5031 - val_accuracy: 0.8902\n",
      "Epoch 76/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0863 - accuracy: 0.9715 - val_loss: 0.4638 - val_accuracy: 0.8878\n",
      "Epoch 77/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0875 - accuracy: 0.9697 - val_loss: 0.4343 - val_accuracy: 0.9000\n",
      "Epoch 78/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0803 - accuracy: 0.9745 - val_loss: 0.4450 - val_accuracy: 0.8902\n",
      "Epoch 79/100\n",
      "359/359 [==============================] - 5s 15ms/step - loss: 0.0870 - accuracy: 0.9696 - val_loss: 0.4499 - val_accuracy: 0.8951\n",
      "Epoch 80/100\n",
      "359/359 [==============================] - 5s 15ms/step - loss: 0.0828 - accuracy: 0.9719 - val_loss: 0.4678 - val_accuracy: 0.8927\n",
      "Epoch 81/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0867 - accuracy: 0.9719 - val_loss: 0.4359 - val_accuracy: 0.9000\n",
      "Epoch 82/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0896 - accuracy: 0.9699 - val_loss: 0.5004 - val_accuracy: 0.8756\n",
      "Epoch 83/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0905 - accuracy: 0.9694 - val_loss: 0.4366 - val_accuracy: 0.9000\n",
      "Epoch 84/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0736 - accuracy: 0.9745 - val_loss: 0.4359 - val_accuracy: 0.8927\n",
      "Epoch 85/100\n",
      "359/359 [==============================] - 5s 14ms/step - loss: 0.0772 - accuracy: 0.9737 - val_loss: 0.4478 - val_accuracy: 0.8976\n",
      "Epoch 00085: early stopping\n",
      "CNN: Epochs=100, Train accuracy=0.97453, Validation accuracy=0.91220\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_X, y=train_y,\n",
    "    epochs = epochs,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[es, cp, lrs]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1598336814187,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "30b0e4a2-9738-4989-eb06-1c54ecef6b41"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EQCvPGZks9v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_9-8vl0.3146-va0.9000-ep35.hdf5\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.9000\n",
      "loss= 0.3146134912967682\n",
      "accuracy= 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'data/cvision/' + model_num + 'auged' + '.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#모델 불러와서 정확도 확인 및 예측\n",
    "file_path = './data/cvision/' + model_num\n",
    "files = os.listdir('./data/cvision/' + model_num)\n",
    "hdf5_file = files[0] #폴더 맨 앞의 val_loss 가장 작은 파일 불러옴\n",
    "print(hdf5_file)\n",
    "\n",
    "model.load_weights(file_path + '/' + hdf5_file)\n",
    "\n",
    "score = model.evaluate(valid_X, valid_y)\n",
    "print('loss=', score[0])        # val_loss\n",
    "print('accuracy=', score[1])    # val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-8nb5jokyny"
   },
   "outputs": [],
   "source": [
    "#예측 진행\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('data/cvision/my_subm_9-8_auged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_9-9:\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(24, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(Conv2D(24, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(24, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(48, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(48, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(48, (3,3), strides = (2,2), padding = 'same', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1598347122783,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "tPFielyJ5yMH"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "lrs = LearningRateScheduler(lambda x: 1e-3 * 0.9995 ** x)\n",
    "\n",
    "#earlystopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=150)\n",
    "\n",
    "#modelcheckpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "model_num = 'model_9-9'\n",
    "MODEL_SAVE_FOLDER_PATH = './data/cvision/' + model_num + '/'\n",
    "\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "    \n",
    "model_path = MODEL_SAVE_FOLDER_PATH + model_num +'vl{val_loss:.4f}-va{val_accuracy:.4f}-ep{epoch:03d}.hdf5'\n",
    "\n",
    "cp = ModelCheckpoint(filepath=model_path, monitor='val_loss',\n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537462,
     "status": "error",
     "timestamp": 1598347660504,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "012ce4a9-2ca8-41d3-d1de-9331032469e3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 3000\n",
    "batch_size = 128\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[es, cp]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1598336814187,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "mDdwZDDFkv5W",
    "outputId": "30b0e4a2-9738-4989-eb06-1c54ecef6b41"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8878\n",
      "loss= 0.3157714605331421\n",
      "accuracy= 0.8878048658370972\n"
     ]
    }
   ],
   "source": [
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'data/cvision/' + model_num + '.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#모델 불러와서 정확도 확인 및 예측\n",
    "file_path = './data/cvision/' + model_num\n",
    "files = os.listdir('./data/cvision/' + model_num)\n",
    "hdf5_file = files[0]\n",
    "print(hdf5_file)\n",
    "\n",
    "model.load_weights(file_path + '/' + hdf5_file)\n",
    "\n",
    "score = model.evaluate(valid_X, valid_y)\n",
    "print('loss=', score[0])        # val_loss\n",
    "print('accuracy=', score[1])    # val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-8nb5jokyny"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-40-dbea146f3fce>:6: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "#예측 진행\n",
    "test_X = test.drop(['id', 'letter'], axis=1).values\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X/255.\n",
    "\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('data/cvision/my_subm_9-9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1598337602169,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "bgfT4Y6_HFgw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 14, 14, 16)   800         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 14, 14, 16)   64          conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 14, 14, 16)   0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 14, 14, 16)   2320        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 14, 14, 16)   2320        conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 14, 14, 16)   0           conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 14, 14, 32)   4640        dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 14, 14, 32)   9248        conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 14, 14, 32)   0           conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 32)     1056        dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 7, 7, 32)     128         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 32)     0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 32)     9248        activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 7, 7, 32)     128         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 32)     0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 64)     2112        activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 64)     2112        dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 7, 7, 64)     256         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 7, 7, 64)     256         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 7, 7, 64)     0           batch_normalization_189[0][0]    \n",
      "                                                                 batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 7, 7, 64)     0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 7, 7, 64)     0           activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 4, 4, 64)     4160        dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 4, 4, 64)     256         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 4, 4, 64)     0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 4, 4, 64)     36928       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 4, 4, 64)     256         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 4, 4, 64)     0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 4, 4, 128)    8320        activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 4, 4, 128)    8320        dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 4, 4, 128)    512         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 4, 4, 128)    512         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 4, 4, 128)    0           batch_normalization_193[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 4, 4, 128)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 4, 4, 128)    0           activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 2048)         0           dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 10)           20490       flatten_19[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 114,442\n",
      "Trainable params: 113,258\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model_10: ResNet 응용\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop, Adagrad\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D\n",
    ")\n",
    "\n",
    "def conv1(x, filter_in=16):\n",
    "    x = Conv2D(filter_in, (7,7), strides=(2,2), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv2(x, layers=3, filter_in=16, filter_out=32):\n",
    "    x = MaxPooling2D((3,3), 2)(x)\n",
    "    \n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(layers):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "        \n",
    "    return x\n",
    "\n",
    "def conv3(x, layers=4, filter_in=32, filter_out=64):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(layers):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv4(x, layers=6, filter_in=64, filter_out=128):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(layers):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv5(x, layers=3, filter_in=128, filter_out=256):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(layers):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "#모델링\n",
    "classes = 10\n",
    "tensor_in = Input(shape= train_X.shape[1:], dtype='float32', name='input')\n",
    "x = conv1(tensor_in)\n",
    "\n",
    "x = Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal')(x)\n",
    "x = Conv2D(16, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal')(x)\n",
    "x = Conv2D(32, (3,3), padding = 'same', activation = 'relu', kernel_initializer='he_normal')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = conv3(x, 1, 32, 64)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = conv4(x, 1, 64, 128)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "tensor_out = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(tensor_in, tensor_out)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1598347122783,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "tPFielyJ5yMH"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** x)\n",
    "\n",
    "#earlystopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=150)\n",
    "\n",
    "#modelcheckpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "model_num = 'model_10'\n",
    "MODEL_SAVE_FOLDER_PATH = './data/cvision/' + model_num + '/'\n",
    "\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "    \n",
    "model_path = MODEL_SAVE_FOLDER_PATH + model_num +'vl{val_loss:.4f}-va{val_accuracy:.4f}-ep{epoch:03d}.hdf5'\n",
    "\n",
    "cp = ModelCheckpoint(filepath=model_path, monitor='val_loss',\n",
    "                               verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537462,
     "status": "error",
     "timestamp": 1598347660504,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "yeNCbX2vko4s",
    "outputId": "012ce4a9-2ca8-41d3-d1de-9331032469e3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "359/359 [==============================] - 3s 8ms/step - loss: 2.6721 - accuracy: 0.1675 - val_loss: 2.0380 - val_accuracy: 0.2561\n",
      "Epoch 2/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 2.1067 - accuracy: 0.2459 - val_loss: 1.8994 - val_accuracy: 0.3122\n",
      "Epoch 3/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 1.8694 - accuracy: 0.3274 - val_loss: 1.8822 - val_accuracy: 0.2951\n",
      "Epoch 4/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 1.6865 - accuracy: 0.3964 - val_loss: 2.0924 - val_accuracy: 0.2780\n",
      "Epoch 5/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 1.5576 - accuracy: 0.4542 - val_loss: 1.5080 - val_accuracy: 0.4537\n",
      "Epoch 6/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 1.4275 - accuracy: 0.4969 - val_loss: 1.3396 - val_accuracy: 0.5171\n",
      "Epoch 7/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 1.3050 - accuracy: 0.5334 - val_loss: 1.2092 - val_accuracy: 0.5659\n",
      "Epoch 8/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 1.1974 - accuracy: 0.5797 - val_loss: 1.5094 - val_accuracy: 0.4951\n",
      "Epoch 9/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 1.1209 - accuracy: 0.6101 - val_loss: 1.0976 - val_accuracy: 0.6146\n",
      "Epoch 10/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 1.0410 - accuracy: 0.6349 - val_loss: 1.0812 - val_accuracy: 0.6293\n",
      "Epoch 11/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.9660 - accuracy: 0.6622 - val_loss: 1.2044 - val_accuracy: 0.5805\n",
      "Epoch 12/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.9173 - accuracy: 0.6770 - val_loss: 0.9857 - val_accuracy: 0.6415\n",
      "Epoch 13/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.8564 - accuracy: 0.7057 - val_loss: 0.9151 - val_accuracy: 0.6780\n",
      "Epoch 14/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.8087 - accuracy: 0.7152 - val_loss: 0.9628 - val_accuracy: 0.6634\n",
      "Epoch 15/1000\n",
      "359/359 [==============================] - 3s 7ms/step - loss: 0.7794 - accuracy: 0.7275 - val_loss: 0.8961 - val_accuracy: 0.6878\n",
      "Epoch 16/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.7371 - accuracy: 0.7365 - val_loss: 0.9228 - val_accuracy: 0.6610\n",
      "Epoch 17/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.6900 - accuracy: 0.7527 - val_loss: 0.9172 - val_accuracy: 0.6780\n",
      "Epoch 18/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.6653 - accuracy: 0.7657 - val_loss: 0.9059 - val_accuracy: 0.7000\n",
      "Epoch 19/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.6477 - accuracy: 0.7706 - val_loss: 0.8590 - val_accuracy: 0.7098\n",
      "Epoch 20/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.6259 - accuracy: 0.7799 - val_loss: 0.8571 - val_accuracy: 0.7024\n",
      "Epoch 21/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.5894 - accuracy: 0.7918 - val_loss: 0.9084 - val_accuracy: 0.7000\n",
      "Epoch 22/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.5730 - accuracy: 0.7984 - val_loss: 1.0058 - val_accuracy: 0.6537\n",
      "Epoch 23/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.5453 - accuracy: 0.8046 - val_loss: 0.8616 - val_accuracy: 0.7171\n",
      "Epoch 24/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.5228 - accuracy: 0.8117 - val_loss: 0.8786 - val_accuracy: 0.7049\n",
      "Epoch 25/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.5090 - accuracy: 0.8196 - val_loss: 0.8893 - val_accuracy: 0.7146\n",
      "Epoch 26/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.4946 - accuracy: 0.8224 - val_loss: 0.8478 - val_accuracy: 0.7317\n",
      "Epoch 27/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.4667 - accuracy: 0.8366 - val_loss: 0.9813 - val_accuracy: 0.6805\n",
      "Epoch 28/1000\n",
      "359/359 [==============================] - 3s 7ms/step - loss: 0.4681 - accuracy: 0.8295 - val_loss: 0.8395 - val_accuracy: 0.7122\n",
      "Epoch 29/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.4548 - accuracy: 0.8345 - val_loss: 0.9523 - val_accuracy: 0.7049\n",
      "Epoch 30/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.4289 - accuracy: 0.8500 - val_loss: 0.9083 - val_accuracy: 0.6951\n",
      "Epoch 31/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.4262 - accuracy: 0.8509 - val_loss: 0.8674 - val_accuracy: 0.7439\n",
      "Epoch 32/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.4085 - accuracy: 0.8533 - val_loss: 0.8652 - val_accuracy: 0.7171\n",
      "Epoch 33/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.3948 - accuracy: 0.8591 - val_loss: 0.9048 - val_accuracy: 0.7146\n",
      "Epoch 34/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.3874 - accuracy: 0.8588 - val_loss: 1.0294 - val_accuracy: 0.6976\n",
      "Epoch 35/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.3710 - accuracy: 0.8692 - val_loss: 0.9660 - val_accuracy: 0.7122\n",
      "Epoch 36/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.3671 - accuracy: 0.8679 - val_loss: 1.0134 - val_accuracy: 0.7146\n",
      "Epoch 37/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.3553 - accuracy: 0.8711 - val_loss: 0.9518 - val_accuracy: 0.7293\n",
      "Epoch 38/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.3560 - accuracy: 0.8706 - val_loss: 0.9452 - val_accuracy: 0.7122\n",
      "Epoch 39/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.3459 - accuracy: 0.8792 - val_loss: 0.8897 - val_accuracy: 0.7220\n",
      "Epoch 40/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.3286 - accuracy: 0.8786 - val_loss: 0.9021 - val_accuracy: 0.7220\n",
      "Epoch 41/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.3139 - accuracy: 0.8860 - val_loss: 1.0245 - val_accuracy: 0.7049\n",
      "Epoch 42/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.3197 - accuracy: 0.8859 - val_loss: 0.9456 - val_accuracy: 0.7268\n",
      "Epoch 43/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.3130 - accuracy: 0.8870 - val_loss: 0.9298 - val_accuracy: 0.7098\n",
      "Epoch 44/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.3106 - accuracy: 0.8918 - val_loss: 0.9322 - val_accuracy: 0.7366\n",
      "Epoch 45/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2975 - accuracy: 0.8954 - val_loss: 0.9392 - val_accuracy: 0.7341\n",
      "Epoch 46/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2925 - accuracy: 0.8950 - val_loss: 0.9110 - val_accuracy: 0.7171\n",
      "Epoch 47/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.3034 - accuracy: 0.8914 - val_loss: 0.9755 - val_accuracy: 0.7195\n",
      "Epoch 48/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2771 - accuracy: 0.9029 - val_loss: 0.8935 - val_accuracy: 0.7171\n",
      "Epoch 49/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2761 - accuracy: 0.9007 - val_loss: 0.9630 - val_accuracy: 0.7317\n",
      "Epoch 50/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2667 - accuracy: 0.9033 - val_loss: 0.9056 - val_accuracy: 0.7317\n",
      "Epoch 51/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2567 - accuracy: 0.9036 - val_loss: 0.9267 - val_accuracy: 0.7244\n",
      "Epoch 52/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2664 - accuracy: 0.9041 - val_loss: 1.0165 - val_accuracy: 0.7268\n",
      "Epoch 53/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2665 - accuracy: 0.9026 - val_loss: 0.9959 - val_accuracy: 0.7195\n",
      "Epoch 54/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2401 - accuracy: 0.9111 - val_loss: 0.9100 - val_accuracy: 0.7244\n",
      "Epoch 55/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2484 - accuracy: 0.9113 - val_loss: 1.0030 - val_accuracy: 0.7171\n",
      "Epoch 56/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2376 - accuracy: 0.9149 - val_loss: 0.9761 - val_accuracy: 0.7317\n",
      "Epoch 57/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2454 - accuracy: 0.9105 - val_loss: 0.9576 - val_accuracy: 0.7220\n",
      "Epoch 58/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2295 - accuracy: 0.9177 - val_loss: 0.9671 - val_accuracy: 0.7268\n",
      "Epoch 59/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2297 - accuracy: 0.9165 - val_loss: 0.9797 - val_accuracy: 0.7317\n",
      "Epoch 60/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2197 - accuracy: 0.9218 - val_loss: 0.9533 - val_accuracy: 0.7244\n",
      "Epoch 61/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2196 - accuracy: 0.9201 - val_loss: 0.9859 - val_accuracy: 0.7122\n",
      "Epoch 62/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2109 - accuracy: 0.9213 - val_loss: 0.9954 - val_accuracy: 0.7317\n",
      "Epoch 63/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.2171 - accuracy: 0.9237 - val_loss: 1.0554 - val_accuracy: 0.7317\n",
      "Epoch 64/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2182 - accuracy: 0.9219 - val_loss: 1.0421 - val_accuracy: 0.7341\n",
      "Epoch 65/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2034 - accuracy: 0.9243 - val_loss: 1.0914 - val_accuracy: 0.6829\n",
      "Epoch 66/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2042 - accuracy: 0.9260 - val_loss: 1.0568 - val_accuracy: 0.7073\n",
      "Epoch 67/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.1992 - accuracy: 0.9273 - val_loss: 1.0406 - val_accuracy: 0.7146\n",
      "Epoch 68/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.1981 - accuracy: 0.9310 - val_loss: 1.0406 - val_accuracy: 0.7268\n",
      "Epoch 69/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.2000 - accuracy: 0.9278 - val_loss: 1.0603 - val_accuracy: 0.7049\n",
      "Epoch 70/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.1961 - accuracy: 0.9295 - val_loss: 1.1026 - val_accuracy: 0.7098\n",
      "Epoch 71/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.1844 - accuracy: 0.9348 - val_loss: 1.0525 - val_accuracy: 0.7220\n",
      "Epoch 72/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.1836 - accuracy: 0.9343 - val_loss: 1.1037 - val_accuracy: 0.7049\n",
      "Epoch 73/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.1792 - accuracy: 0.9359 - val_loss: 1.0918 - val_accuracy: 0.7098\n",
      "Epoch 74/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.1838 - accuracy: 0.9347 - val_loss: 1.1334 - val_accuracy: 0.6854\n",
      "Epoch 75/1000\n",
      "359/359 [==============================] - 2s 7ms/step - loss: 0.1766 - accuracy: 0.9363 - val_loss: 1.1394 - val_accuracy: 0.7024\n",
      "Epoch 76/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.1744 - accuracy: 0.9377 - val_loss: 1.0583 - val_accuracy: 0.7220\n",
      "Epoch 77/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.1709 - accuracy: 0.9384 - val_loss: 1.0813 - val_accuracy: 0.7244\n",
      "Epoch 78/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.1760 - accuracy: 0.9366 - val_loss: 1.1083 - val_accuracy: 0.7098\n",
      "Epoch 79/1000\n",
      "359/359 [==============================] - 2s 6ms/step - loss: 0.1683 - accuracy: 0.9425 - val_loss: 1.1500 - val_accuracy: 0.7049\n",
      "Epoch 80/1000\n",
      " 67/359 [====>.........................] - ETA: 1s - loss: 0.1844 - accuracy: 0.9319"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-2360bb394caa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_X, y=train_y,\n",
    "    epochs = epochs,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[es, cp, lrs]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1598339021678,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "QTPZASsAHFg3",
    "outputId": "2f0741de-2815-4be5-d0ae-fa77588688d4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_10vl1.0138-va0.6659-ep059.hdf5\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0138 - accuracy: 0.6659\n",
      "loss= 1.013812780380249\n",
      "accuracy= 0.6658536791801453\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-b88f6287dfe4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#예측 진행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "#모델 구조 저장\n",
    "model_json = model.to_json()\n",
    "with open(f'data/cvision/' + model_num + '_resnet_auged' + '.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#모델 불러와서 정확도 확인 및 예측\n",
    "file_path = './data/cvision/' + model_num\n",
    "files = os.listdir('./data/cvision/' + model_num)\n",
    "hdf5_file = files[0] #폴더 맨 앞의 val_loss 가장 작은 파일 불러옴\n",
    "print(hdf5_file)\n",
    "\n",
    "model.load_weights(file_path + '/' + hdf5_file)\n",
    "\n",
    "score = model.evaluate(valid_X, valid_y)\n",
    "print('loss=', score[0])        # val_loss\n",
    "print('accuracy=', score[1])    # val_accuracy\n",
    "\n",
    "#예측 진행\n",
    "res = model.predict_classes(test_X)\n",
    "\n",
    "submission.digit = res\n",
    "submission.to_csv('data/cvision/my_subm_10_resnet_auged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54T6v8cCHFg5"
   },
   "outputs": [],
   "source": [
    "#model_10: ResNet - residual block 구성\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D\n",
    ")\n",
    "\n",
    "def conv1(x):\n",
    "    x = Conv2D(64, (7,7), strides=(2,2), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv2(x, filter_in=64, filter_out=256):\n",
    "    x = MaxPooling2D((3,3), 2)(x)\n",
    "    \n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(1):#3):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "        \n",
    "    return x\n",
    "\n",
    "def conv3(x, filter_in=128, filter_out=512):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(2):#4):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv4(x, filter_in=256, filter_out=1024):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(1):#6):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv5(x, filter_in=512, filter_out=2048):\n",
    "    shortcut = x\n",
    "    \n",
    "    for i in range(1):#3):\n",
    "        if(i == 0):\n",
    "            x = Conv2D(filter_in, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            shortcut = Conv2D(filter_out, (1,1), strides=(2,2), padding='valid', kernel_initializer='he_normal')(shortcut) #각 layer의 첫 block에서는 dimension 증가 필요\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "            \n",
    "        else:\n",
    "            x = Conv2D(filter_in, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_in, (3,3), strides=(1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(filter_out, (1,1), strides=(1,1), padding='valid', kernel_initializer='he_normal')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fr98KwNSHFg7",
    "outputId": "3a0dd29f-d4a9-4b93-e734-e9304c3c55de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_55\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1110 (Conv2D)            (None, 14, 14, 64)   3200        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1110 (Batch (None, 14, 14, 64)   256         conv2d_1110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_545 (LeakyReLU)     (None, 14, 14, 64)   0           batch_normalization_1110[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 6, 6, 64)     0           leaky_re_lu_545[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1111 (Conv2D)            (None, 6, 6, 32)     2080        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1111 (Batch (None, 6, 6, 32)     128         conv2d_1111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_546 (LeakyReLU)     (None, 6, 6, 32)     0           batch_normalization_1111[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1112 (Conv2D)            (None, 6, 6, 32)     9248        leaky_re_lu_546[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1112 (Batch (None, 6, 6, 32)     128         conv2d_1112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_547 (LeakyReLU)     (None, 6, 6, 32)     0           batch_normalization_1112[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1113 (Conv2D)            (None, 6, 6, 64)     2112        leaky_re_lu_547[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1114 (Conv2D)            (None, 6, 6, 64)     4160        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1113 (Batch (None, 6, 6, 64)     256         conv2d_1113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1114 (Batch (None, 6, 6, 64)     256         conv2d_1114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_326 (Add)                   (None, 6, 6, 64)     0           batch_normalization_1113[0][0]   \n",
      "                                                                 batch_normalization_1114[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_548 (LeakyReLU)     (None, 6, 6, 64)     0           add_326[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 6, 6, 64)     0           leaky_re_lu_548[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1115 (Conv2D)            (None, 3, 3, 32)     2080        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1115 (Batch (None, 3, 3, 32)     128         conv2d_1115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_549 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1115[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1116 (Conv2D)            (None, 3, 3, 32)     9248        leaky_re_lu_549[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1116 (Batch (None, 3, 3, 32)     128         conv2d_1116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_550 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1116[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1117 (Conv2D)            (None, 3, 3, 64)     2112        leaky_re_lu_550[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1118 (Conv2D)            (None, 3, 3, 64)     4160        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1117 (Batch (None, 3, 3, 64)     256         conv2d_1117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1118 (Batch (None, 3, 3, 64)     256         conv2d_1118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_327 (Add)                   (None, 3, 3, 64)     0           batch_normalization_1117[0][0]   \n",
      "                                                                 batch_normalization_1118[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_551 (LeakyReLU)     (None, 3, 3, 64)     0           add_327[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1119 (Conv2D)            (None, 3, 3, 32)     2080        leaky_re_lu_551[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1119 (Batch (None, 3, 3, 32)     128         conv2d_1119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_552 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1119[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1120 (Conv2D)            (None, 3, 3, 32)     9248        leaky_re_lu_552[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1120 (Batch (None, 3, 3, 32)     128         conv2d_1120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_553 (LeakyReLU)     (None, 3, 3, 32)     0           batch_normalization_1120[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1121 (Conv2D)            (None, 3, 3, 64)     2112        leaky_re_lu_553[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1121 (Batch (None, 3, 3, 64)     256         conv2d_1121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_328 (Add)                   (None, 3, 3, 64)     0           batch_normalization_1121[0][0]   \n",
      "                                                                 leaky_re_lu_551[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_554 (LeakyReLU)     (None, 3, 3, 64)     0           add_328[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 3, 3, 64)     0           leaky_re_lu_554[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1122 (Conv2D)            (None, 2, 2, 64)     4160        dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1122 (Batch (None, 2, 2, 64)     256         conv2d_1122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_555 (LeakyReLU)     (None, 2, 2, 64)     0           batch_normalization_1122[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1123 (Conv2D)            (None, 2, 2, 64)     36928       leaky_re_lu_555[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1123 (Batch (None, 2, 2, 64)     256         conv2d_1123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_556 (LeakyReLU)     (None, 2, 2, 64)     0           batch_normalization_1123[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1124 (Conv2D)            (None, 2, 2, 128)    8320        leaky_re_lu_556[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1125 (Conv2D)            (None, 2, 2, 128)    8320        dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1124 (Batch (None, 2, 2, 128)    512         conv2d_1124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1125 (Batch (None, 2, 2, 128)    512         conv2d_1125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_329 (Add)                   (None, 2, 2, 128)    0           batch_normalization_1124[0][0]   \n",
      "                                                                 batch_normalization_1125[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_557 (LeakyReLU)     (None, 2, 2, 128)    0           add_329[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 2, 2, 128)    0           leaky_re_lu_557[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1126 (Conv2D)            (None, 1, 1, 64)     8256        dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1126 (Batch (None, 1, 1, 64)     256         conv2d_1126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_558 (LeakyReLU)     (None, 1, 1, 64)     0           batch_normalization_1126[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1127 (Conv2D)            (None, 1, 1, 64)     36928       leaky_re_lu_558[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1127 (Batch (None, 1, 1, 64)     256         conv2d_1127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_559 (LeakyReLU)     (None, 1, 1, 64)     0           batch_normalization_1127[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1128 (Conv2D)            (None, 1, 1, 128)    8320        leaky_re_lu_559[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1129 (Conv2D)            (None, 1, 1, 128)    16512       dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1128 (Batch (None, 1, 1, 128)    512         conv2d_1128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1129 (Batch (None, 1, 1, 128)    512         conv2d_1129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_330 (Add)                   (None, 1, 1, 128)    0           batch_normalization_1128[0][0]   \n",
      "                                                                 batch_normalization_1129[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_560 (LeakyReLU)     (None, 1, 1, 128)    0           add_330[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1, 1, 128)    0           leaky_re_lu_560[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_27 (Gl (None, 128)          0           dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 10)           1290        global_average_pooling2d_27[0][0]\n",
      "==================================================================================================\n",
      "Total params: 186,250\n",
      "Trainable params: 183,562\n",
      "Non-trainable params: 2,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "#모델링\n",
    "classes = 10\n",
    "tensor_in = Input(shape= train_X.shape[1:], dtype='float32', name='input')\n",
    "\n",
    "x = conv1(tensor_in)\n",
    "x = conv2(x)\n",
    "x = conv3(x)\n",
    "x = conv4(x)\n",
    "x = conv5(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "tensor_out = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(tensor_in, tensor_out)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1598347122783,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "tPFielyJ5yMH"
   },
   "outputs": [],
   "source": [
    "#earlystopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=150)\n",
    "\n",
    "#modelcheckpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "MODEL_SAVE_FOLDER_PATH = './data/cvision/model_10/'\n",
    "model_num = 'model_10'\n",
    "\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "    \n",
    "model_path = MODEL_SAVE_FOLDER_PATH + model_num +'vl{val_loss:.4f}-ep{epoch:02d}.hdf5'\n",
    "\n",
    "cp = ModelCheckpoint(filepath=model_path, monitor='val_loss',\n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19652,
     "status": "error",
     "timestamp": 1598178350080,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "fPtBXYtwHFg-",
    "outputId": "cb892981-08ed-4ba9-af29-c492b265fb8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 3.3559 - accuracy: 0.0964 - val_loss: 2.9831 - val_accuracy: 0.0877\n",
      "Epoch 2/4000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3912 - accuracy: 0.1006 - val_loss: 2.8385 - val_accuracy: 0.0909\n",
      "Epoch 3/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3649 - accuracy: 0.0992 - val_loss: 2.7397 - val_accuracy: 0.0974\n",
      "Epoch 4/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1698 - accuracy: 0.1159 - val_loss: 2.6587 - val_accuracy: 0.0942\n",
      "Epoch 5/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.2307 - accuracy: 0.1103 - val_loss: 2.5902 - val_accuracy: 0.0974\n",
      "Epoch 6/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.1670 - accuracy: 0.1045 - val_loss: 2.5337 - val_accuracy: 0.0877\n",
      "Epoch 7/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.1895 - accuracy: 0.1034 - val_loss: 2.4875 - val_accuracy: 0.0877\n",
      "Epoch 8/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1855 - accuracy: 0.0918 - val_loss: 2.4508 - val_accuracy: 0.0877\n",
      "Epoch 9/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.1438 - accuracy: 0.1084 - val_loss: 2.4196 - val_accuracy: 0.0877\n",
      "Epoch 10/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1243 - accuracy: 0.0922 - val_loss: 2.3934 - val_accuracy: 0.0877\n",
      "Epoch 11/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9914 - accuracy: 0.1229 - val_loss: 2.3719 - val_accuracy: 0.0942\n",
      "Epoch 12/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.0302 - accuracy: 0.1159 - val_loss: 2.3548 - val_accuracy: 0.1006\n",
      "Epoch 13/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9630 - accuracy: 0.1075 - val_loss: 2.3416 - val_accuracy: 0.0974\n",
      "Epoch 14/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9993 - accuracy: 0.0978 - val_loss: 2.3315 - val_accuracy: 0.0942\n",
      "Epoch 15/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.9481 - accuracy: 0.1201 - val_loss: 2.3232 - val_accuracy: 0.0942\n",
      "Epoch 16/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.9802 - accuracy: 0.1064 - val_loss: 2.3178 - val_accuracy: 0.0844\n",
      "Epoch 17/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.9274 - accuracy: 0.0967 - val_loss: 2.3124 - val_accuracy: 0.0877\n",
      "Epoch 18/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.9336 - accuracy: 0.1045 - val_loss: 2.3080 - val_accuracy: 0.0779\n",
      "Epoch 19/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.9374 - accuracy: 0.1094 - val_loss: 2.3037 - val_accuracy: 0.0714\n",
      "Epoch 20/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.9103 - accuracy: 0.1084 - val_loss: 2.2997 - val_accuracy: 0.0844\n",
      "Epoch 21/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.8997 - accuracy: 0.1094 - val_loss: 2.2950 - val_accuracy: 0.0779\n",
      "Epoch 22/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.9298 - accuracy: 0.1006 - val_loss: 2.2913 - val_accuracy: 0.0877\n",
      "Epoch 23/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.8956 - accuracy: 0.1104 - val_loss: 2.2893 - val_accuracy: 0.1234\n",
      "Epoch 24/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.8087 - accuracy: 0.1173 - val_loss: 2.2888 - val_accuracy: 0.1234\n",
      "Epoch 25/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.8729 - accuracy: 0.0938 - val_loss: 2.2878 - val_accuracy: 0.1299\n",
      "Epoch 26/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.8045 - accuracy: 0.1035 - val_loss: 2.2858 - val_accuracy: 0.1461\n",
      "Epoch 27/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.8440 - accuracy: 0.1123 - val_loss: 2.2831 - val_accuracy: 0.1461\n",
      "Epoch 28/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.7647 - accuracy: 0.1075 - val_loss: 2.2809 - val_accuracy: 0.1494\n",
      "Epoch 29/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.7985 - accuracy: 0.1182 - val_loss: 2.2792 - val_accuracy: 0.1623\n",
      "Epoch 30/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.7777 - accuracy: 0.1123 - val_loss: 2.2777 - val_accuracy: 0.1623\n",
      "Epoch 31/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.7981 - accuracy: 0.1103 - val_loss: 2.2766 - val_accuracy: 0.1688\n",
      "Epoch 32/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.7751 - accuracy: 0.1341 - val_loss: 2.2756 - val_accuracy: 0.1591\n",
      "Epoch 33/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.7998 - accuracy: 0.1034 - val_loss: 2.2743 - val_accuracy: 0.1494\n",
      "Epoch 34/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.7351 - accuracy: 0.1117 - val_loss: 2.2738 - val_accuracy: 0.1494\n",
      "Epoch 35/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.7202 - accuracy: 0.1016 - val_loss: 2.2736 - val_accuracy: 0.1494\n",
      "Epoch 36/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.7096 - accuracy: 0.0977 - val_loss: 2.2730 - val_accuracy: 0.1526\n",
      "Epoch 37/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6793 - accuracy: 0.1211 - val_loss: 2.2721 - val_accuracy: 0.1558\n",
      "Epoch 38/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6852 - accuracy: 0.1201 - val_loss: 2.2715 - val_accuracy: 0.1623\n",
      "Epoch 39/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6476 - accuracy: 0.1173 - val_loss: 2.2712 - val_accuracy: 0.1494\n",
      "Epoch 40/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6726 - accuracy: 0.1201 - val_loss: 2.2709 - val_accuracy: 0.1429\n",
      "Epoch 41/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.7411 - accuracy: 0.0964 - val_loss: 2.2704 - val_accuracy: 0.1396\n",
      "Epoch 42/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.6740 - accuracy: 0.1103 - val_loss: 2.2700 - val_accuracy: 0.1461\n",
      "Epoch 43/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6002 - accuracy: 0.1201 - val_loss: 2.2693 - val_accuracy: 0.1461\n",
      "Epoch 44/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6609 - accuracy: 0.1182 - val_loss: 2.2677 - val_accuracy: 0.1461\n",
      "Epoch 45/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6416 - accuracy: 0.1187 - val_loss: 2.2665 - val_accuracy: 0.1331\n",
      "Epoch 46/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.5942 - accuracy: 0.1327 - val_loss: 2.2659 - val_accuracy: 0.1331\n",
      "Epoch 47/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6864 - accuracy: 0.1201 - val_loss: 2.2653 - val_accuracy: 0.1331\n",
      "Epoch 48/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6283 - accuracy: 0.1173 - val_loss: 2.2650 - val_accuracy: 0.1266\n",
      "Epoch 49/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6614 - accuracy: 0.1113 - val_loss: 2.2652 - val_accuracy: 0.1266\n",
      "Epoch 50/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6383 - accuracy: 0.1143 - val_loss: 2.2658 - val_accuracy: 0.1039\n",
      "Epoch 51/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5500 - accuracy: 0.1230 - val_loss: 2.2660 - val_accuracy: 0.0909\n",
      "Epoch 52/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5997 - accuracy: 0.1229 - val_loss: 2.2663 - val_accuracy: 0.0942\n",
      "Epoch 53/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5509 - accuracy: 0.1117 - val_loss: 2.2665 - val_accuracy: 0.1039\n",
      "Epoch 54/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5918 - accuracy: 0.1035 - val_loss: 2.2666 - val_accuracy: 0.1006\n",
      "Epoch 55/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6295 - accuracy: 0.1075 - val_loss: 2.2662 - val_accuracy: 0.1136\n",
      "Epoch 56/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5616 - accuracy: 0.1299 - val_loss: 2.2654 - val_accuracy: 0.1136\n",
      "Epoch 57/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5678 - accuracy: 0.1240 - val_loss: 2.2648 - val_accuracy: 0.1201\n",
      "Epoch 58/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5844 - accuracy: 0.1113 - val_loss: 2.2640 - val_accuracy: 0.1266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5125 - accuracy: 0.1260 - val_loss: 2.2632 - val_accuracy: 0.1266\n",
      "Epoch 60/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5432 - accuracy: 0.1089 - val_loss: 2.2628 - val_accuracy: 0.1396\n",
      "Epoch 61/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5274 - accuracy: 0.1397 - val_loss: 2.2621 - val_accuracy: 0.1429\n",
      "Epoch 62/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4883 - accuracy: 0.1221 - val_loss: 2.2610 - val_accuracy: 0.1429\n",
      "Epoch 63/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5257 - accuracy: 0.1074 - val_loss: 2.2594 - val_accuracy: 0.1396\n",
      "Epoch 64/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5400 - accuracy: 0.1172 - val_loss: 2.2577 - val_accuracy: 0.1494\n",
      "Epoch 65/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.4593 - accuracy: 0.1397 - val_loss: 2.2554 - val_accuracy: 0.1526\n",
      "Epoch 66/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5329 - accuracy: 0.0978 - val_loss: 2.2535 - val_accuracy: 0.1558\n",
      "Epoch 67/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5395 - accuracy: 0.1104 - val_loss: 2.2516 - val_accuracy: 0.1591\n",
      "Epoch 68/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4761 - accuracy: 0.1369 - val_loss: 2.2500 - val_accuracy: 0.1526\n",
      "Epoch 69/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4866 - accuracy: 0.1143 - val_loss: 2.2481 - val_accuracy: 0.1591\n",
      "Epoch 70/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4883 - accuracy: 0.1240 - val_loss: 2.2463 - val_accuracy: 0.1656\n",
      "Epoch 71/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5064 - accuracy: 0.0978 - val_loss: 2.2451 - val_accuracy: 0.1656\n",
      "Epoch 72/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4676 - accuracy: 0.1243 - val_loss: 2.2438 - val_accuracy: 0.1753\n",
      "Epoch 73/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4555 - accuracy: 0.1299 - val_loss: 2.2427 - val_accuracy: 0.1753\n",
      "Epoch 74/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4463 - accuracy: 0.1162 - val_loss: 2.2417 - val_accuracy: 0.1753\n",
      "Epoch 75/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.5065 - accuracy: 0.1117 - val_loss: 2.2411 - val_accuracy: 0.1786\n",
      "Epoch 76/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4623 - accuracy: 0.1215 - val_loss: 2.2408 - val_accuracy: 0.1851\n",
      "Epoch 77/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4452 - accuracy: 0.1279 - val_loss: 2.2406 - val_accuracy: 0.1916\n",
      "Epoch 78/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4190 - accuracy: 0.1397 - val_loss: 2.2399 - val_accuracy: 0.1948\n",
      "Epoch 79/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3879 - accuracy: 0.1465 - val_loss: 2.2393 - val_accuracy: 0.1981\n",
      "Epoch 80/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4164 - accuracy: 0.1439 - val_loss: 2.2384 - val_accuracy: 0.2045\n",
      "Epoch 81/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4606 - accuracy: 0.1279 - val_loss: 2.2370 - val_accuracy: 0.2013\n",
      "Epoch 82/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4072 - accuracy: 0.1215 - val_loss: 2.2357 - val_accuracy: 0.2078\n",
      "Epoch 83/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4046 - accuracy: 0.1285 - val_loss: 2.2349 - val_accuracy: 0.2143\n",
      "Epoch 84/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4548 - accuracy: 0.1182 - val_loss: 2.2342 - val_accuracy: 0.2143\n",
      "Epoch 85/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4058 - accuracy: 0.1229 - val_loss: 2.2339 - val_accuracy: 0.2175\n",
      "Epoch 86/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3797 - accuracy: 0.1383 - val_loss: 2.2337 - val_accuracy: 0.2175\n",
      "Epoch 87/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4110 - accuracy: 0.1152 - val_loss: 2.2335 - val_accuracy: 0.2143\n",
      "Epoch 88/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3521 - accuracy: 0.1387 - val_loss: 2.2331 - val_accuracy: 0.2110\n",
      "Epoch 89/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3638 - accuracy: 0.1387 - val_loss: 2.2329 - val_accuracy: 0.2143\n",
      "Epoch 90/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3966 - accuracy: 0.1318 - val_loss: 2.2322 - val_accuracy: 0.2110\n",
      "Epoch 91/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4077 - accuracy: 0.1411 - val_loss: 2.2315 - val_accuracy: 0.2110\n",
      "Epoch 92/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4299 - accuracy: 0.1162 - val_loss: 2.2309 - val_accuracy: 0.2078\n",
      "Epoch 93/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.4087 - accuracy: 0.1173 - val_loss: 2.2301 - val_accuracy: 0.2045\n",
      "Epoch 94/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3998 - accuracy: 0.1201 - val_loss: 2.2298 - val_accuracy: 0.2045\n",
      "Epoch 95/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3701 - accuracy: 0.1318 - val_loss: 2.2299 - val_accuracy: 0.1916\n",
      "Epoch 96/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3499 - accuracy: 0.1523 - val_loss: 2.2298 - val_accuracy: 0.1981\n",
      "Epoch 97/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3331 - accuracy: 0.1397 - val_loss: 2.2297 - val_accuracy: 0.1948\n",
      "Epoch 98/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3632 - accuracy: 0.1396 - val_loss: 2.2293 - val_accuracy: 0.1851\n",
      "Epoch 99/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3237 - accuracy: 0.1377 - val_loss: 2.2291 - val_accuracy: 0.1851\n",
      "Epoch 100/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3340 - accuracy: 0.1522 - val_loss: 2.2291 - val_accuracy: 0.1753\n",
      "Epoch 101/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3520 - accuracy: 0.1328 - val_loss: 2.2291 - val_accuracy: 0.1721\n",
      "Epoch 102/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3483 - accuracy: 0.1436 - val_loss: 2.2288 - val_accuracy: 0.1721\n",
      "Epoch 103/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3411 - accuracy: 0.1397 - val_loss: 2.2284 - val_accuracy: 0.1753\n",
      "Epoch 104/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3522 - accuracy: 0.1230 - val_loss: 2.2280 - val_accuracy: 0.1786\n",
      "Epoch 105/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3097 - accuracy: 0.1522 - val_loss: 2.2270 - val_accuracy: 0.1786\n",
      "Epoch 106/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3151 - accuracy: 0.1383 - val_loss: 2.2258 - val_accuracy: 0.1753\n",
      "Epoch 107/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3008 - accuracy: 0.1383 - val_loss: 2.2246 - val_accuracy: 0.1786\n",
      "Epoch 108/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3459 - accuracy: 0.1670 - val_loss: 2.2234 - val_accuracy: 0.1786\n",
      "Epoch 109/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.3234 - accuracy: 0.1425 - val_loss: 2.2220 - val_accuracy: 0.1721\n",
      "Epoch 110/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3314 - accuracy: 0.1327 - val_loss: 2.2209 - val_accuracy: 0.1753\n",
      "Epoch 111/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3012 - accuracy: 0.1445 - val_loss: 2.2200 - val_accuracy: 0.1753\n",
      "Epoch 112/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2940 - accuracy: 0.1611 - val_loss: 2.2197 - val_accuracy: 0.1753\n",
      "Epoch 113/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3067 - accuracy: 0.1494 - val_loss: 2.2197 - val_accuracy: 0.1786\n",
      "Epoch 114/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3240 - accuracy: 0.1475 - val_loss: 2.2198 - val_accuracy: 0.1721\n",
      "Epoch 115/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3044 - accuracy: 0.1536 - val_loss: 2.2196 - val_accuracy: 0.1721\n",
      "Epoch 116/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3216 - accuracy: 0.1426 - val_loss: 2.2196 - val_accuracy: 0.1688\n",
      "Epoch 117/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2946 - accuracy: 0.1582 - val_loss: 2.2195 - val_accuracy: 0.1623\n",
      "Epoch 118/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3182 - accuracy: 0.1494 - val_loss: 2.2194 - val_accuracy: 0.1591\n",
      "Epoch 119/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2904 - accuracy: 0.1522 - val_loss: 2.2200 - val_accuracy: 0.1591\n",
      "Epoch 120/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3126 - accuracy: 0.1411 - val_loss: 2.2204 - val_accuracy: 0.1623\n",
      "Epoch 121/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2908 - accuracy: 0.1425 - val_loss: 2.2208 - val_accuracy: 0.1623\n",
      "Epoch 122/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2812 - accuracy: 0.1494 - val_loss: 2.2213 - val_accuracy: 0.1591\n",
      "Epoch 123/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2891 - accuracy: 0.1611 - val_loss: 2.2217 - val_accuracy: 0.1623\n",
      "Epoch 124/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2812 - accuracy: 0.1582 - val_loss: 2.2223 - val_accuracy: 0.1591\n",
      "Epoch 125/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2875 - accuracy: 0.1620 - val_loss: 2.2226 - val_accuracy: 0.1656\n",
      "Epoch 126/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2675 - accuracy: 0.1480 - val_loss: 2.2232 - val_accuracy: 0.1656\n",
      "Epoch 127/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2595 - accuracy: 0.1582 - val_loss: 2.2241 - val_accuracy: 0.1688\n",
      "Epoch 128/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2503 - accuracy: 0.1533 - val_loss: 2.2248 - val_accuracy: 0.1656\n",
      "Epoch 129/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2835 - accuracy: 0.1550 - val_loss: 2.2254 - val_accuracy: 0.1623\n",
      "Epoch 130/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2858 - accuracy: 0.1357 - val_loss: 2.2258 - val_accuracy: 0.1623\n",
      "Epoch 131/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2739 - accuracy: 0.1453 - val_loss: 2.2260 - val_accuracy: 0.1656\n",
      "Epoch 132/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2702 - accuracy: 0.1466 - val_loss: 2.2265 - val_accuracy: 0.1656\n",
      "Epoch 133/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3002 - accuracy: 0.1676 - val_loss: 2.2271 - val_accuracy: 0.1623\n",
      "Epoch 134/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2528 - accuracy: 0.1718 - val_loss: 2.2274 - val_accuracy: 0.1656\n",
      "Epoch 135/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2330 - accuracy: 0.1777 - val_loss: 2.2279 - val_accuracy: 0.1591\n",
      "Epoch 136/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2760 - accuracy: 0.1670 - val_loss: 2.2280 - val_accuracy: 0.1656\n",
      "Epoch 137/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2546 - accuracy: 0.1927 - val_loss: 2.2277 - val_accuracy: 0.1721\n",
      "Epoch 138/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2613 - accuracy: 0.1718 - val_loss: 2.2272 - val_accuracy: 0.1721\n",
      "Epoch 139/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2706 - accuracy: 0.1718 - val_loss: 2.2270 - val_accuracy: 0.1786\n",
      "Epoch 140/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2356 - accuracy: 0.1983 - val_loss: 2.2266 - val_accuracy: 0.1786\n",
      "Epoch 141/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2645 - accuracy: 0.1718 - val_loss: 2.2263 - val_accuracy: 0.1721\n",
      "Epoch 142/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2663 - accuracy: 0.1578 - val_loss: 2.2260 - val_accuracy: 0.1721\n",
      "Epoch 143/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2167 - accuracy: 0.1606 - val_loss: 2.2256 - val_accuracy: 0.1721\n",
      "Epoch 144/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2437 - accuracy: 0.1718 - val_loss: 2.2249 - val_accuracy: 0.1688\n",
      "Epoch 145/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2428 - accuracy: 0.1855 - val_loss: 2.2244 - val_accuracy: 0.1688\n",
      "Epoch 146/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2283 - accuracy: 0.1787 - val_loss: 2.2238 - val_accuracy: 0.1688\n",
      "Epoch 147/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2133 - accuracy: 0.1774 - val_loss: 2.2234 - val_accuracy: 0.1688\n",
      "Epoch 148/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2701 - accuracy: 0.1572 - val_loss: 2.2229 - val_accuracy: 0.1688\n",
      "Epoch 149/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2627 - accuracy: 0.1453 - val_loss: 2.2220 - val_accuracy: 0.1656\n",
      "Epoch 150/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2380 - accuracy: 0.1899 - val_loss: 2.2210 - val_accuracy: 0.1656\n",
      "Epoch 151/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2115 - accuracy: 0.1788 - val_loss: 2.2202 - val_accuracy: 0.1656\n",
      "Epoch 152/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2306 - accuracy: 0.1758 - val_loss: 2.2194 - val_accuracy: 0.1656\n",
      "Epoch 153/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2532 - accuracy: 0.1620 - val_loss: 2.2186 - val_accuracy: 0.1656\n",
      "Epoch 154/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2219 - accuracy: 0.1738 - val_loss: 2.2178 - val_accuracy: 0.1656\n",
      "Epoch 155/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2022 - accuracy: 0.1904 - val_loss: 2.2168 - val_accuracy: 0.1688\n",
      "Epoch 156/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2022 - accuracy: 0.2053 - val_loss: 2.2159 - val_accuracy: 0.1688\n",
      "Epoch 157/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2579 - accuracy: 0.1550 - val_loss: 2.2148 - val_accuracy: 0.1688\n",
      "Epoch 158/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2149 - accuracy: 0.1746 - val_loss: 2.2137 - val_accuracy: 0.1656\n",
      "Epoch 159/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1968 - accuracy: 0.1983 - val_loss: 2.2126 - val_accuracy: 0.1656\n",
      "Epoch 160/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2303 - accuracy: 0.1760 - val_loss: 2.2119 - val_accuracy: 0.1688\n",
      "Epoch 161/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2400 - accuracy: 0.1718 - val_loss: 2.2108 - val_accuracy: 0.1688\n",
      "Epoch 162/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2168 - accuracy: 0.2025 - val_loss: 2.2101 - val_accuracy: 0.1688\n",
      "Epoch 163/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2140 - accuracy: 0.1758 - val_loss: 2.2098 - val_accuracy: 0.1656\n",
      "Epoch 164/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2132 - accuracy: 0.1816 - val_loss: 2.2095 - val_accuracy: 0.1656\n",
      "Epoch 165/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1809 - accuracy: 0.1895 - val_loss: 2.2088 - val_accuracy: 0.1688\n",
      "Epoch 166/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2010 - accuracy: 0.2039 - val_loss: 2.2081 - val_accuracy: 0.1688\n",
      "Epoch 167/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1956 - accuracy: 0.1758 - val_loss: 2.2073 - val_accuracy: 0.1721\n",
      "Epoch 168/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1959 - accuracy: 0.2080 - val_loss: 2.2070 - val_accuracy: 0.1721\n",
      "Epoch 169/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1950 - accuracy: 0.1816 - val_loss: 2.2066 - val_accuracy: 0.1721\n",
      "Epoch 170/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1816 - accuracy: 0.1634 - val_loss: 2.2061 - val_accuracy: 0.1721\n",
      "Epoch 171/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1798 - accuracy: 0.1963 - val_loss: 2.2057 - val_accuracy: 0.1721\n",
      "Epoch 172/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1617 - accuracy: 0.2039 - val_loss: 2.2055 - val_accuracy: 0.1721\n",
      "Epoch 173/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1894 - accuracy: 0.1983 - val_loss: 2.2052 - val_accuracy: 0.1721\n",
      "Epoch 174/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1680 - accuracy: 0.1982 - val_loss: 2.2050 - val_accuracy: 0.1721\n",
      "Epoch 175/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1786 - accuracy: 0.1802 - val_loss: 2.2041 - val_accuracy: 0.1721\n",
      "Epoch 176/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2019 - accuracy: 0.1738 - val_loss: 2.2034 - val_accuracy: 0.1721\n",
      "Epoch 177/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1919 - accuracy: 0.1992 - val_loss: 2.2026 - val_accuracy: 0.1721\n",
      "Epoch 178/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2139 - accuracy: 0.2053 - val_loss: 2.2020 - val_accuracy: 0.1721\n",
      "Epoch 179/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2114 - accuracy: 0.1865 - val_loss: 2.2013 - val_accuracy: 0.1656\n",
      "Epoch 180/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1730 - accuracy: 0.2179 - val_loss: 2.2006 - val_accuracy: 0.1656\n",
      "Epoch 181/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2014 - accuracy: 0.1992 - val_loss: 2.2000 - val_accuracy: 0.1721\n",
      "Epoch 182/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1690 - accuracy: 0.1875 - val_loss: 2.1996 - val_accuracy: 0.1721\n",
      "Epoch 183/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2087 - accuracy: 0.1969 - val_loss: 2.1992 - val_accuracy: 0.1721\n",
      "Epoch 184/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1676 - accuracy: 0.2053 - val_loss: 2.1983 - val_accuracy: 0.1721\n",
      "Epoch 185/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1885 - accuracy: 0.2041 - val_loss: 2.1969 - val_accuracy: 0.1721\n",
      "Epoch 186/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2122 - accuracy: 0.1858 - val_loss: 2.1953 - val_accuracy: 0.1753\n",
      "Epoch 187/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1820 - accuracy: 0.1982 - val_loss: 2.1940 - val_accuracy: 0.1786\n",
      "Epoch 188/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1766 - accuracy: 0.2011 - val_loss: 2.1923 - val_accuracy: 0.1786\n",
      "Epoch 189/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2107 - accuracy: 0.1885 - val_loss: 2.1909 - val_accuracy: 0.1786\n",
      "Epoch 190/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2146 - accuracy: 0.1760 - val_loss: 2.1890 - val_accuracy: 0.1818\n",
      "Epoch 191/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.1718 - accuracy: 0.1855 - val_loss: 2.1872 - val_accuracy: 0.1818\n",
      "Epoch 192/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1746 - accuracy: 0.1982 - val_loss: 2.1854 - val_accuracy: 0.1818\n",
      "Epoch 193/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2023 - accuracy: 0.1777 - val_loss: 2.1829 - val_accuracy: 0.1818\n",
      "Epoch 194/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2024 - accuracy: 0.2100 - val_loss: 2.1802 - val_accuracy: 0.1818\n",
      "Epoch 195/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1585 - accuracy: 0.2080 - val_loss: 2.1775 - val_accuracy: 0.1851\n",
      "Epoch 196/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1401 - accuracy: 0.2217 - val_loss: 2.1745 - val_accuracy: 0.1883\n",
      "Epoch 197/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1467 - accuracy: 0.1875 - val_loss: 2.1723 - val_accuracy: 0.1981\n",
      "Epoch 198/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1732 - accuracy: 0.2051 - val_loss: 2.1703 - val_accuracy: 0.1981\n",
      "Epoch 199/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1484 - accuracy: 0.2188 - val_loss: 2.1687 - val_accuracy: 0.2013\n",
      "Epoch 200/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1584 - accuracy: 0.2021 - val_loss: 2.1670 - val_accuracy: 0.2013\n",
      "Epoch 201/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1931 - accuracy: 0.1797 - val_loss: 2.1653 - val_accuracy: 0.2013\n",
      "Epoch 202/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1412 - accuracy: 0.2137 - val_loss: 2.1633 - val_accuracy: 0.2013\n",
      "Epoch 203/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1323 - accuracy: 0.2095 - val_loss: 2.1615 - val_accuracy: 0.1981\n",
      "Epoch 204/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1471 - accuracy: 0.2039 - val_loss: 2.1597 - val_accuracy: 0.2013\n",
      "Epoch 205/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1368 - accuracy: 0.1955 - val_loss: 2.1572 - val_accuracy: 0.2013\n",
      "Epoch 206/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1311 - accuracy: 0.2129 - val_loss: 2.1551 - val_accuracy: 0.2013\n",
      "Epoch 207/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1406 - accuracy: 0.1899 - val_loss: 2.1531 - val_accuracy: 0.2013\n",
      "Epoch 208/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1558 - accuracy: 0.2053 - val_loss: 2.1514 - val_accuracy: 0.2045\n",
      "Epoch 209/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1261 - accuracy: 0.2137 - val_loss: 2.1493 - val_accuracy: 0.2045\n",
      "Epoch 210/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1715 - accuracy: 0.1885 - val_loss: 2.1473 - val_accuracy: 0.2045\n",
      "Epoch 211/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1577 - accuracy: 0.2053 - val_loss: 2.1458 - val_accuracy: 0.2078\n",
      "Epoch 212/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1351 - accuracy: 0.2165 - val_loss: 2.1449 - val_accuracy: 0.2045\n",
      "Epoch 213/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1383 - accuracy: 0.2178 - val_loss: 2.1439 - val_accuracy: 0.2045\n",
      "Epoch 214/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1622 - accuracy: 0.2291 - val_loss: 2.1430 - val_accuracy: 0.2078\n",
      "Epoch 215/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1480 - accuracy: 0.2285 - val_loss: 2.1421 - val_accuracy: 0.2078\n",
      "Epoch 216/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1390 - accuracy: 0.2011 - val_loss: 2.1399 - val_accuracy: 0.2078\n",
      "Epoch 217/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1444 - accuracy: 0.2053 - val_loss: 2.1376 - val_accuracy: 0.2078\n",
      "Epoch 218/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1850 - accuracy: 0.2137 - val_loss: 2.1349 - val_accuracy: 0.2110\n",
      "Epoch 219/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1292 - accuracy: 0.2179 - val_loss: 2.1321 - val_accuracy: 0.2110\n",
      "Epoch 220/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1204 - accuracy: 0.2165 - val_loss: 2.1286 - val_accuracy: 0.2110\n",
      "Epoch 221/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1258 - accuracy: 0.2263 - val_loss: 2.1254 - val_accuracy: 0.2143\n",
      "Epoch 222/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1010 - accuracy: 0.2227 - val_loss: 2.1222 - val_accuracy: 0.2175\n",
      "Epoch 223/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1552 - accuracy: 0.2025 - val_loss: 2.1190 - val_accuracy: 0.2143\n",
      "Epoch 224/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1127 - accuracy: 0.2275 - val_loss: 2.1162 - val_accuracy: 0.2175\n",
      "Epoch 225/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1418 - accuracy: 0.2119 - val_loss: 2.1131 - val_accuracy: 0.2175\n",
      "Epoch 226/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0871 - accuracy: 0.2363 - val_loss: 2.1098 - val_accuracy: 0.2208\n",
      "Epoch 227/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1232 - accuracy: 0.2179 - val_loss: 2.1059 - val_accuracy: 0.2240\n",
      "Epoch 228/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1206 - accuracy: 0.2139 - val_loss: 2.1022 - val_accuracy: 0.2338\n",
      "Epoch 229/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1185 - accuracy: 0.2197 - val_loss: 2.0987 - val_accuracy: 0.2403\n",
      "Epoch 230/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1185 - accuracy: 0.2129 - val_loss: 2.0950 - val_accuracy: 0.2435\n",
      "Epoch 231/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1206 - accuracy: 0.2324 - val_loss: 2.0918 - val_accuracy: 0.2532\n",
      "Epoch 232/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0932 - accuracy: 0.2295 - val_loss: 2.0886 - val_accuracy: 0.2565\n",
      "Epoch 233/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0808 - accuracy: 0.2444 - val_loss: 2.0855 - val_accuracy: 0.2532\n",
      "Epoch 234/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1255 - accuracy: 0.2129 - val_loss: 2.0821 - val_accuracy: 0.2565\n",
      "Epoch 235/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1120 - accuracy: 0.2067 - val_loss: 2.0785 - val_accuracy: 0.2532\n",
      "Epoch 236/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0946 - accuracy: 0.2412 - val_loss: 2.0746 - val_accuracy: 0.2532\n",
      "Epoch 237/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1240 - accuracy: 0.2129 - val_loss: 2.0713 - val_accuracy: 0.2565\n",
      "Epoch 238/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0851 - accuracy: 0.2472 - val_loss: 2.0675 - val_accuracy: 0.2597\n",
      "Epoch 239/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1002 - accuracy: 0.2486 - val_loss: 2.0642 - val_accuracy: 0.2630\n",
      "Epoch 240/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1133 - accuracy: 0.2168 - val_loss: 2.0607 - val_accuracy: 0.2630\n",
      "Epoch 241/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1023 - accuracy: 0.2304 - val_loss: 2.0572 - val_accuracy: 0.2630\n",
      "Epoch 242/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0934 - accuracy: 0.2277 - val_loss: 2.0543 - val_accuracy: 0.2662\n",
      "Epoch 243/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1203 - accuracy: 0.2236 - val_loss: 2.0513 - val_accuracy: 0.2727\n",
      "Epoch 244/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1033 - accuracy: 0.2430 - val_loss: 2.0483 - val_accuracy: 0.2727\n",
      "Epoch 245/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1030 - accuracy: 0.2275 - val_loss: 2.0453 - val_accuracy: 0.2727\n",
      "Epoch 246/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0593 - accuracy: 0.2486 - val_loss: 2.0426 - val_accuracy: 0.2727\n",
      "Epoch 247/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0693 - accuracy: 0.2514 - val_loss: 2.0396 - val_accuracy: 0.2727\n",
      "Epoch 248/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1035 - accuracy: 0.2246 - val_loss: 2.0363 - val_accuracy: 0.2792\n",
      "Epoch 249/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0828 - accuracy: 0.2402 - val_loss: 2.0325 - val_accuracy: 0.2825\n",
      "Epoch 250/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1161 - accuracy: 0.2165 - val_loss: 2.0288 - val_accuracy: 0.2792\n",
      "Epoch 251/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0988 - accuracy: 0.2263 - val_loss: 2.0252 - val_accuracy: 0.2825\n",
      "Epoch 252/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1203 - accuracy: 0.2221 - val_loss: 2.0225 - val_accuracy: 0.2857\n",
      "Epoch 253/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0827 - accuracy: 0.2458 - val_loss: 2.0201 - val_accuracy: 0.2890\n",
      "Epoch 254/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0977 - accuracy: 0.2277 - val_loss: 2.0172 - val_accuracy: 0.2857\n",
      "Epoch 255/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0797 - accuracy: 0.2556 - val_loss: 2.0153 - val_accuracy: 0.2857\n",
      "Epoch 256/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0725 - accuracy: 0.2193 - val_loss: 2.0129 - val_accuracy: 0.2857\n",
      "Epoch 257/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0562 - accuracy: 0.2332 - val_loss: 2.0105 - val_accuracy: 0.2890\n",
      "Epoch 258/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0791 - accuracy: 0.2500 - val_loss: 2.0086 - val_accuracy: 0.2890\n",
      "Epoch 259/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0801 - accuracy: 0.2598 - val_loss: 2.0059 - val_accuracy: 0.2922\n",
      "Epoch 260/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1156 - accuracy: 0.2119 - val_loss: 2.0036 - val_accuracy: 0.2955\n",
      "Epoch 261/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0819 - accuracy: 0.2383 - val_loss: 2.0012 - val_accuracy: 0.3052\n",
      "Epoch 262/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0728 - accuracy: 0.2461 - val_loss: 1.9988 - val_accuracy: 0.3052\n",
      "Epoch 263/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0481 - accuracy: 0.2388 - val_loss: 1.9970 - val_accuracy: 0.3084\n",
      "Epoch 264/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0779 - accuracy: 0.2314 - val_loss: 1.9959 - val_accuracy: 0.3052\n",
      "Epoch 265/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0924 - accuracy: 0.2318 - val_loss: 1.9948 - val_accuracy: 0.3084\n",
      "Epoch 266/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0777 - accuracy: 0.2458 - val_loss: 1.9940 - val_accuracy: 0.3084\n",
      "Epoch 267/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0806 - accuracy: 0.2373 - val_loss: 1.9937 - val_accuracy: 0.3052\n",
      "Epoch 268/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0797 - accuracy: 0.2588 - val_loss: 1.9935 - val_accuracy: 0.3052\n",
      "Epoch 269/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0805 - accuracy: 0.2412 - val_loss: 1.9931 - val_accuracy: 0.3052\n",
      "Epoch 270/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0862 - accuracy: 0.2346 - val_loss: 1.9932 - val_accuracy: 0.3084\n",
      "Epoch 271/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0440 - accuracy: 0.2422 - val_loss: 1.9935 - val_accuracy: 0.3084\n",
      "Epoch 272/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0698 - accuracy: 0.2668 - val_loss: 1.9933 - val_accuracy: 0.3052\n",
      "Epoch 273/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0571 - accuracy: 0.2346 - val_loss: 1.9933 - val_accuracy: 0.2987\n",
      "Epoch 274/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0629 - accuracy: 0.2373 - val_loss: 1.9932 - val_accuracy: 0.2987\n",
      "Epoch 275/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0600 - accuracy: 0.2451 - val_loss: 1.9924 - val_accuracy: 0.2987\n",
      "Epoch 276/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0086 - accuracy: 0.2654 - val_loss: 1.9911 - val_accuracy: 0.3019\n",
      "Epoch 277/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0556 - accuracy: 0.2556 - val_loss: 1.9896 - val_accuracy: 0.2987\n",
      "Epoch 278/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0520 - accuracy: 0.2471 - val_loss: 1.9873 - val_accuracy: 0.3019\n",
      "Epoch 279/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0358 - accuracy: 0.2626 - val_loss: 1.9848 - val_accuracy: 0.3084\n",
      "Epoch 280/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0671 - accuracy: 0.2480 - val_loss: 1.9824 - val_accuracy: 0.3084\n",
      "Epoch 281/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0628 - accuracy: 0.2542 - val_loss: 1.9794 - val_accuracy: 0.3084\n",
      "Epoch 282/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0584 - accuracy: 0.2373 - val_loss: 1.9767 - val_accuracy: 0.3084\n",
      "Epoch 283/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0437 - accuracy: 0.2416 - val_loss: 1.9743 - val_accuracy: 0.3084\n",
      "Epoch 284/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0222 - accuracy: 0.2549 - val_loss: 1.9717 - val_accuracy: 0.3084\n",
      "Epoch 285/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0259 - accuracy: 0.2578 - val_loss: 1.9696 - val_accuracy: 0.3117\n",
      "Epoch 286/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0739 - accuracy: 0.2291 - val_loss: 1.9677 - val_accuracy: 0.3117\n",
      "Epoch 287/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0455 - accuracy: 0.2334 - val_loss: 1.9660 - val_accuracy: 0.3149\n",
      "Epoch 288/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0462 - accuracy: 0.2461 - val_loss: 1.9639 - val_accuracy: 0.3149\n",
      "Epoch 289/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0128 - accuracy: 0.2640 - val_loss: 1.9619 - val_accuracy: 0.3149\n",
      "Epoch 290/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0888 - accuracy: 0.2275 - val_loss: 1.9600 - val_accuracy: 0.3149\n",
      "Epoch 291/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0489 - accuracy: 0.2612 - val_loss: 1.9577 - val_accuracy: 0.3214\n",
      "Epoch 292/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0396 - accuracy: 0.2263 - val_loss: 1.9554 - val_accuracy: 0.3279\n",
      "Epoch 293/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0554 - accuracy: 0.2432 - val_loss: 1.9534 - val_accuracy: 0.3247\n",
      "Epoch 294/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0396 - accuracy: 0.2451 - val_loss: 1.9514 - val_accuracy: 0.3247\n",
      "Epoch 295/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0494 - accuracy: 0.2151 - val_loss: 1.9489 - val_accuracy: 0.3247\n",
      "Epoch 296/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0098 - accuracy: 0.2500 - val_loss: 1.9462 - val_accuracy: 0.3214\n",
      "Epoch 297/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0277 - accuracy: 0.2588 - val_loss: 1.9442 - val_accuracy: 0.3214\n",
      "Epoch 298/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0255 - accuracy: 0.2568 - val_loss: 1.9419 - val_accuracy: 0.3247\n",
      "Epoch 299/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0248 - accuracy: 0.2627 - val_loss: 1.9392 - val_accuracy: 0.3214\n",
      "Epoch 300/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9828 - accuracy: 0.2835 - val_loss: 1.9362 - val_accuracy: 0.3247\n",
      "Epoch 301/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0449 - accuracy: 0.2490 - val_loss: 1.9333 - val_accuracy: 0.3279\n",
      "Epoch 302/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0045 - accuracy: 0.2626 - val_loss: 1.9300 - val_accuracy: 0.3312\n",
      "Epoch 303/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0000 - accuracy: 0.2709 - val_loss: 1.9270 - val_accuracy: 0.3312\n",
      "Epoch 304/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0594 - accuracy: 0.2451 - val_loss: 1.9240 - val_accuracy: 0.3377\n",
      "Epoch 305/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0447 - accuracy: 0.2451 - val_loss: 1.9209 - val_accuracy: 0.3312\n",
      "Epoch 306/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0293 - accuracy: 0.2570 - val_loss: 1.9182 - val_accuracy: 0.3377\n",
      "Epoch 307/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0244 - accuracy: 0.2607 - val_loss: 1.9156 - val_accuracy: 0.3377\n",
      "Epoch 308/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0381 - accuracy: 0.2626 - val_loss: 1.9125 - val_accuracy: 0.3344\n",
      "Epoch 309/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0239 - accuracy: 0.2444 - val_loss: 1.9098 - val_accuracy: 0.3279\n",
      "Epoch 310/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0252 - accuracy: 0.2598 - val_loss: 1.9074 - val_accuracy: 0.3312\n",
      "Epoch 311/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0314 - accuracy: 0.2598 - val_loss: 1.9052 - val_accuracy: 0.3344\n",
      "Epoch 312/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0347 - accuracy: 0.2480 - val_loss: 1.9032 - val_accuracy: 0.3377\n",
      "Epoch 313/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0213 - accuracy: 0.2500 - val_loss: 1.9013 - val_accuracy: 0.3377\n",
      "Epoch 314/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0423 - accuracy: 0.2416 - val_loss: 1.8996 - val_accuracy: 0.3377\n",
      "Epoch 315/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0011 - accuracy: 0.2705 - val_loss: 1.8977 - val_accuracy: 0.3409\n",
      "Epoch 316/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9923 - accuracy: 0.2835 - val_loss: 1.8956 - val_accuracy: 0.3409\n",
      "Epoch 317/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0386 - accuracy: 0.2676 - val_loss: 1.8937 - val_accuracy: 0.3442\n",
      "Epoch 318/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9954 - accuracy: 0.2696 - val_loss: 1.8925 - val_accuracy: 0.3409\n",
      "Epoch 319/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0152 - accuracy: 0.2542 - val_loss: 1.8908 - val_accuracy: 0.3409\n",
      "Epoch 320/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0153 - accuracy: 0.2812 - val_loss: 1.8889 - val_accuracy: 0.3409\n",
      "Epoch 321/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0059 - accuracy: 0.2500 - val_loss: 1.8870 - val_accuracy: 0.3442\n",
      "Epoch 322/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9839 - accuracy: 0.2773 - val_loss: 1.8851 - val_accuracy: 0.3474\n",
      "Epoch 323/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9993 - accuracy: 0.2654 - val_loss: 1.8835 - val_accuracy: 0.3474\n",
      "Epoch 324/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9535 - accuracy: 0.2696 - val_loss: 1.8817 - val_accuracy: 0.3474\n",
      "Epoch 325/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9963 - accuracy: 0.2646 - val_loss: 1.8803 - val_accuracy: 0.3539\n",
      "Epoch 326/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9773 - accuracy: 0.2765 - val_loss: 1.8785 - val_accuracy: 0.3539\n",
      "Epoch 327/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9544 - accuracy: 0.2765 - val_loss: 1.8763 - val_accuracy: 0.3539\n",
      "Epoch 328/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0005 - accuracy: 0.2852 - val_loss: 1.8741 - val_accuracy: 0.3506\n",
      "Epoch 329/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9589 - accuracy: 0.2765 - val_loss: 1.8719 - val_accuracy: 0.3474\n",
      "Epoch 330/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9891 - accuracy: 0.2812 - val_loss: 1.8698 - val_accuracy: 0.3442\n",
      "Epoch 331/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9549 - accuracy: 0.2835 - val_loss: 1.8680 - val_accuracy: 0.3442\n",
      "Epoch 332/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9890 - accuracy: 0.2793 - val_loss: 1.8667 - val_accuracy: 0.3442\n",
      "Epoch 333/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0520 - accuracy: 0.2640 - val_loss: 1.8654 - val_accuracy: 0.3474\n",
      "Epoch 334/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0096 - accuracy: 0.2668 - val_loss: 1.8640 - val_accuracy: 0.3571\n",
      "Epoch 335/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0059 - accuracy: 0.2709 - val_loss: 1.8626 - val_accuracy: 0.3604\n",
      "Epoch 336/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9571 - accuracy: 0.2910 - val_loss: 1.8614 - val_accuracy: 0.3669\n",
      "Epoch 337/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9605 - accuracy: 0.2863 - val_loss: 1.8607 - val_accuracy: 0.3669\n",
      "Epoch 338/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9971 - accuracy: 0.2754 - val_loss: 1.8600 - val_accuracy: 0.3669\n",
      "Epoch 339/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9862 - accuracy: 0.2715 - val_loss: 1.8593 - val_accuracy: 0.3669\n",
      "Epoch 340/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9800 - accuracy: 0.2588 - val_loss: 1.8584 - val_accuracy: 0.3669\n",
      "Epoch 341/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9975 - accuracy: 0.2764 - val_loss: 1.8575 - val_accuracy: 0.3701\n",
      "Epoch 342/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9911 - accuracy: 0.2779 - val_loss: 1.8572 - val_accuracy: 0.3669\n",
      "Epoch 343/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9413 - accuracy: 0.2793 - val_loss: 1.8574 - val_accuracy: 0.3701\n",
      "Epoch 344/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9650 - accuracy: 0.2920 - val_loss: 1.8581 - val_accuracy: 0.3701\n",
      "Epoch 345/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9999 - accuracy: 0.2891 - val_loss: 1.8589 - val_accuracy: 0.3539\n",
      "Epoch 346/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9990 - accuracy: 0.2773 - val_loss: 1.8587 - val_accuracy: 0.3539\n",
      "Epoch 347/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9737 - accuracy: 0.2705 - val_loss: 1.8586 - val_accuracy: 0.3506\n",
      "Epoch 348/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9434 - accuracy: 0.2807 - val_loss: 1.8587 - val_accuracy: 0.3474\n",
      "Epoch 349/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9447 - accuracy: 0.2947 - val_loss: 1.8589 - val_accuracy: 0.3506\n",
      "Epoch 350/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9582 - accuracy: 0.3037 - val_loss: 1.8585 - val_accuracy: 0.3506\n",
      "Epoch 351/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9674 - accuracy: 0.2988 - val_loss: 1.8582 - val_accuracy: 0.3539\n",
      "Epoch 352/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9510 - accuracy: 0.2891 - val_loss: 1.8579 - val_accuracy: 0.3506\n",
      "Epoch 353/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9726 - accuracy: 0.2686 - val_loss: 1.8577 - val_accuracy: 0.3506\n",
      "Epoch 354/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9484 - accuracy: 0.2877 - val_loss: 1.8561 - val_accuracy: 0.3474\n",
      "Epoch 355/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9809 - accuracy: 0.2751 - val_loss: 1.8544 - val_accuracy: 0.3474\n",
      "Epoch 356/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9939 - accuracy: 0.2695 - val_loss: 1.8524 - val_accuracy: 0.3539\n",
      "Epoch 357/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9397 - accuracy: 0.2821 - val_loss: 1.8506 - val_accuracy: 0.3571\n",
      "Epoch 358/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9535 - accuracy: 0.2975 - val_loss: 1.8487 - val_accuracy: 0.3571\n",
      "Epoch 359/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9550 - accuracy: 0.2861 - val_loss: 1.8468 - val_accuracy: 0.3539\n",
      "Epoch 360/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9286 - accuracy: 0.2959 - val_loss: 1.8452 - val_accuracy: 0.3539\n",
      "Epoch 361/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9754 - accuracy: 0.2737 - val_loss: 1.8439 - val_accuracy: 0.3539\n",
      "Epoch 362/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9472 - accuracy: 0.2930 - val_loss: 1.8429 - val_accuracy: 0.3506\n",
      "Epoch 363/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9797 - accuracy: 0.2822 - val_loss: 1.8422 - val_accuracy: 0.3539\n",
      "Epoch 364/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9927 - accuracy: 0.2696 - val_loss: 1.8425 - val_accuracy: 0.3539\n",
      "Epoch 365/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9455 - accuracy: 0.2877 - val_loss: 1.8420 - val_accuracy: 0.3442\n",
      "Epoch 366/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9382 - accuracy: 0.3047 - val_loss: 1.8423 - val_accuracy: 0.3506\n",
      "Epoch 367/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9277 - accuracy: 0.2877 - val_loss: 1.8427 - val_accuracy: 0.3474\n",
      "Epoch 368/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9952 - accuracy: 0.2961 - val_loss: 1.8434 - val_accuracy: 0.3506\n",
      "Epoch 369/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9678 - accuracy: 0.3073 - val_loss: 1.8433 - val_accuracy: 0.3506\n",
      "Epoch 370/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9726 - accuracy: 0.2849 - val_loss: 1.8433 - val_accuracy: 0.3474\n",
      "Epoch 371/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9246 - accuracy: 0.2812 - val_loss: 1.8429 - val_accuracy: 0.3474\n",
      "Epoch 372/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9261 - accuracy: 0.2919 - val_loss: 1.8427 - val_accuracy: 0.3506\n",
      "Epoch 373/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9329 - accuracy: 0.3212 - val_loss: 1.8423 - val_accuracy: 0.3506\n",
      "Epoch 374/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8883 - accuracy: 0.3142 - val_loss: 1.8417 - val_accuracy: 0.3571\n",
      "Epoch 375/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9271 - accuracy: 0.2822 - val_loss: 1.8421 - val_accuracy: 0.3539\n",
      "Epoch 376/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9685 - accuracy: 0.2773 - val_loss: 1.8424 - val_accuracy: 0.3474\n",
      "Epoch 377/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9721 - accuracy: 0.2695 - val_loss: 1.8417 - val_accuracy: 0.3377\n",
      "Epoch 378/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9083 - accuracy: 0.3008 - val_loss: 1.8408 - val_accuracy: 0.3442\n",
      "Epoch 379/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9955 - accuracy: 0.2490 - val_loss: 1.8402 - val_accuracy: 0.3474\n",
      "Epoch 380/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9398 - accuracy: 0.2910 - val_loss: 1.8398 - val_accuracy: 0.3539\n",
      "Epoch 381/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9353 - accuracy: 0.2598 - val_loss: 1.8387 - val_accuracy: 0.3442\n",
      "Epoch 382/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9358 - accuracy: 0.2849 - val_loss: 1.8369 - val_accuracy: 0.3474\n",
      "Epoch 383/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9614 - accuracy: 0.2988 - val_loss: 1.8341 - val_accuracy: 0.3604\n",
      "Epoch 384/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9227 - accuracy: 0.3125 - val_loss: 1.8326 - val_accuracy: 0.3636\n",
      "Epoch 385/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9161 - accuracy: 0.2947 - val_loss: 1.8311 - val_accuracy: 0.3604\n",
      "Epoch 386/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9448 - accuracy: 0.2919 - val_loss: 1.8293 - val_accuracy: 0.3571\n",
      "Epoch 387/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9263 - accuracy: 0.3128 - val_loss: 1.8270 - val_accuracy: 0.3571\n",
      "Epoch 388/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9316 - accuracy: 0.2919 - val_loss: 1.8235 - val_accuracy: 0.3539\n",
      "Epoch 389/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9325 - accuracy: 0.2765 - val_loss: 1.8206 - val_accuracy: 0.3506\n",
      "Epoch 390/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9410 - accuracy: 0.3003 - val_loss: 1.8192 - val_accuracy: 0.3506\n",
      "Epoch 391/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9161 - accuracy: 0.3115 - val_loss: 1.8181 - val_accuracy: 0.3474\n",
      "Epoch 392/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.9065 - accuracy: 0.3073 - val_loss: 1.8180 - val_accuracy: 0.3442\n",
      "Epoch 393/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9596 - accuracy: 0.2861 - val_loss: 1.8176 - val_accuracy: 0.3474\n",
      "Epoch 394/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9255 - accuracy: 0.3031 - val_loss: 1.8173 - val_accuracy: 0.3442\n",
      "Epoch 395/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8801 - accuracy: 0.3268 - val_loss: 1.8183 - val_accuracy: 0.3474\n",
      "Epoch 396/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9085 - accuracy: 0.2807 - val_loss: 1.8201 - val_accuracy: 0.3474\n",
      "Epoch 397/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9141 - accuracy: 0.3057 - val_loss: 1.8218 - val_accuracy: 0.3442\n",
      "Epoch 398/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8977 - accuracy: 0.3174 - val_loss: 1.8225 - val_accuracy: 0.3442\n",
      "Epoch 399/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8875 - accuracy: 0.3096 - val_loss: 1.8223 - val_accuracy: 0.3377\n",
      "Epoch 400/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9010 - accuracy: 0.2989 - val_loss: 1.8206 - val_accuracy: 0.3377\n",
      "Epoch 401/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9063 - accuracy: 0.3076 - val_loss: 1.8186 - val_accuracy: 0.3377\n",
      "Epoch 402/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9480 - accuracy: 0.3008 - val_loss: 1.8158 - val_accuracy: 0.3344\n",
      "Epoch 403/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9268 - accuracy: 0.2793 - val_loss: 1.8129 - val_accuracy: 0.3377\n",
      "Epoch 404/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8918 - accuracy: 0.3252 - val_loss: 1.8107 - val_accuracy: 0.3344\n",
      "Epoch 405/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9472 - accuracy: 0.2696 - val_loss: 1.8092 - val_accuracy: 0.3312\n",
      "Epoch 406/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8684 - accuracy: 0.3213 - val_loss: 1.8075 - val_accuracy: 0.3344\n",
      "Epoch 407/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9073 - accuracy: 0.2891 - val_loss: 1.8057 - val_accuracy: 0.3344\n",
      "Epoch 408/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8962 - accuracy: 0.2919 - val_loss: 1.8036 - val_accuracy: 0.3409\n",
      "Epoch 409/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9189 - accuracy: 0.3128 - val_loss: 1.8019 - val_accuracy: 0.3409\n",
      "Epoch 410/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8658 - accuracy: 0.3296 - val_loss: 1.8021 - val_accuracy: 0.3442\n",
      "Epoch 411/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9183 - accuracy: 0.3066 - val_loss: 1.8034 - val_accuracy: 0.3442\n",
      "Epoch 412/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8913 - accuracy: 0.3203 - val_loss: 1.8046 - val_accuracy: 0.3442\n",
      "Epoch 413/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8446 - accuracy: 0.3422 - val_loss: 1.8044 - val_accuracy: 0.3409\n",
      "Epoch 414/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9138 - accuracy: 0.3115 - val_loss: 1.8053 - val_accuracy: 0.3474\n",
      "Epoch 415/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8883 - accuracy: 0.3254 - val_loss: 1.8054 - val_accuracy: 0.3506\n",
      "Epoch 416/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8969 - accuracy: 0.3018 - val_loss: 1.8058 - val_accuracy: 0.3539\n",
      "Epoch 417/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8922 - accuracy: 0.3174 - val_loss: 1.8056 - val_accuracy: 0.3571\n",
      "Epoch 418/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9302 - accuracy: 0.2979 - val_loss: 1.8052 - val_accuracy: 0.3571\n",
      "Epoch 419/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9076 - accuracy: 0.3045 - val_loss: 1.8053 - val_accuracy: 0.3604\n",
      "Epoch 420/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8810 - accuracy: 0.3115 - val_loss: 1.8071 - val_accuracy: 0.3474\n",
      "Epoch 421/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8740 - accuracy: 0.3154 - val_loss: 1.8124 - val_accuracy: 0.3409\n",
      "Epoch 422/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8824 - accuracy: 0.3066 - val_loss: 1.8188 - val_accuracy: 0.3312\n",
      "Epoch 423/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8842 - accuracy: 0.3184 - val_loss: 1.8254 - val_accuracy: 0.3409\n",
      "Epoch 424/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8933 - accuracy: 0.3128 - val_loss: 1.8320 - val_accuracy: 0.3442\n",
      "Epoch 425/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8834 - accuracy: 0.2863 - val_loss: 1.8393 - val_accuracy: 0.3377\n",
      "Epoch 426/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8840 - accuracy: 0.3296 - val_loss: 1.8454 - val_accuracy: 0.3409\n",
      "Epoch 427/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8881 - accuracy: 0.2975 - val_loss: 1.8513 - val_accuracy: 0.3377\n",
      "Epoch 428/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8968 - accuracy: 0.3254 - val_loss: 1.8560 - val_accuracy: 0.3344\n",
      "Epoch 429/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8623 - accuracy: 0.3240 - val_loss: 1.8570 - val_accuracy: 0.3344\n",
      "Epoch 430/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8365 - accuracy: 0.3394 - val_loss: 1.8578 - val_accuracy: 0.3344\n",
      "Epoch 431/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8770 - accuracy: 0.3017 - val_loss: 1.8606 - val_accuracy: 0.3442\n",
      "Epoch 432/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8551 - accuracy: 0.3223 - val_loss: 1.8626 - val_accuracy: 0.3409\n",
      "Epoch 433/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9068 - accuracy: 0.2975 - val_loss: 1.8629 - val_accuracy: 0.3377\n",
      "Epoch 434/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8600 - accuracy: 0.2961 - val_loss: 1.8640 - val_accuracy: 0.3442\n",
      "Epoch 435/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8897 - accuracy: 0.3045 - val_loss: 1.8639 - val_accuracy: 0.3409\n",
      "Epoch 436/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8355 - accuracy: 0.3226 - val_loss: 1.8623 - val_accuracy: 0.3506\n",
      "Epoch 437/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8581 - accuracy: 0.3242 - val_loss: 1.8601 - val_accuracy: 0.3506\n",
      "Epoch 438/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8511 - accuracy: 0.3492 - val_loss: 1.8577 - val_accuracy: 0.3506\n",
      "Epoch 439/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8709 - accuracy: 0.3268 - val_loss: 1.8535 - val_accuracy: 0.3539\n",
      "Epoch 440/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8920 - accuracy: 0.3340 - val_loss: 1.8518 - val_accuracy: 0.3571\n",
      "Epoch 441/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8658 - accuracy: 0.3125 - val_loss: 1.8503 - val_accuracy: 0.3474\n",
      "Epoch 442/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8687 - accuracy: 0.3184 - val_loss: 1.8494 - val_accuracy: 0.3442\n",
      "Epoch 443/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8975 - accuracy: 0.3156 - val_loss: 1.8475 - val_accuracy: 0.3442\n",
      "Epoch 444/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8763 - accuracy: 0.3184 - val_loss: 1.8466 - val_accuracy: 0.3442\n",
      "Epoch 445/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8470 - accuracy: 0.3311 - val_loss: 1.8444 - val_accuracy: 0.3409\n",
      "Epoch 446/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8536 - accuracy: 0.3320 - val_loss: 1.8414 - val_accuracy: 0.3409\n",
      "Epoch 447/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8940 - accuracy: 0.3057 - val_loss: 1.8354 - val_accuracy: 0.3377\n",
      "Epoch 448/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8440 - accuracy: 0.3436 - val_loss: 1.8288 - val_accuracy: 0.3474\n",
      "Epoch 449/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9002 - accuracy: 0.3008 - val_loss: 1.8236 - val_accuracy: 0.3506\n",
      "Epoch 450/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7917 - accuracy: 0.3447 - val_loss: 1.8187 - val_accuracy: 0.3539\n",
      "Epoch 451/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8829 - accuracy: 0.3226 - val_loss: 1.8188 - val_accuracy: 0.3604\n",
      "Epoch 452/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8578 - accuracy: 0.3324 - val_loss: 1.8170 - val_accuracy: 0.3636\n",
      "Epoch 453/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8481 - accuracy: 0.3350 - val_loss: 1.8149 - val_accuracy: 0.3604\n",
      "Epoch 454/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8577 - accuracy: 0.3203 - val_loss: 1.8114 - val_accuracy: 0.3604\n",
      "Epoch 455/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8583 - accuracy: 0.3589 - val_loss: 1.8093 - val_accuracy: 0.3669\n",
      "Epoch 456/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8264 - accuracy: 0.3296 - val_loss: 1.8053 - val_accuracy: 0.3604\n",
      "Epoch 457/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8083 - accuracy: 0.3359 - val_loss: 1.8047 - val_accuracy: 0.3636\n",
      "Epoch 458/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8524 - accuracy: 0.3394 - val_loss: 1.8032 - val_accuracy: 0.3604\n",
      "Epoch 459/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8776 - accuracy: 0.3212 - val_loss: 1.8046 - val_accuracy: 0.3604\n",
      "Epoch 460/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8629 - accuracy: 0.3301 - val_loss: 1.8085 - val_accuracy: 0.3604\n",
      "Epoch 461/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8264 - accuracy: 0.3379 - val_loss: 1.8104 - val_accuracy: 0.3571\n",
      "Epoch 462/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8559 - accuracy: 0.3073 - val_loss: 1.8134 - val_accuracy: 0.3604\n",
      "Epoch 463/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8730 - accuracy: 0.3301 - val_loss: 1.8128 - val_accuracy: 0.3669\n",
      "Epoch 464/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8597 - accuracy: 0.3115 - val_loss: 1.8094 - val_accuracy: 0.3734\n",
      "Epoch 465/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8641 - accuracy: 0.3232 - val_loss: 1.8037 - val_accuracy: 0.3701\n",
      "Epoch 466/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8560 - accuracy: 0.3310 - val_loss: 1.7978 - val_accuracy: 0.3734\n",
      "Epoch 467/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8111 - accuracy: 0.3389 - val_loss: 1.7955 - val_accuracy: 0.3734\n",
      "Epoch 468/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8004 - accuracy: 0.3643 - val_loss: 1.7922 - val_accuracy: 0.3734\n",
      "Epoch 469/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8318 - accuracy: 0.3366 - val_loss: 1.7886 - val_accuracy: 0.3734\n",
      "Epoch 470/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8958 - accuracy: 0.3142 - val_loss: 1.7882 - val_accuracy: 0.3799\n",
      "Epoch 471/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8146 - accuracy: 0.3535 - val_loss: 1.7869 - val_accuracy: 0.3766\n",
      "Epoch 472/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8420 - accuracy: 0.3359 - val_loss: 1.7819 - val_accuracy: 0.3831\n",
      "Epoch 473/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8736 - accuracy: 0.3223 - val_loss: 1.7812 - val_accuracy: 0.3831\n",
      "Epoch 474/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8617 - accuracy: 0.3154 - val_loss: 1.7799 - val_accuracy: 0.3896\n",
      "Epoch 475/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8009 - accuracy: 0.3525 - val_loss: 1.7772 - val_accuracy: 0.3864\n",
      "Epoch 476/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7664 - accuracy: 0.3855 - val_loss: 1.7766 - val_accuracy: 0.3831\n",
      "Epoch 477/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8544 - accuracy: 0.3418 - val_loss: 1.7804 - val_accuracy: 0.3831\n",
      "Epoch 478/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8332 - accuracy: 0.3394 - val_loss: 1.7867 - val_accuracy: 0.3734\n",
      "Epoch 479/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8566 - accuracy: 0.3164 - val_loss: 1.7923 - val_accuracy: 0.3669\n",
      "Epoch 480/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7948 - accuracy: 0.3506 - val_loss: 1.7968 - val_accuracy: 0.3669\n",
      "Epoch 481/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8510 - accuracy: 0.3324 - val_loss: 1.7996 - val_accuracy: 0.3636\n",
      "Epoch 482/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8282 - accuracy: 0.3226 - val_loss: 1.7990 - val_accuracy: 0.3539\n",
      "Epoch 483/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8268 - accuracy: 0.3340 - val_loss: 1.7980 - val_accuracy: 0.3506\n",
      "Epoch 484/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8206 - accuracy: 0.3380 - val_loss: 1.7956 - val_accuracy: 0.3539\n",
      "Epoch 485/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8415 - accuracy: 0.3226 - val_loss: 1.7881 - val_accuracy: 0.3506\n",
      "Epoch 486/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8145 - accuracy: 0.3398 - val_loss: 1.7828 - val_accuracy: 0.3539\n",
      "Epoch 487/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8073 - accuracy: 0.3450 - val_loss: 1.7773 - val_accuracy: 0.3539\n",
      "Epoch 488/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8636 - accuracy: 0.3296 - val_loss: 1.7735 - val_accuracy: 0.3604\n",
      "Epoch 489/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8207 - accuracy: 0.3478 - val_loss: 1.7697 - val_accuracy: 0.3701\n",
      "Epoch 490/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7944 - accuracy: 0.3352 - val_loss: 1.7680 - val_accuracy: 0.3734\n",
      "Epoch 491/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8106 - accuracy: 0.3545 - val_loss: 1.7699 - val_accuracy: 0.3636\n",
      "Epoch 492/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7820 - accuracy: 0.3645 - val_loss: 1.7717 - val_accuracy: 0.3636\n",
      "Epoch 493/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7965 - accuracy: 0.3545 - val_loss: 1.7724 - val_accuracy: 0.3669\n",
      "Epoch 494/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8038 - accuracy: 0.3545 - val_loss: 1.7743 - val_accuracy: 0.3604\n",
      "Epoch 495/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8015 - accuracy: 0.3311 - val_loss: 1.7737 - val_accuracy: 0.3669\n",
      "Epoch 496/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8159 - accuracy: 0.3645 - val_loss: 1.7705 - val_accuracy: 0.3701\n",
      "Epoch 497/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7747 - accuracy: 0.3506 - val_loss: 1.7701 - val_accuracy: 0.3701\n",
      "Epoch 498/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7997 - accuracy: 0.3366 - val_loss: 1.7712 - val_accuracy: 0.3766\n",
      "Epoch 499/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8252 - accuracy: 0.3408 - val_loss: 1.7723 - val_accuracy: 0.3766\n",
      "Epoch 500/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7924 - accuracy: 0.3603 - val_loss: 1.7711 - val_accuracy: 0.3701\n",
      "Epoch 501/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7998 - accuracy: 0.3623 - val_loss: 1.7697 - val_accuracy: 0.3701\n",
      "Epoch 502/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7461 - accuracy: 0.3673 - val_loss: 1.7696 - val_accuracy: 0.3766\n",
      "Epoch 503/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8202 - accuracy: 0.3428 - val_loss: 1.7699 - val_accuracy: 0.3799\n",
      "Epoch 504/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7757 - accuracy: 0.3575 - val_loss: 1.7747 - val_accuracy: 0.3799\n",
      "Epoch 505/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7889 - accuracy: 0.3438 - val_loss: 1.7793 - val_accuracy: 0.3929\n",
      "Epoch 506/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8505 - accuracy: 0.3457 - val_loss: 1.7849 - val_accuracy: 0.3929\n",
      "Epoch 507/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7454 - accuracy: 0.3613 - val_loss: 1.7914 - val_accuracy: 0.3864\n",
      "Epoch 508/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7862 - accuracy: 0.3659 - val_loss: 1.7917 - val_accuracy: 0.3766\n",
      "Epoch 509/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7821 - accuracy: 0.3574 - val_loss: 1.7896 - val_accuracy: 0.3799\n",
      "Epoch 510/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7747 - accuracy: 0.3827 - val_loss: 1.7916 - val_accuracy: 0.3831\n",
      "Epoch 511/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7877 - accuracy: 0.3394 - val_loss: 1.7981 - val_accuracy: 0.3831\n",
      "Epoch 512/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7930 - accuracy: 0.3301 - val_loss: 1.7987 - val_accuracy: 0.3864\n",
      "Epoch 513/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7948 - accuracy: 0.3589 - val_loss: 1.7977 - val_accuracy: 0.3799\n",
      "Epoch 514/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7508 - accuracy: 0.3841 - val_loss: 1.7888 - val_accuracy: 0.3799\n",
      "Epoch 515/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8231 - accuracy: 0.3633 - val_loss: 1.7782 - val_accuracy: 0.3799\n",
      "Epoch 516/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7667 - accuracy: 0.3613 - val_loss: 1.7692 - val_accuracy: 0.3864\n",
      "Epoch 517/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7579 - accuracy: 0.3662 - val_loss: 1.7585 - val_accuracy: 0.3929\n",
      "Epoch 518/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7807 - accuracy: 0.3877 - val_loss: 1.7494 - val_accuracy: 0.3994\n",
      "Epoch 519/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8183 - accuracy: 0.3575 - val_loss: 1.7454 - val_accuracy: 0.3961\n",
      "Epoch 520/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7888 - accuracy: 0.3506 - val_loss: 1.7421 - val_accuracy: 0.4026\n",
      "Epoch 521/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7857 - accuracy: 0.3545 - val_loss: 1.7419 - val_accuracy: 0.4058\n",
      "Epoch 522/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7937 - accuracy: 0.3564 - val_loss: 1.7420 - val_accuracy: 0.4058\n",
      "Epoch 523/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7209 - accuracy: 0.3760 - val_loss: 1.7473 - val_accuracy: 0.4058\n",
      "Epoch 524/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7500 - accuracy: 0.3715 - val_loss: 1.7538 - val_accuracy: 0.4026\n",
      "Epoch 525/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7649 - accuracy: 0.3623 - val_loss: 1.7567 - val_accuracy: 0.3929\n",
      "Epoch 526/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7615 - accuracy: 0.3701 - val_loss: 1.7585 - val_accuracy: 0.3961\n",
      "Epoch 527/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7256 - accuracy: 0.3827 - val_loss: 1.7574 - val_accuracy: 0.3896\n",
      "Epoch 528/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7641 - accuracy: 0.3561 - val_loss: 1.7580 - val_accuracy: 0.3896\n",
      "Epoch 529/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8166 - accuracy: 0.3324 - val_loss: 1.7620 - val_accuracy: 0.3831\n",
      "Epoch 530/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7592 - accuracy: 0.3643 - val_loss: 1.7665 - val_accuracy: 0.3896\n",
      "Epoch 531/4000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.7779 - accuracy: 0.3691 - val_loss: 1.7733 - val_accuracy: 0.3929\n",
      "Epoch 532/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7917 - accuracy: 0.3547 - val_loss: 1.7799 - val_accuracy: 0.3766\n",
      "Epoch 533/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7314 - accuracy: 0.3623 - val_loss: 1.7833 - val_accuracy: 0.3734\n",
      "Epoch 534/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7458 - accuracy: 0.3545 - val_loss: 1.7897 - val_accuracy: 0.3701\n",
      "Epoch 535/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7813 - accuracy: 0.3682 - val_loss: 1.7934 - val_accuracy: 0.3571\n",
      "Epoch 536/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7974 - accuracy: 0.3545 - val_loss: 1.7980 - val_accuracy: 0.3571\n",
      "Epoch 537/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7621 - accuracy: 0.3687 - val_loss: 1.7912 - val_accuracy: 0.3539\n",
      "Epoch 538/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7576 - accuracy: 0.3623 - val_loss: 1.7842 - val_accuracy: 0.3571\n",
      "Epoch 539/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7553 - accuracy: 0.3603 - val_loss: 1.7714 - val_accuracy: 0.3604\n",
      "Epoch 540/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7355 - accuracy: 0.3785 - val_loss: 1.7638 - val_accuracy: 0.3571\n",
      "Epoch 541/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7588 - accuracy: 0.3603 - val_loss: 1.7515 - val_accuracy: 0.3669\n",
      "Epoch 542/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7852 - accuracy: 0.3506 - val_loss: 1.7394 - val_accuracy: 0.3701\n",
      "Epoch 543/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7214 - accuracy: 0.3818 - val_loss: 1.7276 - val_accuracy: 0.3701\n",
      "Epoch 544/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7153 - accuracy: 0.3771 - val_loss: 1.7180 - val_accuracy: 0.3734\n",
      "Epoch 545/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7467 - accuracy: 0.3687 - val_loss: 1.7093 - val_accuracy: 0.3766\n",
      "Epoch 546/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7987 - accuracy: 0.3715 - val_loss: 1.7081 - val_accuracy: 0.3864\n",
      "Epoch 547/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7348 - accuracy: 0.3827 - val_loss: 1.7091 - val_accuracy: 0.3896\n",
      "Epoch 548/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7409 - accuracy: 0.3750 - val_loss: 1.7157 - val_accuracy: 0.3864\n",
      "Epoch 549/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7478 - accuracy: 0.3662 - val_loss: 1.7222 - val_accuracy: 0.3929\n",
      "Epoch 550/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7613 - accuracy: 0.3883 - val_loss: 1.7329 - val_accuracy: 0.3831\n",
      "Epoch 551/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7600 - accuracy: 0.3926 - val_loss: 1.7500 - val_accuracy: 0.3669\n",
      "Epoch 552/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7130 - accuracy: 0.3799 - val_loss: 1.7676 - val_accuracy: 0.3636\n",
      "Epoch 553/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7134 - accuracy: 0.3779 - val_loss: 1.7839 - val_accuracy: 0.3506\n",
      "Epoch 554/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7428 - accuracy: 0.3711 - val_loss: 1.7935 - val_accuracy: 0.3442\n",
      "Epoch 555/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7343 - accuracy: 0.3613 - val_loss: 1.7928 - val_accuracy: 0.3506\n",
      "Epoch 556/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7138 - accuracy: 0.3883 - val_loss: 1.7862 - val_accuracy: 0.3539\n",
      "Epoch 557/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7365 - accuracy: 0.3828 - val_loss: 1.7790 - val_accuracy: 0.3669\n",
      "Epoch 558/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7590 - accuracy: 0.3869 - val_loss: 1.7659 - val_accuracy: 0.3701\n",
      "Epoch 559/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7145 - accuracy: 0.3799 - val_loss: 1.7487 - val_accuracy: 0.3766\n",
      "Epoch 560/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7828 - accuracy: 0.3561 - val_loss: 1.7287 - val_accuracy: 0.3766\n",
      "Epoch 561/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7297 - accuracy: 0.3841 - val_loss: 1.7048 - val_accuracy: 0.3994\n",
      "Epoch 562/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7589 - accuracy: 0.3564 - val_loss: 1.6893 - val_accuracy: 0.3961\n",
      "Epoch 563/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6991 - accuracy: 0.4064 - val_loss: 1.6819 - val_accuracy: 0.3961\n",
      "Epoch 564/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7228 - accuracy: 0.3701 - val_loss: 1.6746 - val_accuracy: 0.4026\n",
      "Epoch 565/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.7471 - accuracy: 0.3799 - val_loss: 1.6689 - val_accuracy: 0.4091\n",
      "Epoch 566/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7440 - accuracy: 0.3740 - val_loss: 1.6683 - val_accuracy: 0.4188\n",
      "Epoch 567/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7205 - accuracy: 0.3897 - val_loss: 1.6759 - val_accuracy: 0.4058\n",
      "Epoch 568/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7970 - accuracy: 0.3575 - val_loss: 1.6833 - val_accuracy: 0.3994\n",
      "Epoch 569/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7093 - accuracy: 0.3818 - val_loss: 1.6889 - val_accuracy: 0.3961\n",
      "Epoch 570/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7370 - accuracy: 0.3809 - val_loss: 1.6954 - val_accuracy: 0.3929\n",
      "Epoch 571/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7134 - accuracy: 0.3848 - val_loss: 1.7006 - val_accuracy: 0.3961\n",
      "Epoch 572/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7228 - accuracy: 0.3730 - val_loss: 1.7113 - val_accuracy: 0.3961\n",
      "Epoch 573/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7321 - accuracy: 0.3682 - val_loss: 1.7224 - val_accuracy: 0.3929\n",
      "Epoch 574/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6684 - accuracy: 0.3841 - val_loss: 1.7364 - val_accuracy: 0.3929\n",
      "Epoch 575/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7624 - accuracy: 0.3855 - val_loss: 1.7542 - val_accuracy: 0.3734\n",
      "Epoch 576/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7189 - accuracy: 0.3838 - val_loss: 1.7671 - val_accuracy: 0.3669\n",
      "Epoch 577/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7412 - accuracy: 0.3925 - val_loss: 1.7671 - val_accuracy: 0.3701\n",
      "Epoch 578/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7068 - accuracy: 0.4008 - val_loss: 1.7639 - val_accuracy: 0.3604\n",
      "Epoch 579/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7091 - accuracy: 0.3883 - val_loss: 1.7634 - val_accuracy: 0.3636\n",
      "Epoch 580/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7340 - accuracy: 0.3757 - val_loss: 1.7624 - val_accuracy: 0.3734\n",
      "Epoch 581/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6879 - accuracy: 0.3877 - val_loss: 1.7544 - val_accuracy: 0.3864\n",
      "Epoch 582/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6881 - accuracy: 0.3945 - val_loss: 1.7478 - val_accuracy: 0.3864\n",
      "Epoch 583/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.7315 - accuracy: 0.3789 - val_loss: 1.7498 - val_accuracy: 0.3766\n",
      "Epoch 584/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6798 - accuracy: 0.3682 - val_loss: 1.7493 - val_accuracy: 0.3701\n",
      "Epoch 585/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7261 - accuracy: 0.3799 - val_loss: 1.7448 - val_accuracy: 0.3669\n",
      "Epoch 586/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7184 - accuracy: 0.3799 - val_loss: 1.7394 - val_accuracy: 0.3734\n",
      "Epoch 587/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6941 - accuracy: 0.3911 - val_loss: 1.7376 - val_accuracy: 0.3864\n",
      "Epoch 588/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7525 - accuracy: 0.4050 - val_loss: 1.7329 - val_accuracy: 0.3994\n",
      "Epoch 589/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7219 - accuracy: 0.3799 - val_loss: 1.7374 - val_accuracy: 0.3961\n",
      "Epoch 590/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7002 - accuracy: 0.3799 - val_loss: 1.7442 - val_accuracy: 0.3929\n",
      "Epoch 591/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7481 - accuracy: 0.3939 - val_loss: 1.7491 - val_accuracy: 0.3929\n",
      "Epoch 592/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7025 - accuracy: 0.3955 - val_loss: 1.7480 - val_accuracy: 0.3896\n",
      "Epoch 593/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6981 - accuracy: 0.3965 - val_loss: 1.7434 - val_accuracy: 0.3994\n",
      "Epoch 594/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6890 - accuracy: 0.3715 - val_loss: 1.7278 - val_accuracy: 0.4123\n",
      "Epoch 595/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6764 - accuracy: 0.3848 - val_loss: 1.7149 - val_accuracy: 0.4351\n",
      "Epoch 596/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6944 - accuracy: 0.3984 - val_loss: 1.7054 - val_accuracy: 0.4383\n",
      "Epoch 597/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7222 - accuracy: 0.3855 - val_loss: 1.7011 - val_accuracy: 0.4448\n",
      "Epoch 598/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6766 - accuracy: 0.4008 - val_loss: 1.6940 - val_accuracy: 0.4318\n",
      "Epoch 599/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6734 - accuracy: 0.3925 - val_loss: 1.6840 - val_accuracy: 0.4156\n",
      "Epoch 600/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6755 - accuracy: 0.4014 - val_loss: 1.6777 - val_accuracy: 0.4156\n",
      "Epoch 601/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6798 - accuracy: 0.4053 - val_loss: 1.6746 - val_accuracy: 0.4221\n",
      "Epoch 602/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6707 - accuracy: 0.3994 - val_loss: 1.6743 - val_accuracy: 0.4123\n",
      "Epoch 603/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6608 - accuracy: 0.3715 - val_loss: 1.6758 - val_accuracy: 0.4123\n",
      "Epoch 604/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6829 - accuracy: 0.4092 - val_loss: 1.6696 - val_accuracy: 0.4156\n",
      "Epoch 605/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6842 - accuracy: 0.3740 - val_loss: 1.6661 - val_accuracy: 0.4156\n",
      "Epoch 606/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7011 - accuracy: 0.3785 - val_loss: 1.6641 - val_accuracy: 0.4156\n",
      "Epoch 607/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7208 - accuracy: 0.3994 - val_loss: 1.6600 - val_accuracy: 0.4156\n",
      "Epoch 608/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6888 - accuracy: 0.3939 - val_loss: 1.6521 - val_accuracy: 0.4188\n",
      "Epoch 609/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6762 - accuracy: 0.3955 - val_loss: 1.6456 - val_accuracy: 0.4156\n",
      "Epoch 610/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6581 - accuracy: 0.3771 - val_loss: 1.6384 - val_accuracy: 0.4123\n",
      "Epoch 611/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7205 - accuracy: 0.3869 - val_loss: 1.6354 - val_accuracy: 0.4156\n",
      "Epoch 612/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6656 - accuracy: 0.3925 - val_loss: 1.6401 - val_accuracy: 0.4123\n",
      "Epoch 613/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6885 - accuracy: 0.3855 - val_loss: 1.6445 - val_accuracy: 0.4058\n",
      "Epoch 614/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6498 - accuracy: 0.4131 - val_loss: 1.6476 - val_accuracy: 0.4058\n",
      "Epoch 615/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6637 - accuracy: 0.4092 - val_loss: 1.6487 - val_accuracy: 0.4156\n",
      "Epoch 616/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6697 - accuracy: 0.3975 - val_loss: 1.6455 - val_accuracy: 0.4123\n",
      "Epoch 617/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6582 - accuracy: 0.3945 - val_loss: 1.6469 - val_accuracy: 0.4091\n",
      "Epoch 618/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6783 - accuracy: 0.3729 - val_loss: 1.6429 - val_accuracy: 0.4091\n",
      "Epoch 619/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6634 - accuracy: 0.4082 - val_loss: 1.6411 - val_accuracy: 0.4091\n",
      "Epoch 620/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6352 - accuracy: 0.4268 - val_loss: 1.6461 - val_accuracy: 0.4058\n",
      "Epoch 621/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6208 - accuracy: 0.4274 - val_loss: 1.6506 - val_accuracy: 0.4026\n",
      "Epoch 622/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6067 - accuracy: 0.4248 - val_loss: 1.6506 - val_accuracy: 0.3961\n",
      "Epoch 623/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6125 - accuracy: 0.4148 - val_loss: 1.6433 - val_accuracy: 0.4026\n",
      "Epoch 624/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6824 - accuracy: 0.3785 - val_loss: 1.6374 - val_accuracy: 0.4058\n",
      "Epoch 625/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6609 - accuracy: 0.3953 - val_loss: 1.6378 - val_accuracy: 0.4091\n",
      "Epoch 626/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6794 - accuracy: 0.3911 - val_loss: 1.6330 - val_accuracy: 0.4156\n",
      "Epoch 627/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6312 - accuracy: 0.4218 - val_loss: 1.6296 - val_accuracy: 0.4286\n",
      "Epoch 628/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6682 - accuracy: 0.3926 - val_loss: 1.6319 - val_accuracy: 0.4286\n",
      "Epoch 629/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6551 - accuracy: 0.4053 - val_loss: 1.6304 - val_accuracy: 0.4286\n",
      "Epoch 630/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6635 - accuracy: 0.4062 - val_loss: 1.6291 - val_accuracy: 0.4318\n",
      "Epoch 631/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6157 - accuracy: 0.4358 - val_loss: 1.6192 - val_accuracy: 0.4286\n",
      "Epoch 632/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6572 - accuracy: 0.4150 - val_loss: 1.6079 - val_accuracy: 0.4253\n",
      "Epoch 633/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6116 - accuracy: 0.3841 - val_loss: 1.6030 - val_accuracy: 0.4188\n",
      "Epoch 634/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6371 - accuracy: 0.4092 - val_loss: 1.6054 - val_accuracy: 0.4123\n",
      "Epoch 635/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6415 - accuracy: 0.4180 - val_loss: 1.6094 - val_accuracy: 0.4123\n",
      "Epoch 636/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5665 - accuracy: 0.4623 - val_loss: 1.6132 - val_accuracy: 0.4123\n",
      "Epoch 637/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6309 - accuracy: 0.4092 - val_loss: 1.6168 - val_accuracy: 0.4156\n",
      "Epoch 638/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6288 - accuracy: 0.3966 - val_loss: 1.6328 - val_accuracy: 0.4026\n",
      "Epoch 639/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6444 - accuracy: 0.3966 - val_loss: 1.6602 - val_accuracy: 0.3961\n",
      "Epoch 640/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6324 - accuracy: 0.4326 - val_loss: 1.6767 - val_accuracy: 0.3864\n",
      "Epoch 641/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6478 - accuracy: 0.4092 - val_loss: 1.6879 - val_accuracy: 0.3799\n",
      "Epoch 642/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5976 - accuracy: 0.4404 - val_loss: 1.6852 - val_accuracy: 0.3734\n",
      "Epoch 643/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6436 - accuracy: 0.4078 - val_loss: 1.6834 - val_accuracy: 0.3799\n",
      "Epoch 644/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5841 - accuracy: 0.4413 - val_loss: 1.6736 - val_accuracy: 0.3864\n",
      "Epoch 645/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5913 - accuracy: 0.4375 - val_loss: 1.6684 - val_accuracy: 0.3929\n",
      "Epoch 646/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6228 - accuracy: 0.4302 - val_loss: 1.6474 - val_accuracy: 0.3994\n",
      "Epoch 647/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6160 - accuracy: 0.4232 - val_loss: 1.6307 - val_accuracy: 0.4123\n",
      "Epoch 648/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6200 - accuracy: 0.4160 - val_loss: 1.6227 - val_accuracy: 0.4058\n",
      "Epoch 649/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.6305 - accuracy: 0.4204 - val_loss: 1.6278 - val_accuracy: 0.4026\n",
      "Epoch 650/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6452 - accuracy: 0.4062 - val_loss: 1.6333 - val_accuracy: 0.3994\n",
      "Epoch 651/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.5975 - accuracy: 0.4287 - val_loss: 1.6406 - val_accuracy: 0.4026\n",
      "Epoch 652/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6645 - accuracy: 0.3994 - val_loss: 1.6591 - val_accuracy: 0.4026\n",
      "Epoch 653/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6095 - accuracy: 0.4344 - val_loss: 1.6669 - val_accuracy: 0.3994\n",
      "Epoch 654/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6142 - accuracy: 0.4365 - val_loss: 1.6786 - val_accuracy: 0.3994\n",
      "Epoch 655/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6085 - accuracy: 0.4219 - val_loss: 1.7038 - val_accuracy: 0.3864\n",
      "Epoch 656/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5762 - accuracy: 0.4344 - val_loss: 1.7316 - val_accuracy: 0.3766\n",
      "Epoch 657/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6403 - accuracy: 0.3980 - val_loss: 1.7588 - val_accuracy: 0.3636\n",
      "Epoch 658/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6134 - accuracy: 0.4344 - val_loss: 1.7753 - val_accuracy: 0.3539\n",
      "Epoch 659/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5713 - accuracy: 0.4453 - val_loss: 1.7847 - val_accuracy: 0.3474\n",
      "Epoch 660/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6416 - accuracy: 0.4180 - val_loss: 1.7659 - val_accuracy: 0.3539\n",
      "Epoch 661/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6087 - accuracy: 0.4160 - val_loss: 1.7423 - val_accuracy: 0.3571\n",
      "Epoch 662/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6524 - accuracy: 0.4043 - val_loss: 1.7128 - val_accuracy: 0.3636\n",
      "Epoch 663/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5952 - accuracy: 0.4469 - val_loss: 1.6996 - val_accuracy: 0.3701\n",
      "Epoch 664/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6128 - accuracy: 0.4260 - val_loss: 1.6917 - val_accuracy: 0.3864\n",
      "Epoch 665/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5972 - accuracy: 0.4258 - val_loss: 1.6817 - val_accuracy: 0.3929\n",
      "Epoch 666/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6267 - accuracy: 0.4248 - val_loss: 1.6825 - val_accuracy: 0.3961\n",
      "Epoch 667/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6041 - accuracy: 0.4316 - val_loss: 1.7037 - val_accuracy: 0.3961\n",
      "Epoch 668/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5960 - accuracy: 0.4229 - val_loss: 1.7212 - val_accuracy: 0.3896\n",
      "Epoch 669/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5946 - accuracy: 0.4326 - val_loss: 1.7393 - val_accuracy: 0.3831\n",
      "Epoch 670/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5285 - accuracy: 0.4707 - val_loss: 1.7748 - val_accuracy: 0.3734\n",
      "Epoch 671/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6249 - accuracy: 0.4277 - val_loss: 1.8000 - val_accuracy: 0.3799\n",
      "Epoch 672/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6198 - accuracy: 0.4078 - val_loss: 1.8248 - val_accuracy: 0.3539\n",
      "Epoch 673/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5998 - accuracy: 0.4473 - val_loss: 1.8460 - val_accuracy: 0.3636\n",
      "Epoch 674/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5328 - accuracy: 0.4525 - val_loss: 1.8757 - val_accuracy: 0.3539\n",
      "Epoch 675/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5719 - accuracy: 0.4246 - val_loss: 1.9096 - val_accuracy: 0.3506\n",
      "Epoch 676/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5857 - accuracy: 0.4365 - val_loss: 1.9202 - val_accuracy: 0.3474\n",
      "Epoch 677/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5858 - accuracy: 0.4346 - val_loss: 1.9217 - val_accuracy: 0.3442\n",
      "Epoch 678/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6060 - accuracy: 0.4189 - val_loss: 1.9186 - val_accuracy: 0.3506\n",
      "Epoch 679/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5820 - accuracy: 0.4395 - val_loss: 1.9027 - val_accuracy: 0.3669\n",
      "Epoch 680/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5858 - accuracy: 0.4297 - val_loss: 1.8687 - val_accuracy: 0.3669\n",
      "Epoch 681/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6138 - accuracy: 0.4246 - val_loss: 1.8310 - val_accuracy: 0.3766\n",
      "Epoch 682/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5906 - accuracy: 0.4274 - val_loss: 1.8187 - val_accuracy: 0.3734\n",
      "Epoch 683/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5511 - accuracy: 0.4482 - val_loss: 1.7984 - val_accuracy: 0.3799\n",
      "Epoch 684/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5453 - accuracy: 0.4805 - val_loss: 1.7833 - val_accuracy: 0.3831\n",
      "Epoch 685/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5992 - accuracy: 0.4372 - val_loss: 1.7586 - val_accuracy: 0.3961\n",
      "Epoch 686/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5111 - accuracy: 0.4679 - val_loss: 1.7241 - val_accuracy: 0.4188\n",
      "Epoch 687/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5403 - accuracy: 0.4497 - val_loss: 1.7022 - val_accuracy: 0.4221\n",
      "Epoch 688/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5863 - accuracy: 0.4434 - val_loss: 1.6880 - val_accuracy: 0.4253\n",
      "Epoch 689/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5563 - accuracy: 0.4463 - val_loss: 1.6771 - val_accuracy: 0.4221\n",
      "Epoch 690/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6243 - accuracy: 0.4473 - val_loss: 1.6693 - val_accuracy: 0.4253\n",
      "Epoch 691/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6311 - accuracy: 0.4258 - val_loss: 1.6727 - val_accuracy: 0.4188\n",
      "Epoch 692/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5840 - accuracy: 0.4473 - val_loss: 1.6878 - val_accuracy: 0.4156\n",
      "Epoch 693/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6189 - accuracy: 0.4148 - val_loss: 1.6820 - val_accuracy: 0.4091\n",
      "Epoch 694/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5941 - accuracy: 0.4268 - val_loss: 1.6657 - val_accuracy: 0.4026\n",
      "Epoch 695/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5959 - accuracy: 0.4204 - val_loss: 1.6644 - val_accuracy: 0.4091\n",
      "Epoch 696/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.5733 - accuracy: 0.4385 - val_loss: 1.6632 - val_accuracy: 0.4026\n",
      "Epoch 697/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5681 - accuracy: 0.4623 - val_loss: 1.6741 - val_accuracy: 0.4058\n",
      "Epoch 698/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5561 - accuracy: 0.4455 - val_loss: 1.6878 - val_accuracy: 0.4058\n",
      "Epoch 699/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5873 - accuracy: 0.4232 - val_loss: 1.6955 - val_accuracy: 0.4058\n",
      "Epoch 700/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5446 - accuracy: 0.4511 - val_loss: 1.7057 - val_accuracy: 0.4123\n",
      "Epoch 701/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5872 - accuracy: 0.4229 - val_loss: 1.7195 - val_accuracy: 0.4156\n",
      "Epoch 702/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5166 - accuracy: 0.4648 - val_loss: 1.7370 - val_accuracy: 0.4058\n",
      "Epoch 703/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5653 - accuracy: 0.4502 - val_loss: 1.7330 - val_accuracy: 0.4091\n",
      "Epoch 704/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5344 - accuracy: 0.4721 - val_loss: 1.7153 - val_accuracy: 0.4026\n",
      "Epoch 705/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5869 - accuracy: 0.4427 - val_loss: 1.6833 - val_accuracy: 0.4091\n",
      "Epoch 706/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5709 - accuracy: 0.4427 - val_loss: 1.6447 - val_accuracy: 0.4318\n",
      "Epoch 707/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5777 - accuracy: 0.4232 - val_loss: 1.6179 - val_accuracy: 0.4416\n",
      "Epoch 708/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5407 - accuracy: 0.4473 - val_loss: 1.6053 - val_accuracy: 0.4253\n",
      "Epoch 709/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4912 - accuracy: 0.4916 - val_loss: 1.6027 - val_accuracy: 0.4253\n",
      "Epoch 710/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5456 - accuracy: 0.4441 - val_loss: 1.6127 - val_accuracy: 0.4318\n",
      "Epoch 711/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5115 - accuracy: 0.4609 - val_loss: 1.6349 - val_accuracy: 0.4221\n",
      "Epoch 712/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5735 - accuracy: 0.4372 - val_loss: 1.6648 - val_accuracy: 0.4286\n",
      "Epoch 713/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5834 - accuracy: 0.4427 - val_loss: 1.6863 - val_accuracy: 0.4286\n",
      "Epoch 714/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5099 - accuracy: 0.4511 - val_loss: 1.6976 - val_accuracy: 0.4253\n",
      "Epoch 715/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5118 - accuracy: 0.4483 - val_loss: 1.7049 - val_accuracy: 0.4286\n",
      "Epoch 716/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5498 - accuracy: 0.4385 - val_loss: 1.7359 - val_accuracy: 0.4188\n",
      "Epoch 717/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5733 - accuracy: 0.4531 - val_loss: 1.7627 - val_accuracy: 0.4253\n",
      "Epoch 718/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6073 - accuracy: 0.4455 - val_loss: 1.7659 - val_accuracy: 0.4156\n",
      "Epoch 719/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5623 - accuracy: 0.4512 - val_loss: 1.7584 - val_accuracy: 0.4091\n",
      "Epoch 720/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5585 - accuracy: 0.4497 - val_loss: 1.7295 - val_accuracy: 0.4091\n",
      "Epoch 721/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5287 - accuracy: 0.4648 - val_loss: 1.7050 - val_accuracy: 0.4123\n",
      "Epoch 722/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5233 - accuracy: 0.4539 - val_loss: 1.6762 - val_accuracy: 0.4286\n",
      "Epoch 723/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5720 - accuracy: 0.4570 - val_loss: 1.6618 - val_accuracy: 0.4351\n",
      "Epoch 724/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.5398 - accuracy: 0.4385 - val_loss: 1.6425 - val_accuracy: 0.4286\n",
      "Epoch 725/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5238 - accuracy: 0.4735 - val_loss: 1.6348 - val_accuracy: 0.4383\n",
      "Epoch 726/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5358 - accuracy: 0.4346 - val_loss: 1.6219 - val_accuracy: 0.4286\n",
      "Epoch 727/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5477 - accuracy: 0.4375 - val_loss: 1.6230 - val_accuracy: 0.4253\n",
      "Epoch 728/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5539 - accuracy: 0.4609 - val_loss: 1.6520 - val_accuracy: 0.4286\n",
      "Epoch 729/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5495 - accuracy: 0.4443 - val_loss: 1.6880 - val_accuracy: 0.4253\n",
      "Epoch 730/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5704 - accuracy: 0.4512 - val_loss: 1.7378 - val_accuracy: 0.4091\n",
      "Epoch 731/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5436 - accuracy: 0.4372 - val_loss: 1.7719 - val_accuracy: 0.3929\n",
      "Epoch 732/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5033 - accuracy: 0.4832 - val_loss: 1.8041 - val_accuracy: 0.3896\n",
      "Epoch 733/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4818 - accuracy: 0.4688 - val_loss: 1.8246 - val_accuracy: 0.3896\n",
      "Epoch 734/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5168 - accuracy: 0.4665 - val_loss: 1.8390 - val_accuracy: 0.3929\n",
      "Epoch 735/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4832 - accuracy: 0.4832 - val_loss: 1.8350 - val_accuracy: 0.3864\n",
      "Epoch 736/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5548 - accuracy: 0.4629 - val_loss: 1.8167 - val_accuracy: 0.3864\n",
      "Epoch 737/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5146 - accuracy: 0.4567 - val_loss: 1.7861 - val_accuracy: 0.4058\n",
      "Epoch 738/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5058 - accuracy: 0.4629 - val_loss: 1.7575 - val_accuracy: 0.4221\n",
      "Epoch 739/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5439 - accuracy: 0.4629 - val_loss: 1.7356 - val_accuracy: 0.4286\n",
      "Epoch 740/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5140 - accuracy: 0.4665 - val_loss: 1.7176 - val_accuracy: 0.4253\n",
      "Epoch 741/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5434 - accuracy: 0.4385 - val_loss: 1.6918 - val_accuracy: 0.4318\n",
      "Epoch 742/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5144 - accuracy: 0.4561 - val_loss: 1.6837 - val_accuracy: 0.4416\n",
      "Epoch 743/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5436 - accuracy: 0.4424 - val_loss: 1.6720 - val_accuracy: 0.4416\n",
      "Epoch 744/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4480 - accuracy: 0.4863 - val_loss: 1.6591 - val_accuracy: 0.4578\n",
      "Epoch 745/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4985 - accuracy: 0.4658 - val_loss: 1.6400 - val_accuracy: 0.4740\n",
      "Epoch 746/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4812 - accuracy: 0.4930 - val_loss: 1.6397 - val_accuracy: 0.4740\n",
      "Epoch 747/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4869 - accuracy: 0.4777 - val_loss: 1.6422 - val_accuracy: 0.4643\n",
      "Epoch 748/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5227 - accuracy: 0.4619 - val_loss: 1.6581 - val_accuracy: 0.4643\n",
      "Epoch 749/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5058 - accuracy: 0.4883 - val_loss: 1.6809 - val_accuracy: 0.4481\n",
      "Epoch 750/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4914 - accuracy: 0.4637 - val_loss: 1.7199 - val_accuracy: 0.4513\n",
      "Epoch 751/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4260 - accuracy: 0.4893 - val_loss: 1.7274 - val_accuracy: 0.4513\n",
      "Epoch 752/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5018 - accuracy: 0.4749 - val_loss: 1.7418 - val_accuracy: 0.4513\n",
      "Epoch 753/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5324 - accuracy: 0.4580 - val_loss: 1.7508 - val_accuracy: 0.4416\n",
      "Epoch 754/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4748 - accuracy: 0.4986 - val_loss: 1.7667 - val_accuracy: 0.4286\n",
      "Epoch 755/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4889 - accuracy: 0.4531 - val_loss: 1.8024 - val_accuracy: 0.4123\n",
      "Epoch 756/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4378 - accuracy: 0.4818 - val_loss: 1.8136 - val_accuracy: 0.4058\n",
      "Epoch 757/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5222 - accuracy: 0.4749 - val_loss: 1.8019 - val_accuracy: 0.4026\n",
      "Epoch 758/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4883 - accuracy: 0.4561 - val_loss: 1.7842 - val_accuracy: 0.4123\n",
      "Epoch 759/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4126 - accuracy: 0.5084 - val_loss: 1.7697 - val_accuracy: 0.4253\n",
      "Epoch 760/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5006 - accuracy: 0.4763 - val_loss: 1.7495 - val_accuracy: 0.4221\n",
      "Epoch 761/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4827 - accuracy: 0.4777 - val_loss: 1.7587 - val_accuracy: 0.4156\n",
      "Epoch 762/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5156 - accuracy: 0.4619 - val_loss: 1.7641 - val_accuracy: 0.4188\n",
      "Epoch 763/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5076 - accuracy: 0.4854 - val_loss: 1.7513 - val_accuracy: 0.4156\n",
      "Epoch 764/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5051 - accuracy: 0.4902 - val_loss: 1.7357 - val_accuracy: 0.4253\n",
      "Epoch 765/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5127 - accuracy: 0.4648 - val_loss: 1.7012 - val_accuracy: 0.4351\n",
      "Epoch 766/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4729 - accuracy: 0.4893 - val_loss: 1.6586 - val_accuracy: 0.4578\n",
      "Epoch 767/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5038 - accuracy: 0.4541 - val_loss: 1.6225 - val_accuracy: 0.4610\n",
      "Epoch 768/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4828 - accuracy: 0.4551 - val_loss: 1.6023 - val_accuracy: 0.4675\n",
      "Epoch 769/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5376 - accuracy: 0.4570 - val_loss: 1.6138 - val_accuracy: 0.4675\n",
      "Epoch 770/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5237 - accuracy: 0.4581 - val_loss: 1.6395 - val_accuracy: 0.4578\n",
      "Epoch 771/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4244 - accuracy: 0.4980 - val_loss: 1.6819 - val_accuracy: 0.4513\n",
      "Epoch 772/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4494 - accuracy: 0.5029 - val_loss: 1.7164 - val_accuracy: 0.4448\n",
      "Epoch 773/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4398 - accuracy: 0.5049 - val_loss: 1.7336 - val_accuracy: 0.4481\n",
      "Epoch 774/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4663 - accuracy: 0.4971 - val_loss: 1.7239 - val_accuracy: 0.4481\n",
      "Epoch 775/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4581 - accuracy: 0.4912 - val_loss: 1.6973 - val_accuracy: 0.4545\n",
      "Epoch 776/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4970 - accuracy: 0.4763 - val_loss: 1.6658 - val_accuracy: 0.4513\n",
      "Epoch 777/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4716 - accuracy: 0.4749 - val_loss: 1.6285 - val_accuracy: 0.4481\n",
      "Epoch 778/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4713 - accuracy: 0.4581 - val_loss: 1.6019 - val_accuracy: 0.4708\n",
      "Epoch 779/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4712 - accuracy: 0.4805 - val_loss: 1.5725 - val_accuracy: 0.4805\n",
      "Epoch 780/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4604 - accuracy: 0.4912 - val_loss: 1.5799 - val_accuracy: 0.4708\n",
      "Epoch 781/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4386 - accuracy: 0.5000 - val_loss: 1.5996 - val_accuracy: 0.4610\n",
      "Epoch 782/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4999 - accuracy: 0.4521 - val_loss: 1.6234 - val_accuracy: 0.4513\n",
      "Epoch 783/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4763 - accuracy: 0.4846 - val_loss: 1.6433 - val_accuracy: 0.4481\n",
      "Epoch 784/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4370 - accuracy: 0.4844 - val_loss: 1.6817 - val_accuracy: 0.4416\n",
      "Epoch 785/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4838 - accuracy: 0.4814 - val_loss: 1.6983 - val_accuracy: 0.4221\n",
      "Epoch 786/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4875 - accuracy: 0.4648 - val_loss: 1.7065 - val_accuracy: 0.4188\n",
      "Epoch 787/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4166 - accuracy: 0.5195 - val_loss: 1.7167 - val_accuracy: 0.4188\n",
      "Epoch 788/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4795 - accuracy: 0.5056 - val_loss: 1.7298 - val_accuracy: 0.4253\n",
      "Epoch 789/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4437 - accuracy: 0.5000 - val_loss: 1.7600 - val_accuracy: 0.3994\n",
      "Epoch 790/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4772 - accuracy: 0.4600 - val_loss: 1.7997 - val_accuracy: 0.3864\n",
      "Epoch 791/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4200 - accuracy: 0.5070 - val_loss: 1.8403 - val_accuracy: 0.3734\n",
      "Epoch 792/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4505 - accuracy: 0.5020 - val_loss: 1.8690 - val_accuracy: 0.3636\n",
      "Epoch 793/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4551 - accuracy: 0.4958 - val_loss: 1.8537 - val_accuracy: 0.3734\n",
      "Epoch 794/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4530 - accuracy: 0.4922 - val_loss: 1.8092 - val_accuracy: 0.3864\n",
      "Epoch 795/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4218 - accuracy: 0.4961 - val_loss: 1.7451 - val_accuracy: 0.3961\n",
      "Epoch 796/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4171 - accuracy: 0.5000 - val_loss: 1.6662 - val_accuracy: 0.4481\n",
      "Epoch 797/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4841 - accuracy: 0.4860 - val_loss: 1.5957 - val_accuracy: 0.4578\n",
      "Epoch 798/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4419 - accuracy: 0.4971 - val_loss: 1.5350 - val_accuracy: 0.4773\n",
      "Epoch 799/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5279 - accuracy: 0.4791 - val_loss: 1.5053 - val_accuracy: 0.4903\n",
      "Epoch 800/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3891 - accuracy: 0.5127 - val_loss: 1.5096 - val_accuracy: 0.4805\n",
      "Epoch 801/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4008 - accuracy: 0.5196 - val_loss: 1.5345 - val_accuracy: 0.4740\n",
      "Epoch 802/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4908 - accuracy: 0.4912 - val_loss: 1.5697 - val_accuracy: 0.4610\n",
      "Epoch 803/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4793 - accuracy: 0.4902 - val_loss: 1.6084 - val_accuracy: 0.4513\n",
      "Epoch 804/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4159 - accuracy: 0.5014 - val_loss: 1.6332 - val_accuracy: 0.4481\n",
      "Epoch 805/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4300 - accuracy: 0.5056 - val_loss: 1.6493 - val_accuracy: 0.4513\n",
      "Epoch 806/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4428 - accuracy: 0.5117 - val_loss: 1.6644 - val_accuracy: 0.4351\n",
      "Epoch 807/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4198 - accuracy: 0.5168 - val_loss: 1.6511 - val_accuracy: 0.4448\n",
      "Epoch 808/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4233 - accuracy: 0.5078 - val_loss: 1.6395 - val_accuracy: 0.4740\n",
      "Epoch 809/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4610 - accuracy: 0.4932 - val_loss: 1.6328 - val_accuracy: 0.4708\n",
      "Epoch 810/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3646 - accuracy: 0.5265 - val_loss: 1.6317 - val_accuracy: 0.4708\n",
      "Epoch 811/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5046 - accuracy: 0.4756 - val_loss: 1.6441 - val_accuracy: 0.4675\n",
      "Epoch 812/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3783 - accuracy: 0.5205 - val_loss: 1.6438 - val_accuracy: 0.4740\n",
      "Epoch 813/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4211 - accuracy: 0.4986 - val_loss: 1.6663 - val_accuracy: 0.4708\n",
      "Epoch 814/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4284 - accuracy: 0.4707 - val_loss: 1.6786 - val_accuracy: 0.4773\n",
      "Epoch 815/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4586 - accuracy: 0.5014 - val_loss: 1.6835 - val_accuracy: 0.4675\n",
      "Epoch 816/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3773 - accuracy: 0.5000 - val_loss: 1.6734 - val_accuracy: 0.4675\n",
      "Epoch 817/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4373 - accuracy: 0.5010 - val_loss: 1.6915 - val_accuracy: 0.4578\n",
      "Epoch 818/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3527 - accuracy: 0.5244 - val_loss: 1.6629 - val_accuracy: 0.4610\n",
      "Epoch 819/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4532 - accuracy: 0.4736 - val_loss: 1.6324 - val_accuracy: 0.4675\n",
      "Epoch 820/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4458 - accuracy: 0.4775 - val_loss: 1.5807 - val_accuracy: 0.5000\n",
      "Epoch 821/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3821 - accuracy: 0.5084 - val_loss: 1.5442 - val_accuracy: 0.5065\n",
      "Epoch 822/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4027 - accuracy: 0.5215 - val_loss: 1.5180 - val_accuracy: 0.5065\n",
      "Epoch 823/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4147 - accuracy: 0.5117 - val_loss: 1.5108 - val_accuracy: 0.5097\n",
      "Epoch 824/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4128 - accuracy: 0.5215 - val_loss: 1.4865 - val_accuracy: 0.5097\n",
      "Epoch 825/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4097 - accuracy: 0.5168 - val_loss: 1.4634 - val_accuracy: 0.5065\n",
      "Epoch 826/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3858 - accuracy: 0.5059 - val_loss: 1.4573 - val_accuracy: 0.5097\n",
      "Epoch 827/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4263 - accuracy: 0.5039 - val_loss: 1.4654 - val_accuracy: 0.5000\n",
      "Epoch 828/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4518 - accuracy: 0.5112 - val_loss: 1.4920 - val_accuracy: 0.4968\n",
      "Epoch 829/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3736 - accuracy: 0.5205 - val_loss: 1.5204 - val_accuracy: 0.4805\n",
      "Epoch 830/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3801 - accuracy: 0.5154 - val_loss: 1.5425 - val_accuracy: 0.4740\n",
      "Epoch 831/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4409 - accuracy: 0.4888 - val_loss: 1.5773 - val_accuracy: 0.4578\n",
      "Epoch 832/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4313 - accuracy: 0.5020 - val_loss: 1.5919 - val_accuracy: 0.4643\n",
      "Epoch 833/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3570 - accuracy: 0.5117 - val_loss: 1.6133 - val_accuracy: 0.4545\n",
      "Epoch 834/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4642 - accuracy: 0.4824 - val_loss: 1.6446 - val_accuracy: 0.4513\n",
      "Epoch 835/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4592 - accuracy: 0.4972 - val_loss: 1.6875 - val_accuracy: 0.4351\n",
      "Epoch 836/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4106 - accuracy: 0.5042 - val_loss: 1.7135 - val_accuracy: 0.4351\n",
      "Epoch 837/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4167 - accuracy: 0.5088 - val_loss: 1.7175 - val_accuracy: 0.4318\n",
      "Epoch 838/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4241 - accuracy: 0.5029 - val_loss: 1.7105 - val_accuracy: 0.4351\n",
      "Epoch 839/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3715 - accuracy: 0.5176 - val_loss: 1.6894 - val_accuracy: 0.4383\n",
      "Epoch 840/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3994 - accuracy: 0.5127 - val_loss: 1.6540 - val_accuracy: 0.4416\n",
      "Epoch 841/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3995 - accuracy: 0.5112 - val_loss: 1.6073 - val_accuracy: 0.4578\n",
      "Epoch 842/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4275 - accuracy: 0.4902 - val_loss: 1.5738 - val_accuracy: 0.4773\n",
      "Epoch 843/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4395 - accuracy: 0.5088 - val_loss: 1.5593 - val_accuracy: 0.4935\n",
      "Epoch 844/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4444 - accuracy: 0.4902 - val_loss: 1.5699 - val_accuracy: 0.4968\n",
      "Epoch 845/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.3818 - accuracy: 0.5137 - val_loss: 1.5729 - val_accuracy: 0.5000\n",
      "Epoch 846/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3768 - accuracy: 0.5209 - val_loss: 1.5924 - val_accuracy: 0.4968\n",
      "Epoch 847/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3845 - accuracy: 0.5098 - val_loss: 1.6226 - val_accuracy: 0.4903\n",
      "Epoch 848/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3693 - accuracy: 0.5223 - val_loss: 1.6651 - val_accuracy: 0.4643\n",
      "Epoch 849/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4593 - accuracy: 0.4688 - val_loss: 1.6818 - val_accuracy: 0.4513\n",
      "Epoch 850/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3737 - accuracy: 0.5251 - val_loss: 1.6788 - val_accuracy: 0.4578\n",
      "Epoch 851/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3912 - accuracy: 0.5209 - val_loss: 1.6425 - val_accuracy: 0.4675\n",
      "Epoch 852/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3572 - accuracy: 0.5279 - val_loss: 1.6020 - val_accuracy: 0.4935\n",
      "Epoch 853/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3872 - accuracy: 0.5215 - val_loss: 1.5691 - val_accuracy: 0.5065\n",
      "Epoch 854/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3964 - accuracy: 0.5237 - val_loss: 1.5512 - val_accuracy: 0.5130\n",
      "Epoch 855/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3991 - accuracy: 0.4860 - val_loss: 1.5636 - val_accuracy: 0.5065\n",
      "Epoch 856/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3838 - accuracy: 0.5168 - val_loss: 1.6140 - val_accuracy: 0.4805\n",
      "Epoch 857/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3809 - accuracy: 0.5168 - val_loss: 1.6831 - val_accuracy: 0.4643\n",
      "Epoch 858/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4559 - accuracy: 0.4717 - val_loss: 1.7616 - val_accuracy: 0.4610\n",
      "Epoch 859/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4036 - accuracy: 0.5042 - val_loss: 1.8207 - val_accuracy: 0.4351\n",
      "Epoch 860/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4042 - accuracy: 0.5146 - val_loss: 1.8310 - val_accuracy: 0.4221\n",
      "Epoch 861/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3770 - accuracy: 0.5312 - val_loss: 1.8074 - val_accuracy: 0.4253\n",
      "Epoch 862/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4181 - accuracy: 0.5166 - val_loss: 1.7462 - val_accuracy: 0.4416\n",
      "Epoch 863/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3957 - accuracy: 0.5042 - val_loss: 1.6836 - val_accuracy: 0.4416\n",
      "Epoch 864/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3345 - accuracy: 0.5303 - val_loss: 1.6011 - val_accuracy: 0.4578\n",
      "Epoch 865/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3598 - accuracy: 0.5056 - val_loss: 1.5240 - val_accuracy: 0.5000\n",
      "Epoch 866/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4047 - accuracy: 0.5098 - val_loss: 1.4670 - val_accuracy: 0.5000\n",
      "Epoch 867/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3726 - accuracy: 0.5293 - val_loss: 1.4255 - val_accuracy: 0.5162\n",
      "Epoch 868/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3714 - accuracy: 0.5307 - val_loss: 1.4034 - val_accuracy: 0.5227\n",
      "Epoch 869/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3140 - accuracy: 0.5461 - val_loss: 1.3990 - val_accuracy: 0.5227\n",
      "Epoch 870/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4051 - accuracy: 0.5029 - val_loss: 1.4138 - val_accuracy: 0.5000\n",
      "Epoch 871/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4190 - accuracy: 0.5056 - val_loss: 1.4236 - val_accuracy: 0.5000\n",
      "Epoch 872/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3586 - accuracy: 0.5137 - val_loss: 1.4368 - val_accuracy: 0.5065\n",
      "Epoch 873/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3692 - accuracy: 0.5283 - val_loss: 1.4527 - val_accuracy: 0.5032\n",
      "Epoch 874/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3924 - accuracy: 0.4971 - val_loss: 1.4545 - val_accuracy: 0.5032\n",
      "Epoch 875/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3846 - accuracy: 0.5244 - val_loss: 1.4524 - val_accuracy: 0.5000\n",
      "Epoch 876/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3925 - accuracy: 0.5237 - val_loss: 1.4216 - val_accuracy: 0.5032\n",
      "Epoch 877/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3159 - accuracy: 0.5349 - val_loss: 1.4207 - val_accuracy: 0.5227\n",
      "Epoch 878/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3254 - accuracy: 0.5140 - val_loss: 1.4073 - val_accuracy: 0.5325\n",
      "Epoch 879/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3727 - accuracy: 0.5049 - val_loss: 1.3997 - val_accuracy: 0.5195\n",
      "Epoch 880/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3822 - accuracy: 0.5405 - val_loss: 1.4094 - val_accuracy: 0.5162\n",
      "Epoch 881/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3383 - accuracy: 0.5447 - val_loss: 1.4127 - val_accuracy: 0.5260\n",
      "Epoch 882/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2981 - accuracy: 0.5381 - val_loss: 1.4097 - val_accuracy: 0.5292\n",
      "Epoch 883/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3659 - accuracy: 0.5293 - val_loss: 1.3846 - val_accuracy: 0.5390\n",
      "Epoch 884/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3282 - accuracy: 0.5503 - val_loss: 1.3725 - val_accuracy: 0.5584\n",
      "Epoch 885/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3638 - accuracy: 0.5293 - val_loss: 1.3757 - val_accuracy: 0.5390\n",
      "Epoch 886/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3353 - accuracy: 0.5205 - val_loss: 1.3694 - val_accuracy: 0.5422\n",
      "Epoch 887/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3359 - accuracy: 0.5489 - val_loss: 1.3837 - val_accuracy: 0.5422\n",
      "Epoch 888/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3828 - accuracy: 0.5166 - val_loss: 1.4001 - val_accuracy: 0.5422\n",
      "Epoch 889/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3681 - accuracy: 0.5293 - val_loss: 1.4160 - val_accuracy: 0.5325\n",
      "Epoch 890/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3639 - accuracy: 0.5234 - val_loss: 1.4392 - val_accuracy: 0.5195\n",
      "Epoch 891/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3419 - accuracy: 0.5215 - val_loss: 1.4680 - val_accuracy: 0.5097\n",
      "Epoch 892/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3912 - accuracy: 0.5196 - val_loss: 1.4957 - val_accuracy: 0.5032\n",
      "Epoch 893/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3234 - accuracy: 0.5391 - val_loss: 1.5021 - val_accuracy: 0.5032\n",
      "Epoch 894/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3155 - accuracy: 0.5461 - val_loss: 1.5160 - val_accuracy: 0.5130\n",
      "Epoch 895/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3471 - accuracy: 0.5293 - val_loss: 1.5128 - val_accuracy: 0.5162\n",
      "Epoch 896/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3495 - accuracy: 0.5312 - val_loss: 1.4913 - val_accuracy: 0.5357\n",
      "Epoch 897/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3539 - accuracy: 0.5410 - val_loss: 1.4703 - val_accuracy: 0.5390\n",
      "Epoch 898/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3278 - accuracy: 0.5461 - val_loss: 1.4680 - val_accuracy: 0.5325\n",
      "Epoch 899/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3410 - accuracy: 0.5363 - val_loss: 1.4914 - val_accuracy: 0.5260\n",
      "Epoch 900/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3818 - accuracy: 0.5342 - val_loss: 1.5187 - val_accuracy: 0.5032\n",
      "Epoch 901/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2892 - accuracy: 0.5587 - val_loss: 1.5582 - val_accuracy: 0.4935\n",
      "Epoch 902/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3647 - accuracy: 0.5156 - val_loss: 1.5847 - val_accuracy: 0.4675\n",
      "Epoch 903/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3581 - accuracy: 0.5196 - val_loss: 1.6094 - val_accuracy: 0.4708\n",
      "Epoch 904/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3901 - accuracy: 0.5166 - val_loss: 1.6019 - val_accuracy: 0.4643\n",
      "Epoch 905/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3265 - accuracy: 0.5447 - val_loss: 1.5383 - val_accuracy: 0.4935\n",
      "Epoch 906/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4168 - accuracy: 0.4980 - val_loss: 1.4607 - val_accuracy: 0.5065\n",
      "Epoch 907/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3289 - accuracy: 0.5312 - val_loss: 1.4006 - val_accuracy: 0.5390\n",
      "Epoch 908/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2939 - accuracy: 0.5391 - val_loss: 1.3503 - val_accuracy: 0.5584\n",
      "Epoch 909/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2607 - accuracy: 0.5664 - val_loss: 1.3155 - val_accuracy: 0.5714\n",
      "Epoch 910/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3326 - accuracy: 0.5264 - val_loss: 1.3267 - val_accuracy: 0.5649\n",
      "Epoch 911/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3743 - accuracy: 0.5430 - val_loss: 1.3765 - val_accuracy: 0.5649\n",
      "Epoch 912/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3084 - accuracy: 0.5391 - val_loss: 1.4301 - val_accuracy: 0.5325\n",
      "Epoch 913/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3619 - accuracy: 0.5391 - val_loss: 1.4874 - val_accuracy: 0.5000\n",
      "Epoch 914/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3717 - accuracy: 0.5056 - val_loss: 1.5587 - val_accuracy: 0.4935\n",
      "Epoch 915/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3069 - accuracy: 0.5400 - val_loss: 1.5937 - val_accuracy: 0.4935\n",
      "Epoch 916/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3357 - accuracy: 0.5293 - val_loss: 1.5925 - val_accuracy: 0.4903\n",
      "Epoch 917/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3160 - accuracy: 0.5447 - val_loss: 1.5271 - val_accuracy: 0.5097\n",
      "Epoch 918/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2883 - accuracy: 0.5352 - val_loss: 1.4380 - val_accuracy: 0.5455\n",
      "Epoch 919/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3326 - accuracy: 0.5405 - val_loss: 1.3378 - val_accuracy: 0.5519\n",
      "Epoch 920/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2804 - accuracy: 0.5447 - val_loss: 1.2743 - val_accuracy: 0.5877\n",
      "Epoch 921/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3016 - accuracy: 0.5419 - val_loss: 1.2591 - val_accuracy: 0.5779\n",
      "Epoch 922/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3541 - accuracy: 0.5215 - val_loss: 1.2579 - val_accuracy: 0.5714\n",
      "Epoch 923/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3443 - accuracy: 0.5469 - val_loss: 1.2582 - val_accuracy: 0.5714\n",
      "Epoch 924/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2793 - accuracy: 0.5791 - val_loss: 1.2566 - val_accuracy: 0.5682\n",
      "Epoch 925/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3545 - accuracy: 0.5127 - val_loss: 1.2667 - val_accuracy: 0.5682\n",
      "Epoch 926/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2874 - accuracy: 0.5684 - val_loss: 1.2817 - val_accuracy: 0.5617\n",
      "Epoch 927/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3433 - accuracy: 0.5400 - val_loss: 1.3108 - val_accuracy: 0.5455\n",
      "Epoch 928/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3176 - accuracy: 0.5449 - val_loss: 1.3352 - val_accuracy: 0.5552\n",
      "Epoch 929/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3236 - accuracy: 0.5531 - val_loss: 1.3524 - val_accuracy: 0.5617\n",
      "Epoch 930/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3221 - accuracy: 0.5391 - val_loss: 1.3609 - val_accuracy: 0.5584\n",
      "Epoch 931/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3309 - accuracy: 0.5405 - val_loss: 1.3658 - val_accuracy: 0.5584\n",
      "Epoch 932/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3239 - accuracy: 0.5307 - val_loss: 1.3637 - val_accuracy: 0.5552\n",
      "Epoch 933/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2940 - accuracy: 0.5654 - val_loss: 1.3485 - val_accuracy: 0.5519\n",
      "Epoch 934/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3136 - accuracy: 0.5283 - val_loss: 1.3362 - val_accuracy: 0.5487\n",
      "Epoch 935/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4034 - accuracy: 0.5059 - val_loss: 1.3224 - val_accuracy: 0.5357\n",
      "Epoch 936/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2514 - accuracy: 0.5670 - val_loss: 1.3044 - val_accuracy: 0.5455\n",
      "Epoch 937/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3037 - accuracy: 0.5537 - val_loss: 1.2966 - val_accuracy: 0.5487\n",
      "Epoch 938/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3572 - accuracy: 0.5377 - val_loss: 1.2978 - val_accuracy: 0.5487\n",
      "Epoch 939/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3051 - accuracy: 0.5405 - val_loss: 1.3024 - val_accuracy: 0.5487\n",
      "Epoch 940/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2912 - accuracy: 0.5517 - val_loss: 1.3066 - val_accuracy: 0.5682\n",
      "Epoch 941/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3205 - accuracy: 0.5488 - val_loss: 1.3203 - val_accuracy: 0.5682\n",
      "Epoch 942/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2849 - accuracy: 0.5488 - val_loss: 1.3381 - val_accuracy: 0.5682\n",
      "Epoch 943/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2901 - accuracy: 0.5479 - val_loss: 1.3529 - val_accuracy: 0.5682\n",
      "Epoch 944/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3216 - accuracy: 0.5475 - val_loss: 1.3626 - val_accuracy: 0.5682\n",
      "Epoch 945/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3260 - accuracy: 0.5459 - val_loss: 1.3667 - val_accuracy: 0.5584\n",
      "Epoch 946/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3646 - accuracy: 0.5332 - val_loss: 1.3805 - val_accuracy: 0.5649\n",
      "Epoch 947/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2985 - accuracy: 0.5573 - val_loss: 1.3764 - val_accuracy: 0.5584\n",
      "Epoch 948/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2870 - accuracy: 0.5625 - val_loss: 1.3640 - val_accuracy: 0.5584\n",
      "Epoch 949/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3424 - accuracy: 0.5363 - val_loss: 1.3870 - val_accuracy: 0.5390\n",
      "Epoch 950/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3188 - accuracy: 0.5527 - val_loss: 1.4148 - val_accuracy: 0.5357\n",
      "Epoch 951/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2151 - accuracy: 0.5964 - val_loss: 1.4349 - val_accuracy: 0.5097\n",
      "Epoch 952/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3106 - accuracy: 0.5670 - val_loss: 1.4317 - val_accuracy: 0.5130\n",
      "Epoch 953/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3203 - accuracy: 0.5332 - val_loss: 1.4000 - val_accuracy: 0.5260\n",
      "Epoch 954/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3411 - accuracy: 0.5615 - val_loss: 1.3700 - val_accuracy: 0.5487\n",
      "Epoch 955/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2619 - accuracy: 0.5625 - val_loss: 1.3487 - val_accuracy: 0.5519\n",
      "Epoch 956/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3376 - accuracy: 0.5307 - val_loss: 1.3520 - val_accuracy: 0.5519\n",
      "Epoch 957/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2801 - accuracy: 0.5596 - val_loss: 1.3690 - val_accuracy: 0.5487\n",
      "Epoch 958/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2976 - accuracy: 0.5557 - val_loss: 1.3788 - val_accuracy: 0.5390\n",
      "Epoch 959/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.3114 - accuracy: 0.5566 - val_loss: 1.3939 - val_accuracy: 0.5292\n",
      "Epoch 960/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2899 - accuracy: 0.5469 - val_loss: 1.4102 - val_accuracy: 0.5357\n",
      "Epoch 961/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2487 - accuracy: 0.5605 - val_loss: 1.4042 - val_accuracy: 0.5292\n",
      "Epoch 962/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3254 - accuracy: 0.5559 - val_loss: 1.4001 - val_accuracy: 0.5487\n",
      "Epoch 963/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2823 - accuracy: 0.5587 - val_loss: 1.3831 - val_accuracy: 0.5519\n",
      "Epoch 964/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2883 - accuracy: 0.5645 - val_loss: 1.3745 - val_accuracy: 0.5519\n",
      "Epoch 965/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2315 - accuracy: 0.5922 - val_loss: 1.3696 - val_accuracy: 0.5519\n",
      "Epoch 966/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2646 - accuracy: 0.5586 - val_loss: 1.3680 - val_accuracy: 0.5422\n",
      "Epoch 967/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2727 - accuracy: 0.5547 - val_loss: 1.3589 - val_accuracy: 0.5390\n",
      "Epoch 968/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2436 - accuracy: 0.5754 - val_loss: 1.3888 - val_accuracy: 0.5292\n",
      "Epoch 969/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2587 - accuracy: 0.5508 - val_loss: 1.4223 - val_accuracy: 0.5162\n",
      "Epoch 970/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3311 - accuracy: 0.5251 - val_loss: 1.4360 - val_accuracy: 0.5000\n",
      "Epoch 971/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2989 - accuracy: 0.5469 - val_loss: 1.4211 - val_accuracy: 0.5162\n",
      "Epoch 972/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3307 - accuracy: 0.5391 - val_loss: 1.3917 - val_accuracy: 0.5195\n",
      "Epoch 973/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3652 - accuracy: 0.5279 - val_loss: 1.3415 - val_accuracy: 0.5519\n",
      "Epoch 974/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2571 - accuracy: 0.5628 - val_loss: 1.2995 - val_accuracy: 0.5942\n",
      "Epoch 975/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2777 - accuracy: 0.5517 - val_loss: 1.2724 - val_accuracy: 0.5877\n",
      "Epoch 976/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2493 - accuracy: 0.5449 - val_loss: 1.2528 - val_accuracy: 0.5942\n",
      "Epoch 977/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2969 - accuracy: 0.5782 - val_loss: 1.2469 - val_accuracy: 0.5812\n",
      "Epoch 978/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2366 - accuracy: 0.5537 - val_loss: 1.2363 - val_accuracy: 0.5909\n",
      "Epoch 979/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2482 - accuracy: 0.5674 - val_loss: 1.2214 - val_accuracy: 0.5877\n",
      "Epoch 980/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2860 - accuracy: 0.5615 - val_loss: 1.2124 - val_accuracy: 0.5877\n",
      "Epoch 981/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2731 - accuracy: 0.5566 - val_loss: 1.2105 - val_accuracy: 0.5844\n",
      "Epoch 982/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2722 - accuracy: 0.5656 - val_loss: 1.2077 - val_accuracy: 0.5844\n",
      "Epoch 983/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2639 - accuracy: 0.5587 - val_loss: 1.2073 - val_accuracy: 0.5779\n",
      "Epoch 984/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2682 - accuracy: 0.5531 - val_loss: 1.2074 - val_accuracy: 0.5779\n",
      "Epoch 985/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3016 - accuracy: 0.5410 - val_loss: 1.2065 - val_accuracy: 0.5747\n",
      "Epoch 986/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2664 - accuracy: 0.5850 - val_loss: 1.2045 - val_accuracy: 0.5844\n",
      "Epoch 987/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2396 - accuracy: 0.5684 - val_loss: 1.2141 - val_accuracy: 0.5877\n",
      "Epoch 988/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2594 - accuracy: 0.5547 - val_loss: 1.2313 - val_accuracy: 0.5779\n",
      "Epoch 989/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2828 - accuracy: 0.5596 - val_loss: 1.2458 - val_accuracy: 0.5747\n",
      "Epoch 990/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2766 - accuracy: 0.5615 - val_loss: 1.2788 - val_accuracy: 0.5584\n",
      "Epoch 991/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2349 - accuracy: 0.5635 - val_loss: 1.3154 - val_accuracy: 0.5682\n",
      "Epoch 992/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2864 - accuracy: 0.5537 - val_loss: 1.3475 - val_accuracy: 0.5552\n",
      "Epoch 993/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2056 - accuracy: 0.5684 - val_loss: 1.3577 - val_accuracy: 0.5519\n",
      "Epoch 994/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2787 - accuracy: 0.5656 - val_loss: 1.3880 - val_accuracy: 0.5390\n",
      "Epoch 995/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2270 - accuracy: 0.5752 - val_loss: 1.4091 - val_accuracy: 0.5357\n",
      "Epoch 996/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2299 - accuracy: 0.5791 - val_loss: 1.4271 - val_accuracy: 0.5390\n",
      "Epoch 997/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3195 - accuracy: 0.5503 - val_loss: 1.4356 - val_accuracy: 0.5325\n",
      "Epoch 998/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3091 - accuracy: 0.5419 - val_loss: 1.4181 - val_accuracy: 0.5455\n",
      "Epoch 999/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1796 - accuracy: 0.5830 - val_loss: 1.3944 - val_accuracy: 0.5422\n",
      "Epoch 1000/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2275 - accuracy: 0.5964 - val_loss: 1.3657 - val_accuracy: 0.5422\n",
      "Epoch 1001/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2496 - accuracy: 0.5605 - val_loss: 1.3458 - val_accuracy: 0.5519\n",
      "Epoch 1002/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3094 - accuracy: 0.5419 - val_loss: 1.3266 - val_accuracy: 0.5617\n",
      "Epoch 1003/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2852 - accuracy: 0.5693 - val_loss: 1.3198 - val_accuracy: 0.5714\n",
      "Epoch 1004/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2692 - accuracy: 0.5559 - val_loss: 1.3230 - val_accuracy: 0.5649\n",
      "Epoch 1005/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2253 - accuracy: 0.5768 - val_loss: 1.3626 - val_accuracy: 0.5617\n",
      "Epoch 1006/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3211 - accuracy: 0.5527 - val_loss: 1.4025 - val_accuracy: 0.5455\n",
      "Epoch 1007/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2109 - accuracy: 0.5908 - val_loss: 1.4461 - val_accuracy: 0.5390\n",
      "Epoch 1008/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2215 - accuracy: 0.5908 - val_loss: 1.4856 - val_accuracy: 0.5260\n",
      "Epoch 1009/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2146 - accuracy: 0.5850 - val_loss: 1.5216 - val_accuracy: 0.5032\n",
      "Epoch 1010/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2612 - accuracy: 0.5605 - val_loss: 1.5464 - val_accuracy: 0.4968\n",
      "Epoch 1011/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2605 - accuracy: 0.5475 - val_loss: 1.5206 - val_accuracy: 0.4968\n",
      "Epoch 1012/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2525 - accuracy: 0.5615 - val_loss: 1.4652 - val_accuracy: 0.5000\n",
      "Epoch 1013/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2098 - accuracy: 0.5967 - val_loss: 1.4040 - val_accuracy: 0.5162\n",
      "Epoch 1014/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2532 - accuracy: 0.5664 - val_loss: 1.3500 - val_accuracy: 0.5487\n",
      "Epoch 1015/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2125 - accuracy: 0.5752 - val_loss: 1.3102 - val_accuracy: 0.5682\n",
      "Epoch 1016/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2197 - accuracy: 0.5820 - val_loss: 1.2945 - val_accuracy: 0.5649\n",
      "Epoch 1017/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1753 - accuracy: 0.5964 - val_loss: 1.2956 - val_accuracy: 0.5617\n",
      "Epoch 1018/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1910 - accuracy: 0.5964 - val_loss: 1.2753 - val_accuracy: 0.5682\n",
      "Epoch 1019/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2292 - accuracy: 0.5880 - val_loss: 1.2599 - val_accuracy: 0.5682\n",
      "Epoch 1020/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2336 - accuracy: 0.5573 - val_loss: 1.2335 - val_accuracy: 0.5747\n",
      "Epoch 1021/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2254 - accuracy: 0.5752 - val_loss: 1.2215 - val_accuracy: 0.5877\n",
      "Epoch 1022/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2316 - accuracy: 0.5879 - val_loss: 1.2124 - val_accuracy: 0.5877\n",
      "Epoch 1023/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2390 - accuracy: 0.5573 - val_loss: 1.2050 - val_accuracy: 0.5974\n",
      "Epoch 1024/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2341 - accuracy: 0.5869 - val_loss: 1.2068 - val_accuracy: 0.5909\n",
      "Epoch 1025/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2464 - accuracy: 0.5670 - val_loss: 1.2098 - val_accuracy: 0.5844\n",
      "Epoch 1026/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2463 - accuracy: 0.5811 - val_loss: 1.2191 - val_accuracy: 0.5877\n",
      "Epoch 1027/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2501 - accuracy: 0.5938 - val_loss: 1.2250 - val_accuracy: 0.5909\n",
      "Epoch 1028/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2204 - accuracy: 0.5967 - val_loss: 1.2247 - val_accuracy: 0.5909\n",
      "Epoch 1029/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2077 - accuracy: 0.5859 - val_loss: 1.2222 - val_accuracy: 0.5909\n",
      "Epoch 1030/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2088 - accuracy: 0.5801 - val_loss: 1.2268 - val_accuracy: 0.5909\n",
      "Epoch 1031/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2132 - accuracy: 0.5824 - val_loss: 1.2318 - val_accuracy: 0.5877\n",
      "Epoch 1032/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2084 - accuracy: 0.5859 - val_loss: 1.2400 - val_accuracy: 0.6006\n",
      "Epoch 1033/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2413 - accuracy: 0.5740 - val_loss: 1.2206 - val_accuracy: 0.5974\n",
      "Epoch 1034/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2341 - accuracy: 0.5781 - val_loss: 1.2012 - val_accuracy: 0.6136\n",
      "Epoch 1035/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2146 - accuracy: 0.5684 - val_loss: 1.1807 - val_accuracy: 0.6136\n",
      "Epoch 1036/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1905 - accuracy: 0.5810 - val_loss: 1.1795 - val_accuracy: 0.6104\n",
      "Epoch 1037/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2256 - accuracy: 0.5754 - val_loss: 1.1923 - val_accuracy: 0.6234\n",
      "Epoch 1038/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2068 - accuracy: 0.5947 - val_loss: 1.2094 - val_accuracy: 0.6104\n",
      "Epoch 1039/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1566 - accuracy: 0.5967 - val_loss: 1.2216 - val_accuracy: 0.6104\n",
      "Epoch 1040/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2035 - accuracy: 0.5723 - val_loss: 1.2212 - val_accuracy: 0.6136\n",
      "Epoch 1041/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2102 - accuracy: 0.5938 - val_loss: 1.2267 - val_accuracy: 0.6039\n",
      "Epoch 1042/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3049 - accuracy: 0.5381 - val_loss: 1.2409 - val_accuracy: 0.5877\n",
      "Epoch 1043/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2020 - accuracy: 0.5964 - val_loss: 1.2421 - val_accuracy: 0.5844\n",
      "Epoch 1044/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1811 - accuracy: 0.6034 - val_loss: 1.2356 - val_accuracy: 0.5877\n",
      "Epoch 1045/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2283 - accuracy: 0.5824 - val_loss: 1.2307 - val_accuracy: 0.5942\n",
      "Epoch 1046/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1843 - accuracy: 0.5824 - val_loss: 1.2222 - val_accuracy: 0.5909\n",
      "Epoch 1047/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2413 - accuracy: 0.5820 - val_loss: 1.2179 - val_accuracy: 0.5877\n",
      "Epoch 1048/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1547 - accuracy: 0.6034 - val_loss: 1.2327 - val_accuracy: 0.5779\n",
      "Epoch 1049/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1930 - accuracy: 0.5918 - val_loss: 1.2416 - val_accuracy: 0.5812\n",
      "Epoch 1050/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2373 - accuracy: 0.5726 - val_loss: 1.2754 - val_accuracy: 0.5779\n",
      "Epoch 1051/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1375 - accuracy: 0.5936 - val_loss: 1.2791 - val_accuracy: 0.5747\n",
      "Epoch 1052/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1452 - accuracy: 0.6064 - val_loss: 1.2705 - val_accuracy: 0.5779\n",
      "Epoch 1053/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2193 - accuracy: 0.5824 - val_loss: 1.2199 - val_accuracy: 0.5909\n",
      "Epoch 1054/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2235 - accuracy: 0.5850 - val_loss: 1.1808 - val_accuracy: 0.5942\n",
      "Epoch 1055/4000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.2586 - accuracy: 0.5830 - val_loss: 1.1383 - val_accuracy: 0.6169\n",
      "Epoch 1056/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1504 - accuracy: 0.6094 - val_loss: 1.1146 - val_accuracy: 0.6396\n",
      "Epoch 1057/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1464 - accuracy: 0.6047 - val_loss: 1.1010 - val_accuracy: 0.6429\n",
      "Epoch 1058/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1601 - accuracy: 0.5824 - val_loss: 1.1084 - val_accuracy: 0.6429\n",
      "Epoch 1059/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2111 - accuracy: 0.5889 - val_loss: 1.1201 - val_accuracy: 0.6494\n",
      "Epoch 1060/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2084 - accuracy: 0.5796 - val_loss: 1.1405 - val_accuracy: 0.6429\n",
      "Epoch 1061/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1662 - accuracy: 0.5928 - val_loss: 1.1681 - val_accuracy: 0.6201\n",
      "Epoch 1062/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1768 - accuracy: 0.6064 - val_loss: 1.1934 - val_accuracy: 0.6104\n",
      "Epoch 1063/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2121 - accuracy: 0.5791 - val_loss: 1.2133 - val_accuracy: 0.6039\n",
      "Epoch 1064/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2324 - accuracy: 0.5880 - val_loss: 1.2318 - val_accuracy: 0.5974\n",
      "Epoch 1065/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1184 - accuracy: 0.6133 - val_loss: 1.2224 - val_accuracy: 0.5974\n",
      "Epoch 1066/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1656 - accuracy: 0.6075 - val_loss: 1.1857 - val_accuracy: 0.6071\n",
      "Epoch 1067/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2457 - accuracy: 0.5596 - val_loss: 1.1480 - val_accuracy: 0.6201\n",
      "Epoch 1068/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2215 - accuracy: 0.5782 - val_loss: 1.1353 - val_accuracy: 0.6136\n",
      "Epoch 1069/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1842 - accuracy: 0.5894 - val_loss: 1.1675 - val_accuracy: 0.6006\n",
      "Epoch 1070/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1944 - accuracy: 0.5768 - val_loss: 1.1901 - val_accuracy: 0.5974\n",
      "Epoch 1071/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1533 - accuracy: 0.6133 - val_loss: 1.2279 - val_accuracy: 0.5974\n",
      "Epoch 1072/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1871 - accuracy: 0.5781 - val_loss: 1.2759 - val_accuracy: 0.5714\n",
      "Epoch 1073/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2172 - accuracy: 0.5918 - val_loss: 1.3023 - val_accuracy: 0.5487\n",
      "Epoch 1074/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1602 - accuracy: 0.6075 - val_loss: 1.3132 - val_accuracy: 0.5455\n",
      "Epoch 1075/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1793 - accuracy: 0.5879 - val_loss: 1.2748 - val_accuracy: 0.5487\n",
      "Epoch 1076/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1855 - accuracy: 0.5922 - val_loss: 1.2248 - val_accuracy: 0.5844\n",
      "Epoch 1077/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1803 - accuracy: 0.6145 - val_loss: 1.1837 - val_accuracy: 0.6006\n",
      "Epoch 1078/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1468 - accuracy: 0.5986 - val_loss: 1.1491 - val_accuracy: 0.6039\n",
      "Epoch 1079/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2290 - accuracy: 0.5852 - val_loss: 1.1247 - val_accuracy: 0.6169\n",
      "Epoch 1080/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1844 - accuracy: 0.5938 - val_loss: 1.1126 - val_accuracy: 0.6331\n",
      "Epoch 1081/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1199 - accuracy: 0.6215 - val_loss: 1.1024 - val_accuracy: 0.6299\n",
      "Epoch 1082/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1666 - accuracy: 0.5879 - val_loss: 1.1049 - val_accuracy: 0.6266\n",
      "Epoch 1083/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2073 - accuracy: 0.5782 - val_loss: 1.1068 - val_accuracy: 0.6201\n",
      "Epoch 1084/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1817 - accuracy: 0.6084 - val_loss: 1.1121 - val_accuracy: 0.6104\n",
      "Epoch 1085/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1556 - accuracy: 0.6089 - val_loss: 1.1186 - val_accuracy: 0.6136\n",
      "Epoch 1086/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1980 - accuracy: 0.5964 - val_loss: 1.1272 - val_accuracy: 0.6104\n",
      "Epoch 1087/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1287 - accuracy: 0.6064 - val_loss: 1.1387 - val_accuracy: 0.6104\n",
      "Epoch 1088/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2165 - accuracy: 0.5645 - val_loss: 1.1521 - val_accuracy: 0.5974\n",
      "Epoch 1089/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2081 - accuracy: 0.5936 - val_loss: 1.1560 - val_accuracy: 0.5942\n",
      "Epoch 1090/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1520 - accuracy: 0.6074 - val_loss: 1.1616 - val_accuracy: 0.5909\n",
      "Epoch 1091/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1097 - accuracy: 0.6411 - val_loss: 1.1606 - val_accuracy: 0.5942\n",
      "Epoch 1092/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1542 - accuracy: 0.6035 - val_loss: 1.1517 - val_accuracy: 0.5974\n",
      "Epoch 1093/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1316 - accuracy: 0.6211 - val_loss: 1.1421 - val_accuracy: 0.6006\n",
      "Epoch 1094/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1748 - accuracy: 0.6133 - val_loss: 1.1180 - val_accuracy: 0.6071\n",
      "Epoch 1095/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1326 - accuracy: 0.6025 - val_loss: 1.0961 - val_accuracy: 0.6234\n",
      "Epoch 1096/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2117 - accuracy: 0.5740 - val_loss: 1.0878 - val_accuracy: 0.6201\n",
      "Epoch 1097/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1867 - accuracy: 0.5894 - val_loss: 1.0914 - val_accuracy: 0.6136\n",
      "Epoch 1098/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1341 - accuracy: 0.6103 - val_loss: 1.0949 - val_accuracy: 0.6201\n",
      "Epoch 1099/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1416 - accuracy: 0.6162 - val_loss: 1.0887 - val_accuracy: 0.6299\n",
      "Epoch 1100/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1185 - accuracy: 0.6103 - val_loss: 1.0843 - val_accuracy: 0.6201\n",
      "Epoch 1101/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1187 - accuracy: 0.6103 - val_loss: 1.0835 - val_accuracy: 0.6169\n",
      "Epoch 1102/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1604 - accuracy: 0.6074 - val_loss: 1.0937 - val_accuracy: 0.6136\n",
      "Epoch 1103/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1000 - accuracy: 0.6289 - val_loss: 1.1091 - val_accuracy: 0.6071\n",
      "Epoch 1104/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2400 - accuracy: 0.5503 - val_loss: 1.1244 - val_accuracy: 0.5974\n",
      "Epoch 1105/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1718 - accuracy: 0.6016 - val_loss: 1.1428 - val_accuracy: 0.6006\n",
      "Epoch 1106/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1989 - accuracy: 0.5889 - val_loss: 1.1635 - val_accuracy: 0.6039\n",
      "Epoch 1107/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0755 - accuracy: 0.6215 - val_loss: 1.1907 - val_accuracy: 0.5942\n",
      "Epoch 1108/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0999 - accuracy: 0.6162 - val_loss: 1.2165 - val_accuracy: 0.5844\n",
      "Epoch 1109/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1175 - accuracy: 0.6271 - val_loss: 1.2531 - val_accuracy: 0.5747\n",
      "Epoch 1110/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1693 - accuracy: 0.6145 - val_loss: 1.2761 - val_accuracy: 0.5552\n",
      "Epoch 1111/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0948 - accuracy: 0.6145 - val_loss: 1.2962 - val_accuracy: 0.5617\n",
      "Epoch 1112/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1637 - accuracy: 0.6123 - val_loss: 1.3033 - val_accuracy: 0.5519\n",
      "Epoch 1113/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1495 - accuracy: 0.6240 - val_loss: 1.3104 - val_accuracy: 0.5487\n",
      "Epoch 1114/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1391 - accuracy: 0.6172 - val_loss: 1.2822 - val_accuracy: 0.5584\n",
      "Epoch 1115/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1197 - accuracy: 0.6172 - val_loss: 1.2699 - val_accuracy: 0.5519\n",
      "Epoch 1116/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2109 - accuracy: 0.6020 - val_loss: 1.2795 - val_accuracy: 0.5682\n",
      "Epoch 1117/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1681 - accuracy: 0.5894 - val_loss: 1.3234 - val_accuracy: 0.5682\n",
      "Epoch 1118/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0816 - accuracy: 0.6104 - val_loss: 1.3892 - val_accuracy: 0.5519\n",
      "Epoch 1119/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1038 - accuracy: 0.6133 - val_loss: 1.4714 - val_accuracy: 0.5390\n",
      "Epoch 1120/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0930 - accuracy: 0.6313 - val_loss: 1.5615 - val_accuracy: 0.5162\n",
      "Epoch 1121/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0933 - accuracy: 0.6377 - val_loss: 1.6096 - val_accuracy: 0.5227\n",
      "Epoch 1122/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1404 - accuracy: 0.6201 - val_loss: 1.6209 - val_accuracy: 0.5097\n",
      "Epoch 1123/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1227 - accuracy: 0.6020 - val_loss: 1.6042 - val_accuracy: 0.5097\n",
      "Epoch 1124/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1682 - accuracy: 0.6104 - val_loss: 1.5164 - val_accuracy: 0.5195\n",
      "Epoch 1125/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1325 - accuracy: 0.6173 - val_loss: 1.4168 - val_accuracy: 0.5519\n",
      "Epoch 1126/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1113 - accuracy: 0.6201 - val_loss: 1.3176 - val_accuracy: 0.5682\n",
      "Epoch 1127/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1382 - accuracy: 0.6299 - val_loss: 1.2583 - val_accuracy: 0.5844\n",
      "Epoch 1128/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0894 - accuracy: 0.6145 - val_loss: 1.2020 - val_accuracy: 0.5909\n",
      "Epoch 1129/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1406 - accuracy: 0.6143 - val_loss: 1.1726 - val_accuracy: 0.5974\n",
      "Epoch 1130/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2017 - accuracy: 0.5908 - val_loss: 1.1679 - val_accuracy: 0.5877\n",
      "Epoch 1131/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1071 - accuracy: 0.6191 - val_loss: 1.1714 - val_accuracy: 0.5942\n",
      "Epoch 1132/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0936 - accuracy: 0.6162 - val_loss: 1.1613 - val_accuracy: 0.5974\n",
      "Epoch 1133/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1135 - accuracy: 0.6243 - val_loss: 1.1484 - val_accuracy: 0.5974\n",
      "Epoch 1134/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0885 - accuracy: 0.6445 - val_loss: 1.1313 - val_accuracy: 0.6006\n",
      "Epoch 1135/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1138 - accuracy: 0.6313 - val_loss: 1.1324 - val_accuracy: 0.5942\n",
      "Epoch 1136/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1588 - accuracy: 0.5838 - val_loss: 1.1542 - val_accuracy: 0.5942\n",
      "Epoch 1137/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1655 - accuracy: 0.6094 - val_loss: 1.1956 - val_accuracy: 0.5844\n",
      "Epoch 1138/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1088 - accuracy: 0.6172 - val_loss: 1.2373 - val_accuracy: 0.5649\n",
      "Epoch 1139/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1132 - accuracy: 0.6211 - val_loss: 1.2824 - val_accuracy: 0.5487\n",
      "Epoch 1140/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0894 - accuracy: 0.6215 - val_loss: 1.3260 - val_accuracy: 0.5390\n",
      "Epoch 1141/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1443 - accuracy: 0.5922 - val_loss: 1.3226 - val_accuracy: 0.5390\n",
      "Epoch 1142/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0452 - accuracy: 0.6367 - val_loss: 1.2961 - val_accuracy: 0.5357\n",
      "Epoch 1143/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1183 - accuracy: 0.6123 - val_loss: 1.2720 - val_accuracy: 0.5455\n",
      "Epoch 1144/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1568 - accuracy: 0.5936 - val_loss: 1.2268 - val_accuracy: 0.5682\n",
      "Epoch 1145/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1254 - accuracy: 0.6257 - val_loss: 1.1817 - val_accuracy: 0.5747\n",
      "Epoch 1146/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1072 - accuracy: 0.6243 - val_loss: 1.1469 - val_accuracy: 0.5942\n",
      "Epoch 1147/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1222 - accuracy: 0.6229 - val_loss: 1.1315 - val_accuracy: 0.5974\n",
      "Epoch 1148/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1087 - accuracy: 0.6377 - val_loss: 1.1400 - val_accuracy: 0.6006\n",
      "Epoch 1149/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1174 - accuracy: 0.6075 - val_loss: 1.1578 - val_accuracy: 0.6006\n",
      "Epoch 1150/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0727 - accuracy: 0.6299 - val_loss: 1.1622 - val_accuracy: 0.6039\n",
      "Epoch 1151/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1116 - accuracy: 0.6341 - val_loss: 1.1592 - val_accuracy: 0.6136\n",
      "Epoch 1152/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1283 - accuracy: 0.6094 - val_loss: 1.1501 - val_accuracy: 0.6039\n",
      "Epoch 1153/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0821 - accuracy: 0.6257 - val_loss: 1.1577 - val_accuracy: 0.6136\n",
      "Epoch 1154/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1092 - accuracy: 0.6260 - val_loss: 1.1685 - val_accuracy: 0.5942\n",
      "Epoch 1155/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1123 - accuracy: 0.6211 - val_loss: 1.1631 - val_accuracy: 0.5909\n",
      "Epoch 1156/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0523 - accuracy: 0.6466 - val_loss: 1.1604 - val_accuracy: 0.5942\n",
      "Epoch 1157/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0600 - accuracy: 0.6270 - val_loss: 1.1506 - val_accuracy: 0.6104\n",
      "Epoch 1158/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.0771 - accuracy: 0.6285 - val_loss: 1.1488 - val_accuracy: 0.6136\n",
      "Epoch 1159/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0744 - accuracy: 0.6230 - val_loss: 1.1392 - val_accuracy: 0.6234\n",
      "Epoch 1160/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1228 - accuracy: 0.6369 - val_loss: 1.1312 - val_accuracy: 0.6169\n",
      "Epoch 1161/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0662 - accuracy: 0.6309 - val_loss: 1.1282 - val_accuracy: 0.5942\n",
      "Epoch 1162/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1267 - accuracy: 0.6215 - val_loss: 1.1308 - val_accuracy: 0.5747\n",
      "Epoch 1163/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0885 - accuracy: 0.6230 - val_loss: 1.1315 - val_accuracy: 0.5747\n",
      "Epoch 1164/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0370 - accuracy: 0.6338 - val_loss: 1.1388 - val_accuracy: 0.5812\n",
      "Epoch 1165/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0981 - accuracy: 0.6285 - val_loss: 1.1546 - val_accuracy: 0.5779\n",
      "Epoch 1166/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0811 - accuracy: 0.6211 - val_loss: 1.1694 - val_accuracy: 0.5714\n",
      "Epoch 1167/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1701 - accuracy: 0.6006 - val_loss: 1.1787 - val_accuracy: 0.5747\n",
      "Epoch 1168/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1059 - accuracy: 0.6494 - val_loss: 1.1804 - val_accuracy: 0.5779\n",
      "Epoch 1169/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0844 - accuracy: 0.6369 - val_loss: 1.1846 - val_accuracy: 0.5779\n",
      "Epoch 1170/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0303 - accuracy: 0.6504 - val_loss: 1.1970 - val_accuracy: 0.5844\n",
      "Epoch 1171/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0819 - accuracy: 0.6426 - val_loss: 1.2008 - val_accuracy: 0.5909\n",
      "Epoch 1172/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1226 - accuracy: 0.6162 - val_loss: 1.1930 - val_accuracy: 0.5779\n",
      "Epoch 1173/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0357 - accuracy: 0.6550 - val_loss: 1.1889 - val_accuracy: 0.5844\n",
      "Epoch 1174/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0722 - accuracy: 0.6397 - val_loss: 1.1821 - val_accuracy: 0.5747\n",
      "Epoch 1175/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0585 - accuracy: 0.6426 - val_loss: 1.1738 - val_accuracy: 0.5779\n",
      "Epoch 1176/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0388 - accuracy: 0.6536 - val_loss: 1.1643 - val_accuracy: 0.5877\n",
      "Epoch 1177/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1054 - accuracy: 0.6240 - val_loss: 1.1613 - val_accuracy: 0.5974\n",
      "Epoch 1178/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0460 - accuracy: 0.6387 - val_loss: 1.1633 - val_accuracy: 0.5942\n",
      "Epoch 1179/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1101 - accuracy: 0.6270 - val_loss: 1.1798 - val_accuracy: 0.5812\n",
      "Epoch 1180/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1432 - accuracy: 0.6327 - val_loss: 1.1917 - val_accuracy: 0.5747\n",
      "Epoch 1181/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0415 - accuracy: 0.6439 - val_loss: 1.1889 - val_accuracy: 0.6104\n",
      "Epoch 1182/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0912 - accuracy: 0.6387 - val_loss: 1.1673 - val_accuracy: 0.6104\n",
      "Epoch 1183/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1005 - accuracy: 0.6131 - val_loss: 1.1425 - val_accuracy: 0.6169\n",
      "Epoch 1184/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0978 - accuracy: 0.6328 - val_loss: 1.1180 - val_accuracy: 0.6234\n",
      "Epoch 1185/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0899 - accuracy: 0.6289 - val_loss: 1.0981 - val_accuracy: 0.6039\n",
      "Epoch 1186/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0244 - accuracy: 0.6508 - val_loss: 1.0873 - val_accuracy: 0.6169\n",
      "Epoch 1187/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1087 - accuracy: 0.6240 - val_loss: 1.1045 - val_accuracy: 0.6169\n",
      "Epoch 1188/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0618 - accuracy: 0.6348 - val_loss: 1.1269 - val_accuracy: 0.6104\n",
      "Epoch 1189/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0734 - accuracy: 0.6260 - val_loss: 1.1488 - val_accuracy: 0.5942\n",
      "Epoch 1190/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0806 - accuracy: 0.6289 - val_loss: 1.1920 - val_accuracy: 0.5974\n",
      "Epoch 1191/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0684 - accuracy: 0.6377 - val_loss: 1.2183 - val_accuracy: 0.5909\n",
      "Epoch 1192/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0424 - accuracy: 0.6369 - val_loss: 1.2524 - val_accuracy: 0.5877\n",
      "Epoch 1193/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0467 - accuracy: 0.6426 - val_loss: 1.2665 - val_accuracy: 0.5844\n",
      "Epoch 1194/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0370 - accuracy: 0.6536 - val_loss: 1.2554 - val_accuracy: 0.5844\n",
      "Epoch 1195/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0374 - accuracy: 0.6480 - val_loss: 1.2496 - val_accuracy: 0.5877\n",
      "Epoch 1196/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0797 - accuracy: 0.6113 - val_loss: 1.2572 - val_accuracy: 0.5844\n",
      "Epoch 1197/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0541 - accuracy: 0.6543 - val_loss: 1.2729 - val_accuracy: 0.5812\n",
      "Epoch 1198/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0505 - accuracy: 0.6355 - val_loss: 1.3056 - val_accuracy: 0.5649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1199/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1041 - accuracy: 0.6191 - val_loss: 1.3476 - val_accuracy: 0.5714\n",
      "Epoch 1200/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0735 - accuracy: 0.6348 - val_loss: 1.3675 - val_accuracy: 0.5617\n",
      "Epoch 1201/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0849 - accuracy: 0.6338 - val_loss: 1.3686 - val_accuracy: 0.5584\n",
      "Epoch 1202/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0975 - accuracy: 0.6445 - val_loss: 1.3793 - val_accuracy: 0.5552\n",
      "Epoch 1203/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0328 - accuracy: 0.6523 - val_loss: 1.3727 - val_accuracy: 0.5617\n",
      "Epoch 1204/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0505 - accuracy: 0.6257 - val_loss: 1.3932 - val_accuracy: 0.5455\n",
      "Epoch 1205/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0169 - accuracy: 0.6522 - val_loss: 1.4052 - val_accuracy: 0.5455\n",
      "Epoch 1206/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0235 - accuracy: 0.6465 - val_loss: 1.4137 - val_accuracy: 0.5390\n",
      "Epoch 1207/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0551 - accuracy: 0.6367 - val_loss: 1.4393 - val_accuracy: 0.5357\n",
      "Epoch 1208/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0090 - accuracy: 0.6522 - val_loss: 1.4223 - val_accuracy: 0.5325\n",
      "Epoch 1209/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1371 - accuracy: 0.6182 - val_loss: 1.3974 - val_accuracy: 0.5390\n",
      "Epoch 1210/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0428 - accuracy: 0.6411 - val_loss: 1.3710 - val_accuracy: 0.5422\n",
      "Epoch 1211/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1033 - accuracy: 0.6250 - val_loss: 1.3407 - val_accuracy: 0.5552\n",
      "Epoch 1212/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1013 - accuracy: 0.6172 - val_loss: 1.3072 - val_accuracy: 0.5682\n",
      "Epoch 1213/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0115 - accuracy: 0.6704 - val_loss: 1.3113 - val_accuracy: 0.5714\n",
      "Epoch 1214/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0264 - accuracy: 0.6357 - val_loss: 1.3278 - val_accuracy: 0.5682\n",
      "Epoch 1215/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0848 - accuracy: 0.6367 - val_loss: 1.3459 - val_accuracy: 0.5487\n",
      "Epoch 1216/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0575 - accuracy: 0.6465 - val_loss: 1.3490 - val_accuracy: 0.5487\n",
      "Epoch 1217/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0033 - accuracy: 0.6662 - val_loss: 1.3412 - val_accuracy: 0.5455\n",
      "Epoch 1218/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0377 - accuracy: 0.6411 - val_loss: 1.3149 - val_accuracy: 0.5552\n",
      "Epoch 1219/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0666 - accuracy: 0.6355 - val_loss: 1.2897 - val_accuracy: 0.5519\n",
      "Epoch 1220/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0136 - accuracy: 0.6550 - val_loss: 1.2604 - val_accuracy: 0.5682\n",
      "Epoch 1221/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9955 - accuracy: 0.6650 - val_loss: 1.2333 - val_accuracy: 0.5682\n",
      "Epoch 1222/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0765 - accuracy: 0.6318 - val_loss: 1.2057 - val_accuracy: 0.5779\n",
      "Epoch 1223/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0546 - accuracy: 0.6387 - val_loss: 1.1909 - val_accuracy: 0.5844\n",
      "Epoch 1224/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0430 - accuracy: 0.6455 - val_loss: 1.2011 - val_accuracy: 0.5812\n",
      "Epoch 1225/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0412 - accuracy: 0.6522 - val_loss: 1.2430 - val_accuracy: 0.5747\n",
      "Epoch 1226/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0388 - accuracy: 0.6533 - val_loss: 1.2949 - val_accuracy: 0.5649\n",
      "Epoch 1227/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0026 - accuracy: 0.6611 - val_loss: 1.3389 - val_accuracy: 0.5487\n",
      "Epoch 1228/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0843 - accuracy: 0.6355 - val_loss: 1.3568 - val_accuracy: 0.5519\n",
      "Epoch 1229/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0324 - accuracy: 0.6411 - val_loss: 1.3612 - val_accuracy: 0.5487\n",
      "Epoch 1230/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0718 - accuracy: 0.6367 - val_loss: 1.3389 - val_accuracy: 0.5552\n",
      "Epoch 1231/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0991 - accuracy: 0.6313 - val_loss: 1.3441 - val_accuracy: 0.5617\n",
      "Epoch 1232/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0451 - accuracy: 0.6348 - val_loss: 1.3693 - val_accuracy: 0.5552\n",
      "Epoch 1233/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0908 - accuracy: 0.6466 - val_loss: 1.3741 - val_accuracy: 0.5552\n",
      "Epoch 1234/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0111 - accuracy: 0.6709 - val_loss: 1.4032 - val_accuracy: 0.5519\n",
      "Epoch 1235/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0466 - accuracy: 0.6377 - val_loss: 1.4311 - val_accuracy: 0.5357\n",
      "Epoch 1236/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0357 - accuracy: 0.6453 - val_loss: 1.4237 - val_accuracy: 0.5357\n",
      "Epoch 1237/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9842 - accuracy: 0.6729 - val_loss: 1.4091 - val_accuracy: 0.5455\n",
      "Epoch 1238/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0321 - accuracy: 0.6453 - val_loss: 1.3565 - val_accuracy: 0.5617\n",
      "Epoch 1239/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0915 - accuracy: 0.6338 - val_loss: 1.3121 - val_accuracy: 0.5682\n",
      "Epoch 1240/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0205 - accuracy: 0.6536 - val_loss: 1.2630 - val_accuracy: 0.5747\n",
      "Epoch 1241/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0268 - accuracy: 0.6508 - val_loss: 1.2469 - val_accuracy: 0.5779\n",
      "Epoch 1242/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0682 - accuracy: 0.6285 - val_loss: 1.2306 - val_accuracy: 0.5747\n",
      "Epoch 1243/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0793 - accuracy: 0.6313 - val_loss: 1.2186 - val_accuracy: 0.5877\n",
      "Epoch 1244/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9883 - accuracy: 0.6650 - val_loss: 1.2180 - val_accuracy: 0.5877\n",
      "Epoch 1245/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0763 - accuracy: 0.6327 - val_loss: 1.2305 - val_accuracy: 0.5844\n",
      "Epoch 1246/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0585 - accuracy: 0.6411 - val_loss: 1.2647 - val_accuracy: 0.5779\n",
      "Epoch 1247/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0076 - accuracy: 0.6523 - val_loss: 1.2985 - val_accuracy: 0.5779\n",
      "Epoch 1248/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0817 - accuracy: 0.6250 - val_loss: 1.3202 - val_accuracy: 0.5812\n",
      "Epoch 1249/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0303 - accuracy: 0.6411 - val_loss: 1.3177 - val_accuracy: 0.5747\n",
      "Epoch 1250/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0017 - accuracy: 0.6582 - val_loss: 1.3021 - val_accuracy: 0.5682\n",
      "Epoch 1251/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0408 - accuracy: 0.6872 - val_loss: 1.2974 - val_accuracy: 0.5617\n",
      "Epoch 1252/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0425 - accuracy: 0.6550 - val_loss: 1.2969 - val_accuracy: 0.5422\n",
      "Epoch 1253/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0416 - accuracy: 0.6522 - val_loss: 1.3080 - val_accuracy: 0.5292\n",
      "Epoch 1254/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0324 - accuracy: 0.6564 - val_loss: 1.2976 - val_accuracy: 0.5390\n",
      "Epoch 1255/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1154 - accuracy: 0.6348 - val_loss: 1.2649 - val_accuracy: 0.5519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1256/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9710 - accuracy: 0.6660 - val_loss: 1.2305 - val_accuracy: 0.5682\n",
      "Epoch 1257/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0238 - accuracy: 0.6606 - val_loss: 1.2512 - val_accuracy: 0.5812\n",
      "Epoch 1258/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.0424 - accuracy: 0.6494 - val_loss: 1.2700 - val_accuracy: 0.5779\n",
      "Epoch 1259/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1036 - accuracy: 0.6055 - val_loss: 1.2601 - val_accuracy: 0.5779\n",
      "Epoch 1260/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0136 - accuracy: 0.6634 - val_loss: 1.2257 - val_accuracy: 0.5942\n",
      "Epoch 1261/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9823 - accuracy: 0.6816 - val_loss: 1.1874 - val_accuracy: 0.5974\n",
      "Epoch 1262/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0253 - accuracy: 0.6453 - val_loss: 1.1527 - val_accuracy: 0.5942\n",
      "Epoch 1263/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0434 - accuracy: 0.6533 - val_loss: 1.1384 - val_accuracy: 0.5974\n",
      "Epoch 1264/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0067 - accuracy: 0.6504 - val_loss: 1.1308 - val_accuracy: 0.5909\n",
      "Epoch 1265/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0381 - accuracy: 0.6299 - val_loss: 1.1456 - val_accuracy: 0.6104\n",
      "Epoch 1266/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0040 - accuracy: 0.6572 - val_loss: 1.1615 - val_accuracy: 0.6071\n",
      "Epoch 1267/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9896 - accuracy: 0.6660 - val_loss: 1.1733 - val_accuracy: 0.5909\n",
      "Epoch 1268/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9906 - accuracy: 0.6729 - val_loss: 1.1880 - val_accuracy: 0.5942\n",
      "Epoch 1269/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9883 - accuracy: 0.6816 - val_loss: 1.1986 - val_accuracy: 0.5844\n",
      "Epoch 1270/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0412 - accuracy: 0.6406 - val_loss: 1.1911 - val_accuracy: 0.5812\n",
      "Epoch 1271/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0655 - accuracy: 0.6397 - val_loss: 1.1705 - val_accuracy: 0.5877\n",
      "Epoch 1272/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0183 - accuracy: 0.6508 - val_loss: 1.1399 - val_accuracy: 0.5974\n",
      "Epoch 1273/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9494 - accuracy: 0.6680 - val_loss: 1.1046 - val_accuracy: 0.6071\n",
      "Epoch 1274/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0437 - accuracy: 0.6369 - val_loss: 1.0852 - val_accuracy: 0.6104\n",
      "Epoch 1275/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0316 - accuracy: 0.6536 - val_loss: 1.0759 - val_accuracy: 0.6104\n",
      "Epoch 1276/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0409 - accuracy: 0.6313 - val_loss: 1.0758 - val_accuracy: 0.6039\n",
      "Epoch 1277/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0658 - accuracy: 0.6494 - val_loss: 1.0758 - val_accuracy: 0.6136\n",
      "Epoch 1278/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9940 - accuracy: 0.6662 - val_loss: 1.0959 - val_accuracy: 0.6234\n",
      "Epoch 1279/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9522 - accuracy: 0.6865 - val_loss: 1.1112 - val_accuracy: 0.6136\n",
      "Epoch 1280/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9935 - accuracy: 0.6631 - val_loss: 1.1101 - val_accuracy: 0.6234\n",
      "Epoch 1281/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9629 - accuracy: 0.6788 - val_loss: 1.0902 - val_accuracy: 0.6266\n",
      "Epoch 1282/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0311 - accuracy: 0.6660 - val_loss: 1.0708 - val_accuracy: 0.6331\n",
      "Epoch 1283/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9700 - accuracy: 0.6453 - val_loss: 1.0571 - val_accuracy: 0.6364\n",
      "Epoch 1284/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9929 - accuracy: 0.6680 - val_loss: 1.0640 - val_accuracy: 0.6299\n",
      "Epoch 1285/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0177 - accuracy: 0.6648 - val_loss: 1.0841 - val_accuracy: 0.6169\n",
      "Epoch 1286/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0257 - accuracy: 0.6578 - val_loss: 1.1142 - val_accuracy: 0.6201\n",
      "Epoch 1287/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0137 - accuracy: 0.6436 - val_loss: 1.1546 - val_accuracy: 0.6006\n",
      "Epoch 1288/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9735 - accuracy: 0.6662 - val_loss: 1.2072 - val_accuracy: 0.6006\n",
      "Epoch 1289/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9555 - accuracy: 0.6924 - val_loss: 1.2431 - val_accuracy: 0.6071\n",
      "Epoch 1290/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9863 - accuracy: 0.6690 - val_loss: 1.2512 - val_accuracy: 0.5974\n",
      "Epoch 1291/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9833 - accuracy: 0.6484 - val_loss: 1.2292 - val_accuracy: 0.6071\n",
      "Epoch 1292/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9950 - accuracy: 0.6572 - val_loss: 1.2171 - val_accuracy: 0.5942\n",
      "Epoch 1293/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0168 - accuracy: 0.6550 - val_loss: 1.2084 - val_accuracy: 0.6006\n",
      "Epoch 1294/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9739 - accuracy: 0.6955 - val_loss: 1.1851 - val_accuracy: 0.6201\n",
      "Epoch 1295/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9530 - accuracy: 0.6872 - val_loss: 1.1399 - val_accuracy: 0.6201\n",
      "Epoch 1296/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0168 - accuracy: 0.6621 - val_loss: 1.1148 - val_accuracy: 0.6136\n",
      "Epoch 1297/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9978 - accuracy: 0.6611 - val_loss: 1.1065 - val_accuracy: 0.6136\n",
      "Epoch 1298/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9997 - accuracy: 0.6578 - val_loss: 1.1015 - val_accuracy: 0.6201\n",
      "Epoch 1299/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9799 - accuracy: 0.6802 - val_loss: 1.1128 - val_accuracy: 0.6201\n",
      "Epoch 1300/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9750 - accuracy: 0.6738 - val_loss: 1.1304 - val_accuracy: 0.6136\n",
      "Epoch 1301/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9795 - accuracy: 0.6760 - val_loss: 1.1459 - val_accuracy: 0.6071\n",
      "Epoch 1302/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9485 - accuracy: 0.6758 - val_loss: 1.1549 - val_accuracy: 0.6039\n",
      "Epoch 1303/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9432 - accuracy: 0.6760 - val_loss: 1.1561 - val_accuracy: 0.6006\n",
      "Epoch 1304/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0031 - accuracy: 0.6611 - val_loss: 1.1693 - val_accuracy: 0.5974\n",
      "Epoch 1305/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0025 - accuracy: 0.6641 - val_loss: 1.1589 - val_accuracy: 0.6039\n",
      "Epoch 1306/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9675 - accuracy: 0.6631 - val_loss: 1.1347 - val_accuracy: 0.6136\n",
      "Epoch 1307/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9737 - accuracy: 0.6777 - val_loss: 1.1015 - val_accuracy: 0.6299\n",
      "Epoch 1308/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9655 - accuracy: 0.6797 - val_loss: 1.0749 - val_accuracy: 0.6364\n",
      "Epoch 1309/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9393 - accuracy: 0.6875 - val_loss: 1.0584 - val_accuracy: 0.6429\n",
      "Epoch 1310/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9726 - accuracy: 0.6592 - val_loss: 1.0465 - val_accuracy: 0.6396\n",
      "Epoch 1311/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9466 - accuracy: 0.6844 - val_loss: 1.0427 - val_accuracy: 0.6494\n",
      "Epoch 1312/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9486 - accuracy: 0.6865 - val_loss: 1.0410 - val_accuracy: 0.6461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1313/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9726 - accuracy: 0.6816 - val_loss: 1.0493 - val_accuracy: 0.6266\n",
      "Epoch 1314/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0321 - accuracy: 0.6602 - val_loss: 1.0572 - val_accuracy: 0.6266\n",
      "Epoch 1315/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9759 - accuracy: 0.6699 - val_loss: 1.0698 - val_accuracy: 0.6364\n",
      "Epoch 1316/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9165 - accuracy: 0.6836 - val_loss: 1.0696 - val_accuracy: 0.6299\n",
      "Epoch 1317/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9605 - accuracy: 0.6924 - val_loss: 1.0667 - val_accuracy: 0.6364\n",
      "Epoch 1318/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9307 - accuracy: 0.6758 - val_loss: 1.0716 - val_accuracy: 0.6364\n",
      "Epoch 1319/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9961 - accuracy: 0.6718 - val_loss: 1.0687 - val_accuracy: 0.6429\n",
      "Epoch 1320/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9725 - accuracy: 0.6718 - val_loss: 1.0691 - val_accuracy: 0.6331\n",
      "Epoch 1321/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9605 - accuracy: 0.6802 - val_loss: 1.0539 - val_accuracy: 0.6364\n",
      "Epoch 1322/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9323 - accuracy: 0.6768 - val_loss: 1.0502 - val_accuracy: 0.6266\n",
      "Epoch 1323/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9543 - accuracy: 0.6858 - val_loss: 1.0570 - val_accuracy: 0.6266\n",
      "Epoch 1324/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9393 - accuracy: 0.6844 - val_loss: 1.0673 - val_accuracy: 0.6299\n",
      "Epoch 1325/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9339 - accuracy: 0.6746 - val_loss: 1.0852 - val_accuracy: 0.6234\n",
      "Epoch 1326/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0095 - accuracy: 0.6504 - val_loss: 1.0984 - val_accuracy: 0.6169\n",
      "Epoch 1327/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9856 - accuracy: 0.6729 - val_loss: 1.0902 - val_accuracy: 0.6039\n",
      "Epoch 1328/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9673 - accuracy: 0.6621 - val_loss: 1.0793 - val_accuracy: 0.6006\n",
      "Epoch 1329/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9301 - accuracy: 0.6941 - val_loss: 1.0763 - val_accuracy: 0.6201\n",
      "Epoch 1330/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9668 - accuracy: 0.6830 - val_loss: 1.0749 - val_accuracy: 0.6234\n",
      "Epoch 1331/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9747 - accuracy: 0.6729 - val_loss: 1.0815 - val_accuracy: 0.6234\n",
      "Epoch 1332/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9257 - accuracy: 0.6969 - val_loss: 1.0964 - val_accuracy: 0.6071\n",
      "Epoch 1333/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0539 - accuracy: 0.6328 - val_loss: 1.1074 - val_accuracy: 0.6104\n",
      "Epoch 1334/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9592 - accuracy: 0.6774 - val_loss: 1.1167 - val_accuracy: 0.6104\n",
      "Epoch 1335/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9716 - accuracy: 0.6592 - val_loss: 1.1390 - val_accuracy: 0.6104\n",
      "Epoch 1336/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9502 - accuracy: 0.6816 - val_loss: 1.1435 - val_accuracy: 0.6071\n",
      "Epoch 1337/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9798 - accuracy: 0.6872 - val_loss: 1.1409 - val_accuracy: 0.6136\n",
      "Epoch 1338/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9908 - accuracy: 0.6606 - val_loss: 1.1430 - val_accuracy: 0.6169\n",
      "Epoch 1339/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9257 - accuracy: 0.6844 - val_loss: 1.1365 - val_accuracy: 0.6104\n",
      "Epoch 1340/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9422 - accuracy: 0.6895 - val_loss: 1.1272 - val_accuracy: 0.6169\n",
      "Epoch 1341/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9653 - accuracy: 0.6621 - val_loss: 1.1096 - val_accuracy: 0.6201\n",
      "Epoch 1342/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9158 - accuracy: 0.6963 - val_loss: 1.0835 - val_accuracy: 0.6331\n",
      "Epoch 1343/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9845 - accuracy: 0.6689 - val_loss: 1.0830 - val_accuracy: 0.6364\n",
      "Epoch 1344/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8784 - accuracy: 0.7123 - val_loss: 1.0837 - val_accuracy: 0.6299\n",
      "Epoch 1345/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9445 - accuracy: 0.6872 - val_loss: 1.0930 - val_accuracy: 0.6396\n",
      "Epoch 1346/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9643 - accuracy: 0.6802 - val_loss: 1.0989 - val_accuracy: 0.6266\n",
      "Epoch 1347/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0106 - accuracy: 0.6582 - val_loss: 1.1112 - val_accuracy: 0.6234\n",
      "Epoch 1348/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9384 - accuracy: 0.6858 - val_loss: 1.1537 - val_accuracy: 0.6136\n",
      "Epoch 1349/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9545 - accuracy: 0.6885 - val_loss: 1.2026 - val_accuracy: 0.6039\n",
      "Epoch 1350/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9433 - accuracy: 0.6620 - val_loss: 1.2300 - val_accuracy: 0.5974\n",
      "Epoch 1351/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9353 - accuracy: 0.6885 - val_loss: 1.2798 - val_accuracy: 0.5877\n",
      "Epoch 1352/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9376 - accuracy: 0.6914 - val_loss: 1.3333 - val_accuracy: 0.5779\n",
      "Epoch 1353/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9750 - accuracy: 0.6564 - val_loss: 1.3509 - val_accuracy: 0.5617\n",
      "Epoch 1354/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9598 - accuracy: 0.6621 - val_loss: 1.3297 - val_accuracy: 0.5487\n",
      "Epoch 1355/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9071 - accuracy: 0.6973 - val_loss: 1.2970 - val_accuracy: 0.5487\n",
      "Epoch 1356/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9436 - accuracy: 0.6927 - val_loss: 1.2562 - val_accuracy: 0.5584\n",
      "Epoch 1357/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9916 - accuracy: 0.6494 - val_loss: 1.2166 - val_accuracy: 0.5812\n",
      "Epoch 1358/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9619 - accuracy: 0.6836 - val_loss: 1.1843 - val_accuracy: 0.5779\n",
      "Epoch 1359/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9463 - accuracy: 0.6830 - val_loss: 1.1707 - val_accuracy: 0.5844\n",
      "Epoch 1360/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9711 - accuracy: 0.6816 - val_loss: 1.1553 - val_accuracy: 0.6039\n",
      "Epoch 1361/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9865 - accuracy: 0.6592 - val_loss: 1.1503 - val_accuracy: 0.6234\n",
      "Epoch 1362/4000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9266 - accuracy: 0.6807 - val_loss: 1.1422 - val_accuracy: 0.6169\n",
      "Epoch 1363/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9628 - accuracy: 0.6983 - val_loss: 1.1501 - val_accuracy: 0.6169\n",
      "Epoch 1364/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9037 - accuracy: 0.6914 - val_loss: 1.1645 - val_accuracy: 0.6071\n",
      "Epoch 1365/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9316 - accuracy: 0.6904 - val_loss: 1.1633 - val_accuracy: 0.6136\n",
      "Epoch 1366/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0076 - accuracy: 0.6602 - val_loss: 1.1713 - val_accuracy: 0.6136\n",
      "Epoch 1367/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9260 - accuracy: 0.6826 - val_loss: 1.1902 - val_accuracy: 0.5909\n",
      "Epoch 1368/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8984 - accuracy: 0.7053 - val_loss: 1.1988 - val_accuracy: 0.5909\n",
      "Epoch 1369/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9653 - accuracy: 0.6855 - val_loss: 1.1971 - val_accuracy: 0.5909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1370/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9536 - accuracy: 0.6836 - val_loss: 1.1855 - val_accuracy: 0.5909\n",
      "Epoch 1371/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8744 - accuracy: 0.6941 - val_loss: 1.1664 - val_accuracy: 0.5877\n",
      "Epoch 1372/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9765 - accuracy: 0.6680 - val_loss: 1.1423 - val_accuracy: 0.5909\n",
      "Epoch 1373/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9388 - accuracy: 0.6760 - val_loss: 1.1295 - val_accuracy: 0.6006\n",
      "Epoch 1374/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9582 - accuracy: 0.6774 - val_loss: 1.1451 - val_accuracy: 0.5974\n",
      "Epoch 1375/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9122 - accuracy: 0.6826 - val_loss: 1.1526 - val_accuracy: 0.5974\n",
      "Epoch 1376/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9427 - accuracy: 0.6816 - val_loss: 1.1432 - val_accuracy: 0.6136\n",
      "Epoch 1377/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9284 - accuracy: 0.6895 - val_loss: 1.1468 - val_accuracy: 0.6169\n",
      "Epoch 1378/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9498 - accuracy: 0.6846 - val_loss: 1.1700 - val_accuracy: 0.6071\n",
      "Epoch 1379/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9552 - accuracy: 0.6797 - val_loss: 1.2065 - val_accuracy: 0.6006\n",
      "Epoch 1380/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9377 - accuracy: 0.6826 - val_loss: 1.2155 - val_accuracy: 0.6039\n",
      "Epoch 1381/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8888 - accuracy: 0.6924 - val_loss: 1.2180 - val_accuracy: 0.6104\n",
      "Epoch 1382/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9844 - accuracy: 0.6826 - val_loss: 1.2309 - val_accuracy: 0.6039\n",
      "Epoch 1383/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0134 - accuracy: 0.6746 - val_loss: 1.2137 - val_accuracy: 0.6039\n",
      "Epoch 1384/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8902 - accuracy: 0.7039 - val_loss: 1.1814 - val_accuracy: 0.6201\n",
      "Epoch 1385/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8643 - accuracy: 0.7151 - val_loss: 1.1582 - val_accuracy: 0.6201\n",
      "Epoch 1386/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8888 - accuracy: 0.6885 - val_loss: 1.1484 - val_accuracy: 0.6299\n",
      "Epoch 1387/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8558 - accuracy: 0.7053 - val_loss: 1.1436 - val_accuracy: 0.6299\n",
      "Epoch 1388/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9920 - accuracy: 0.6611 - val_loss: 1.1386 - val_accuracy: 0.6331\n",
      "Epoch 1389/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9511 - accuracy: 0.6924 - val_loss: 1.1259 - val_accuracy: 0.6299\n",
      "Epoch 1390/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9442 - accuracy: 0.6816 - val_loss: 1.1137 - val_accuracy: 0.6234\n",
      "Epoch 1391/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9256 - accuracy: 0.6875 - val_loss: 1.1062 - val_accuracy: 0.6201\n",
      "Epoch 1392/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9413 - accuracy: 0.7025 - val_loss: 1.1034 - val_accuracy: 0.6201\n",
      "Epoch 1393/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8948 - accuracy: 0.7151 - val_loss: 1.1014 - val_accuracy: 0.6299\n",
      "Epoch 1394/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9131 - accuracy: 0.6836 - val_loss: 1.1007 - val_accuracy: 0.6266\n",
      "Epoch 1395/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8910 - accuracy: 0.7041 - val_loss: 1.1061 - val_accuracy: 0.6266\n",
      "Epoch 1396/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8997 - accuracy: 0.7151 - val_loss: 1.1167 - val_accuracy: 0.6299\n",
      "Epoch 1397/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9383 - accuracy: 0.6858 - val_loss: 1.1273 - val_accuracy: 0.6234\n",
      "Epoch 1398/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.9202 - accuracy: 0.7002 - val_loss: 1.1291 - val_accuracy: 0.6299\n",
      "Epoch 1399/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9362 - accuracy: 0.6913 - val_loss: 1.1293 - val_accuracy: 0.6364\n",
      "Epoch 1400/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8703 - accuracy: 0.7031 - val_loss: 1.1147 - val_accuracy: 0.6396\n",
      "Epoch 1401/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9006 - accuracy: 0.6941 - val_loss: 1.1004 - val_accuracy: 0.6429\n",
      "Epoch 1402/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9688 - accuracy: 0.6816 - val_loss: 1.0894 - val_accuracy: 0.6494\n",
      "Epoch 1403/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9083 - accuracy: 0.6872 - val_loss: 1.0921 - val_accuracy: 0.6429\n",
      "Epoch 1404/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8995 - accuracy: 0.6973 - val_loss: 1.1014 - val_accuracy: 0.6396\n",
      "Epoch 1405/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8987 - accuracy: 0.6885 - val_loss: 1.1067 - val_accuracy: 0.6364\n",
      "Epoch 1406/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9403 - accuracy: 0.6885 - val_loss: 1.1118 - val_accuracy: 0.6299\n",
      "Epoch 1407/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9787 - accuracy: 0.6826 - val_loss: 1.1092 - val_accuracy: 0.6266\n",
      "Epoch 1408/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9291 - accuracy: 0.6846 - val_loss: 1.1050 - val_accuracy: 0.6201\n",
      "Epoch 1409/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8551 - accuracy: 0.7197 - val_loss: 1.1097 - val_accuracy: 0.6201\n",
      "Epoch 1410/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9232 - accuracy: 0.7109 - val_loss: 1.1210 - val_accuracy: 0.6136\n",
      "Epoch 1411/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9108 - accuracy: 0.6787 - val_loss: 1.1281 - val_accuracy: 0.6266\n",
      "Epoch 1412/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8607 - accuracy: 0.7039 - val_loss: 1.1325 - val_accuracy: 0.6104\n",
      "Epoch 1413/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8824 - accuracy: 0.7002 - val_loss: 1.1291 - val_accuracy: 0.6136\n",
      "Epoch 1414/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9167 - accuracy: 0.6943 - val_loss: 1.1197 - val_accuracy: 0.6071\n",
      "Epoch 1415/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9447 - accuracy: 0.6899 - val_loss: 1.1122 - val_accuracy: 0.6396\n",
      "Epoch 1416/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8932 - accuracy: 0.7051 - val_loss: 1.1062 - val_accuracy: 0.6364\n",
      "Epoch 1417/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9209 - accuracy: 0.6934 - val_loss: 1.0899 - val_accuracy: 0.6331\n",
      "Epoch 1418/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9057 - accuracy: 0.6913 - val_loss: 1.0770 - val_accuracy: 0.6429\n",
      "Epoch 1419/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8591 - accuracy: 0.7137 - val_loss: 1.0628 - val_accuracy: 0.6396\n",
      "Epoch 1420/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9304 - accuracy: 0.6865 - val_loss: 1.0532 - val_accuracy: 0.6494\n",
      "Epoch 1421/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8719 - accuracy: 0.6913 - val_loss: 1.0447 - val_accuracy: 0.6494\n",
      "Epoch 1422/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8761 - accuracy: 0.7109 - val_loss: 1.0419 - val_accuracy: 0.6494\n",
      "Epoch 1423/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8821 - accuracy: 0.7025 - val_loss: 1.0535 - val_accuracy: 0.6429\n",
      "Epoch 1424/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8685 - accuracy: 0.7123 - val_loss: 1.0701 - val_accuracy: 0.6396\n",
      "Epoch 1425/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8948 - accuracy: 0.6992 - val_loss: 1.0952 - val_accuracy: 0.6494\n",
      "Epoch 1426/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9342 - accuracy: 0.7081 - val_loss: 1.1479 - val_accuracy: 0.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1427/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9357 - accuracy: 0.6858 - val_loss: 1.1937 - val_accuracy: 0.6104\n",
      "Epoch 1428/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8900 - accuracy: 0.7158 - val_loss: 1.2270 - val_accuracy: 0.5974\n",
      "Epoch 1429/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8966 - accuracy: 0.6973 - val_loss: 1.1997 - val_accuracy: 0.6006\n",
      "Epoch 1430/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8488 - accuracy: 0.7123 - val_loss: 1.1691 - val_accuracy: 0.6104\n",
      "Epoch 1431/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9171 - accuracy: 0.6914 - val_loss: 1.1402 - val_accuracy: 0.6104\n",
      "Epoch 1432/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8458 - accuracy: 0.7179 - val_loss: 1.1447 - val_accuracy: 0.6071\n",
      "Epoch 1433/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9064 - accuracy: 0.6997 - val_loss: 1.1808 - val_accuracy: 0.5942\n",
      "Epoch 1434/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9279 - accuracy: 0.6913 - val_loss: 1.2626 - val_accuracy: 0.5714\n",
      "Epoch 1435/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8880 - accuracy: 0.6963 - val_loss: 1.3415 - val_accuracy: 0.5422\n",
      "Epoch 1436/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9035 - accuracy: 0.6982 - val_loss: 1.4038 - val_accuracy: 0.5325\n",
      "Epoch 1437/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8458 - accuracy: 0.7227 - val_loss: 1.4064 - val_accuracy: 0.5390\n",
      "Epoch 1438/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8818 - accuracy: 0.6802 - val_loss: 1.3843 - val_accuracy: 0.5519\n",
      "Epoch 1439/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8629 - accuracy: 0.7227 - val_loss: 1.3598 - val_accuracy: 0.5714\n",
      "Epoch 1440/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9154 - accuracy: 0.6914 - val_loss: 1.3075 - val_accuracy: 0.5714\n",
      "Epoch 1441/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9279 - accuracy: 0.6802 - val_loss: 1.2435 - val_accuracy: 0.5844\n",
      "Epoch 1442/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8411 - accuracy: 0.7246 - val_loss: 1.1859 - val_accuracy: 0.6169\n",
      "Epoch 1443/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9494 - accuracy: 0.6997 - val_loss: 1.1455 - val_accuracy: 0.6299\n",
      "Epoch 1444/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8914 - accuracy: 0.6872 - val_loss: 1.1241 - val_accuracy: 0.6299\n",
      "Epoch 1445/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9094 - accuracy: 0.6927 - val_loss: 1.1072 - val_accuracy: 0.6429\n",
      "Epoch 1446/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9300 - accuracy: 0.6816 - val_loss: 1.0969 - val_accuracy: 0.6591\n",
      "Epoch 1447/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8533 - accuracy: 0.7081 - val_loss: 1.0959 - val_accuracy: 0.6494\n",
      "Epoch 1448/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9442 - accuracy: 0.7039 - val_loss: 1.1079 - val_accuracy: 0.6429\n",
      "Epoch 1449/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8737 - accuracy: 0.6934 - val_loss: 1.1289 - val_accuracy: 0.6299\n",
      "Epoch 1450/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9435 - accuracy: 0.6943 - val_loss: 1.1628 - val_accuracy: 0.6104\n",
      "Epoch 1451/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8876 - accuracy: 0.6955 - val_loss: 1.2012 - val_accuracy: 0.5942\n",
      "Epoch 1452/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8571 - accuracy: 0.7158 - val_loss: 1.2195 - val_accuracy: 0.6039\n",
      "Epoch 1453/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8745 - accuracy: 0.7095 - val_loss: 1.2142 - val_accuracy: 0.6006\n",
      "Epoch 1454/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8962 - accuracy: 0.6816 - val_loss: 1.2048 - val_accuracy: 0.6104\n",
      "Epoch 1455/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8998 - accuracy: 0.6997 - val_loss: 1.1906 - val_accuracy: 0.6104\n",
      "Epoch 1456/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8783 - accuracy: 0.7095 - val_loss: 1.1845 - val_accuracy: 0.6104\n",
      "Epoch 1457/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8951 - accuracy: 0.7090 - val_loss: 1.1830 - val_accuracy: 0.6104\n",
      "Epoch 1458/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8616 - accuracy: 0.7168 - val_loss: 1.1866 - val_accuracy: 0.6169\n",
      "Epoch 1459/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9256 - accuracy: 0.6872 - val_loss: 1.1842 - val_accuracy: 0.6169\n",
      "Epoch 1460/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8997 - accuracy: 0.7304 - val_loss: 1.1930 - val_accuracy: 0.6071\n",
      "Epoch 1461/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8633 - accuracy: 0.7061 - val_loss: 1.1987 - val_accuracy: 0.6006\n",
      "Epoch 1462/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8313 - accuracy: 0.7246 - val_loss: 1.2185 - val_accuracy: 0.6006\n",
      "Epoch 1463/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8851 - accuracy: 0.6865 - val_loss: 1.2198 - val_accuracy: 0.6006\n",
      "Epoch 1464/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9274 - accuracy: 0.7025 - val_loss: 1.2231 - val_accuracy: 0.5942\n",
      "Epoch 1465/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8321 - accuracy: 0.7344 - val_loss: 1.2294 - val_accuracy: 0.5812\n",
      "Epoch 1466/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8925 - accuracy: 0.7012 - val_loss: 1.2300 - val_accuracy: 0.5779\n",
      "Epoch 1467/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7465 - accuracy: 0.7430 - val_loss: 1.2202 - val_accuracy: 0.5844\n",
      "Epoch 1468/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9545 - accuracy: 0.6826 - val_loss: 1.2051 - val_accuracy: 0.5909\n",
      "Epoch 1469/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8887 - accuracy: 0.7041 - val_loss: 1.1922 - val_accuracy: 0.6006\n",
      "Epoch 1470/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9131 - accuracy: 0.6807 - val_loss: 1.1658 - val_accuracy: 0.6071\n",
      "Epoch 1471/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9058 - accuracy: 0.7012 - val_loss: 1.1489 - val_accuracy: 0.6169\n",
      "Epoch 1472/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8485 - accuracy: 0.7025 - val_loss: 1.1311 - val_accuracy: 0.6136\n",
      "Epoch 1473/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8679 - accuracy: 0.7178 - val_loss: 1.1268 - val_accuracy: 0.6136\n",
      "Epoch 1474/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9061 - accuracy: 0.7109 - val_loss: 1.1533 - val_accuracy: 0.6104\n",
      "Epoch 1475/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9143 - accuracy: 0.6983 - val_loss: 1.1899 - val_accuracy: 0.6006\n",
      "Epoch 1476/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8945 - accuracy: 0.7193 - val_loss: 1.2317 - val_accuracy: 0.5812\n",
      "Epoch 1477/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8539 - accuracy: 0.7061 - val_loss: 1.2665 - val_accuracy: 0.5812\n",
      "Epoch 1478/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8097 - accuracy: 0.7304 - val_loss: 1.3005 - val_accuracy: 0.5779\n",
      "Epoch 1479/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8969 - accuracy: 0.6941 - val_loss: 1.3162 - val_accuracy: 0.5844\n",
      "Epoch 1480/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8976 - accuracy: 0.7109 - val_loss: 1.3098 - val_accuracy: 0.5909\n",
      "Epoch 1481/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8702 - accuracy: 0.7151 - val_loss: 1.2651 - val_accuracy: 0.5909\n",
      "Epoch 1482/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8343 - accuracy: 0.7285 - val_loss: 1.2263 - val_accuracy: 0.5942\n",
      "Epoch 1483/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9393 - accuracy: 0.6904 - val_loss: 1.1803 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1484/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8196 - accuracy: 0.7360 - val_loss: 1.1331 - val_accuracy: 0.6266\n",
      "Epoch 1485/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9236 - accuracy: 0.6955 - val_loss: 1.1074 - val_accuracy: 0.6331\n",
      "Epoch 1486/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8865 - accuracy: 0.7179 - val_loss: 1.0869 - val_accuracy: 0.6266\n",
      "Epoch 1487/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8274 - accuracy: 0.7053 - val_loss: 1.0880 - val_accuracy: 0.6266\n",
      "Epoch 1488/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8508 - accuracy: 0.7165 - val_loss: 1.1132 - val_accuracy: 0.6299\n",
      "Epoch 1489/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8052 - accuracy: 0.7246 - val_loss: 1.1538 - val_accuracy: 0.6071\n",
      "Epoch 1490/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8263 - accuracy: 0.7139 - val_loss: 1.1953 - val_accuracy: 0.6006\n",
      "Epoch 1491/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9064 - accuracy: 0.6997 - val_loss: 1.2296 - val_accuracy: 0.5974\n",
      "Epoch 1492/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8798 - accuracy: 0.6997 - val_loss: 1.2380 - val_accuracy: 0.6039\n",
      "Epoch 1493/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8744 - accuracy: 0.7151 - val_loss: 1.2478 - val_accuracy: 0.6201\n",
      "Epoch 1494/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9081 - accuracy: 0.6955 - val_loss: 1.2203 - val_accuracy: 0.6201\n",
      "Epoch 1495/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8304 - accuracy: 0.7137 - val_loss: 1.2004 - val_accuracy: 0.6201\n",
      "Epoch 1496/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7986 - accuracy: 0.7354 - val_loss: 1.2063 - val_accuracy: 0.6201\n",
      "Epoch 1497/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8639 - accuracy: 0.7090 - val_loss: 1.2230 - val_accuracy: 0.6104\n",
      "Epoch 1498/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8055 - accuracy: 0.7246 - val_loss: 1.2260 - val_accuracy: 0.6136\n",
      "Epoch 1499/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8519 - accuracy: 0.7277 - val_loss: 1.2344 - val_accuracy: 0.6104\n",
      "Epoch 1500/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8971 - accuracy: 0.6924 - val_loss: 1.2285 - val_accuracy: 0.6006\n",
      "Epoch 1501/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8826 - accuracy: 0.7100 - val_loss: 1.2412 - val_accuracy: 0.6006\n",
      "Epoch 1502/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8465 - accuracy: 0.7080 - val_loss: 1.2681 - val_accuracy: 0.5942\n",
      "Epoch 1503/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8492 - accuracy: 0.7263 - val_loss: 1.3118 - val_accuracy: 0.5844\n",
      "Epoch 1504/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9566 - accuracy: 0.6885 - val_loss: 1.3514 - val_accuracy: 0.5747\n",
      "Epoch 1505/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7967 - accuracy: 0.7360 - val_loss: 1.3421 - val_accuracy: 0.5714\n",
      "Epoch 1506/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8148 - accuracy: 0.7363 - val_loss: 1.3281 - val_accuracy: 0.5649\n",
      "Epoch 1507/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8455 - accuracy: 0.7318 - val_loss: 1.2703 - val_accuracy: 0.5844\n",
      "Epoch 1508/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8908 - accuracy: 0.6973 - val_loss: 1.2183 - val_accuracy: 0.5844\n",
      "Epoch 1509/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7963 - accuracy: 0.7451 - val_loss: 1.1905 - val_accuracy: 0.5909\n",
      "Epoch 1510/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8749 - accuracy: 0.7148 - val_loss: 1.1696 - val_accuracy: 0.5909\n",
      "Epoch 1511/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8397 - accuracy: 0.7109 - val_loss: 1.1635 - val_accuracy: 0.5974\n",
      "Epoch 1512/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8616 - accuracy: 0.7139 - val_loss: 1.1787 - val_accuracy: 0.6071\n",
      "Epoch 1513/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7890 - accuracy: 0.7363 - val_loss: 1.1837 - val_accuracy: 0.6104\n",
      "Epoch 1514/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8353 - accuracy: 0.7067 - val_loss: 1.1778 - val_accuracy: 0.6104\n",
      "Epoch 1515/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8678 - accuracy: 0.7067 - val_loss: 1.1698 - val_accuracy: 0.6266\n",
      "Epoch 1516/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8348 - accuracy: 0.7197 - val_loss: 1.1566 - val_accuracy: 0.6299\n",
      "Epoch 1517/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8293 - accuracy: 0.7165 - val_loss: 1.1105 - val_accuracy: 0.6364\n",
      "Epoch 1518/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7826 - accuracy: 0.7291 - val_loss: 1.0636 - val_accuracy: 0.6396\n",
      "Epoch 1519/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8577 - accuracy: 0.7061 - val_loss: 1.0426 - val_accuracy: 0.6364\n",
      "Epoch 1520/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9035 - accuracy: 0.7100 - val_loss: 1.0341 - val_accuracy: 0.6461\n",
      "Epoch 1521/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8564 - accuracy: 0.7217 - val_loss: 1.0432 - val_accuracy: 0.6461\n",
      "Epoch 1522/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8627 - accuracy: 0.7025 - val_loss: 1.0760 - val_accuracy: 0.6201\n",
      "Epoch 1523/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8553 - accuracy: 0.7100 - val_loss: 1.1286 - val_accuracy: 0.6234\n",
      "Epoch 1524/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8270 - accuracy: 0.7304 - val_loss: 1.1987 - val_accuracy: 0.6136\n",
      "Epoch 1525/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8940 - accuracy: 0.7025 - val_loss: 1.2705 - val_accuracy: 0.6104\n",
      "Epoch 1526/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8344 - accuracy: 0.7100 - val_loss: 1.3302 - val_accuracy: 0.6039\n",
      "Epoch 1527/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8503 - accuracy: 0.7100 - val_loss: 1.3597 - val_accuracy: 0.5974\n",
      "Epoch 1528/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8655 - accuracy: 0.7221 - val_loss: 1.3441 - val_accuracy: 0.5844\n",
      "Epoch 1529/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9177 - accuracy: 0.7039 - val_loss: 1.3064 - val_accuracy: 0.5877\n",
      "Epoch 1530/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8213 - accuracy: 0.7168 - val_loss: 1.2498 - val_accuracy: 0.5942\n",
      "Epoch 1531/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8432 - accuracy: 0.7090 - val_loss: 1.1923 - val_accuracy: 0.6039\n",
      "Epoch 1532/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8272 - accuracy: 0.7236 - val_loss: 1.1560 - val_accuracy: 0.5974\n",
      "Epoch 1533/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8449 - accuracy: 0.7139 - val_loss: 1.1414 - val_accuracy: 0.6039\n",
      "Epoch 1534/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8062 - accuracy: 0.7304 - val_loss: 1.1363 - val_accuracy: 0.6071\n",
      "Epoch 1535/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8321 - accuracy: 0.7266 - val_loss: 1.1553 - val_accuracy: 0.6136\n",
      "Epoch 1536/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9159 - accuracy: 0.6826 - val_loss: 1.1853 - val_accuracy: 0.6039\n",
      "Epoch 1537/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8387 - accuracy: 0.7249 - val_loss: 1.2096 - val_accuracy: 0.6006\n",
      "Epoch 1538/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8045 - accuracy: 0.7393 - val_loss: 1.2339 - val_accuracy: 0.6071\n",
      "Epoch 1539/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7916 - accuracy: 0.7354 - val_loss: 1.2542 - val_accuracy: 0.6071\n",
      "Epoch 1540/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8447 - accuracy: 0.7285 - val_loss: 1.2469 - val_accuracy: 0.6071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1541/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8375 - accuracy: 0.7363 - val_loss: 1.2163 - val_accuracy: 0.6071\n",
      "Epoch 1542/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8436 - accuracy: 0.7236 - val_loss: 1.1702 - val_accuracy: 0.6104\n",
      "Epoch 1543/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8198 - accuracy: 0.7363 - val_loss: 1.1168 - val_accuracy: 0.6169\n",
      "Epoch 1544/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9080 - accuracy: 0.6955 - val_loss: 1.0803 - val_accuracy: 0.6266\n",
      "Epoch 1545/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8448 - accuracy: 0.7193 - val_loss: 1.0735 - val_accuracy: 0.6331\n",
      "Epoch 1546/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8604 - accuracy: 0.7100 - val_loss: 1.0749 - val_accuracy: 0.6331\n",
      "Epoch 1547/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8325 - accuracy: 0.7291 - val_loss: 1.0665 - val_accuracy: 0.6364\n",
      "Epoch 1548/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8372 - accuracy: 0.7109 - val_loss: 1.0541 - val_accuracy: 0.6364\n",
      "Epoch 1549/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8037 - accuracy: 0.7324 - val_loss: 1.0441 - val_accuracy: 0.6364\n",
      "Epoch 1550/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7993 - accuracy: 0.7277 - val_loss: 1.0492 - val_accuracy: 0.6331\n",
      "Epoch 1551/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7718 - accuracy: 0.7430 - val_loss: 1.0502 - val_accuracy: 0.6201\n",
      "Epoch 1552/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8700 - accuracy: 0.7179 - val_loss: 1.0524 - val_accuracy: 0.6266\n",
      "Epoch 1553/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8574 - accuracy: 0.7263 - val_loss: 1.0832 - val_accuracy: 0.6364\n",
      "Epoch 1554/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7827 - accuracy: 0.7363 - val_loss: 1.1186 - val_accuracy: 0.6396\n",
      "Epoch 1555/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8433 - accuracy: 0.7139 - val_loss: 1.1361 - val_accuracy: 0.6429\n",
      "Epoch 1556/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8247 - accuracy: 0.7314 - val_loss: 1.1361 - val_accuracy: 0.6364\n",
      "Epoch 1557/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8376 - accuracy: 0.7188 - val_loss: 1.1350 - val_accuracy: 0.6266\n",
      "Epoch 1558/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8701 - accuracy: 0.7041 - val_loss: 1.1411 - val_accuracy: 0.6266\n",
      "Epoch 1559/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8038 - accuracy: 0.7486 - val_loss: 1.1683 - val_accuracy: 0.6299\n",
      "Epoch 1560/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8361 - accuracy: 0.7291 - val_loss: 1.1916 - val_accuracy: 0.6364\n",
      "Epoch 1561/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8526 - accuracy: 0.7002 - val_loss: 1.2352 - val_accuracy: 0.6266\n",
      "Epoch 1562/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8306 - accuracy: 0.7263 - val_loss: 1.2818 - val_accuracy: 0.6071\n",
      "Epoch 1563/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8312 - accuracy: 0.7256 - val_loss: 1.3050 - val_accuracy: 0.6039\n",
      "Epoch 1564/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8213 - accuracy: 0.7256 - val_loss: 1.3137 - val_accuracy: 0.6071\n",
      "Epoch 1565/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8195 - accuracy: 0.7188 - val_loss: 1.3012 - val_accuracy: 0.6039\n",
      "Epoch 1566/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8380 - accuracy: 0.7179 - val_loss: 1.2595 - val_accuracy: 0.6169\n",
      "Epoch 1567/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8347 - accuracy: 0.7263 - val_loss: 1.2150 - val_accuracy: 0.6234\n",
      "Epoch 1568/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7975 - accuracy: 0.7416 - val_loss: 1.1807 - val_accuracy: 0.6331\n",
      "Epoch 1569/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8593 - accuracy: 0.7285 - val_loss: 1.1622 - val_accuracy: 0.6299\n",
      "Epoch 1570/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8357 - accuracy: 0.7246 - val_loss: 1.1596 - val_accuracy: 0.6396\n",
      "Epoch 1571/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8287 - accuracy: 0.7304 - val_loss: 1.1718 - val_accuracy: 0.6234\n",
      "Epoch 1572/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7707 - accuracy: 0.7500 - val_loss: 1.1835 - val_accuracy: 0.6201\n",
      "Epoch 1573/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7625 - accuracy: 0.7432 - val_loss: 1.1978 - val_accuracy: 0.6071\n",
      "Epoch 1574/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7911 - accuracy: 0.7416 - val_loss: 1.2144 - val_accuracy: 0.6039\n",
      "Epoch 1575/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8721 - accuracy: 0.7109 - val_loss: 1.2217 - val_accuracy: 0.6039\n",
      "Epoch 1576/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8163 - accuracy: 0.7277 - val_loss: 1.2274 - val_accuracy: 0.6006\n",
      "Epoch 1577/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8256 - accuracy: 0.7332 - val_loss: 1.2392 - val_accuracy: 0.6039\n",
      "Epoch 1578/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7952 - accuracy: 0.7500 - val_loss: 1.2454 - val_accuracy: 0.5942\n",
      "Epoch 1579/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8586 - accuracy: 0.7207 - val_loss: 1.2589 - val_accuracy: 0.5877\n",
      "Epoch 1580/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7625 - accuracy: 0.7500 - val_loss: 1.2615 - val_accuracy: 0.5877\n",
      "Epoch 1581/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8174 - accuracy: 0.7129 - val_loss: 1.2707 - val_accuracy: 0.6071\n",
      "Epoch 1582/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7967 - accuracy: 0.7373 - val_loss: 1.2860 - val_accuracy: 0.6136\n",
      "Epoch 1583/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8648 - accuracy: 0.7249 - val_loss: 1.3011 - val_accuracy: 0.6201\n",
      "Epoch 1584/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7813 - accuracy: 0.7374 - val_loss: 1.3273 - val_accuracy: 0.6104\n",
      "Epoch 1585/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7681 - accuracy: 0.7514 - val_loss: 1.3552 - val_accuracy: 0.6136\n",
      "Epoch 1586/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9046 - accuracy: 0.7002 - val_loss: 1.3897 - val_accuracy: 0.6006\n",
      "Epoch 1587/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7855 - accuracy: 0.7402 - val_loss: 1.4029 - val_accuracy: 0.5844\n",
      "Epoch 1588/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8344 - accuracy: 0.7165 - val_loss: 1.3864 - val_accuracy: 0.5682\n",
      "Epoch 1589/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8183 - accuracy: 0.7295 - val_loss: 1.2935 - val_accuracy: 0.5812\n",
      "Epoch 1590/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7677 - accuracy: 0.7388 - val_loss: 1.2240 - val_accuracy: 0.6039\n",
      "Epoch 1591/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7345 - accuracy: 0.7607 - val_loss: 1.1532 - val_accuracy: 0.6136\n",
      "Epoch 1592/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7933 - accuracy: 0.7416 - val_loss: 1.1098 - val_accuracy: 0.6331\n",
      "Epoch 1593/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7945 - accuracy: 0.7305 - val_loss: 1.0901 - val_accuracy: 0.6364\n",
      "Epoch 1594/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8408 - accuracy: 0.7193 - val_loss: 1.0720 - val_accuracy: 0.6331\n",
      "Epoch 1595/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7771 - accuracy: 0.7451 - val_loss: 1.0843 - val_accuracy: 0.6331\n",
      "Epoch 1596/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7772 - accuracy: 0.7432 - val_loss: 1.1131 - val_accuracy: 0.6234\n",
      "Epoch 1597/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7762 - accuracy: 0.7528 - val_loss: 1.1691 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1598/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8128 - accuracy: 0.7318 - val_loss: 1.2305 - val_accuracy: 0.6136\n",
      "Epoch 1599/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8944 - accuracy: 0.7053 - val_loss: 1.2694 - val_accuracy: 0.6136\n",
      "Epoch 1600/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7884 - accuracy: 0.7363 - val_loss: 1.2825 - val_accuracy: 0.6104\n",
      "Epoch 1601/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8597 - accuracy: 0.7188 - val_loss: 1.2786 - val_accuracy: 0.6104\n",
      "Epoch 1602/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8242 - accuracy: 0.7383 - val_loss: 1.2005 - val_accuracy: 0.6299\n",
      "Epoch 1603/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8255 - accuracy: 0.7277 - val_loss: 1.1291 - val_accuracy: 0.6331\n",
      "Epoch 1604/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8160 - accuracy: 0.7305 - val_loss: 1.0798 - val_accuracy: 0.6396\n",
      "Epoch 1605/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8064 - accuracy: 0.7249 - val_loss: 1.0643 - val_accuracy: 0.6526\n",
      "Epoch 1606/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7960 - accuracy: 0.7422 - val_loss: 1.0683 - val_accuracy: 0.6526\n",
      "Epoch 1607/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8098 - accuracy: 0.7402 - val_loss: 1.0736 - val_accuracy: 0.6526\n",
      "Epoch 1608/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7627 - accuracy: 0.7510 - val_loss: 1.0749 - val_accuracy: 0.6558\n",
      "Epoch 1609/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8084 - accuracy: 0.7207 - val_loss: 1.0712 - val_accuracy: 0.6526\n",
      "Epoch 1610/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7149 - accuracy: 0.7849 - val_loss: 1.0790 - val_accuracy: 0.6331\n",
      "Epoch 1611/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7993 - accuracy: 0.7393 - val_loss: 1.0998 - val_accuracy: 0.6234\n",
      "Epoch 1612/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7534 - accuracy: 0.7441 - val_loss: 1.1537 - val_accuracy: 0.6104\n",
      "Epoch 1613/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7787 - accuracy: 0.7275 - val_loss: 1.2164 - val_accuracy: 0.5974\n",
      "Epoch 1614/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8202 - accuracy: 0.7067 - val_loss: 1.2711 - val_accuracy: 0.5942\n",
      "Epoch 1615/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8309 - accuracy: 0.7236 - val_loss: 1.2796 - val_accuracy: 0.5942\n",
      "Epoch 1616/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7400 - accuracy: 0.7584 - val_loss: 1.2607 - val_accuracy: 0.6039\n",
      "Epoch 1617/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7908 - accuracy: 0.7432 - val_loss: 1.2523 - val_accuracy: 0.6006\n",
      "Epoch 1618/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8026 - accuracy: 0.7430 - val_loss: 1.2600 - val_accuracy: 0.6006\n",
      "Epoch 1619/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8056 - accuracy: 0.7363 - val_loss: 1.2751 - val_accuracy: 0.6071\n",
      "Epoch 1620/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7884 - accuracy: 0.7430 - val_loss: 1.2433 - val_accuracy: 0.6169\n",
      "Epoch 1621/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7820 - accuracy: 0.7472 - val_loss: 1.2292 - val_accuracy: 0.6234\n",
      "Epoch 1622/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7503 - accuracy: 0.7500 - val_loss: 1.2295 - val_accuracy: 0.6169\n",
      "Epoch 1623/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7602 - accuracy: 0.7393 - val_loss: 1.2384 - val_accuracy: 0.6071\n",
      "Epoch 1624/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7487 - accuracy: 0.7559 - val_loss: 1.2511 - val_accuracy: 0.6104\n",
      "Epoch 1625/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7634 - accuracy: 0.7402 - val_loss: 1.2412 - val_accuracy: 0.6136\n",
      "Epoch 1626/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7598 - accuracy: 0.7584 - val_loss: 1.2770 - val_accuracy: 0.6071\n",
      "Epoch 1627/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7622 - accuracy: 0.7549 - val_loss: 1.3044 - val_accuracy: 0.6006\n",
      "Epoch 1628/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8247 - accuracy: 0.7137 - val_loss: 1.3642 - val_accuracy: 0.5974\n",
      "Epoch 1629/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7988 - accuracy: 0.7263 - val_loss: 1.3713 - val_accuracy: 0.6039\n",
      "Epoch 1630/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7436 - accuracy: 0.7402 - val_loss: 1.3485 - val_accuracy: 0.6039\n",
      "Epoch 1631/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7906 - accuracy: 0.7451 - val_loss: 1.3488 - val_accuracy: 0.5974\n",
      "Epoch 1632/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8096 - accuracy: 0.7354 - val_loss: 1.3445 - val_accuracy: 0.6006\n",
      "Epoch 1633/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7802 - accuracy: 0.7542 - val_loss: 1.3584 - val_accuracy: 0.5942\n",
      "Epoch 1634/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7959 - accuracy: 0.7263 - val_loss: 1.3926 - val_accuracy: 0.5844\n",
      "Epoch 1635/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8288 - accuracy: 0.7314 - val_loss: 1.4236 - val_accuracy: 0.5714\n",
      "Epoch 1636/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8050 - accuracy: 0.7256 - val_loss: 1.4465 - val_accuracy: 0.5779\n",
      "Epoch 1637/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8442 - accuracy: 0.7346 - val_loss: 1.4512 - val_accuracy: 0.5747\n",
      "Epoch 1638/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8026 - accuracy: 0.7249 - val_loss: 1.4816 - val_accuracy: 0.5682\n",
      "Epoch 1639/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8226 - accuracy: 0.7061 - val_loss: 1.4900 - val_accuracy: 0.5714\n",
      "Epoch 1640/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7714 - accuracy: 0.7549 - val_loss: 1.4141 - val_accuracy: 0.5714\n",
      "Epoch 1641/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7758 - accuracy: 0.7458 - val_loss: 1.3243 - val_accuracy: 0.5942\n",
      "Epoch 1642/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7783 - accuracy: 0.7472 - val_loss: 1.2360 - val_accuracy: 0.6234\n",
      "Epoch 1643/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7661 - accuracy: 0.7383 - val_loss: 1.1436 - val_accuracy: 0.6558\n",
      "Epoch 1644/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7545 - accuracy: 0.7607 - val_loss: 1.0722 - val_accuracy: 0.6591\n",
      "Epoch 1645/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7626 - accuracy: 0.7441 - val_loss: 1.0327 - val_accuracy: 0.6688\n",
      "Epoch 1646/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8158 - accuracy: 0.7221 - val_loss: 1.0154 - val_accuracy: 0.6688\n",
      "Epoch 1647/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7983 - accuracy: 0.7332 - val_loss: 1.0093 - val_accuracy: 0.6688\n",
      "Epoch 1648/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7876 - accuracy: 0.7568 - val_loss: 1.0089 - val_accuracy: 0.6558\n",
      "Epoch 1649/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7568 - accuracy: 0.7480 - val_loss: 1.0226 - val_accuracy: 0.6494\n",
      "Epoch 1650/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7577 - accuracy: 0.7514 - val_loss: 1.0334 - val_accuracy: 0.6396\n",
      "Epoch 1651/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7662 - accuracy: 0.7458 - val_loss: 1.0285 - val_accuracy: 0.6396\n",
      "Epoch 1652/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7625 - accuracy: 0.7471 - val_loss: 1.0182 - val_accuracy: 0.6558\n",
      "Epoch 1653/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7673 - accuracy: 0.7441 - val_loss: 1.0165 - val_accuracy: 0.6558\n",
      "Epoch 1654/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7711 - accuracy: 0.7412 - val_loss: 1.0209 - val_accuracy: 0.6688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1655/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7771 - accuracy: 0.7360 - val_loss: 1.0336 - val_accuracy: 0.6688\n",
      "Epoch 1656/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7849 - accuracy: 0.7263 - val_loss: 1.0576 - val_accuracy: 0.6623\n",
      "Epoch 1657/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8007 - accuracy: 0.7393 - val_loss: 1.0834 - val_accuracy: 0.6623\n",
      "Epoch 1658/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7628 - accuracy: 0.7556 - val_loss: 1.1362 - val_accuracy: 0.6396\n",
      "Epoch 1659/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7369 - accuracy: 0.7668 - val_loss: 1.1976 - val_accuracy: 0.6169\n",
      "Epoch 1660/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7490 - accuracy: 0.7514 - val_loss: 1.2231 - val_accuracy: 0.6266\n",
      "Epoch 1661/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7472 - accuracy: 0.7637 - val_loss: 1.2286 - val_accuracy: 0.6331\n",
      "Epoch 1662/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7751 - accuracy: 0.7332 - val_loss: 1.2220 - val_accuracy: 0.6331\n",
      "Epoch 1663/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7861 - accuracy: 0.7458 - val_loss: 1.2316 - val_accuracy: 0.6331\n",
      "Epoch 1664/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7820 - accuracy: 0.7246 - val_loss: 1.2313 - val_accuracy: 0.6364\n",
      "Epoch 1665/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7715 - accuracy: 0.7500 - val_loss: 1.2186 - val_accuracy: 0.6364\n",
      "Epoch 1666/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8326 - accuracy: 0.7295 - val_loss: 1.1937 - val_accuracy: 0.6364\n",
      "Epoch 1667/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7941 - accuracy: 0.7432 - val_loss: 1.1764 - val_accuracy: 0.6299\n",
      "Epoch 1668/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7500 - accuracy: 0.7444 - val_loss: 1.1438 - val_accuracy: 0.6364\n",
      "Epoch 1669/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7521 - accuracy: 0.7578 - val_loss: 1.1515 - val_accuracy: 0.6331\n",
      "Epoch 1670/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8471 - accuracy: 0.7346 - val_loss: 1.1752 - val_accuracy: 0.6136\n",
      "Epoch 1671/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7740 - accuracy: 0.7627 - val_loss: 1.2055 - val_accuracy: 0.6201\n",
      "Epoch 1672/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7524 - accuracy: 0.7461 - val_loss: 1.2594 - val_accuracy: 0.6169\n",
      "Epoch 1673/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7308 - accuracy: 0.7696 - val_loss: 1.3043 - val_accuracy: 0.6169\n",
      "Epoch 1674/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8147 - accuracy: 0.7332 - val_loss: 1.3798 - val_accuracy: 0.6136\n",
      "Epoch 1675/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8081 - accuracy: 0.7227 - val_loss: 1.4923 - val_accuracy: 0.5779\n",
      "Epoch 1676/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7488 - accuracy: 0.7539 - val_loss: 1.5971 - val_accuracy: 0.5552\n",
      "Epoch 1677/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8058 - accuracy: 0.7373 - val_loss: 1.6989 - val_accuracy: 0.5227\n",
      "Epoch 1678/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7618 - accuracy: 0.7472 - val_loss: 1.7155 - val_accuracy: 0.5162\n",
      "Epoch 1679/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7401 - accuracy: 0.7598 - val_loss: 1.6651 - val_accuracy: 0.5292\n",
      "Epoch 1680/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7816 - accuracy: 0.7383 - val_loss: 1.5747 - val_accuracy: 0.5487\n",
      "Epoch 1681/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7982 - accuracy: 0.7256 - val_loss: 1.4899 - val_accuracy: 0.5812\n",
      "Epoch 1682/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7709 - accuracy: 0.7528 - val_loss: 1.4254 - val_accuracy: 0.6006\n",
      "Epoch 1683/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7327 - accuracy: 0.7514 - val_loss: 1.3945 - val_accuracy: 0.6104\n",
      "Epoch 1684/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7436 - accuracy: 0.7480 - val_loss: 1.3792 - val_accuracy: 0.6201\n",
      "Epoch 1685/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6880 - accuracy: 0.7654 - val_loss: 1.3603 - val_accuracy: 0.6169\n",
      "Epoch 1686/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7825 - accuracy: 0.7291 - val_loss: 1.2998 - val_accuracy: 0.6299\n",
      "Epoch 1687/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7514 - accuracy: 0.7584 - val_loss: 1.2260 - val_accuracy: 0.6429\n",
      "Epoch 1688/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7467 - accuracy: 0.7472 - val_loss: 1.1824 - val_accuracy: 0.6591\n",
      "Epoch 1689/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7368 - accuracy: 0.7584 - val_loss: 1.1530 - val_accuracy: 0.6591\n",
      "Epoch 1690/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7708 - accuracy: 0.7490 - val_loss: 1.1288 - val_accuracy: 0.6591\n",
      "Epoch 1691/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7316 - accuracy: 0.7520 - val_loss: 1.1229 - val_accuracy: 0.6558\n",
      "Epoch 1692/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7759 - accuracy: 0.7559 - val_loss: 1.1221 - val_accuracy: 0.6656\n",
      "Epoch 1693/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8163 - accuracy: 0.7332 - val_loss: 1.1305 - val_accuracy: 0.6558\n",
      "Epoch 1694/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7632 - accuracy: 0.7539 - val_loss: 1.1232 - val_accuracy: 0.6591\n",
      "Epoch 1695/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7915 - accuracy: 0.7402 - val_loss: 1.1244 - val_accuracy: 0.6429\n",
      "Epoch 1696/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8019 - accuracy: 0.7354 - val_loss: 1.1337 - val_accuracy: 0.6364\n",
      "Epoch 1697/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7427 - accuracy: 0.7471 - val_loss: 1.1474 - val_accuracy: 0.6364\n",
      "Epoch 1698/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7859 - accuracy: 0.7277 - val_loss: 1.1344 - val_accuracy: 0.6396\n",
      "Epoch 1699/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6913 - accuracy: 0.7754 - val_loss: 1.1150 - val_accuracy: 0.6526\n",
      "Epoch 1700/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7224 - accuracy: 0.7705 - val_loss: 1.1320 - val_accuracy: 0.6558\n",
      "Epoch 1701/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7858 - accuracy: 0.7441 - val_loss: 1.1778 - val_accuracy: 0.6494\n",
      "Epoch 1702/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6778 - accuracy: 0.7821 - val_loss: 1.2494 - val_accuracy: 0.6266\n",
      "Epoch 1703/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7340 - accuracy: 0.7402 - val_loss: 1.3158 - val_accuracy: 0.6201\n",
      "Epoch 1704/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7733 - accuracy: 0.7578 - val_loss: 1.3234 - val_accuracy: 0.6201\n",
      "Epoch 1705/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7566 - accuracy: 0.7472 - val_loss: 1.3061 - val_accuracy: 0.6266\n",
      "Epoch 1706/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7531 - accuracy: 0.7640 - val_loss: 1.2717 - val_accuracy: 0.6234\n",
      "Epoch 1707/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7348 - accuracy: 0.7617 - val_loss: 1.2617 - val_accuracy: 0.6234\n",
      "Epoch 1708/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7496 - accuracy: 0.7542 - val_loss: 1.2764 - val_accuracy: 0.6266\n",
      "Epoch 1709/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7544 - accuracy: 0.7480 - val_loss: 1.2724 - val_accuracy: 0.6364\n",
      "Epoch 1710/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7183 - accuracy: 0.7607 - val_loss: 1.2576 - val_accuracy: 0.6396\n",
      "Epoch 1711/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7797 - accuracy: 0.7461 - val_loss: 1.2340 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1712/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7811 - accuracy: 0.7388 - val_loss: 1.2149 - val_accuracy: 0.6331\n",
      "Epoch 1713/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7447 - accuracy: 0.7570 - val_loss: 1.1996 - val_accuracy: 0.6266\n",
      "Epoch 1714/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7268 - accuracy: 0.7514 - val_loss: 1.1916 - val_accuracy: 0.6331\n",
      "Epoch 1715/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7172 - accuracy: 0.7656 - val_loss: 1.1834 - val_accuracy: 0.6396\n",
      "Epoch 1716/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6961 - accuracy: 0.7744 - val_loss: 1.1802 - val_accuracy: 0.6331\n",
      "Epoch 1717/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7435 - accuracy: 0.7360 - val_loss: 1.1799 - val_accuracy: 0.6396\n",
      "Epoch 1718/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7589 - accuracy: 0.7607 - val_loss: 1.1801 - val_accuracy: 0.6299\n",
      "Epoch 1719/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7081 - accuracy: 0.7656 - val_loss: 1.1673 - val_accuracy: 0.6331\n",
      "Epoch 1720/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7662 - accuracy: 0.7490 - val_loss: 1.1599 - val_accuracy: 0.6331\n",
      "Epoch 1721/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7755 - accuracy: 0.7422 - val_loss: 1.1481 - val_accuracy: 0.6364\n",
      "Epoch 1722/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8346 - accuracy: 0.7430 - val_loss: 1.1427 - val_accuracy: 0.6364\n",
      "Epoch 1723/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7711 - accuracy: 0.7514 - val_loss: 1.1473 - val_accuracy: 0.6364\n",
      "Epoch 1724/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6880 - accuracy: 0.7646 - val_loss: 1.1551 - val_accuracy: 0.6364\n",
      "Epoch 1725/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7485 - accuracy: 0.7374 - val_loss: 1.1775 - val_accuracy: 0.6169\n",
      "Epoch 1726/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7171 - accuracy: 0.7686 - val_loss: 1.1975 - val_accuracy: 0.6169\n",
      "Epoch 1727/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7352 - accuracy: 0.7490 - val_loss: 1.2084 - val_accuracy: 0.6136\n",
      "Epoch 1728/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7603 - accuracy: 0.7556 - val_loss: 1.2048 - val_accuracy: 0.6006\n",
      "Epoch 1729/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7173 - accuracy: 0.7598 - val_loss: 1.2155 - val_accuracy: 0.5974\n",
      "Epoch 1730/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7949 - accuracy: 0.7344 - val_loss: 1.2041 - val_accuracy: 0.5974\n",
      "Epoch 1731/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7199 - accuracy: 0.7637 - val_loss: 1.1900 - val_accuracy: 0.6039\n",
      "Epoch 1732/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7345 - accuracy: 0.7559 - val_loss: 1.1764 - val_accuracy: 0.6104\n",
      "Epoch 1733/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7489 - accuracy: 0.7383 - val_loss: 1.1644 - val_accuracy: 0.6234\n",
      "Epoch 1734/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7704 - accuracy: 0.7451 - val_loss: 1.1547 - val_accuracy: 0.6234\n",
      "Epoch 1735/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8425 - accuracy: 0.7137 - val_loss: 1.1369 - val_accuracy: 0.6331\n",
      "Epoch 1736/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7153 - accuracy: 0.7637 - val_loss: 1.1184 - val_accuracy: 0.6364\n",
      "Epoch 1737/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7717 - accuracy: 0.7360 - val_loss: 1.0977 - val_accuracy: 0.6494\n",
      "Epoch 1738/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7632 - accuracy: 0.7451 - val_loss: 1.0854 - val_accuracy: 0.6526\n",
      "Epoch 1739/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7458 - accuracy: 0.7500 - val_loss: 1.0737 - val_accuracy: 0.6623\n",
      "Epoch 1740/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7026 - accuracy: 0.7654 - val_loss: 1.0692 - val_accuracy: 0.6526\n",
      "Epoch 1741/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7061 - accuracy: 0.7695 - val_loss: 1.0664 - val_accuracy: 0.6558\n",
      "Epoch 1742/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7665 - accuracy: 0.7514 - val_loss: 1.0682 - val_accuracy: 0.6526\n",
      "Epoch 1743/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7839 - accuracy: 0.7441 - val_loss: 1.0812 - val_accuracy: 0.6364\n",
      "Epoch 1744/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7347 - accuracy: 0.7520 - val_loss: 1.0928 - val_accuracy: 0.6461\n",
      "Epoch 1745/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7483 - accuracy: 0.7520 - val_loss: 1.1104 - val_accuracy: 0.6299\n",
      "Epoch 1746/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7232 - accuracy: 0.7612 - val_loss: 1.1247 - val_accuracy: 0.6234\n",
      "Epoch 1747/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6910 - accuracy: 0.7723 - val_loss: 1.1207 - val_accuracy: 0.6234\n",
      "Epoch 1748/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7036 - accuracy: 0.7646 - val_loss: 1.1171 - val_accuracy: 0.6331\n",
      "Epoch 1749/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7237 - accuracy: 0.7559 - val_loss: 1.1052 - val_accuracy: 0.6558\n",
      "Epoch 1750/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7884 - accuracy: 0.7444 - val_loss: 1.1045 - val_accuracy: 0.6558\n",
      "Epoch 1751/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7583 - accuracy: 0.7607 - val_loss: 1.0985 - val_accuracy: 0.6494\n",
      "Epoch 1752/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7095 - accuracy: 0.7793 - val_loss: 1.0964 - val_accuracy: 0.6591\n",
      "Epoch 1753/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7105 - accuracy: 0.7539 - val_loss: 1.0989 - val_accuracy: 0.6558\n",
      "Epoch 1754/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7422 - accuracy: 0.7402 - val_loss: 1.1029 - val_accuracy: 0.6526\n",
      "Epoch 1755/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7082 - accuracy: 0.7542 - val_loss: 1.1077 - val_accuracy: 0.6396\n",
      "Epoch 1756/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6964 - accuracy: 0.7849 - val_loss: 1.1237 - val_accuracy: 0.6461\n",
      "Epoch 1757/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7247 - accuracy: 0.7607 - val_loss: 1.1365 - val_accuracy: 0.6396\n",
      "Epoch 1758/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7881 - accuracy: 0.7318 - val_loss: 1.1528 - val_accuracy: 0.6396\n",
      "Epoch 1759/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8142 - accuracy: 0.7291 - val_loss: 1.1605 - val_accuracy: 0.6494\n",
      "Epoch 1760/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7644 - accuracy: 0.7458 - val_loss: 1.1454 - val_accuracy: 0.6331\n",
      "Epoch 1761/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6851 - accuracy: 0.7765 - val_loss: 1.1377 - val_accuracy: 0.6429\n",
      "Epoch 1762/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7814 - accuracy: 0.7510 - val_loss: 1.1333 - val_accuracy: 0.6688\n",
      "Epoch 1763/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7646 - accuracy: 0.7500 - val_loss: 1.1311 - val_accuracy: 0.6526\n",
      "Epoch 1764/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7482 - accuracy: 0.7500 - val_loss: 1.1411 - val_accuracy: 0.6591\n",
      "Epoch 1765/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7048 - accuracy: 0.7682 - val_loss: 1.1579 - val_accuracy: 0.6623\n",
      "Epoch 1766/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7690 - accuracy: 0.7402 - val_loss: 1.1769 - val_accuracy: 0.6623\n",
      "Epoch 1767/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8039 - accuracy: 0.7402 - val_loss: 1.1936 - val_accuracy: 0.6494\n",
      "Epoch 1768/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7381 - accuracy: 0.7490 - val_loss: 1.2040 - val_accuracy: 0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1769/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7233 - accuracy: 0.7646 - val_loss: 1.2095 - val_accuracy: 0.6234\n",
      "Epoch 1770/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7225 - accuracy: 0.7715 - val_loss: 1.2088 - val_accuracy: 0.6039\n",
      "Epoch 1771/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7315 - accuracy: 0.7773 - val_loss: 1.2005 - val_accuracy: 0.6136\n",
      "Epoch 1772/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7859 - accuracy: 0.7432 - val_loss: 1.1952 - val_accuracy: 0.6299\n",
      "Epoch 1773/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6498 - accuracy: 0.7723 - val_loss: 1.1933 - val_accuracy: 0.6331\n",
      "Epoch 1774/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7555 - accuracy: 0.7556 - val_loss: 1.1831 - val_accuracy: 0.6299\n",
      "Epoch 1775/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6843 - accuracy: 0.7822 - val_loss: 1.1751 - val_accuracy: 0.6396\n",
      "Epoch 1776/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7301 - accuracy: 0.7539 - val_loss: 1.1519 - val_accuracy: 0.6396\n",
      "Epoch 1777/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7056 - accuracy: 0.7723 - val_loss: 1.1295 - val_accuracy: 0.6461\n",
      "Epoch 1778/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7269 - accuracy: 0.7705 - val_loss: 1.1013 - val_accuracy: 0.6494\n",
      "Epoch 1779/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7350 - accuracy: 0.7584 - val_loss: 1.0840 - val_accuracy: 0.6558\n",
      "Epoch 1780/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6847 - accuracy: 0.7842 - val_loss: 1.0855 - val_accuracy: 0.6429\n",
      "Epoch 1781/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6977 - accuracy: 0.7607 - val_loss: 1.1115 - val_accuracy: 0.6396\n",
      "Epoch 1782/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6904 - accuracy: 0.7779 - val_loss: 1.1430 - val_accuracy: 0.6299\n",
      "Epoch 1783/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6679 - accuracy: 0.7861 - val_loss: 1.1332 - val_accuracy: 0.6396\n",
      "Epoch 1784/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7378 - accuracy: 0.7529 - val_loss: 1.1172 - val_accuracy: 0.6429\n",
      "Epoch 1785/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7476 - accuracy: 0.7668 - val_loss: 1.0980 - val_accuracy: 0.6331\n",
      "Epoch 1786/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6572 - accuracy: 0.7877 - val_loss: 1.0854 - val_accuracy: 0.6558\n",
      "Epoch 1787/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7422 - accuracy: 0.7578 - val_loss: 1.0828 - val_accuracy: 0.6623\n",
      "Epoch 1788/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7263 - accuracy: 0.7744 - val_loss: 1.0859 - val_accuracy: 0.6558\n",
      "Epoch 1789/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7381 - accuracy: 0.7520 - val_loss: 1.0887 - val_accuracy: 0.6494\n",
      "Epoch 1790/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7064 - accuracy: 0.7656 - val_loss: 1.0927 - val_accuracy: 0.6429\n",
      "Epoch 1791/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7467 - accuracy: 0.7514 - val_loss: 1.1052 - val_accuracy: 0.6429\n",
      "Epoch 1792/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7388 - accuracy: 0.7402 - val_loss: 1.1219 - val_accuracy: 0.6364\n",
      "Epoch 1793/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7162 - accuracy: 0.7458 - val_loss: 1.1504 - val_accuracy: 0.6234\n",
      "Epoch 1794/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7827 - accuracy: 0.7682 - val_loss: 1.1757 - val_accuracy: 0.6234\n",
      "Epoch 1795/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7020 - accuracy: 0.7793 - val_loss: 1.2091 - val_accuracy: 0.6136\n",
      "Epoch 1796/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7141 - accuracy: 0.7461 - val_loss: 1.2191 - val_accuracy: 0.6006\n",
      "Epoch 1797/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6919 - accuracy: 0.7754 - val_loss: 1.1929 - val_accuracy: 0.6039\n",
      "Epoch 1798/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7114 - accuracy: 0.7744 - val_loss: 1.1651 - val_accuracy: 0.6169\n",
      "Epoch 1799/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7195 - accuracy: 0.7607 - val_loss: 1.1449 - val_accuracy: 0.6201\n",
      "Epoch 1800/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7381 - accuracy: 0.7444 - val_loss: 1.1384 - val_accuracy: 0.6299\n",
      "Epoch 1801/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7254 - accuracy: 0.7556 - val_loss: 1.1448 - val_accuracy: 0.6201\n",
      "Epoch 1802/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7356 - accuracy: 0.7682 - val_loss: 1.1565 - val_accuracy: 0.6299\n",
      "Epoch 1803/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6917 - accuracy: 0.7668 - val_loss: 1.1678 - val_accuracy: 0.6169\n",
      "Epoch 1804/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7620 - accuracy: 0.7314 - val_loss: 1.1680 - val_accuracy: 0.6266\n",
      "Epoch 1805/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7207 - accuracy: 0.7528 - val_loss: 1.1702 - val_accuracy: 0.6299\n",
      "Epoch 1806/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7138 - accuracy: 0.7656 - val_loss: 1.1737 - val_accuracy: 0.6429\n",
      "Epoch 1807/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7329 - accuracy: 0.7637 - val_loss: 1.1793 - val_accuracy: 0.6461\n",
      "Epoch 1808/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6746 - accuracy: 0.7682 - val_loss: 1.1903 - val_accuracy: 0.6429\n",
      "Epoch 1809/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7047 - accuracy: 0.7754 - val_loss: 1.2026 - val_accuracy: 0.6461\n",
      "Epoch 1810/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7652 - accuracy: 0.7617 - val_loss: 1.2021 - val_accuracy: 0.6331\n",
      "Epoch 1811/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7112 - accuracy: 0.7578 - val_loss: 1.1837 - val_accuracy: 0.6429\n",
      "Epoch 1812/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7351 - accuracy: 0.7598 - val_loss: 1.1732 - val_accuracy: 0.6526\n",
      "Epoch 1813/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6997 - accuracy: 0.7598 - val_loss: 1.1409 - val_accuracy: 0.6396\n",
      "Epoch 1814/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7389 - accuracy: 0.7549 - val_loss: 1.1252 - val_accuracy: 0.6429\n",
      "Epoch 1815/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7226 - accuracy: 0.7542 - val_loss: 1.1131 - val_accuracy: 0.6526\n",
      "Epoch 1816/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6665 - accuracy: 0.7637 - val_loss: 1.0983 - val_accuracy: 0.6558\n",
      "Epoch 1817/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7561 - accuracy: 0.7510 - val_loss: 1.0963 - val_accuracy: 0.6656\n",
      "Epoch 1818/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6433 - accuracy: 0.8017 - val_loss: 1.0987 - val_accuracy: 0.6526\n",
      "Epoch 1819/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6613 - accuracy: 0.7863 - val_loss: 1.1023 - val_accuracy: 0.6591\n",
      "Epoch 1820/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6982 - accuracy: 0.7751 - val_loss: 1.1032 - val_accuracy: 0.6591\n",
      "Epoch 1821/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7813 - accuracy: 0.7393 - val_loss: 1.1022 - val_accuracy: 0.6461\n",
      "Epoch 1822/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7379 - accuracy: 0.7612 - val_loss: 1.1018 - val_accuracy: 0.6526\n",
      "Epoch 1823/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6864 - accuracy: 0.7821 - val_loss: 1.1091 - val_accuracy: 0.6494\n",
      "Epoch 1824/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7070 - accuracy: 0.7686 - val_loss: 1.1104 - val_accuracy: 0.6396\n",
      "Epoch 1825/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6947 - accuracy: 0.7626 - val_loss: 1.1069 - val_accuracy: 0.6461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1826/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6967 - accuracy: 0.7764 - val_loss: 1.1023 - val_accuracy: 0.6494\n",
      "Epoch 1827/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6811 - accuracy: 0.7654 - val_loss: 1.1036 - val_accuracy: 0.6558\n",
      "Epoch 1828/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7056 - accuracy: 0.7654 - val_loss: 1.1111 - val_accuracy: 0.6364\n",
      "Epoch 1829/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7070 - accuracy: 0.7709 - val_loss: 1.1190 - val_accuracy: 0.6331\n",
      "Epoch 1830/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6501 - accuracy: 0.7737 - val_loss: 1.1354 - val_accuracy: 0.6396\n",
      "Epoch 1831/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6641 - accuracy: 0.7900 - val_loss: 1.1386 - val_accuracy: 0.6461\n",
      "Epoch 1832/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7132 - accuracy: 0.7751 - val_loss: 1.1505 - val_accuracy: 0.6234\n",
      "Epoch 1833/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7082 - accuracy: 0.7723 - val_loss: 1.1741 - val_accuracy: 0.6136\n",
      "Epoch 1834/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7416 - accuracy: 0.7682 - val_loss: 1.2154 - val_accuracy: 0.6136\n",
      "Epoch 1835/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6985 - accuracy: 0.7617 - val_loss: 1.2499 - val_accuracy: 0.6169\n",
      "Epoch 1836/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6808 - accuracy: 0.7835 - val_loss: 1.2694 - val_accuracy: 0.6201\n",
      "Epoch 1837/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6462 - accuracy: 0.7900 - val_loss: 1.2688 - val_accuracy: 0.6169\n",
      "Epoch 1838/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7249 - accuracy: 0.7668 - val_loss: 1.2578 - val_accuracy: 0.6201\n",
      "Epoch 1839/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6781 - accuracy: 0.7709 - val_loss: 1.2184 - val_accuracy: 0.6299\n",
      "Epoch 1840/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6904 - accuracy: 0.7793 - val_loss: 1.1944 - val_accuracy: 0.6266\n",
      "Epoch 1841/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7194 - accuracy: 0.7598 - val_loss: 1.1900 - val_accuracy: 0.6234\n",
      "Epoch 1842/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7159 - accuracy: 0.7520 - val_loss: 1.1689 - val_accuracy: 0.6331\n",
      "Epoch 1843/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6951 - accuracy: 0.7612 - val_loss: 1.1573 - val_accuracy: 0.6429\n",
      "Epoch 1844/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7588 - accuracy: 0.7627 - val_loss: 1.1399 - val_accuracy: 0.6429\n",
      "Epoch 1845/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7349 - accuracy: 0.7539 - val_loss: 1.1162 - val_accuracy: 0.6461\n",
      "Epoch 1846/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6833 - accuracy: 0.7754 - val_loss: 1.0924 - val_accuracy: 0.6623\n",
      "Epoch 1847/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7325 - accuracy: 0.7514 - val_loss: 1.0800 - val_accuracy: 0.6721\n",
      "Epoch 1848/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7253 - accuracy: 0.7637 - val_loss: 1.0731 - val_accuracy: 0.6623\n",
      "Epoch 1849/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7018 - accuracy: 0.7682 - val_loss: 1.0724 - val_accuracy: 0.6591\n",
      "Epoch 1850/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6947 - accuracy: 0.7765 - val_loss: 1.0655 - val_accuracy: 0.6656\n",
      "Epoch 1851/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7238 - accuracy: 0.7472 - val_loss: 1.0706 - val_accuracy: 0.6656\n",
      "Epoch 1852/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6507 - accuracy: 0.7835 - val_loss: 1.0746 - val_accuracy: 0.6591\n",
      "Epoch 1853/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6418 - accuracy: 0.7861 - val_loss: 1.0806 - val_accuracy: 0.6494\n",
      "Epoch 1854/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6412 - accuracy: 0.7835 - val_loss: 1.0950 - val_accuracy: 0.6461\n",
      "Epoch 1855/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6996 - accuracy: 0.7725 - val_loss: 1.0917 - val_accuracy: 0.6299\n",
      "Epoch 1856/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7660 - accuracy: 0.7416 - val_loss: 1.0762 - val_accuracy: 0.6331\n",
      "Epoch 1857/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7012 - accuracy: 0.7783 - val_loss: 1.0722 - val_accuracy: 0.6364\n",
      "Epoch 1858/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7098 - accuracy: 0.7578 - val_loss: 1.0651 - val_accuracy: 0.6429\n",
      "Epoch 1859/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6704 - accuracy: 0.7822 - val_loss: 1.0602 - val_accuracy: 0.6461\n",
      "Epoch 1860/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7046 - accuracy: 0.7737 - val_loss: 1.0700 - val_accuracy: 0.6494\n",
      "Epoch 1861/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6729 - accuracy: 0.7835 - val_loss: 1.0755 - val_accuracy: 0.6623\n",
      "Epoch 1862/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7022 - accuracy: 0.7696 - val_loss: 1.0872 - val_accuracy: 0.6526\n",
      "Epoch 1863/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6878 - accuracy: 0.7919 - val_loss: 1.1153 - val_accuracy: 0.6461\n",
      "Epoch 1864/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6640 - accuracy: 0.7705 - val_loss: 1.1417 - val_accuracy: 0.6234\n",
      "Epoch 1865/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6926 - accuracy: 0.7744 - val_loss: 1.1613 - val_accuracy: 0.6364\n",
      "Epoch 1866/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7443 - accuracy: 0.7556 - val_loss: 1.1788 - val_accuracy: 0.6266\n",
      "Epoch 1867/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6611 - accuracy: 0.7930 - val_loss: 1.1893 - val_accuracy: 0.6266\n",
      "Epoch 1868/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6616 - accuracy: 0.7723 - val_loss: 1.2057 - val_accuracy: 0.6396\n",
      "Epoch 1869/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6304 - accuracy: 0.7849 - val_loss: 1.1774 - val_accuracy: 0.6429\n",
      "Epoch 1870/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7254 - accuracy: 0.7444 - val_loss: 1.1554 - val_accuracy: 0.6494\n",
      "Epoch 1871/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7392 - accuracy: 0.7559 - val_loss: 1.1121 - val_accuracy: 0.6429\n",
      "Epoch 1872/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7488 - accuracy: 0.7486 - val_loss: 1.0876 - val_accuracy: 0.6558\n",
      "Epoch 1873/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7077 - accuracy: 0.7584 - val_loss: 1.0847 - val_accuracy: 0.6558\n",
      "Epoch 1874/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7166 - accuracy: 0.7612 - val_loss: 1.0897 - val_accuracy: 0.6526\n",
      "Epoch 1875/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6564 - accuracy: 0.7979 - val_loss: 1.0964 - val_accuracy: 0.6688\n",
      "Epoch 1876/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6658 - accuracy: 0.7807 - val_loss: 1.1135 - val_accuracy: 0.6688\n",
      "Epoch 1877/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7145 - accuracy: 0.7725 - val_loss: 1.1418 - val_accuracy: 0.6494\n",
      "Epoch 1878/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6886 - accuracy: 0.7696 - val_loss: 1.1676 - val_accuracy: 0.6429\n",
      "Epoch 1879/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6792 - accuracy: 0.7754 - val_loss: 1.1874 - val_accuracy: 0.6396\n",
      "Epoch 1880/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6374 - accuracy: 0.7919 - val_loss: 1.1951 - val_accuracy: 0.6429\n",
      "Epoch 1881/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6986 - accuracy: 0.7588 - val_loss: 1.1880 - val_accuracy: 0.6494\n",
      "Epoch 1882/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7159 - accuracy: 0.7640 - val_loss: 1.1841 - val_accuracy: 0.6526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1883/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7244 - accuracy: 0.7556 - val_loss: 1.1661 - val_accuracy: 0.6526\n",
      "Epoch 1884/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6688 - accuracy: 0.7779 - val_loss: 1.1541 - val_accuracy: 0.6623\n",
      "Epoch 1885/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6673 - accuracy: 0.7832 - val_loss: 1.1581 - val_accuracy: 0.6494\n",
      "Epoch 1886/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6670 - accuracy: 0.7910 - val_loss: 1.1488 - val_accuracy: 0.6494\n",
      "Epoch 1887/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6779 - accuracy: 0.7989 - val_loss: 1.1458 - val_accuracy: 0.6494\n",
      "Epoch 1888/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6950 - accuracy: 0.7737 - val_loss: 1.1254 - val_accuracy: 0.6526\n",
      "Epoch 1889/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6446 - accuracy: 0.7891 - val_loss: 1.1044 - val_accuracy: 0.6558\n",
      "Epoch 1890/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6868 - accuracy: 0.7754 - val_loss: 1.0922 - val_accuracy: 0.6721\n",
      "Epoch 1891/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6816 - accuracy: 0.7861 - val_loss: 1.0876 - val_accuracy: 0.6688\n",
      "Epoch 1892/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7090 - accuracy: 0.7709 - val_loss: 1.0841 - val_accuracy: 0.6623\n",
      "Epoch 1893/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6335 - accuracy: 0.7939 - val_loss: 1.0838 - val_accuracy: 0.6591\n",
      "Epoch 1894/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7100 - accuracy: 0.7584 - val_loss: 1.0854 - val_accuracy: 0.6656\n",
      "Epoch 1895/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6782 - accuracy: 0.7773 - val_loss: 1.0974 - val_accuracy: 0.6591\n",
      "Epoch 1896/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6680 - accuracy: 0.7754 - val_loss: 1.1161 - val_accuracy: 0.6591\n",
      "Epoch 1897/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6634 - accuracy: 0.7773 - val_loss: 1.1470 - val_accuracy: 0.6461\n",
      "Epoch 1898/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6308 - accuracy: 0.7881 - val_loss: 1.1778 - val_accuracy: 0.6331\n",
      "Epoch 1899/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7000 - accuracy: 0.7737 - val_loss: 1.1730 - val_accuracy: 0.6299\n",
      "Epoch 1900/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6858 - accuracy: 0.7751 - val_loss: 1.1376 - val_accuracy: 0.6461\n",
      "Epoch 1901/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7001 - accuracy: 0.7737 - val_loss: 1.1135 - val_accuracy: 0.6526\n",
      "Epoch 1902/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6523 - accuracy: 0.7979 - val_loss: 1.0816 - val_accuracy: 0.6688\n",
      "Epoch 1903/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6957 - accuracy: 0.7803 - val_loss: 1.0616 - val_accuracy: 0.6558\n",
      "Epoch 1904/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6662 - accuracy: 0.7725 - val_loss: 1.0527 - val_accuracy: 0.6494\n",
      "Epoch 1905/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6976 - accuracy: 0.7793 - val_loss: 1.0602 - val_accuracy: 0.6526\n",
      "Epoch 1906/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7118 - accuracy: 0.7682 - val_loss: 1.0671 - val_accuracy: 0.6623\n",
      "Epoch 1907/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6673 - accuracy: 0.7891 - val_loss: 1.0802 - val_accuracy: 0.6591\n",
      "Epoch 1908/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6439 - accuracy: 0.7910 - val_loss: 1.0907 - val_accuracy: 0.6494\n",
      "Epoch 1909/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6337 - accuracy: 0.7905 - val_loss: 1.0852 - val_accuracy: 0.6526\n",
      "Epoch 1910/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6140 - accuracy: 0.7947 - val_loss: 1.0835 - val_accuracy: 0.6558\n",
      "Epoch 1911/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6348 - accuracy: 0.7988 - val_loss: 1.0830 - val_accuracy: 0.6591\n",
      "Epoch 1912/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6259 - accuracy: 0.7920 - val_loss: 1.0756 - val_accuracy: 0.6688\n",
      "Epoch 1913/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7136 - accuracy: 0.7500 - val_loss: 1.0766 - val_accuracy: 0.6688\n",
      "Epoch 1914/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6701 - accuracy: 0.7779 - val_loss: 1.0837 - val_accuracy: 0.6558\n",
      "Epoch 1915/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6902 - accuracy: 0.7754 - val_loss: 1.0956 - val_accuracy: 0.6558\n",
      "Epoch 1916/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6947 - accuracy: 0.7598 - val_loss: 1.1134 - val_accuracy: 0.6526\n",
      "Epoch 1917/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6229 - accuracy: 0.7891 - val_loss: 1.1368 - val_accuracy: 0.6429\n",
      "Epoch 1918/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6191 - accuracy: 0.7947 - val_loss: 1.1460 - val_accuracy: 0.6396\n",
      "Epoch 1919/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6380 - accuracy: 0.7849 - val_loss: 1.1432 - val_accuracy: 0.6396\n",
      "Epoch 1920/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6908 - accuracy: 0.7905 - val_loss: 1.1317 - val_accuracy: 0.6429\n",
      "Epoch 1921/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7101 - accuracy: 0.7695 - val_loss: 1.1085 - val_accuracy: 0.6591\n",
      "Epoch 1922/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6516 - accuracy: 0.7822 - val_loss: 1.0868 - val_accuracy: 0.6558\n",
      "Epoch 1923/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6344 - accuracy: 0.7871 - val_loss: 1.0669 - val_accuracy: 0.6623\n",
      "Epoch 1924/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6888 - accuracy: 0.7734 - val_loss: 1.0469 - val_accuracy: 0.6591\n",
      "Epoch 1925/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6453 - accuracy: 0.7949 - val_loss: 1.0353 - val_accuracy: 0.6656\n",
      "Epoch 1926/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6616 - accuracy: 0.7737 - val_loss: 1.0257 - val_accuracy: 0.6883\n",
      "Epoch 1927/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6574 - accuracy: 0.7734 - val_loss: 1.0259 - val_accuracy: 0.6981\n",
      "Epoch 1928/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6293 - accuracy: 0.8047 - val_loss: 1.0353 - val_accuracy: 0.6981\n",
      "Epoch 1929/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6559 - accuracy: 0.7852 - val_loss: 1.0461 - val_accuracy: 0.6948\n",
      "Epoch 1930/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6543 - accuracy: 0.7793 - val_loss: 1.0740 - val_accuracy: 0.6721\n",
      "Epoch 1931/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6917 - accuracy: 0.7682 - val_loss: 1.1113 - val_accuracy: 0.6494\n",
      "Epoch 1932/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6986 - accuracy: 0.7607 - val_loss: 1.1488 - val_accuracy: 0.6396\n",
      "Epoch 1933/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6173 - accuracy: 0.8128 - val_loss: 1.1615 - val_accuracy: 0.6429\n",
      "Epoch 1934/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6602 - accuracy: 0.7852 - val_loss: 1.1821 - val_accuracy: 0.6331\n",
      "Epoch 1935/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6489 - accuracy: 0.7900 - val_loss: 1.1949 - val_accuracy: 0.6234\n",
      "Epoch 1936/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6598 - accuracy: 0.7682 - val_loss: 1.1871 - val_accuracy: 0.6331\n",
      "Epoch 1937/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7069 - accuracy: 0.7676 - val_loss: 1.1832 - val_accuracy: 0.6331\n",
      "Epoch 1938/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6987 - accuracy: 0.7812 - val_loss: 1.1828 - val_accuracy: 0.6461\n",
      "Epoch 1939/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6231 - accuracy: 0.7905 - val_loss: 1.1630 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1940/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7395 - accuracy: 0.7510 - val_loss: 1.1602 - val_accuracy: 0.6429\n",
      "Epoch 1941/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6232 - accuracy: 0.7998 - val_loss: 1.1572 - val_accuracy: 0.6494\n",
      "Epoch 1942/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6328 - accuracy: 0.7939 - val_loss: 1.1527 - val_accuracy: 0.6494\n",
      "Epoch 1943/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6757 - accuracy: 0.7646 - val_loss: 1.1453 - val_accuracy: 0.6461\n",
      "Epoch 1944/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5724 - accuracy: 0.8086 - val_loss: 1.1403 - val_accuracy: 0.6526\n",
      "Epoch 1945/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6594 - accuracy: 0.7803 - val_loss: 1.1455 - val_accuracy: 0.6494\n",
      "Epoch 1946/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6217 - accuracy: 0.7891 - val_loss: 1.1517 - val_accuracy: 0.6526\n",
      "Epoch 1947/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6464 - accuracy: 0.7754 - val_loss: 1.1640 - val_accuracy: 0.6396\n",
      "Epoch 1948/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6871 - accuracy: 0.7764 - val_loss: 1.1942 - val_accuracy: 0.6299\n",
      "Epoch 1949/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6779 - accuracy: 0.7584 - val_loss: 1.2240 - val_accuracy: 0.6266\n",
      "Epoch 1950/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6820 - accuracy: 0.7881 - val_loss: 1.2273 - val_accuracy: 0.6266\n",
      "Epoch 1951/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6035 - accuracy: 0.7947 - val_loss: 1.2329 - val_accuracy: 0.6201\n",
      "Epoch 1952/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5917 - accuracy: 0.8066 - val_loss: 1.2336 - val_accuracy: 0.6169\n",
      "Epoch 1953/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6179 - accuracy: 0.7988 - val_loss: 1.2210 - val_accuracy: 0.6136\n",
      "Epoch 1954/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6101 - accuracy: 0.8073 - val_loss: 1.2081 - val_accuracy: 0.6169\n",
      "Epoch 1955/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6481 - accuracy: 0.7891 - val_loss: 1.2089 - val_accuracy: 0.6136\n",
      "Epoch 1956/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6627 - accuracy: 0.7881 - val_loss: 1.1913 - val_accuracy: 0.6201\n",
      "Epoch 1957/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6652 - accuracy: 0.7842 - val_loss: 1.1710 - val_accuracy: 0.6169\n",
      "Epoch 1958/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6175 - accuracy: 0.7863 - val_loss: 1.1545 - val_accuracy: 0.6299\n",
      "Epoch 1959/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6217 - accuracy: 0.7933 - val_loss: 1.1524 - val_accuracy: 0.6429\n",
      "Epoch 1960/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6257 - accuracy: 0.7891 - val_loss: 1.1474 - val_accuracy: 0.6396\n",
      "Epoch 1961/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6554 - accuracy: 0.7979 - val_loss: 1.1423 - val_accuracy: 0.6364\n",
      "Epoch 1962/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6416 - accuracy: 0.7668 - val_loss: 1.1472 - val_accuracy: 0.6266\n",
      "Epoch 1963/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6287 - accuracy: 0.7939 - val_loss: 1.1517 - val_accuracy: 0.6234\n",
      "Epoch 1964/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5994 - accuracy: 0.8027 - val_loss: 1.1666 - val_accuracy: 0.6364\n",
      "Epoch 1965/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6893 - accuracy: 0.7910 - val_loss: 1.1816 - val_accuracy: 0.6461\n",
      "Epoch 1966/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6534 - accuracy: 0.7905 - val_loss: 1.1787 - val_accuracy: 0.6364\n",
      "Epoch 1967/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6382 - accuracy: 0.7705 - val_loss: 1.1790 - val_accuracy: 0.6331\n",
      "Epoch 1968/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6545 - accuracy: 0.7871 - val_loss: 1.1607 - val_accuracy: 0.6169\n",
      "Epoch 1969/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6088 - accuracy: 0.7947 - val_loss: 1.1437 - val_accuracy: 0.6266\n",
      "Epoch 1970/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6370 - accuracy: 0.8008 - val_loss: 1.1270 - val_accuracy: 0.6266\n",
      "Epoch 1971/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6705 - accuracy: 0.7773 - val_loss: 1.1221 - val_accuracy: 0.6234\n",
      "Epoch 1972/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6279 - accuracy: 0.8045 - val_loss: 1.1158 - val_accuracy: 0.6234\n",
      "Epoch 1973/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6028 - accuracy: 0.8017 - val_loss: 1.1155 - val_accuracy: 0.6299\n",
      "Epoch 1974/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6125 - accuracy: 0.7900 - val_loss: 1.1159 - val_accuracy: 0.6331\n",
      "Epoch 1975/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6798 - accuracy: 0.7627 - val_loss: 1.1146 - val_accuracy: 0.6331\n",
      "Epoch 1976/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6322 - accuracy: 0.7905 - val_loss: 1.1175 - val_accuracy: 0.6331\n",
      "Epoch 1977/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6560 - accuracy: 0.7933 - val_loss: 1.1400 - val_accuracy: 0.6364\n",
      "Epoch 1978/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6434 - accuracy: 0.7961 - val_loss: 1.1725 - val_accuracy: 0.6331\n",
      "Epoch 1979/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5769 - accuracy: 0.8115 - val_loss: 1.1892 - val_accuracy: 0.6201\n",
      "Epoch 1980/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6305 - accuracy: 0.7754 - val_loss: 1.1873 - val_accuracy: 0.6234\n",
      "Epoch 1981/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7076 - accuracy: 0.7682 - val_loss: 1.1473 - val_accuracy: 0.6299\n",
      "Epoch 1982/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6490 - accuracy: 0.7696 - val_loss: 1.0964 - val_accuracy: 0.6461\n",
      "Epoch 1983/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6693 - accuracy: 0.7682 - val_loss: 1.0586 - val_accuracy: 0.6558\n",
      "Epoch 1984/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6478 - accuracy: 0.7803 - val_loss: 1.0479 - val_accuracy: 0.6558\n",
      "Epoch 1985/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6192 - accuracy: 0.7852 - val_loss: 1.0535 - val_accuracy: 0.6656\n",
      "Epoch 1986/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6029 - accuracy: 0.7939 - val_loss: 1.0640 - val_accuracy: 0.6753\n",
      "Epoch 1987/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6287 - accuracy: 0.7852 - val_loss: 1.0618 - val_accuracy: 0.6721\n",
      "Epoch 1988/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6110 - accuracy: 0.8128 - val_loss: 1.0600 - val_accuracy: 0.6721\n",
      "Epoch 1989/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6048 - accuracy: 0.7979 - val_loss: 1.0546 - val_accuracy: 0.6558\n",
      "Epoch 1990/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6308 - accuracy: 0.7910 - val_loss: 1.0655 - val_accuracy: 0.6526\n",
      "Epoch 1991/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6615 - accuracy: 0.7933 - val_loss: 1.0914 - val_accuracy: 0.6558\n",
      "Epoch 1992/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6639 - accuracy: 0.7852 - val_loss: 1.1368 - val_accuracy: 0.6526\n",
      "Epoch 1993/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6288 - accuracy: 0.7900 - val_loss: 1.1773 - val_accuracy: 0.6526\n",
      "Epoch 1994/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6048 - accuracy: 0.8008 - val_loss: 1.1807 - val_accuracy: 0.6461\n",
      "Epoch 1995/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6683 - accuracy: 0.7919 - val_loss: 1.1850 - val_accuracy: 0.6396\n",
      "Epoch 1996/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5729 - accuracy: 0.8037 - val_loss: 1.1765 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1997/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6222 - accuracy: 0.7877 - val_loss: 1.1461 - val_accuracy: 0.6429\n",
      "Epoch 1998/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6324 - accuracy: 0.7933 - val_loss: 1.1219 - val_accuracy: 0.6331\n",
      "Epoch 1999/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6257 - accuracy: 0.7961 - val_loss: 1.1188 - val_accuracy: 0.6331\n",
      "Epoch 2000/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5651 - accuracy: 0.8115 - val_loss: 1.1225 - val_accuracy: 0.6299\n",
      "Epoch 2001/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6723 - accuracy: 0.7807 - val_loss: 1.1259 - val_accuracy: 0.6429\n",
      "Epoch 2002/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6680 - accuracy: 0.7779 - val_loss: 1.1271 - val_accuracy: 0.6461\n",
      "Epoch 2003/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6443 - accuracy: 0.7793 - val_loss: 1.1401 - val_accuracy: 0.6299\n",
      "Epoch 2004/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5864 - accuracy: 0.8105 - val_loss: 1.1631 - val_accuracy: 0.6396\n",
      "Epoch 2005/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6030 - accuracy: 0.8105 - val_loss: 1.1809 - val_accuracy: 0.6364\n",
      "Epoch 2006/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6235 - accuracy: 0.7959 - val_loss: 1.1909 - val_accuracy: 0.6234\n",
      "Epoch 2007/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6023 - accuracy: 0.8076 - val_loss: 1.1860 - val_accuracy: 0.6266\n",
      "Epoch 2008/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5994 - accuracy: 0.8047 - val_loss: 1.1843 - val_accuracy: 0.6331\n",
      "Epoch 2009/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6277 - accuracy: 0.7910 - val_loss: 1.1783 - val_accuracy: 0.6364\n",
      "Epoch 2010/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6402 - accuracy: 0.7920 - val_loss: 1.1749 - val_accuracy: 0.6331\n",
      "Epoch 2011/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6113 - accuracy: 0.8087 - val_loss: 1.1727 - val_accuracy: 0.6299\n",
      "Epoch 2012/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6504 - accuracy: 0.7793 - val_loss: 1.1832 - val_accuracy: 0.6234\n",
      "Epoch 2013/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5629 - accuracy: 0.8045 - val_loss: 1.2039 - val_accuracy: 0.6429\n",
      "Epoch 2014/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6032 - accuracy: 0.7975 - val_loss: 1.2338 - val_accuracy: 0.6364\n",
      "Epoch 2015/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5652 - accuracy: 0.8226 - val_loss: 1.2647 - val_accuracy: 0.6201\n",
      "Epoch 2016/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6201 - accuracy: 0.8008 - val_loss: 1.2956 - val_accuracy: 0.6201\n",
      "Epoch 2017/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6327 - accuracy: 0.7877 - val_loss: 1.3209 - val_accuracy: 0.6266\n",
      "Epoch 2018/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6602 - accuracy: 0.7949 - val_loss: 1.2958 - val_accuracy: 0.6299\n",
      "Epoch 2019/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6537 - accuracy: 0.7881 - val_loss: 1.2479 - val_accuracy: 0.6429\n",
      "Epoch 2020/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5784 - accuracy: 0.8101 - val_loss: 1.1893 - val_accuracy: 0.6396\n",
      "Epoch 2021/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5936 - accuracy: 0.7988 - val_loss: 1.1567 - val_accuracy: 0.6364\n",
      "Epoch 2022/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6643 - accuracy: 0.7871 - val_loss: 1.1434 - val_accuracy: 0.6331\n",
      "Epoch 2023/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6057 - accuracy: 0.7939 - val_loss: 1.1362 - val_accuracy: 0.6461\n",
      "Epoch 2024/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6128 - accuracy: 0.8003 - val_loss: 1.1360 - val_accuracy: 0.6623\n",
      "Epoch 2025/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5995 - accuracy: 0.7961 - val_loss: 1.1280 - val_accuracy: 0.6656\n",
      "Epoch 2026/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6071 - accuracy: 0.8105 - val_loss: 1.1122 - val_accuracy: 0.6656\n",
      "Epoch 2027/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6441 - accuracy: 0.7835 - val_loss: 1.1058 - val_accuracy: 0.6656\n",
      "Epoch 2028/4000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6594 - accuracy: 0.7832 - val_loss: 1.1079 - val_accuracy: 0.6558\n",
      "Epoch 2029/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6269 - accuracy: 0.7959 - val_loss: 1.1164 - val_accuracy: 0.6526\n",
      "Epoch 2030/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6674 - accuracy: 0.7871 - val_loss: 1.1301 - val_accuracy: 0.6526\n",
      "Epoch 2031/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6243 - accuracy: 0.7863 - val_loss: 1.1160 - val_accuracy: 0.6591\n",
      "Epoch 2032/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6147 - accuracy: 0.7877 - val_loss: 1.0940 - val_accuracy: 0.6688\n",
      "Epoch 2033/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5932 - accuracy: 0.8066 - val_loss: 1.0883 - val_accuracy: 0.6623\n",
      "Epoch 2034/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6045 - accuracy: 0.7947 - val_loss: 1.0909 - val_accuracy: 0.6688\n",
      "Epoch 2035/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5878 - accuracy: 0.7988 - val_loss: 1.1063 - val_accuracy: 0.6721\n",
      "Epoch 2036/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6197 - accuracy: 0.8017 - val_loss: 1.1133 - val_accuracy: 0.6656\n",
      "Epoch 2037/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6653 - accuracy: 0.7877 - val_loss: 1.1108 - val_accuracy: 0.6688\n",
      "Epoch 2038/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6204 - accuracy: 0.8076 - val_loss: 1.0920 - val_accuracy: 0.6623\n",
      "Epoch 2039/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6522 - accuracy: 0.7900 - val_loss: 1.0725 - val_accuracy: 0.6656\n",
      "Epoch 2040/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5816 - accuracy: 0.7989 - val_loss: 1.0673 - val_accuracy: 0.6721\n",
      "Epoch 2041/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6534 - accuracy: 0.7891 - val_loss: 1.0671 - val_accuracy: 0.6721\n",
      "Epoch 2042/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6693 - accuracy: 0.7821 - val_loss: 1.0652 - val_accuracy: 0.6623\n",
      "Epoch 2043/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6878 - accuracy: 0.7807 - val_loss: 1.0847 - val_accuracy: 0.6461\n",
      "Epoch 2044/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6037 - accuracy: 0.8017 - val_loss: 1.1061 - val_accuracy: 0.6396\n",
      "Epoch 2045/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6200 - accuracy: 0.7947 - val_loss: 1.1308 - val_accuracy: 0.6429\n",
      "Epoch 2046/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6682 - accuracy: 0.7754 - val_loss: 1.1381 - val_accuracy: 0.6396\n",
      "Epoch 2047/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6006 - accuracy: 0.8027 - val_loss: 1.1354 - val_accuracy: 0.6234\n",
      "Epoch 2048/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6351 - accuracy: 0.8003 - val_loss: 1.1404 - val_accuracy: 0.6364\n",
      "Epoch 2049/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6214 - accuracy: 0.7988 - val_loss: 1.1302 - val_accuracy: 0.6429\n",
      "Epoch 2050/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6717 - accuracy: 0.7779 - val_loss: 1.1159 - val_accuracy: 0.6623\n",
      "Epoch 2051/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6414 - accuracy: 0.7835 - val_loss: 1.0964 - val_accuracy: 0.6656\n",
      "Epoch 2052/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6102 - accuracy: 0.7998 - val_loss: 1.0755 - val_accuracy: 0.6721\n",
      "Epoch 2053/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5958 - accuracy: 0.8087 - val_loss: 1.0691 - val_accuracy: 0.6688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2054/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6987 - accuracy: 0.7514 - val_loss: 1.0716 - val_accuracy: 0.6461\n",
      "Epoch 2055/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6891 - accuracy: 0.7696 - val_loss: 1.0890 - val_accuracy: 0.6494\n",
      "Epoch 2056/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6145 - accuracy: 0.7905 - val_loss: 1.1069 - val_accuracy: 0.6558\n",
      "Epoch 2057/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5975 - accuracy: 0.7849 - val_loss: 1.1056 - val_accuracy: 0.6526\n",
      "Epoch 2058/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6340 - accuracy: 0.7861 - val_loss: 1.0996 - val_accuracy: 0.6656\n",
      "Epoch 2059/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6576 - accuracy: 0.7751 - val_loss: 1.0952 - val_accuracy: 0.6623\n",
      "Epoch 2060/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5606 - accuracy: 0.8170 - val_loss: 1.0982 - val_accuracy: 0.6753\n",
      "Epoch 2061/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6483 - accuracy: 0.7852 - val_loss: 1.0909 - val_accuracy: 0.6721\n",
      "Epoch 2062/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6162 - accuracy: 0.7998 - val_loss: 1.0763 - val_accuracy: 0.6786\n",
      "Epoch 2063/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6719 - accuracy: 0.7905 - val_loss: 1.0824 - val_accuracy: 0.6753\n",
      "Epoch 2064/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5795 - accuracy: 0.8057 - val_loss: 1.1044 - val_accuracy: 0.6558\n",
      "Epoch 2065/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6227 - accuracy: 0.7734 - val_loss: 1.1454 - val_accuracy: 0.6429\n",
      "Epoch 2066/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5943 - accuracy: 0.8008 - val_loss: 1.1715 - val_accuracy: 0.6299\n",
      "Epoch 2067/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5975 - accuracy: 0.8003 - val_loss: 1.1944 - val_accuracy: 0.6266\n",
      "Epoch 2068/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5994 - accuracy: 0.7905 - val_loss: 1.2138 - val_accuracy: 0.6266\n",
      "Epoch 2069/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5620 - accuracy: 0.8198 - val_loss: 1.2244 - val_accuracy: 0.6234\n",
      "Epoch 2070/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6805 - accuracy: 0.7723 - val_loss: 1.2396 - val_accuracy: 0.6299\n",
      "Epoch 2071/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5598 - accuracy: 0.8125 - val_loss: 1.2700 - val_accuracy: 0.6169\n",
      "Epoch 2072/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5945 - accuracy: 0.8047 - val_loss: 1.3145 - val_accuracy: 0.6169\n",
      "Epoch 2073/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6329 - accuracy: 0.8226 - val_loss: 1.3378 - val_accuracy: 0.6039\n",
      "Epoch 2074/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6615 - accuracy: 0.7871 - val_loss: 1.3808 - val_accuracy: 0.5844\n",
      "Epoch 2075/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6256 - accuracy: 0.7849 - val_loss: 1.4080 - val_accuracy: 0.5747\n",
      "Epoch 2076/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6520 - accuracy: 0.7988 - val_loss: 1.3801 - val_accuracy: 0.5779\n",
      "Epoch 2077/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5749 - accuracy: 0.7979 - val_loss: 1.3269 - val_accuracy: 0.5844\n",
      "Epoch 2078/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5774 - accuracy: 0.8076 - val_loss: 1.2853 - val_accuracy: 0.5877\n",
      "Epoch 2079/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5575 - accuracy: 0.8226 - val_loss: 1.2648 - val_accuracy: 0.5942\n",
      "Epoch 2080/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6252 - accuracy: 0.7979 - val_loss: 1.2565 - val_accuracy: 0.5909\n",
      "Epoch 2081/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5754 - accuracy: 0.8125 - val_loss: 1.2303 - val_accuracy: 0.6006\n",
      "Epoch 2082/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5804 - accuracy: 0.8115 - val_loss: 1.2470 - val_accuracy: 0.6234\n",
      "Epoch 2083/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5383 - accuracy: 0.8359 - val_loss: 1.2612 - val_accuracy: 0.6299\n",
      "Epoch 2084/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5598 - accuracy: 0.8170 - val_loss: 1.2540 - val_accuracy: 0.6364\n",
      "Epoch 2085/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5953 - accuracy: 0.8045 - val_loss: 1.2520 - val_accuracy: 0.6364\n",
      "Epoch 2086/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6140 - accuracy: 0.7900 - val_loss: 1.2613 - val_accuracy: 0.6331\n",
      "Epoch 2087/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5880 - accuracy: 0.8115 - val_loss: 1.2436 - val_accuracy: 0.6396\n",
      "Epoch 2088/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5940 - accuracy: 0.8086 - val_loss: 1.2341 - val_accuracy: 0.6299\n",
      "Epoch 2089/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6021 - accuracy: 0.7933 - val_loss: 1.2348 - val_accuracy: 0.6266\n",
      "Epoch 2090/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6346 - accuracy: 0.7961 - val_loss: 1.2052 - val_accuracy: 0.6364\n",
      "Epoch 2091/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6025 - accuracy: 0.8018 - val_loss: 1.1907 - val_accuracy: 0.6234\n",
      "Epoch 2092/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6161 - accuracy: 0.7989 - val_loss: 1.1742 - val_accuracy: 0.6266\n",
      "Epoch 2093/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5749 - accuracy: 0.8059 - val_loss: 1.1584 - val_accuracy: 0.6364\n",
      "Epoch 2094/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5213 - accuracy: 0.8240 - val_loss: 1.1651 - val_accuracy: 0.6266\n",
      "Epoch 2095/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5700 - accuracy: 0.8338 - val_loss: 1.1608 - val_accuracy: 0.6266\n",
      "Epoch 2096/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6231 - accuracy: 0.7933 - val_loss: 1.1585 - val_accuracy: 0.6364\n",
      "Epoch 2097/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5703 - accuracy: 0.8066 - val_loss: 1.1602 - val_accuracy: 0.6364\n",
      "Epoch 2098/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5658 - accuracy: 0.8076 - val_loss: 1.1663 - val_accuracy: 0.6201\n",
      "Epoch 2099/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6547 - accuracy: 0.7930 - val_loss: 1.1778 - val_accuracy: 0.6136\n",
      "Epoch 2100/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6742 - accuracy: 0.7905 - val_loss: 1.1710 - val_accuracy: 0.6136\n",
      "Epoch 2101/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5608 - accuracy: 0.8045 - val_loss: 1.1304 - val_accuracy: 0.6201\n",
      "Epoch 2102/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5932 - accuracy: 0.8027 - val_loss: 1.0940 - val_accuracy: 0.6266\n",
      "Epoch 2103/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6060 - accuracy: 0.8184 - val_loss: 1.0714 - val_accuracy: 0.6461\n",
      "Epoch 2104/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5887 - accuracy: 0.7961 - val_loss: 1.0649 - val_accuracy: 0.6396\n",
      "Epoch 2105/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6256 - accuracy: 0.8073 - val_loss: 1.0724 - val_accuracy: 0.6526\n",
      "Epoch 2106/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5951 - accuracy: 0.8027 - val_loss: 1.0923 - val_accuracy: 0.6429\n",
      "Epoch 2107/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6011 - accuracy: 0.7988 - val_loss: 1.1178 - val_accuracy: 0.6364\n",
      "Epoch 2108/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5785 - accuracy: 0.8047 - val_loss: 1.1611 - val_accuracy: 0.6234\n",
      "Epoch 2109/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6631 - accuracy: 0.7744 - val_loss: 1.2271 - val_accuracy: 0.6169\n",
      "Epoch 2110/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6158 - accuracy: 0.7881 - val_loss: 1.2742 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2111/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5939 - accuracy: 0.8156 - val_loss: 1.2939 - val_accuracy: 0.6169\n",
      "Epoch 2112/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6493 - accuracy: 0.7920 - val_loss: 1.2474 - val_accuracy: 0.6234\n",
      "Epoch 2113/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5826 - accuracy: 0.8174 - val_loss: 1.2011 - val_accuracy: 0.6201\n",
      "Epoch 2114/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6505 - accuracy: 0.7919 - val_loss: 1.1880 - val_accuracy: 0.6364\n",
      "Epoch 2115/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6219 - accuracy: 0.7863 - val_loss: 1.1773 - val_accuracy: 0.6299\n",
      "Epoch 2116/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6493 - accuracy: 0.7988 - val_loss: 1.1483 - val_accuracy: 0.6364\n",
      "Epoch 2117/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5950 - accuracy: 0.8027 - val_loss: 1.1140 - val_accuracy: 0.6266\n",
      "Epoch 2118/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6012 - accuracy: 0.7905 - val_loss: 1.1073 - val_accuracy: 0.6331\n",
      "Epoch 2119/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6107 - accuracy: 0.7891 - val_loss: 1.0986 - val_accuracy: 0.6266\n",
      "Epoch 2120/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5847 - accuracy: 0.8128 - val_loss: 1.0985 - val_accuracy: 0.6331\n",
      "Epoch 2121/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6217 - accuracy: 0.7998 - val_loss: 1.1044 - val_accuracy: 0.6364\n",
      "Epoch 2122/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6023 - accuracy: 0.7910 - val_loss: 1.1268 - val_accuracy: 0.6331\n",
      "Epoch 2123/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6426 - accuracy: 0.8017 - val_loss: 1.1634 - val_accuracy: 0.6364\n",
      "Epoch 2124/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6005 - accuracy: 0.8008 - val_loss: 1.2293 - val_accuracy: 0.6201\n",
      "Epoch 2125/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6047 - accuracy: 0.8087 - val_loss: 1.3066 - val_accuracy: 0.6071\n",
      "Epoch 2126/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6312 - accuracy: 0.7961 - val_loss: 1.3422 - val_accuracy: 0.6071\n",
      "Epoch 2127/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5834 - accuracy: 0.8059 - val_loss: 1.3545 - val_accuracy: 0.5974\n",
      "Epoch 2128/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6113 - accuracy: 0.7939 - val_loss: 1.3393 - val_accuracy: 0.6104\n",
      "Epoch 2129/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5982 - accuracy: 0.8145 - val_loss: 1.3033 - val_accuracy: 0.6266\n",
      "Epoch 2130/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6045 - accuracy: 0.7989 - val_loss: 1.2729 - val_accuracy: 0.6104\n",
      "Epoch 2131/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5885 - accuracy: 0.8008 - val_loss: 1.2244 - val_accuracy: 0.6364\n",
      "Epoch 2132/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6045 - accuracy: 0.8105 - val_loss: 1.1893 - val_accuracy: 0.6364\n",
      "Epoch 2133/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5779 - accuracy: 0.8003 - val_loss: 1.1821 - val_accuracy: 0.6299\n",
      "Epoch 2134/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6138 - accuracy: 0.8101 - val_loss: 1.2082 - val_accuracy: 0.6299\n",
      "Epoch 2135/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5857 - accuracy: 0.7998 - val_loss: 1.2398 - val_accuracy: 0.6136\n",
      "Epoch 2136/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5977 - accuracy: 0.8045 - val_loss: 1.2934 - val_accuracy: 0.6169\n",
      "Epoch 2137/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5809 - accuracy: 0.8086 - val_loss: 1.3540 - val_accuracy: 0.6039\n",
      "Epoch 2138/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5960 - accuracy: 0.8154 - val_loss: 1.4205 - val_accuracy: 0.5877\n",
      "Epoch 2139/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6415 - accuracy: 0.7989 - val_loss: 1.4881 - val_accuracy: 0.5747\n",
      "Epoch 2140/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5531 - accuracy: 0.8320 - val_loss: 1.5249 - val_accuracy: 0.5714\n",
      "Epoch 2141/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5743 - accuracy: 0.8017 - val_loss: 1.5189 - val_accuracy: 0.5812\n",
      "Epoch 2142/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6282 - accuracy: 0.7849 - val_loss: 1.4935 - val_accuracy: 0.5909\n",
      "Epoch 2143/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5956 - accuracy: 0.8017 - val_loss: 1.4698 - val_accuracy: 0.6006\n",
      "Epoch 2144/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5687 - accuracy: 0.8291 - val_loss: 1.4186 - val_accuracy: 0.6104\n",
      "Epoch 2145/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5652 - accuracy: 0.8240 - val_loss: 1.3742 - val_accuracy: 0.5974\n",
      "Epoch 2146/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5710 - accuracy: 0.8115 - val_loss: 1.3366 - val_accuracy: 0.6006\n",
      "Epoch 2147/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6524 - accuracy: 0.7877 - val_loss: 1.2951 - val_accuracy: 0.6331\n",
      "Epoch 2148/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5227 - accuracy: 0.8242 - val_loss: 1.2822 - val_accuracy: 0.6299\n",
      "Epoch 2149/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6139 - accuracy: 0.8174 - val_loss: 1.2852 - val_accuracy: 0.6299\n",
      "Epoch 2150/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6164 - accuracy: 0.7905 - val_loss: 1.3050 - val_accuracy: 0.6169\n",
      "Epoch 2151/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6074 - accuracy: 0.8059 - val_loss: 1.3446 - val_accuracy: 0.6169\n",
      "Epoch 2152/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5975 - accuracy: 0.8101 - val_loss: 1.3746 - val_accuracy: 0.6266\n",
      "Epoch 2153/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6215 - accuracy: 0.7910 - val_loss: 1.3914 - val_accuracy: 0.6299\n",
      "Epoch 2154/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6038 - accuracy: 0.7905 - val_loss: 1.3549 - val_accuracy: 0.6234\n",
      "Epoch 2155/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5619 - accuracy: 0.8135 - val_loss: 1.3093 - val_accuracy: 0.6364\n",
      "Epoch 2156/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5903 - accuracy: 0.8086 - val_loss: 1.2815 - val_accuracy: 0.6266\n",
      "Epoch 2157/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5406 - accuracy: 0.8254 - val_loss: 1.2402 - val_accuracy: 0.6234\n",
      "Epoch 2158/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5867 - accuracy: 0.7835 - val_loss: 1.2156 - val_accuracy: 0.6299\n",
      "Epoch 2159/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5804 - accuracy: 0.8045 - val_loss: 1.2051 - val_accuracy: 0.6299\n",
      "Epoch 2160/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5845 - accuracy: 0.8154 - val_loss: 1.2089 - val_accuracy: 0.6396\n",
      "Epoch 2161/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6084 - accuracy: 0.7949 - val_loss: 1.2229 - val_accuracy: 0.6461\n",
      "Epoch 2162/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5747 - accuracy: 0.8047 - val_loss: 1.2411 - val_accuracy: 0.6526\n",
      "Epoch 2163/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6043 - accuracy: 0.8057 - val_loss: 1.2634 - val_accuracy: 0.6558\n",
      "Epoch 2164/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5659 - accuracy: 0.8128 - val_loss: 1.2724 - val_accuracy: 0.6526\n",
      "Epoch 2165/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6155 - accuracy: 0.8037 - val_loss: 1.3033 - val_accuracy: 0.6364\n",
      "Epoch 2166/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6488 - accuracy: 0.7849 - val_loss: 1.3414 - val_accuracy: 0.6104\n",
      "Epoch 2167/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5882 - accuracy: 0.8135 - val_loss: 1.3458 - val_accuracy: 0.6169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2168/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5220 - accuracy: 0.8352 - val_loss: 1.3075 - val_accuracy: 0.6136\n",
      "Epoch 2169/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6076 - accuracy: 0.7975 - val_loss: 1.2299 - val_accuracy: 0.6201\n",
      "Epoch 2170/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5848 - accuracy: 0.8087 - val_loss: 1.1578 - val_accuracy: 0.6201\n",
      "Epoch 2171/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6275 - accuracy: 0.8031 - val_loss: 1.1170 - val_accuracy: 0.6266\n",
      "Epoch 2172/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6047 - accuracy: 0.7989 - val_loss: 1.1024 - val_accuracy: 0.6429\n",
      "Epoch 2173/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5401 - accuracy: 0.8198 - val_loss: 1.1114 - val_accuracy: 0.6429\n",
      "Epoch 2174/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5502 - accuracy: 0.8174 - val_loss: 1.1282 - val_accuracy: 0.6429\n",
      "Epoch 2175/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6588 - accuracy: 0.7877 - val_loss: 1.1605 - val_accuracy: 0.6494\n",
      "Epoch 2176/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5638 - accuracy: 0.8115 - val_loss: 1.2051 - val_accuracy: 0.6396\n",
      "Epoch 2177/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5889 - accuracy: 0.8066 - val_loss: 1.2397 - val_accuracy: 0.6234\n",
      "Epoch 2178/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5501 - accuracy: 0.8203 - val_loss: 1.2812 - val_accuracy: 0.6104\n",
      "Epoch 2179/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6007 - accuracy: 0.8018 - val_loss: 1.3077 - val_accuracy: 0.6006\n",
      "Epoch 2180/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5703 - accuracy: 0.8128 - val_loss: 1.3172 - val_accuracy: 0.5974\n",
      "Epoch 2181/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5379 - accuracy: 0.8170 - val_loss: 1.2796 - val_accuracy: 0.6071\n",
      "Epoch 2182/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5308 - accuracy: 0.8296 - val_loss: 1.2358 - val_accuracy: 0.6104\n",
      "Epoch 2183/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5535 - accuracy: 0.8142 - val_loss: 1.2000 - val_accuracy: 0.6234\n",
      "Epoch 2184/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5664 - accuracy: 0.8170 - val_loss: 1.1791 - val_accuracy: 0.6461\n",
      "Epoch 2185/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5672 - accuracy: 0.8142 - val_loss: 1.1662 - val_accuracy: 0.6526\n",
      "Epoch 2186/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5489 - accuracy: 0.8271 - val_loss: 1.1547 - val_accuracy: 0.6526\n",
      "Epoch 2187/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5527 - accuracy: 0.8184 - val_loss: 1.1548 - val_accuracy: 0.6396\n",
      "Epoch 2188/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4816 - accuracy: 0.8492 - val_loss: 1.1574 - val_accuracy: 0.6396\n",
      "Epoch 2189/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5251 - accuracy: 0.8184 - val_loss: 1.1750 - val_accuracy: 0.6331\n",
      "Epoch 2190/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6566 - accuracy: 0.7783 - val_loss: 1.1951 - val_accuracy: 0.6461\n",
      "Epoch 2191/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5659 - accuracy: 0.8135 - val_loss: 1.2019 - val_accuracy: 0.6429\n",
      "Epoch 2192/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5798 - accuracy: 0.8045 - val_loss: 1.1902 - val_accuracy: 0.6429\n",
      "Epoch 2193/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6194 - accuracy: 0.8017 - val_loss: 1.1762 - val_accuracy: 0.6429\n",
      "Epoch 2194/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6435 - accuracy: 0.7919 - val_loss: 1.1629 - val_accuracy: 0.6429\n",
      "Epoch 2195/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5403 - accuracy: 0.8213 - val_loss: 1.1561 - val_accuracy: 0.6526\n",
      "Epoch 2196/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6026 - accuracy: 0.8125 - val_loss: 1.1646 - val_accuracy: 0.6558\n",
      "Epoch 2197/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5551 - accuracy: 0.8115 - val_loss: 1.1794 - val_accuracy: 0.6494\n",
      "Epoch 2198/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6114 - accuracy: 0.7949 - val_loss: 1.1878 - val_accuracy: 0.6494\n",
      "Epoch 2199/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5633 - accuracy: 0.7933 - val_loss: 1.2040 - val_accuracy: 0.6429\n",
      "Epoch 2200/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5806 - accuracy: 0.8156 - val_loss: 1.2403 - val_accuracy: 0.6201\n",
      "Epoch 2201/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5187 - accuracy: 0.8324 - val_loss: 1.2808 - val_accuracy: 0.6136\n",
      "Epoch 2202/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5258 - accuracy: 0.8125 - val_loss: 1.3076 - val_accuracy: 0.6006\n",
      "Epoch 2203/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5616 - accuracy: 0.8223 - val_loss: 1.3282 - val_accuracy: 0.6006\n",
      "Epoch 2204/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5527 - accuracy: 0.8105 - val_loss: 1.3487 - val_accuracy: 0.5812\n",
      "Epoch 2205/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5677 - accuracy: 0.8086 - val_loss: 1.3631 - val_accuracy: 0.5844\n",
      "Epoch 2206/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6053 - accuracy: 0.7959 - val_loss: 1.3446 - val_accuracy: 0.5812\n",
      "Epoch 2207/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5787 - accuracy: 0.8145 - val_loss: 1.3166 - val_accuracy: 0.5844\n",
      "Epoch 2208/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5841 - accuracy: 0.8198 - val_loss: 1.2742 - val_accuracy: 0.5844\n",
      "Epoch 2209/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6154 - accuracy: 0.7900 - val_loss: 1.2482 - val_accuracy: 0.5844\n",
      "Epoch 2210/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5960 - accuracy: 0.8037 - val_loss: 1.2459 - val_accuracy: 0.6039\n",
      "Epoch 2211/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5614 - accuracy: 0.8115 - val_loss: 1.2439 - val_accuracy: 0.6201\n",
      "Epoch 2212/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5583 - accuracy: 0.8017 - val_loss: 1.2581 - val_accuracy: 0.6331\n",
      "Epoch 2213/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5009 - accuracy: 0.8394 - val_loss: 1.2877 - val_accuracy: 0.6331\n",
      "Epoch 2214/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5549 - accuracy: 0.8045 - val_loss: 1.3119 - val_accuracy: 0.6201\n",
      "Epoch 2215/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5793 - accuracy: 0.8073 - val_loss: 1.3182 - val_accuracy: 0.6136\n",
      "Epoch 2216/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5926 - accuracy: 0.8037 - val_loss: 1.3024 - val_accuracy: 0.6169\n",
      "Epoch 2217/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6305 - accuracy: 0.7920 - val_loss: 1.2799 - val_accuracy: 0.6299\n",
      "Epoch 2218/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5754 - accuracy: 0.8128 - val_loss: 1.2435 - val_accuracy: 0.6494\n",
      "Epoch 2219/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5174 - accuracy: 0.8198 - val_loss: 1.2027 - val_accuracy: 0.6429\n",
      "Epoch 2220/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5504 - accuracy: 0.8115 - val_loss: 1.1834 - val_accuracy: 0.6396\n",
      "Epoch 2221/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6003 - accuracy: 0.8115 - val_loss: 1.1715 - val_accuracy: 0.6429\n",
      "Epoch 2222/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5549 - accuracy: 0.8198 - val_loss: 1.1663 - val_accuracy: 0.6364\n",
      "Epoch 2223/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5617 - accuracy: 0.8324 - val_loss: 1.1697 - val_accuracy: 0.6331\n",
      "Epoch 2224/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5642 - accuracy: 0.8170 - val_loss: 1.1920 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2225/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5101 - accuracy: 0.8142 - val_loss: 1.2499 - val_accuracy: 0.6136\n",
      "Epoch 2226/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4849 - accuracy: 0.8478 - val_loss: 1.2883 - val_accuracy: 0.6104\n",
      "Epoch 2227/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5387 - accuracy: 0.8232 - val_loss: 1.3385 - val_accuracy: 0.5974\n",
      "Epoch 2228/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5934 - accuracy: 0.8125 - val_loss: 1.3534 - val_accuracy: 0.5877\n",
      "Epoch 2229/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5838 - accuracy: 0.7989 - val_loss: 1.3188 - val_accuracy: 0.6071\n",
      "Epoch 2230/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5160 - accuracy: 0.8311 - val_loss: 1.2892 - val_accuracy: 0.6039\n",
      "Epoch 2231/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5489 - accuracy: 0.8223 - val_loss: 1.2573 - val_accuracy: 0.6104\n",
      "Epoch 2232/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5361 - accuracy: 0.8059 - val_loss: 1.2483 - val_accuracy: 0.6104\n",
      "Epoch 2233/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5142 - accuracy: 0.8464 - val_loss: 1.2332 - val_accuracy: 0.6266\n",
      "Epoch 2234/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5677 - accuracy: 0.8059 - val_loss: 1.2281 - val_accuracy: 0.6234\n",
      "Epoch 2235/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5238 - accuracy: 0.8268 - val_loss: 1.2219 - val_accuracy: 0.6364\n",
      "Epoch 2236/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5651 - accuracy: 0.8096 - val_loss: 1.2287 - val_accuracy: 0.6494\n",
      "Epoch 2237/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5487 - accuracy: 0.8115 - val_loss: 1.2586 - val_accuracy: 0.6331\n",
      "Epoch 2238/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5877 - accuracy: 0.8115 - val_loss: 1.3033 - val_accuracy: 0.6136\n",
      "Epoch 2239/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5614 - accuracy: 0.8193 - val_loss: 1.3210 - val_accuracy: 0.6136\n",
      "Epoch 2240/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5592 - accuracy: 0.8156 - val_loss: 1.2919 - val_accuracy: 0.6266\n",
      "Epoch 2241/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5638 - accuracy: 0.8115 - val_loss: 1.2663 - val_accuracy: 0.6331\n",
      "Epoch 2242/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5383 - accuracy: 0.8242 - val_loss: 1.2527 - val_accuracy: 0.6234\n",
      "Epoch 2243/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5296 - accuracy: 0.8282 - val_loss: 1.2636 - val_accuracy: 0.6331\n",
      "Epoch 2244/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4746 - accuracy: 0.8438 - val_loss: 1.2713 - val_accuracy: 0.6169\n",
      "Epoch 2245/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5534 - accuracy: 0.8203 - val_loss: 1.2977 - val_accuracy: 0.6006\n",
      "Epoch 2246/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5777 - accuracy: 0.8145 - val_loss: 1.3332 - val_accuracy: 0.5942\n",
      "Epoch 2247/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5429 - accuracy: 0.8115 - val_loss: 1.3837 - val_accuracy: 0.5877\n",
      "Epoch 2248/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5589 - accuracy: 0.8037 - val_loss: 1.4336 - val_accuracy: 0.5747\n",
      "Epoch 2249/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5300 - accuracy: 0.8203 - val_loss: 1.4628 - val_accuracy: 0.5682\n",
      "Epoch 2250/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5445 - accuracy: 0.8059 - val_loss: 1.4469 - val_accuracy: 0.5844\n",
      "Epoch 2251/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5233 - accuracy: 0.8436 - val_loss: 1.3995 - val_accuracy: 0.5974\n",
      "Epoch 2252/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5398 - accuracy: 0.8170 - val_loss: 1.3484 - val_accuracy: 0.6039\n",
      "Epoch 2253/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5227 - accuracy: 0.8203 - val_loss: 1.2810 - val_accuracy: 0.6071\n",
      "Epoch 2254/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5990 - accuracy: 0.8073 - val_loss: 1.2283 - val_accuracy: 0.6299\n",
      "Epoch 2255/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5975 - accuracy: 0.7949 - val_loss: 1.2116 - val_accuracy: 0.6364\n",
      "Epoch 2256/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5542 - accuracy: 0.8105 - val_loss: 1.2012 - val_accuracy: 0.6299\n",
      "Epoch 2257/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5588 - accuracy: 0.8045 - val_loss: 1.1931 - val_accuracy: 0.6331\n",
      "Epoch 2258/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5525 - accuracy: 0.8115 - val_loss: 1.1874 - val_accuracy: 0.6364\n",
      "Epoch 2259/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5695 - accuracy: 0.8135 - val_loss: 1.2114 - val_accuracy: 0.6201\n",
      "Epoch 2260/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5635 - accuracy: 0.8059 - val_loss: 1.2949 - val_accuracy: 0.6104\n",
      "Epoch 2261/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5344 - accuracy: 0.8301 - val_loss: 1.3870 - val_accuracy: 0.5877\n",
      "Epoch 2262/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5217 - accuracy: 0.8296 - val_loss: 1.4364 - val_accuracy: 0.5779\n",
      "Epoch 2263/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5318 - accuracy: 0.8213 - val_loss: 1.4836 - val_accuracy: 0.5682\n",
      "Epoch 2264/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5720 - accuracy: 0.8142 - val_loss: 1.5297 - val_accuracy: 0.5552\n",
      "Epoch 2265/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5144 - accuracy: 0.8174 - val_loss: 1.5133 - val_accuracy: 0.5584\n",
      "Epoch 2266/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5974 - accuracy: 0.8045 - val_loss: 1.4938 - val_accuracy: 0.5714\n",
      "Epoch 2267/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4397 - accuracy: 0.8436 - val_loss: 1.4696 - val_accuracy: 0.5714\n",
      "Epoch 2268/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5167 - accuracy: 0.8352 - val_loss: 1.4368 - val_accuracy: 0.5747\n",
      "Epoch 2269/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5125 - accuracy: 0.8310 - val_loss: 1.3738 - val_accuracy: 0.5974\n",
      "Epoch 2270/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5324 - accuracy: 0.8045 - val_loss: 1.3220 - val_accuracy: 0.6039\n",
      "Epoch 2271/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5519 - accuracy: 0.8240 - val_loss: 1.2609 - val_accuracy: 0.6234\n",
      "Epoch 2272/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6152 - accuracy: 0.8096 - val_loss: 1.2323 - val_accuracy: 0.6234\n",
      "Epoch 2273/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5556 - accuracy: 0.8135 - val_loss: 1.2370 - val_accuracy: 0.6364\n",
      "Epoch 2274/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5035 - accuracy: 0.8422 - val_loss: 1.2688 - val_accuracy: 0.6201\n",
      "Epoch 2275/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5335 - accuracy: 0.8436 - val_loss: 1.3274 - val_accuracy: 0.6006\n",
      "Epoch 2276/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5770 - accuracy: 0.8086 - val_loss: 1.4008 - val_accuracy: 0.5812\n",
      "Epoch 2277/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5850 - accuracy: 0.7949 - val_loss: 1.4926 - val_accuracy: 0.5747\n",
      "Epoch 2278/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5539 - accuracy: 0.8174 - val_loss: 1.5633 - val_accuracy: 0.5682\n",
      "Epoch 2279/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5396 - accuracy: 0.8101 - val_loss: 1.5949 - val_accuracy: 0.5617\n",
      "Epoch 2280/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5109 - accuracy: 0.8320 - val_loss: 1.6235 - val_accuracy: 0.5519\n",
      "Epoch 2281/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5735 - accuracy: 0.8142 - val_loss: 1.5813 - val_accuracy: 0.5617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2282/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5545 - accuracy: 0.8213 - val_loss: 1.5443 - val_accuracy: 0.5584\n",
      "Epoch 2283/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5384 - accuracy: 0.8213 - val_loss: 1.4767 - val_accuracy: 0.5682\n",
      "Epoch 2284/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5254 - accuracy: 0.8198 - val_loss: 1.4425 - val_accuracy: 0.5682\n",
      "Epoch 2285/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5209 - accuracy: 0.8320 - val_loss: 1.3988 - val_accuracy: 0.5714\n",
      "Epoch 2286/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5201 - accuracy: 0.8338 - val_loss: 1.3720 - val_accuracy: 0.5649\n",
      "Epoch 2287/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5206 - accuracy: 0.8262 - val_loss: 1.3398 - val_accuracy: 0.5779\n",
      "Epoch 2288/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5367 - accuracy: 0.8240 - val_loss: 1.3128 - val_accuracy: 0.5844\n",
      "Epoch 2289/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5924 - accuracy: 0.8115 - val_loss: 1.2809 - val_accuracy: 0.5974\n",
      "Epoch 2290/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6194 - accuracy: 0.7877 - val_loss: 1.2769 - val_accuracy: 0.5974\n",
      "Epoch 2291/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5178 - accuracy: 0.8379 - val_loss: 1.2853 - val_accuracy: 0.6136\n",
      "Epoch 2292/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5509 - accuracy: 0.8226 - val_loss: 1.3106 - val_accuracy: 0.5974\n",
      "Epoch 2293/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5438 - accuracy: 0.8281 - val_loss: 1.3080 - val_accuracy: 0.5909\n",
      "Epoch 2294/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5740 - accuracy: 0.7919 - val_loss: 1.3069 - val_accuracy: 0.5974\n",
      "Epoch 2295/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5304 - accuracy: 0.8252 - val_loss: 1.3015 - val_accuracy: 0.5974\n",
      "Epoch 2296/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5717 - accuracy: 0.8017 - val_loss: 1.2706 - val_accuracy: 0.6071\n",
      "Epoch 2297/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5391 - accuracy: 0.8198 - val_loss: 1.2558 - val_accuracy: 0.6136\n",
      "Epoch 2298/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5647 - accuracy: 0.8170 - val_loss: 1.2725 - val_accuracy: 0.6071\n",
      "Epoch 2299/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5556 - accuracy: 0.8135 - val_loss: 1.2880 - val_accuracy: 0.6006\n",
      "Epoch 2300/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5562 - accuracy: 0.8212 - val_loss: 1.2952 - val_accuracy: 0.5942\n",
      "Epoch 2301/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5707 - accuracy: 0.8184 - val_loss: 1.2881 - val_accuracy: 0.6006\n",
      "Epoch 2302/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5703 - accuracy: 0.8135 - val_loss: 1.3061 - val_accuracy: 0.5974\n",
      "Epoch 2303/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5808 - accuracy: 0.8115 - val_loss: 1.3380 - val_accuracy: 0.6071\n",
      "Epoch 2304/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5508 - accuracy: 0.8101 - val_loss: 1.3437 - val_accuracy: 0.6039\n",
      "Epoch 2305/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5598 - accuracy: 0.8076 - val_loss: 1.3029 - val_accuracy: 0.6104\n",
      "Epoch 2306/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5120 - accuracy: 0.8359 - val_loss: 1.2783 - val_accuracy: 0.6169\n",
      "Epoch 2307/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5819 - accuracy: 0.8076 - val_loss: 1.2761 - val_accuracy: 0.6136\n",
      "Epoch 2308/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4979 - accuracy: 0.8291 - val_loss: 1.2654 - val_accuracy: 0.6266\n",
      "Epoch 2309/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5241 - accuracy: 0.8198 - val_loss: 1.2682 - val_accuracy: 0.6364\n",
      "Epoch 2310/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5570 - accuracy: 0.8174 - val_loss: 1.2632 - val_accuracy: 0.6364\n",
      "Epoch 2311/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5790 - accuracy: 0.8115 - val_loss: 1.2664 - val_accuracy: 0.6266\n",
      "Epoch 2312/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5501 - accuracy: 0.8226 - val_loss: 1.2718 - val_accuracy: 0.6364\n",
      "Epoch 2313/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5240 - accuracy: 0.8268 - val_loss: 1.2628 - val_accuracy: 0.6104\n",
      "Epoch 2314/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5121 - accuracy: 0.8291 - val_loss: 1.2788 - val_accuracy: 0.6136\n",
      "Epoch 2315/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5037 - accuracy: 0.8282 - val_loss: 1.2820 - val_accuracy: 0.6169\n",
      "Epoch 2316/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5294 - accuracy: 0.8193 - val_loss: 1.2715 - val_accuracy: 0.6169\n",
      "Epoch 2317/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5462 - accuracy: 0.8311 - val_loss: 1.2379 - val_accuracy: 0.6169\n",
      "Epoch 2318/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5654 - accuracy: 0.8164 - val_loss: 1.2316 - val_accuracy: 0.6234\n",
      "Epoch 2319/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5402 - accuracy: 0.8242 - val_loss: 1.2243 - val_accuracy: 0.6331\n",
      "Epoch 2320/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5635 - accuracy: 0.8018 - val_loss: 1.2245 - val_accuracy: 0.6299\n",
      "Epoch 2321/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5390 - accuracy: 0.8291 - val_loss: 1.2125 - val_accuracy: 0.6364\n",
      "Epoch 2322/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5600 - accuracy: 0.8271 - val_loss: 1.2069 - val_accuracy: 0.6331\n",
      "Epoch 2323/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5285 - accuracy: 0.8389 - val_loss: 1.2177 - val_accuracy: 0.6299\n",
      "Epoch 2324/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5205 - accuracy: 0.8324 - val_loss: 1.2546 - val_accuracy: 0.6039\n",
      "Epoch 2325/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5283 - accuracy: 0.8330 - val_loss: 1.3403 - val_accuracy: 0.5682\n",
      "Epoch 2326/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5431 - accuracy: 0.8296 - val_loss: 1.4677 - val_accuracy: 0.5519\n",
      "Epoch 2327/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5233 - accuracy: 0.8268 - val_loss: 1.6472 - val_accuracy: 0.5292\n",
      "Epoch 2328/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5937 - accuracy: 0.8047 - val_loss: 1.7508 - val_accuracy: 0.5032\n",
      "Epoch 2329/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5608 - accuracy: 0.8105 - val_loss: 1.7802 - val_accuracy: 0.5032\n",
      "Epoch 2330/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5541 - accuracy: 0.8135 - val_loss: 1.7482 - val_accuracy: 0.5130\n",
      "Epoch 2331/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5646 - accuracy: 0.8170 - val_loss: 1.6372 - val_accuracy: 0.5260\n",
      "Epoch 2332/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5232 - accuracy: 0.8320 - val_loss: 1.5057 - val_accuracy: 0.5714\n",
      "Epoch 2333/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5629 - accuracy: 0.8184 - val_loss: 1.3989 - val_accuracy: 0.5942\n",
      "Epoch 2334/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4580 - accuracy: 0.8366 - val_loss: 1.3089 - val_accuracy: 0.6006\n",
      "Epoch 2335/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5037 - accuracy: 0.8492 - val_loss: 1.2647 - val_accuracy: 0.6071\n",
      "Epoch 2336/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5322 - accuracy: 0.8262 - val_loss: 1.2351 - val_accuracy: 0.6234\n",
      "Epoch 2337/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5262 - accuracy: 0.8193 - val_loss: 1.2175 - val_accuracy: 0.6266\n",
      "Epoch 2338/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5233 - accuracy: 0.8320 - val_loss: 1.1968 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2339/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5649 - accuracy: 0.8125 - val_loss: 1.1847 - val_accuracy: 0.6364\n",
      "Epoch 2340/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4812 - accuracy: 0.8324 - val_loss: 1.1695 - val_accuracy: 0.6494\n",
      "Epoch 2341/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4824 - accuracy: 0.8352 - val_loss: 1.1769 - val_accuracy: 0.6558\n",
      "Epoch 2342/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4664 - accuracy: 0.8350 - val_loss: 1.1943 - val_accuracy: 0.6591\n",
      "Epoch 2343/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5115 - accuracy: 0.8389 - val_loss: 1.2108 - val_accuracy: 0.6526\n",
      "Epoch 2344/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5138 - accuracy: 0.8422 - val_loss: 1.1980 - val_accuracy: 0.6461\n",
      "Epoch 2345/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5336 - accuracy: 0.8213 - val_loss: 1.1897 - val_accuracy: 0.6526\n",
      "Epoch 2346/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5212 - accuracy: 0.8156 - val_loss: 1.1842 - val_accuracy: 0.6494\n",
      "Epoch 2347/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5435 - accuracy: 0.8394 - val_loss: 1.1678 - val_accuracy: 0.6591\n",
      "Epoch 2348/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4533 - accuracy: 0.8575 - val_loss: 1.1630 - val_accuracy: 0.6558\n",
      "Epoch 2349/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5078 - accuracy: 0.8350 - val_loss: 1.1597 - val_accuracy: 0.6494\n",
      "Epoch 2350/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4895 - accuracy: 0.8467 - val_loss: 1.1699 - val_accuracy: 0.6494\n",
      "Epoch 2351/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5495 - accuracy: 0.8301 - val_loss: 1.1799 - val_accuracy: 0.6429\n",
      "Epoch 2352/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5114 - accuracy: 0.8340 - val_loss: 1.1971 - val_accuracy: 0.6266\n",
      "Epoch 2353/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5389 - accuracy: 0.8184 - val_loss: 1.2238 - val_accuracy: 0.6201\n",
      "Epoch 2354/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4849 - accuracy: 0.8359 - val_loss: 1.2473 - val_accuracy: 0.6201\n",
      "Epoch 2355/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4831 - accuracy: 0.8268 - val_loss: 1.2591 - val_accuracy: 0.6234\n",
      "Epoch 2356/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5479 - accuracy: 0.8226 - val_loss: 1.2362 - val_accuracy: 0.6234\n",
      "Epoch 2357/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5264 - accuracy: 0.8282 - val_loss: 1.1758 - val_accuracy: 0.6364\n",
      "Epoch 2358/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5238 - accuracy: 0.8359 - val_loss: 1.1285 - val_accuracy: 0.6526\n",
      "Epoch 2359/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5314 - accuracy: 0.8212 - val_loss: 1.1159 - val_accuracy: 0.6623\n",
      "Epoch 2360/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5333 - accuracy: 0.8170 - val_loss: 1.1189 - val_accuracy: 0.6558\n",
      "Epoch 2361/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5234 - accuracy: 0.8226 - val_loss: 1.1234 - val_accuracy: 0.6656\n",
      "Epoch 2362/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4845 - accuracy: 0.8589 - val_loss: 1.1191 - val_accuracy: 0.6688\n",
      "Epoch 2363/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5206 - accuracy: 0.8350 - val_loss: 1.1182 - val_accuracy: 0.6656\n",
      "Epoch 2364/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4897 - accuracy: 0.8369 - val_loss: 1.1206 - val_accuracy: 0.6753\n",
      "Epoch 2365/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5751 - accuracy: 0.8135 - val_loss: 1.1130 - val_accuracy: 0.6786\n",
      "Epoch 2366/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4907 - accuracy: 0.8506 - val_loss: 1.1069 - val_accuracy: 0.6753\n",
      "Epoch 2367/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5936 - accuracy: 0.8031 - val_loss: 1.1044 - val_accuracy: 0.6818\n",
      "Epoch 2368/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5381 - accuracy: 0.8125 - val_loss: 1.1104 - val_accuracy: 0.6688\n",
      "Epoch 2369/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5057 - accuracy: 0.8232 - val_loss: 1.1212 - val_accuracy: 0.6623\n",
      "Epoch 2370/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4705 - accuracy: 0.8492 - val_loss: 1.1495 - val_accuracy: 0.6526\n",
      "Epoch 2371/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5199 - accuracy: 0.8281 - val_loss: 1.1784 - val_accuracy: 0.6461\n",
      "Epoch 2372/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4884 - accuracy: 0.8320 - val_loss: 1.2173 - val_accuracy: 0.6396\n",
      "Epoch 2373/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5829 - accuracy: 0.7979 - val_loss: 1.2393 - val_accuracy: 0.6201\n",
      "Epoch 2374/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5386 - accuracy: 0.8282 - val_loss: 1.2638 - val_accuracy: 0.6006\n",
      "Epoch 2375/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5475 - accuracy: 0.8281 - val_loss: 1.3045 - val_accuracy: 0.6136\n",
      "Epoch 2376/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5001 - accuracy: 0.8320 - val_loss: 1.3290 - val_accuracy: 0.6104\n",
      "Epoch 2377/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4898 - accuracy: 0.8296 - val_loss: 1.3401 - val_accuracy: 0.6104\n",
      "Epoch 2378/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4971 - accuracy: 0.8418 - val_loss: 1.3288 - val_accuracy: 0.6006\n",
      "Epoch 2379/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4751 - accuracy: 0.8438 - val_loss: 1.3132 - val_accuracy: 0.6039\n",
      "Epoch 2380/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4812 - accuracy: 0.8310 - val_loss: 1.2898 - val_accuracy: 0.6299\n",
      "Epoch 2381/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5520 - accuracy: 0.8242 - val_loss: 1.2649 - val_accuracy: 0.6429\n",
      "Epoch 2382/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5063 - accuracy: 0.8240 - val_loss: 1.2274 - val_accuracy: 0.6623\n",
      "Epoch 2383/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6116 - accuracy: 0.8073 - val_loss: 1.1870 - val_accuracy: 0.6721\n",
      "Epoch 2384/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5083 - accuracy: 0.8128 - val_loss: 1.1559 - val_accuracy: 0.6721\n",
      "Epoch 2385/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5233 - accuracy: 0.8240 - val_loss: 1.1138 - val_accuracy: 0.6721\n",
      "Epoch 2386/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5104 - accuracy: 0.8428 - val_loss: 1.0952 - val_accuracy: 0.6818\n",
      "Epoch 2387/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5072 - accuracy: 0.8338 - val_loss: 1.0948 - val_accuracy: 0.6786\n",
      "Epoch 2388/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5341 - accuracy: 0.8164 - val_loss: 1.1116 - val_accuracy: 0.6688\n",
      "Epoch 2389/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4509 - accuracy: 0.8450 - val_loss: 1.1372 - val_accuracy: 0.6429\n",
      "Epoch 2390/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5338 - accuracy: 0.8184 - val_loss: 1.1710 - val_accuracy: 0.6396\n",
      "Epoch 2391/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4887 - accuracy: 0.8436 - val_loss: 1.2101 - val_accuracy: 0.6299\n",
      "Epoch 2392/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5486 - accuracy: 0.8135 - val_loss: 1.2174 - val_accuracy: 0.6234\n",
      "Epoch 2393/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5025 - accuracy: 0.8350 - val_loss: 1.2094 - val_accuracy: 0.6266\n",
      "Epoch 2394/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4916 - accuracy: 0.8301 - val_loss: 1.1871 - val_accuracy: 0.6364\n",
      "Epoch 2395/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6052 - accuracy: 0.7975 - val_loss: 1.1806 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2396/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5311 - accuracy: 0.8296 - val_loss: 1.1715 - val_accuracy: 0.6591\n",
      "Epoch 2397/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5233 - accuracy: 0.8324 - val_loss: 1.1927 - val_accuracy: 0.6396\n",
      "Epoch 2398/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5448 - accuracy: 0.8240 - val_loss: 1.2173 - val_accuracy: 0.6429\n",
      "Epoch 2399/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4967 - accuracy: 0.8252 - val_loss: 1.2370 - val_accuracy: 0.6299\n",
      "Epoch 2400/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5050 - accuracy: 0.8438 - val_loss: 1.2319 - val_accuracy: 0.6234\n",
      "Epoch 2401/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5676 - accuracy: 0.8164 - val_loss: 1.2334 - val_accuracy: 0.6299\n",
      "Epoch 2402/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5197 - accuracy: 0.8282 - val_loss: 1.2380 - val_accuracy: 0.6299\n",
      "Epoch 2403/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4910 - accuracy: 0.8359 - val_loss: 1.2270 - val_accuracy: 0.6396\n",
      "Epoch 2404/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4821 - accuracy: 0.8324 - val_loss: 1.2175 - val_accuracy: 0.6429\n",
      "Epoch 2405/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5221 - accuracy: 0.8350 - val_loss: 1.2054 - val_accuracy: 0.6429\n",
      "Epoch 2406/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4651 - accuracy: 0.8398 - val_loss: 1.1985 - val_accuracy: 0.6461\n",
      "Epoch 2407/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5633 - accuracy: 0.8145 - val_loss: 1.1882 - val_accuracy: 0.6331\n",
      "Epoch 2408/4000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4792 - accuracy: 0.8268 - val_loss: 1.1761 - val_accuracy: 0.6364\n",
      "Epoch 2409/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4957 - accuracy: 0.8380 - val_loss: 1.1752 - val_accuracy: 0.6461\n",
      "Epoch 2410/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5051 - accuracy: 0.8268 - val_loss: 1.1779 - val_accuracy: 0.6396\n",
      "Epoch 2411/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4857 - accuracy: 0.8252 - val_loss: 1.1845 - val_accuracy: 0.6396\n",
      "Epoch 2412/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4914 - accuracy: 0.8282 - val_loss: 1.1921 - val_accuracy: 0.6429\n",
      "Epoch 2413/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4944 - accuracy: 0.8271 - val_loss: 1.2096 - val_accuracy: 0.6461\n",
      "Epoch 2414/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5374 - accuracy: 0.8184 - val_loss: 1.2063 - val_accuracy: 0.6591\n",
      "Epoch 2415/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4565 - accuracy: 0.8478 - val_loss: 1.2076 - val_accuracy: 0.6494\n",
      "Epoch 2416/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5217 - accuracy: 0.8422 - val_loss: 1.2135 - val_accuracy: 0.6526\n",
      "Epoch 2417/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5172 - accuracy: 0.8394 - val_loss: 1.2293 - val_accuracy: 0.6429\n",
      "Epoch 2418/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4970 - accuracy: 0.8301 - val_loss: 1.2430 - val_accuracy: 0.6494\n",
      "Epoch 2419/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4214 - accuracy: 0.8575 - val_loss: 1.2516 - val_accuracy: 0.6494\n",
      "Epoch 2420/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5589 - accuracy: 0.8101 - val_loss: 1.2564 - val_accuracy: 0.6396\n",
      "Epoch 2421/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5428 - accuracy: 0.8156 - val_loss: 1.2519 - val_accuracy: 0.6396\n",
      "Epoch 2422/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4691 - accuracy: 0.8545 - val_loss: 1.2731 - val_accuracy: 0.6136\n",
      "Epoch 2423/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4869 - accuracy: 0.8379 - val_loss: 1.2767 - val_accuracy: 0.6104\n",
      "Epoch 2424/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4755 - accuracy: 0.8467 - val_loss: 1.2787 - val_accuracy: 0.6169\n",
      "Epoch 2425/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5126 - accuracy: 0.8324 - val_loss: 1.2905 - val_accuracy: 0.6039\n",
      "Epoch 2426/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5258 - accuracy: 0.8320 - val_loss: 1.2778 - val_accuracy: 0.6234\n",
      "Epoch 2427/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5755 - accuracy: 0.8184 - val_loss: 1.2562 - val_accuracy: 0.6201\n",
      "Epoch 2428/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5274 - accuracy: 0.8320 - val_loss: 1.2344 - val_accuracy: 0.6234\n",
      "Epoch 2429/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4281 - accuracy: 0.8561 - val_loss: 1.2156 - val_accuracy: 0.6429\n",
      "Epoch 2430/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5313 - accuracy: 0.8170 - val_loss: 1.2075 - val_accuracy: 0.6623\n",
      "Epoch 2431/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4562 - accuracy: 0.8408 - val_loss: 1.2043 - val_accuracy: 0.6558\n",
      "Epoch 2432/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4661 - accuracy: 0.8340 - val_loss: 1.2013 - val_accuracy: 0.6623\n",
      "Epoch 2433/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5005 - accuracy: 0.8428 - val_loss: 1.2094 - val_accuracy: 0.6558\n",
      "Epoch 2434/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5171 - accuracy: 0.8450 - val_loss: 1.2329 - val_accuracy: 0.6364\n",
      "Epoch 2435/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4678 - accuracy: 0.8254 - val_loss: 1.2523 - val_accuracy: 0.6494\n",
      "Epoch 2436/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5159 - accuracy: 0.8156 - val_loss: 1.2646 - val_accuracy: 0.6461\n",
      "Epoch 2437/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4901 - accuracy: 0.8492 - val_loss: 1.2640 - val_accuracy: 0.6494\n",
      "Epoch 2438/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5243 - accuracy: 0.8311 - val_loss: 1.2582 - val_accuracy: 0.6558\n",
      "Epoch 2439/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5281 - accuracy: 0.8242 - val_loss: 1.2461 - val_accuracy: 0.6558\n",
      "Epoch 2440/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4471 - accuracy: 0.8673 - val_loss: 1.2506 - val_accuracy: 0.6558\n",
      "Epoch 2441/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5212 - accuracy: 0.8291 - val_loss: 1.2597 - val_accuracy: 0.6591\n",
      "Epoch 2442/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5046 - accuracy: 0.8436 - val_loss: 1.2794 - val_accuracy: 0.6526\n",
      "Epoch 2443/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4892 - accuracy: 0.8408 - val_loss: 1.2735 - val_accuracy: 0.6656\n",
      "Epoch 2444/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5105 - accuracy: 0.8338 - val_loss: 1.2690 - val_accuracy: 0.6656\n",
      "Epoch 2445/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5298 - accuracy: 0.8408 - val_loss: 1.2543 - val_accuracy: 0.6721\n",
      "Epoch 2446/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5018 - accuracy: 0.8281 - val_loss: 1.2380 - val_accuracy: 0.6721\n",
      "Epoch 2447/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4956 - accuracy: 0.8447 - val_loss: 1.2337 - val_accuracy: 0.6688\n",
      "Epoch 2448/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5146 - accuracy: 0.8380 - val_loss: 1.2318 - val_accuracy: 0.6623\n",
      "Epoch 2449/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5282 - accuracy: 0.8226 - val_loss: 1.2313 - val_accuracy: 0.6623\n",
      "Epoch 2450/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5452 - accuracy: 0.8338 - val_loss: 1.2286 - val_accuracy: 0.6623\n",
      "Epoch 2451/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4778 - accuracy: 0.8366 - val_loss: 1.2278 - val_accuracy: 0.6461\n",
      "Epoch 2452/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5337 - accuracy: 0.8380 - val_loss: 1.2286 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2453/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4962 - accuracy: 0.8380 - val_loss: 1.2363 - val_accuracy: 0.6396\n",
      "Epoch 2454/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4797 - accuracy: 0.8467 - val_loss: 1.2368 - val_accuracy: 0.6396\n",
      "Epoch 2455/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5115 - accuracy: 0.8311 - val_loss: 1.2243 - val_accuracy: 0.6429\n",
      "Epoch 2456/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5463 - accuracy: 0.8184 - val_loss: 1.2128 - val_accuracy: 0.6396\n",
      "Epoch 2457/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4623 - accuracy: 0.8477 - val_loss: 1.1953 - val_accuracy: 0.6364\n",
      "Epoch 2458/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4458 - accuracy: 0.8575 - val_loss: 1.1829 - val_accuracy: 0.6461\n",
      "Epoch 2459/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4904 - accuracy: 0.8340 - val_loss: 1.1830 - val_accuracy: 0.6396\n",
      "Epoch 2460/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4999 - accuracy: 0.8394 - val_loss: 1.1816 - val_accuracy: 0.6396\n",
      "Epoch 2461/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4943 - accuracy: 0.8324 - val_loss: 1.1772 - val_accuracy: 0.6461\n",
      "Epoch 2462/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5044 - accuracy: 0.8369 - val_loss: 1.1767 - val_accuracy: 0.6494\n",
      "Epoch 2463/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5397 - accuracy: 0.8212 - val_loss: 1.1842 - val_accuracy: 0.6591\n",
      "Epoch 2464/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4916 - accuracy: 0.8408 - val_loss: 1.1990 - val_accuracy: 0.6623\n",
      "Epoch 2465/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4668 - accuracy: 0.8589 - val_loss: 1.2105 - val_accuracy: 0.6461\n",
      "Epoch 2466/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4906 - accuracy: 0.8296 - val_loss: 1.2184 - val_accuracy: 0.6461\n",
      "Epoch 2467/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5377 - accuracy: 0.8301 - val_loss: 1.2266 - val_accuracy: 0.6494\n",
      "Epoch 2468/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4585 - accuracy: 0.8561 - val_loss: 1.2560 - val_accuracy: 0.6331\n",
      "Epoch 2469/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4956 - accuracy: 0.8340 - val_loss: 1.3103 - val_accuracy: 0.6234\n",
      "Epoch 2470/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4524 - accuracy: 0.8464 - val_loss: 1.3787 - val_accuracy: 0.6169\n",
      "Epoch 2471/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4768 - accuracy: 0.8408 - val_loss: 1.4372 - val_accuracy: 0.5942\n",
      "Epoch 2472/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4995 - accuracy: 0.8486 - val_loss: 1.4666 - val_accuracy: 0.5779\n",
      "Epoch 2473/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5151 - accuracy: 0.8226 - val_loss: 1.4780 - val_accuracy: 0.5682\n",
      "Epoch 2474/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4615 - accuracy: 0.8324 - val_loss: 1.4507 - val_accuracy: 0.5747\n",
      "Epoch 2475/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5125 - accuracy: 0.8193 - val_loss: 1.4143 - val_accuracy: 0.5877\n",
      "Epoch 2476/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4908 - accuracy: 0.8380 - val_loss: 1.3757 - val_accuracy: 0.6039\n",
      "Epoch 2477/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4490 - accuracy: 0.8603 - val_loss: 1.3399 - val_accuracy: 0.6299\n",
      "Epoch 2478/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4601 - accuracy: 0.8478 - val_loss: 1.3089 - val_accuracy: 0.6429\n",
      "Epoch 2479/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4635 - accuracy: 0.8547 - val_loss: 1.2819 - val_accuracy: 0.6558\n",
      "Epoch 2480/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4842 - accuracy: 0.8330 - val_loss: 1.2581 - val_accuracy: 0.6396\n",
      "Epoch 2481/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4873 - accuracy: 0.8447 - val_loss: 1.2438 - val_accuracy: 0.6494\n",
      "Epoch 2482/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4734 - accuracy: 0.8457 - val_loss: 1.2275 - val_accuracy: 0.6591\n",
      "Epoch 2483/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4497 - accuracy: 0.8408 - val_loss: 1.2228 - val_accuracy: 0.6591\n",
      "Epoch 2484/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4603 - accuracy: 0.8422 - val_loss: 1.2325 - val_accuracy: 0.6558\n",
      "Epoch 2485/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5265 - accuracy: 0.8212 - val_loss: 1.2555 - val_accuracy: 0.6623\n",
      "Epoch 2486/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4740 - accuracy: 0.8301 - val_loss: 1.2808 - val_accuracy: 0.6494\n",
      "Epoch 2487/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4742 - accuracy: 0.8496 - val_loss: 1.3002 - val_accuracy: 0.6331\n",
      "Epoch 2488/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4797 - accuracy: 0.8330 - val_loss: 1.3104 - val_accuracy: 0.6169\n",
      "Epoch 2489/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4832 - accuracy: 0.8478 - val_loss: 1.3027 - val_accuracy: 0.6136\n",
      "Epoch 2490/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5308 - accuracy: 0.8408 - val_loss: 1.2725 - val_accuracy: 0.6299\n",
      "Epoch 2491/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4916 - accuracy: 0.8436 - val_loss: 1.2437 - val_accuracy: 0.6461\n",
      "Epoch 2492/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4911 - accuracy: 0.8252 - val_loss: 1.2210 - val_accuracy: 0.6494\n",
      "Epoch 2493/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4800 - accuracy: 0.8350 - val_loss: 1.2053 - val_accuracy: 0.6396\n",
      "Epoch 2494/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4947 - accuracy: 0.8359 - val_loss: 1.1958 - val_accuracy: 0.6461\n",
      "Epoch 2495/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5141 - accuracy: 0.8193 - val_loss: 1.1940 - val_accuracy: 0.6526\n",
      "Epoch 2496/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4848 - accuracy: 0.8240 - val_loss: 1.2098 - val_accuracy: 0.6494\n",
      "Epoch 2497/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4782 - accuracy: 0.8436 - val_loss: 1.2408 - val_accuracy: 0.6461\n",
      "Epoch 2498/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4381 - accuracy: 0.8589 - val_loss: 1.2880 - val_accuracy: 0.6331\n",
      "Epoch 2499/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5364 - accuracy: 0.8262 - val_loss: 1.3212 - val_accuracy: 0.6266\n",
      "Epoch 2500/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4772 - accuracy: 0.8547 - val_loss: 1.3315 - val_accuracy: 0.6331\n",
      "Epoch 2501/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4979 - accuracy: 0.8359 - val_loss: 1.3203 - val_accuracy: 0.6364\n",
      "Epoch 2502/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4779 - accuracy: 0.8310 - val_loss: 1.3058 - val_accuracy: 0.6396\n",
      "Epoch 2503/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4516 - accuracy: 0.8603 - val_loss: 1.2706 - val_accuracy: 0.6331\n",
      "Epoch 2504/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4838 - accuracy: 0.8350 - val_loss: 1.2330 - val_accuracy: 0.6429\n",
      "Epoch 2505/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4929 - accuracy: 0.8436 - val_loss: 1.2110 - val_accuracy: 0.6526\n",
      "Epoch 2506/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4384 - accuracy: 0.8575 - val_loss: 1.2129 - val_accuracy: 0.6526\n",
      "Epoch 2507/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4436 - accuracy: 0.8457 - val_loss: 1.2099 - val_accuracy: 0.6591\n",
      "Epoch 2508/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4832 - accuracy: 0.8282 - val_loss: 1.2160 - val_accuracy: 0.6623\n",
      "Epoch 2509/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4506 - accuracy: 0.8506 - val_loss: 1.2261 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2510/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5327 - accuracy: 0.8128 - val_loss: 1.2322 - val_accuracy: 0.6396\n",
      "Epoch 2511/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4756 - accuracy: 0.8436 - val_loss: 1.2480 - val_accuracy: 0.6396\n",
      "Epoch 2512/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4665 - accuracy: 0.8525 - val_loss: 1.2743 - val_accuracy: 0.6266\n",
      "Epoch 2513/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5438 - accuracy: 0.8240 - val_loss: 1.3103 - val_accuracy: 0.6039\n",
      "Epoch 2514/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5096 - accuracy: 0.8436 - val_loss: 1.3330 - val_accuracy: 0.5779\n",
      "Epoch 2515/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5176 - accuracy: 0.8156 - val_loss: 1.3176 - val_accuracy: 0.5942\n",
      "Epoch 2516/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4791 - accuracy: 0.8447 - val_loss: 1.2685 - val_accuracy: 0.6136\n",
      "Epoch 2517/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5262 - accuracy: 0.8324 - val_loss: 1.2310 - val_accuracy: 0.6461\n",
      "Epoch 2518/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4481 - accuracy: 0.8520 - val_loss: 1.2081 - val_accuracy: 0.6591\n",
      "Epoch 2519/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4300 - accuracy: 0.8652 - val_loss: 1.2009 - val_accuracy: 0.6721\n",
      "Epoch 2520/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4768 - accuracy: 0.8436 - val_loss: 1.2079 - val_accuracy: 0.6753\n",
      "Epoch 2521/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5008 - accuracy: 0.8428 - val_loss: 1.2324 - val_accuracy: 0.6623\n",
      "Epoch 2522/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4398 - accuracy: 0.8525 - val_loss: 1.2585 - val_accuracy: 0.6494\n",
      "Epoch 2523/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4771 - accuracy: 0.8389 - val_loss: 1.2955 - val_accuracy: 0.6169\n",
      "Epoch 2524/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4462 - accuracy: 0.8555 - val_loss: 1.3292 - val_accuracy: 0.6071\n",
      "Epoch 2525/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4914 - accuracy: 0.8418 - val_loss: 1.3828 - val_accuracy: 0.6006\n",
      "Epoch 2526/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4592 - accuracy: 0.8643 - val_loss: 1.4224 - val_accuracy: 0.6006\n",
      "Epoch 2527/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4662 - accuracy: 0.8394 - val_loss: 1.4638 - val_accuracy: 0.5877\n",
      "Epoch 2528/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4780 - accuracy: 0.8352 - val_loss: 1.4715 - val_accuracy: 0.5974\n",
      "Epoch 2529/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5093 - accuracy: 0.8359 - val_loss: 1.4490 - val_accuracy: 0.5942\n",
      "Epoch 2530/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4793 - accuracy: 0.8438 - val_loss: 1.4214 - val_accuracy: 0.6039\n",
      "Epoch 2531/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4499 - accuracy: 0.8467 - val_loss: 1.3828 - val_accuracy: 0.6104\n",
      "Epoch 2532/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4985 - accuracy: 0.8447 - val_loss: 1.3240 - val_accuracy: 0.6201\n",
      "Epoch 2533/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4654 - accuracy: 0.8436 - val_loss: 1.2891 - val_accuracy: 0.6299\n",
      "Epoch 2534/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4468 - accuracy: 0.8525 - val_loss: 1.2797 - val_accuracy: 0.6461\n",
      "Epoch 2535/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4231 - accuracy: 0.8715 - val_loss: 1.2913 - val_accuracy: 0.6429\n",
      "Epoch 2536/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5060 - accuracy: 0.8516 - val_loss: 1.3261 - val_accuracy: 0.6136\n",
      "Epoch 2537/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4617 - accuracy: 0.8457 - val_loss: 1.3883 - val_accuracy: 0.5942\n",
      "Epoch 2538/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4799 - accuracy: 0.8408 - val_loss: 1.4463 - val_accuracy: 0.5779\n",
      "Epoch 2539/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4985 - accuracy: 0.8366 - val_loss: 1.4809 - val_accuracy: 0.5714\n",
      "Epoch 2540/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4365 - accuracy: 0.8672 - val_loss: 1.4637 - val_accuracy: 0.5812\n",
      "Epoch 2541/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4845 - accuracy: 0.8394 - val_loss: 1.4392 - val_accuracy: 0.5877\n",
      "Epoch 2542/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5385 - accuracy: 0.8320 - val_loss: 1.4016 - val_accuracy: 0.5942\n",
      "Epoch 2543/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4030 - accuracy: 0.8673 - val_loss: 1.3688 - val_accuracy: 0.6039\n",
      "Epoch 2544/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5031 - accuracy: 0.8338 - val_loss: 1.3287 - val_accuracy: 0.6039\n",
      "Epoch 2545/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4762 - accuracy: 0.8428 - val_loss: 1.3124 - val_accuracy: 0.6201\n",
      "Epoch 2546/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5078 - accuracy: 0.8352 - val_loss: 1.3075 - val_accuracy: 0.6234\n",
      "Epoch 2547/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4541 - accuracy: 0.8492 - val_loss: 1.3121 - val_accuracy: 0.6169\n",
      "Epoch 2548/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4613 - accuracy: 0.8594 - val_loss: 1.3006 - val_accuracy: 0.6169\n",
      "Epoch 2549/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4928 - accuracy: 0.8520 - val_loss: 1.3052 - val_accuracy: 0.5974\n",
      "Epoch 2550/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4985 - accuracy: 0.8366 - val_loss: 1.3146 - val_accuracy: 0.5942\n",
      "Epoch 2551/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4433 - accuracy: 0.8555 - val_loss: 1.3336 - val_accuracy: 0.5714\n",
      "Epoch 2552/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5122 - accuracy: 0.8296 - val_loss: 1.3635 - val_accuracy: 0.5714\n",
      "Epoch 2553/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5078 - accuracy: 0.8330 - val_loss: 1.4170 - val_accuracy: 0.5617\n",
      "Epoch 2554/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4779 - accuracy: 0.8464 - val_loss: 1.4857 - val_accuracy: 0.5584\n",
      "Epoch 2555/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4996 - accuracy: 0.8492 - val_loss: 1.5389 - val_accuracy: 0.5487\n",
      "Epoch 2556/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5036 - accuracy: 0.8422 - val_loss: 1.5939 - val_accuracy: 0.5584\n",
      "Epoch 2557/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5601 - accuracy: 0.8156 - val_loss: 1.6384 - val_accuracy: 0.5455\n",
      "Epoch 2558/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4788 - accuracy: 0.8464 - val_loss: 1.6323 - val_accuracy: 0.5487\n",
      "Epoch 2559/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4607 - accuracy: 0.8438 - val_loss: 1.5879 - val_accuracy: 0.5649\n",
      "Epoch 2560/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4759 - accuracy: 0.8496 - val_loss: 1.5198 - val_accuracy: 0.5519\n",
      "Epoch 2561/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4829 - accuracy: 0.8418 - val_loss: 1.4451 - val_accuracy: 0.5877\n",
      "Epoch 2562/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4666 - accuracy: 0.8478 - val_loss: 1.3999 - val_accuracy: 0.6071\n",
      "Epoch 2563/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4676 - accuracy: 0.8438 - val_loss: 1.3841 - val_accuracy: 0.6136\n",
      "Epoch 2564/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5107 - accuracy: 0.8340 - val_loss: 1.4025 - val_accuracy: 0.6169\n",
      "Epoch 2565/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4333 - accuracy: 0.8682 - val_loss: 1.4195 - val_accuracy: 0.6201\n",
      "Epoch 2566/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4513 - accuracy: 0.8547 - val_loss: 1.4449 - val_accuracy: 0.6006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2567/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5136 - accuracy: 0.8492 - val_loss: 1.4693 - val_accuracy: 0.6006\n",
      "Epoch 2568/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5034 - accuracy: 0.8408 - val_loss: 1.4816 - val_accuracy: 0.6071\n",
      "Epoch 2569/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4898 - accuracy: 0.8478 - val_loss: 1.4620 - val_accuracy: 0.6039\n",
      "Epoch 2570/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5032 - accuracy: 0.8408 - val_loss: 1.4235 - val_accuracy: 0.6266\n",
      "Epoch 2571/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5141 - accuracy: 0.8254 - val_loss: 1.3780 - val_accuracy: 0.6364\n",
      "Epoch 2572/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4457 - accuracy: 0.8520 - val_loss: 1.3485 - val_accuracy: 0.6364\n",
      "Epoch 2573/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4963 - accuracy: 0.8240 - val_loss: 1.3261 - val_accuracy: 0.6494\n",
      "Epoch 2574/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4770 - accuracy: 0.8516 - val_loss: 1.3042 - val_accuracy: 0.6558\n",
      "Epoch 2575/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4511 - accuracy: 0.8535 - val_loss: 1.2875 - val_accuracy: 0.6591\n",
      "Epoch 2576/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4425 - accuracy: 0.8613 - val_loss: 1.2833 - val_accuracy: 0.6591\n",
      "Epoch 2577/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5148 - accuracy: 0.8394 - val_loss: 1.2939 - val_accuracy: 0.6429\n",
      "Epoch 2578/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4732 - accuracy: 0.8398 - val_loss: 1.3275 - val_accuracy: 0.6169\n",
      "Epoch 2579/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5133 - accuracy: 0.8398 - val_loss: 1.3507 - val_accuracy: 0.6234\n",
      "Epoch 2580/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4786 - accuracy: 0.8291 - val_loss: 1.3644 - val_accuracy: 0.6071\n",
      "Epoch 2581/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4787 - accuracy: 0.8478 - val_loss: 1.3870 - val_accuracy: 0.6006\n",
      "Epoch 2582/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4779 - accuracy: 0.8545 - val_loss: 1.4225 - val_accuracy: 0.5974\n",
      "Epoch 2583/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4944 - accuracy: 0.8394 - val_loss: 1.4722 - val_accuracy: 0.5942\n",
      "Epoch 2584/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4081 - accuracy: 0.8633 - val_loss: 1.5003 - val_accuracy: 0.6104\n",
      "Epoch 2585/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4564 - accuracy: 0.8555 - val_loss: 1.4962 - val_accuracy: 0.6104\n",
      "Epoch 2586/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4249 - accuracy: 0.8574 - val_loss: 1.4773 - val_accuracy: 0.6169\n",
      "Epoch 2587/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4930 - accuracy: 0.8350 - val_loss: 1.4487 - val_accuracy: 0.6136\n",
      "Epoch 2588/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4460 - accuracy: 0.8535 - val_loss: 1.4047 - val_accuracy: 0.6234\n",
      "Epoch 2589/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4583 - accuracy: 0.8525 - val_loss: 1.3885 - val_accuracy: 0.6234\n",
      "Epoch 2590/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4158 - accuracy: 0.8643 - val_loss: 1.3756 - val_accuracy: 0.6201\n",
      "Epoch 2591/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4594 - accuracy: 0.8506 - val_loss: 1.3507 - val_accuracy: 0.6266\n",
      "Epoch 2592/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4569 - accuracy: 0.8535 - val_loss: 1.3356 - val_accuracy: 0.6266\n",
      "Epoch 2593/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4670 - accuracy: 0.8428 - val_loss: 1.3236 - val_accuracy: 0.6299\n",
      "Epoch 2594/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4949 - accuracy: 0.8450 - val_loss: 1.3491 - val_accuracy: 0.6331\n",
      "Epoch 2595/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4611 - accuracy: 0.8478 - val_loss: 1.3812 - val_accuracy: 0.6201\n",
      "Epoch 2596/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4720 - accuracy: 0.8324 - val_loss: 1.3869 - val_accuracy: 0.6136\n",
      "Epoch 2597/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4913 - accuracy: 0.8398 - val_loss: 1.3687 - val_accuracy: 0.6104\n",
      "Epoch 2598/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4272 - accuracy: 0.8604 - val_loss: 1.3287 - val_accuracy: 0.6201\n",
      "Epoch 2599/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5124 - accuracy: 0.8352 - val_loss: 1.2831 - val_accuracy: 0.6526\n",
      "Epoch 2600/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4810 - accuracy: 0.8320 - val_loss: 1.2552 - val_accuracy: 0.6494\n",
      "Epoch 2601/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4574 - accuracy: 0.8422 - val_loss: 1.2348 - val_accuracy: 0.6623\n",
      "Epoch 2602/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4844 - accuracy: 0.8464 - val_loss: 1.2351 - val_accuracy: 0.6591\n",
      "Epoch 2603/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3979 - accuracy: 0.8617 - val_loss: 1.2551 - val_accuracy: 0.6429\n",
      "Epoch 2604/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4853 - accuracy: 0.8296 - val_loss: 1.2866 - val_accuracy: 0.6234\n",
      "Epoch 2605/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4333 - accuracy: 0.8594 - val_loss: 1.3216 - val_accuracy: 0.6201\n",
      "Epoch 2606/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5185 - accuracy: 0.8389 - val_loss: 1.3444 - val_accuracy: 0.6136\n",
      "Epoch 2607/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4820 - accuracy: 0.8398 - val_loss: 1.3505 - val_accuracy: 0.6169\n",
      "Epoch 2608/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4837 - accuracy: 0.8457 - val_loss: 1.3719 - val_accuracy: 0.6169\n",
      "Epoch 2609/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4206 - accuracy: 0.8721 - val_loss: 1.3685 - val_accuracy: 0.6169\n",
      "Epoch 2610/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4232 - accuracy: 0.8721 - val_loss: 1.3501 - val_accuracy: 0.6234\n",
      "Epoch 2611/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4576 - accuracy: 0.8492 - val_loss: 1.3044 - val_accuracy: 0.6364\n",
      "Epoch 2612/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4419 - accuracy: 0.8617 - val_loss: 1.2900 - val_accuracy: 0.6364\n",
      "Epoch 2613/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4688 - accuracy: 0.8394 - val_loss: 1.2720 - val_accuracy: 0.6331\n",
      "Epoch 2614/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4710 - accuracy: 0.8408 - val_loss: 1.2756 - val_accuracy: 0.6169\n",
      "Epoch 2615/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4791 - accuracy: 0.8575 - val_loss: 1.2797 - val_accuracy: 0.6234\n",
      "Epoch 2616/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4851 - accuracy: 0.8447 - val_loss: 1.2818 - val_accuracy: 0.6331\n",
      "Epoch 2617/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4834 - accuracy: 0.8380 - val_loss: 1.2846 - val_accuracy: 0.6299\n",
      "Epoch 2618/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4646 - accuracy: 0.8478 - val_loss: 1.2806 - val_accuracy: 0.6331\n",
      "Epoch 2619/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4138 - accuracy: 0.8701 - val_loss: 1.2715 - val_accuracy: 0.6461\n",
      "Epoch 2620/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4138 - accuracy: 0.8631 - val_loss: 1.2567 - val_accuracy: 0.6494\n",
      "Epoch 2621/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4665 - accuracy: 0.8486 - val_loss: 1.2502 - val_accuracy: 0.6526\n",
      "Epoch 2622/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4611 - accuracy: 0.8584 - val_loss: 1.2525 - val_accuracy: 0.6656\n",
      "Epoch 2623/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4161 - accuracy: 0.8589 - val_loss: 1.2616 - val_accuracy: 0.6753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2624/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4405 - accuracy: 0.8486 - val_loss: 1.2774 - val_accuracy: 0.6753\n",
      "Epoch 2625/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4086 - accuracy: 0.8770 - val_loss: 1.2923 - val_accuracy: 0.6688\n",
      "Epoch 2626/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4414 - accuracy: 0.8535 - val_loss: 1.3004 - val_accuracy: 0.6656\n",
      "Epoch 2627/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5258 - accuracy: 0.8291 - val_loss: 1.3138 - val_accuracy: 0.6623\n",
      "Epoch 2628/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4615 - accuracy: 0.8408 - val_loss: 1.3342 - val_accuracy: 0.6494\n",
      "Epoch 2629/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4396 - accuracy: 0.8545 - val_loss: 1.3577 - val_accuracy: 0.6201\n",
      "Epoch 2630/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4172 - accuracy: 0.8575 - val_loss: 1.3810 - val_accuracy: 0.6266\n",
      "Epoch 2631/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4459 - accuracy: 0.8575 - val_loss: 1.3693 - val_accuracy: 0.6429\n",
      "Epoch 2632/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4419 - accuracy: 0.8492 - val_loss: 1.3581 - val_accuracy: 0.6461\n",
      "Epoch 2633/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4444 - accuracy: 0.8603 - val_loss: 1.3537 - val_accuracy: 0.6494\n",
      "Epoch 2634/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4536 - accuracy: 0.8464 - val_loss: 1.3531 - val_accuracy: 0.6364\n",
      "Epoch 2635/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4867 - accuracy: 0.8394 - val_loss: 1.3427 - val_accuracy: 0.6429\n",
      "Epoch 2636/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4638 - accuracy: 0.8506 - val_loss: 1.3300 - val_accuracy: 0.6364\n",
      "Epoch 2637/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4497 - accuracy: 0.8673 - val_loss: 1.3175 - val_accuracy: 0.6461\n",
      "Epoch 2638/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4647 - accuracy: 0.8438 - val_loss: 1.3094 - val_accuracy: 0.6429\n",
      "Epoch 2639/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4705 - accuracy: 0.8450 - val_loss: 1.2981 - val_accuracy: 0.6461\n",
      "Epoch 2640/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5400 - accuracy: 0.8240 - val_loss: 1.2958 - val_accuracy: 0.6461\n",
      "Epoch 2641/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4361 - accuracy: 0.8659 - val_loss: 1.2851 - val_accuracy: 0.6364\n",
      "Epoch 2642/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4395 - accuracy: 0.8428 - val_loss: 1.2734 - val_accuracy: 0.6461\n",
      "Epoch 2643/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4748 - accuracy: 0.8350 - val_loss: 1.2675 - val_accuracy: 0.6526\n",
      "Epoch 2644/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5057 - accuracy: 0.8226 - val_loss: 1.2744 - val_accuracy: 0.6558\n",
      "Epoch 2645/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4558 - accuracy: 0.8438 - val_loss: 1.2783 - val_accuracy: 0.6526\n",
      "Epoch 2646/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4585 - accuracy: 0.8516 - val_loss: 1.2835 - val_accuracy: 0.6461\n",
      "Epoch 2647/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4465 - accuracy: 0.8574 - val_loss: 1.2837 - val_accuracy: 0.6526\n",
      "Epoch 2648/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5160 - accuracy: 0.8389 - val_loss: 1.2807 - val_accuracy: 0.6591\n",
      "Epoch 2649/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4924 - accuracy: 0.8296 - val_loss: 1.2848 - val_accuracy: 0.6558\n",
      "Epoch 2650/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4624 - accuracy: 0.8564 - val_loss: 1.2895 - val_accuracy: 0.6494\n",
      "Epoch 2651/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5112 - accuracy: 0.8310 - val_loss: 1.2974 - val_accuracy: 0.6429\n",
      "Epoch 2652/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4190 - accuracy: 0.8687 - val_loss: 1.3077 - val_accuracy: 0.6299\n",
      "Epoch 2653/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5386 - accuracy: 0.8242 - val_loss: 1.3154 - val_accuracy: 0.6234\n",
      "Epoch 2654/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4393 - accuracy: 0.8631 - val_loss: 1.3107 - val_accuracy: 0.6201\n",
      "Epoch 2655/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4236 - accuracy: 0.8701 - val_loss: 1.2984 - val_accuracy: 0.6234\n",
      "Epoch 2656/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4424 - accuracy: 0.8477 - val_loss: 1.2885 - val_accuracy: 0.6266\n",
      "Epoch 2657/4000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4240 - accuracy: 0.8617 - val_loss: 1.2984 - val_accuracy: 0.6299\n",
      "Epoch 2658/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4786 - accuracy: 0.8478 - val_loss: 1.3030 - val_accuracy: 0.6169\n",
      "Epoch 2659/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4109 - accuracy: 0.8740 - val_loss: 1.2980 - val_accuracy: 0.6201\n",
      "Epoch 2660/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4520 - accuracy: 0.8535 - val_loss: 1.3030 - val_accuracy: 0.6104\n",
      "Epoch 2661/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4940 - accuracy: 0.8281 - val_loss: 1.3090 - val_accuracy: 0.6071\n",
      "Epoch 2662/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4613 - accuracy: 0.8428 - val_loss: 1.3025 - val_accuracy: 0.6136\n",
      "Epoch 2663/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4733 - accuracy: 0.8408 - val_loss: 1.3136 - val_accuracy: 0.6104\n",
      "Epoch 2664/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4656 - accuracy: 0.8555 - val_loss: 1.3252 - val_accuracy: 0.6136\n",
      "Epoch 2665/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4351 - accuracy: 0.8594 - val_loss: 1.3223 - val_accuracy: 0.6169\n",
      "Epoch 2666/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4938 - accuracy: 0.8310 - val_loss: 1.3615 - val_accuracy: 0.6039\n",
      "Epoch 2667/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4439 - accuracy: 0.8701 - val_loss: 1.3586 - val_accuracy: 0.6136\n",
      "Epoch 2668/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5048 - accuracy: 0.8422 - val_loss: 1.3486 - val_accuracy: 0.6234\n",
      "Epoch 2669/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4685 - accuracy: 0.8408 - val_loss: 1.3513 - val_accuracy: 0.6169\n",
      "Epoch 2670/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4827 - accuracy: 0.8422 - val_loss: 1.3437 - val_accuracy: 0.6201\n",
      "Epoch 2671/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4180 - accuracy: 0.8545 - val_loss: 1.3519 - val_accuracy: 0.6169\n",
      "Epoch 2672/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4444 - accuracy: 0.8516 - val_loss: 1.3818 - val_accuracy: 0.6006\n",
      "Epoch 2673/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4561 - accuracy: 0.8418 - val_loss: 1.4271 - val_accuracy: 0.5812\n",
      "Epoch 2674/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5270 - accuracy: 0.8226 - val_loss: 1.4650 - val_accuracy: 0.5812\n",
      "Epoch 2675/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4754 - accuracy: 0.8408 - val_loss: 1.5007 - val_accuracy: 0.5779\n",
      "Epoch 2676/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4379 - accuracy: 0.8478 - val_loss: 1.4927 - val_accuracy: 0.5779\n",
      "Epoch 2677/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5035 - accuracy: 0.8389 - val_loss: 1.4451 - val_accuracy: 0.5812\n",
      "Epoch 2678/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5311 - accuracy: 0.8366 - val_loss: 1.3678 - val_accuracy: 0.5844\n",
      "Epoch 2679/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4405 - accuracy: 0.8575 - val_loss: 1.3217 - val_accuracy: 0.6136\n",
      "Epoch 2680/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4309 - accuracy: 0.8643 - val_loss: 1.2986 - val_accuracy: 0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2681/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4631 - accuracy: 0.8574 - val_loss: 1.3020 - val_accuracy: 0.6364\n",
      "Epoch 2682/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4683 - accuracy: 0.8436 - val_loss: 1.2952 - val_accuracy: 0.6364\n",
      "Epoch 2683/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5166 - accuracy: 0.8213 - val_loss: 1.2943 - val_accuracy: 0.6396\n",
      "Epoch 2684/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4849 - accuracy: 0.8447 - val_loss: 1.3079 - val_accuracy: 0.6364\n",
      "Epoch 2685/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4972 - accuracy: 0.8436 - val_loss: 1.3271 - val_accuracy: 0.6331\n",
      "Epoch 2686/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4042 - accuracy: 0.8730 - val_loss: 1.3454 - val_accuracy: 0.6299\n",
      "Epoch 2687/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4021 - accuracy: 0.8547 - val_loss: 1.3426 - val_accuracy: 0.6266\n",
      "Epoch 2688/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4713 - accuracy: 0.8398 - val_loss: 1.3399 - val_accuracy: 0.6201\n",
      "Epoch 2689/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4608 - accuracy: 0.8520 - val_loss: 1.3303 - val_accuracy: 0.6201\n",
      "Epoch 2690/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4899 - accuracy: 0.8477 - val_loss: 1.3389 - val_accuracy: 0.6201\n",
      "Epoch 2691/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4372 - accuracy: 0.8555 - val_loss: 1.3661 - val_accuracy: 0.6071\n",
      "Epoch 2692/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4664 - accuracy: 0.8422 - val_loss: 1.4041 - val_accuracy: 0.5877\n",
      "Epoch 2693/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4501 - accuracy: 0.8534 - val_loss: 1.4104 - val_accuracy: 0.5942\n",
      "Epoch 2694/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4438 - accuracy: 0.8617 - val_loss: 1.4087 - val_accuracy: 0.5877\n",
      "Epoch 2695/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4610 - accuracy: 0.8301 - val_loss: 1.4030 - val_accuracy: 0.5877\n",
      "Epoch 2696/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4225 - accuracy: 0.8604 - val_loss: 1.4121 - val_accuracy: 0.5974\n",
      "Epoch 2697/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4374 - accuracy: 0.8492 - val_loss: 1.4193 - val_accuracy: 0.6039\n",
      "Epoch 2698/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4133 - accuracy: 0.8691 - val_loss: 1.4433 - val_accuracy: 0.6039\n",
      "Epoch 2699/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3561 - accuracy: 0.8771 - val_loss: 1.4677 - val_accuracy: 0.6006\n",
      "Epoch 2700/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3696 - accuracy: 0.8771 - val_loss: 1.4748 - val_accuracy: 0.6104\n",
      "Epoch 2701/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4517 - accuracy: 0.8604 - val_loss: 1.4409 - val_accuracy: 0.6104\n",
      "Epoch 2702/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4383 - accuracy: 0.8477 - val_loss: 1.4229 - val_accuracy: 0.6201\n",
      "Epoch 2703/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4444 - accuracy: 0.8447 - val_loss: 1.3891 - val_accuracy: 0.6266\n",
      "Epoch 2704/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4238 - accuracy: 0.8564 - val_loss: 1.3565 - val_accuracy: 0.6266\n",
      "Epoch 2705/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4870 - accuracy: 0.8436 - val_loss: 1.3529 - val_accuracy: 0.6234\n",
      "Epoch 2706/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5044 - accuracy: 0.8478 - val_loss: 1.3414 - val_accuracy: 0.6266\n",
      "Epoch 2707/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4833 - accuracy: 0.8547 - val_loss: 1.3361 - val_accuracy: 0.6331\n",
      "Epoch 2708/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4289 - accuracy: 0.8534 - val_loss: 1.3240 - val_accuracy: 0.6461\n",
      "Epoch 2709/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5129 - accuracy: 0.8268 - val_loss: 1.3037 - val_accuracy: 0.6558\n",
      "Epoch 2710/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4048 - accuracy: 0.8604 - val_loss: 1.3065 - val_accuracy: 0.6331\n",
      "Epoch 2711/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4053 - accuracy: 0.8594 - val_loss: 1.3146 - val_accuracy: 0.6266\n",
      "Epoch 2712/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3880 - accuracy: 0.8743 - val_loss: 1.3114 - val_accuracy: 0.6136\n",
      "Epoch 2713/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4423 - accuracy: 0.8516 - val_loss: 1.3173 - val_accuracy: 0.6039\n",
      "Epoch 2714/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4410 - accuracy: 0.8631 - val_loss: 1.3271 - val_accuracy: 0.6104\n",
      "Epoch 2715/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4581 - accuracy: 0.8645 - val_loss: 1.3375 - val_accuracy: 0.6234\n",
      "Epoch 2716/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4240 - accuracy: 0.8652 - val_loss: 1.3381 - val_accuracy: 0.6266\n",
      "Epoch 2717/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4389 - accuracy: 0.8496 - val_loss: 1.3561 - val_accuracy: 0.6266\n",
      "Epoch 2718/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4698 - accuracy: 0.8525 - val_loss: 1.3796 - val_accuracy: 0.6136\n",
      "Epoch 2719/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4105 - accuracy: 0.8617 - val_loss: 1.3887 - val_accuracy: 0.6071\n",
      "Epoch 2720/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4138 - accuracy: 0.8631 - val_loss: 1.3992 - val_accuracy: 0.6039\n",
      "Epoch 2721/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4635 - accuracy: 0.8574 - val_loss: 1.4069 - val_accuracy: 0.6039\n",
      "Epoch 2722/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4541 - accuracy: 0.8477 - val_loss: 1.4044 - val_accuracy: 0.6071\n",
      "Epoch 2723/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4852 - accuracy: 0.8447 - val_loss: 1.3978 - val_accuracy: 0.6071\n",
      "Epoch 2724/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4496 - accuracy: 0.8496 - val_loss: 1.3936 - val_accuracy: 0.6136\n",
      "Epoch 2725/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4537 - accuracy: 0.8478 - val_loss: 1.3935 - val_accuracy: 0.6071\n",
      "Epoch 2726/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4077 - accuracy: 0.8743 - val_loss: 1.3856 - val_accuracy: 0.6169\n",
      "Epoch 2727/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4631 - accuracy: 0.8428 - val_loss: 1.3805 - val_accuracy: 0.6201\n",
      "Epoch 2728/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4464 - accuracy: 0.8561 - val_loss: 1.3790 - val_accuracy: 0.6169\n",
      "Epoch 2729/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4458 - accuracy: 0.8467 - val_loss: 1.3819 - val_accuracy: 0.6169\n",
      "Epoch 2730/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4476 - accuracy: 0.8555 - val_loss: 1.3748 - val_accuracy: 0.6039\n",
      "Epoch 2731/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4989 - accuracy: 0.8464 - val_loss: 1.3369 - val_accuracy: 0.6039\n",
      "Epoch 2732/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4768 - accuracy: 0.8438 - val_loss: 1.3132 - val_accuracy: 0.6201\n",
      "Epoch 2733/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4619 - accuracy: 0.8478 - val_loss: 1.3074 - val_accuracy: 0.6266\n",
      "Epoch 2734/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4759 - accuracy: 0.8394 - val_loss: 1.3140 - val_accuracy: 0.6136\n",
      "Epoch 2735/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4640 - accuracy: 0.8525 - val_loss: 1.3410 - val_accuracy: 0.6266\n",
      "Epoch 2736/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4674 - accuracy: 0.8330 - val_loss: 1.3489 - val_accuracy: 0.6234\n",
      "Epoch 2737/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4438 - accuracy: 0.8631 - val_loss: 1.3832 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2738/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4682 - accuracy: 0.8398 - val_loss: 1.4121 - val_accuracy: 0.5942\n",
      "Epoch 2739/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4117 - accuracy: 0.8659 - val_loss: 1.4427 - val_accuracy: 0.5779\n",
      "Epoch 2740/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4766 - accuracy: 0.8516 - val_loss: 1.4931 - val_accuracy: 0.5714\n",
      "Epoch 2741/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4373 - accuracy: 0.8525 - val_loss: 1.5273 - val_accuracy: 0.5844\n",
      "Epoch 2742/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4449 - accuracy: 0.8506 - val_loss: 1.5313 - val_accuracy: 0.5844\n",
      "Epoch 2743/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4155 - accuracy: 0.8750 - val_loss: 1.5134 - val_accuracy: 0.5812\n",
      "Epoch 2744/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4541 - accuracy: 0.8310 - val_loss: 1.4885 - val_accuracy: 0.5747\n",
      "Epoch 2745/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4520 - accuracy: 0.8506 - val_loss: 1.4987 - val_accuracy: 0.6006\n",
      "Epoch 2746/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4618 - accuracy: 0.8520 - val_loss: 1.5274 - val_accuracy: 0.6136\n",
      "Epoch 2747/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4611 - accuracy: 0.8520 - val_loss: 1.5777 - val_accuracy: 0.6169\n",
      "Epoch 2748/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4911 - accuracy: 0.8492 - val_loss: 1.5442 - val_accuracy: 0.5974\n",
      "Epoch 2749/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4247 - accuracy: 0.8561 - val_loss: 1.4824 - val_accuracy: 0.6104\n",
      "Epoch 2750/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4236 - accuracy: 0.8652 - val_loss: 1.4270 - val_accuracy: 0.6136\n",
      "Epoch 2751/4000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4195 - accuracy: 0.8643 - val_loss: 1.3904 - val_accuracy: 0.6136\n",
      "Epoch 2752/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4594 - accuracy: 0.8561 - val_loss: 1.3568 - val_accuracy: 0.6266\n",
      "Epoch 2753/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4387 - accuracy: 0.8603 - val_loss: 1.3279 - val_accuracy: 0.6071\n",
      "Epoch 2754/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4569 - accuracy: 0.8492 - val_loss: 1.3131 - val_accuracy: 0.6266\n",
      "Epoch 2755/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4487 - accuracy: 0.8506 - val_loss: 1.2619 - val_accuracy: 0.6364\n",
      "Epoch 2756/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4196 - accuracy: 0.8547 - val_loss: 1.2272 - val_accuracy: 0.6656\n",
      "Epoch 2757/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4086 - accuracy: 0.8631 - val_loss: 1.2388 - val_accuracy: 0.6494\n",
      "Epoch 2758/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4391 - accuracy: 0.8408 - val_loss: 1.2745 - val_accuracy: 0.6396\n",
      "Epoch 2759/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4159 - accuracy: 0.8715 - val_loss: 1.3087 - val_accuracy: 0.6331\n",
      "Epoch 2760/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4233 - accuracy: 0.8603 - val_loss: 1.3340 - val_accuracy: 0.6331\n",
      "Epoch 2761/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4546 - accuracy: 0.8545 - val_loss: 1.3523 - val_accuracy: 0.6364\n",
      "Epoch 2762/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4123 - accuracy: 0.8603 - val_loss: 1.3523 - val_accuracy: 0.6299\n",
      "Epoch 2763/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4128 - accuracy: 0.8534 - val_loss: 1.3562 - val_accuracy: 0.6169\n",
      "Epoch 2764/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4232 - accuracy: 0.8584 - val_loss: 1.3496 - val_accuracy: 0.6104\n",
      "Epoch 2765/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4396 - accuracy: 0.8486 - val_loss: 1.3411 - val_accuracy: 0.6136\n",
      "Epoch 2766/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4650 - accuracy: 0.8547 - val_loss: 1.3257 - val_accuracy: 0.6266\n",
      "Epoch 2767/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4605 - accuracy: 0.8564 - val_loss: 1.3137 - val_accuracy: 0.6136\n",
      "Epoch 2768/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4485 - accuracy: 0.8477 - val_loss: 1.2931 - val_accuracy: 0.6201\n",
      "Epoch 2769/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4537 - accuracy: 0.8418 - val_loss: 1.2823 - val_accuracy: 0.6364\n",
      "Epoch 2770/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5020 - accuracy: 0.8311 - val_loss: 1.2950 - val_accuracy: 0.6299\n",
      "Epoch 2771/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4492 - accuracy: 0.8520 - val_loss: 1.2975 - val_accuracy: 0.6201\n",
      "Epoch 2772/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4569 - accuracy: 0.8492 - val_loss: 1.2992 - val_accuracy: 0.6299\n",
      "Epoch 2773/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4257 - accuracy: 0.8574 - val_loss: 1.3025 - val_accuracy: 0.6364\n",
      "Epoch 2774/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5048 - accuracy: 0.8350 - val_loss: 1.3084 - val_accuracy: 0.6169\n",
      "Epoch 2775/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4393 - accuracy: 0.8589 - val_loss: 1.3209 - val_accuracy: 0.6136\n",
      "Epoch 2776/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4644 - accuracy: 0.8525 - val_loss: 1.3339 - val_accuracy: 0.6104\n",
      "Epoch 2777/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4266 - accuracy: 0.8584 - val_loss: 1.3232 - val_accuracy: 0.6169\n",
      "Epoch 2778/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4158 - accuracy: 0.8408 - val_loss: 1.3089 - val_accuracy: 0.6299\n",
      "Epoch 2779/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4329 - accuracy: 0.8574 - val_loss: 1.2895 - val_accuracy: 0.6461\n",
      "Epoch 2780/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3722 - accuracy: 0.8701 - val_loss: 1.2869 - val_accuracy: 0.6494\n",
      "Epoch 2781/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4604 - accuracy: 0.8457 - val_loss: 1.2842 - val_accuracy: 0.6591\n",
      "Epoch 2782/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4573 - accuracy: 0.8464 - val_loss: 1.2886 - val_accuracy: 0.6461\n",
      "Epoch 2783/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4081 - accuracy: 0.8604 - val_loss: 1.2911 - val_accuracy: 0.6331\n",
      "Epoch 2784/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4444 - accuracy: 0.8535 - val_loss: 1.2961 - val_accuracy: 0.6331\n",
      "Epoch 2785/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4393 - accuracy: 0.8535 - val_loss: 1.3045 - val_accuracy: 0.6234\n",
      "Epoch 2786/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4202 - accuracy: 0.8584 - val_loss: 1.3018 - val_accuracy: 0.6396\n",
      "Epoch 2787/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4244 - accuracy: 0.8687 - val_loss: 1.3164 - val_accuracy: 0.6429\n",
      "Epoch 2788/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4789 - accuracy: 0.8369 - val_loss: 1.3481 - val_accuracy: 0.6266\n",
      "Epoch 2789/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4324 - accuracy: 0.8594 - val_loss: 1.4055 - val_accuracy: 0.6169\n",
      "Epoch 2790/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4442 - accuracy: 0.8672 - val_loss: 1.5056 - val_accuracy: 0.5747\n",
      "Epoch 2791/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4058 - accuracy: 0.8701 - val_loss: 1.5967 - val_accuracy: 0.5617\n",
      "Epoch 2792/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3942 - accuracy: 0.8771 - val_loss: 1.6847 - val_accuracy: 0.5487\n",
      "Epoch 2793/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4211 - accuracy: 0.8631 - val_loss: 1.7298 - val_accuracy: 0.5455\n",
      "Epoch 2794/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4228 - accuracy: 0.8687 - val_loss: 1.7478 - val_accuracy: 0.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2795/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3802 - accuracy: 0.8799 - val_loss: 1.7329 - val_accuracy: 0.5519\n",
      "Epoch 2796/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3708 - accuracy: 0.8757 - val_loss: 1.6743 - val_accuracy: 0.5584\n",
      "Epoch 2797/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4517 - accuracy: 0.8555 - val_loss: 1.6047 - val_accuracy: 0.5649\n",
      "Epoch 2798/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4244 - accuracy: 0.8652 - val_loss: 1.5397 - val_accuracy: 0.5747\n",
      "Epoch 2799/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4864 - accuracy: 0.8350 - val_loss: 1.5082 - val_accuracy: 0.5747\n",
      "Epoch 2800/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4495 - accuracy: 0.8457 - val_loss: 1.4762 - val_accuracy: 0.5942\n",
      "Epoch 2801/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4200 - accuracy: 0.8450 - val_loss: 1.4521 - val_accuracy: 0.5942\n",
      "Epoch 2802/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4123 - accuracy: 0.8760 - val_loss: 1.4331 - val_accuracy: 0.5942\n",
      "Epoch 2803/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4991 - accuracy: 0.8464 - val_loss: 1.4127 - val_accuracy: 0.5974\n",
      "Epoch 2804/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4058 - accuracy: 0.8652 - val_loss: 1.4030 - val_accuracy: 0.5877\n",
      "Epoch 2805/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4685 - accuracy: 0.8547 - val_loss: 1.4087 - val_accuracy: 0.5942\n",
      "Epoch 2806/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4196 - accuracy: 0.8525 - val_loss: 1.4098 - val_accuracy: 0.5942\n",
      "Epoch 2807/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3769 - accuracy: 0.8750 - val_loss: 1.4020 - val_accuracy: 0.5942\n",
      "Epoch 2808/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5258 - accuracy: 0.8408 - val_loss: 1.3888 - val_accuracy: 0.6071\n",
      "Epoch 2809/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4392 - accuracy: 0.8545 - val_loss: 1.3562 - val_accuracy: 0.6201\n",
      "Epoch 2810/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4326 - accuracy: 0.8574 - val_loss: 1.3243 - val_accuracy: 0.6266\n",
      "Epoch 2811/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4264 - accuracy: 0.8467 - val_loss: 1.2873 - val_accuracy: 0.6429\n",
      "Epoch 2812/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4325 - accuracy: 0.8631 - val_loss: 1.2594 - val_accuracy: 0.6429\n",
      "Epoch 2813/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4214 - accuracy: 0.8682 - val_loss: 1.2439 - val_accuracy: 0.6526\n",
      "Epoch 2814/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4263 - accuracy: 0.8547 - val_loss: 1.2348 - val_accuracy: 0.6591\n",
      "Epoch 2815/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4157 - accuracy: 0.8613 - val_loss: 1.2293 - val_accuracy: 0.6591\n",
      "Epoch 2816/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4707 - accuracy: 0.8422 - val_loss: 1.2286 - val_accuracy: 0.6591\n",
      "Epoch 2817/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4499 - accuracy: 0.8525 - val_loss: 1.2406 - val_accuracy: 0.6558\n",
      "Epoch 2818/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4180 - accuracy: 0.8757 - val_loss: 1.2490 - val_accuracy: 0.6461\n",
      "Epoch 2819/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4723 - accuracy: 0.8561 - val_loss: 1.2675 - val_accuracy: 0.6461\n",
      "Epoch 2820/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3818 - accuracy: 0.8623 - val_loss: 1.2867 - val_accuracy: 0.6299\n",
      "Epoch 2821/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4571 - accuracy: 0.8506 - val_loss: 1.2917 - val_accuracy: 0.6266\n",
      "Epoch 2822/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4471 - accuracy: 0.8438 - val_loss: 1.2957 - val_accuracy: 0.6234\n",
      "Epoch 2823/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4477 - accuracy: 0.8659 - val_loss: 1.2870 - val_accuracy: 0.6201\n",
      "Epoch 2824/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4184 - accuracy: 0.8701 - val_loss: 1.2980 - val_accuracy: 0.6169\n",
      "Epoch 2825/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4038 - accuracy: 0.8691 - val_loss: 1.3079 - val_accuracy: 0.6169\n",
      "Epoch 2826/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4265 - accuracy: 0.8604 - val_loss: 1.3008 - val_accuracy: 0.6266\n",
      "Epoch 2827/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3786 - accuracy: 0.8603 - val_loss: 1.2931 - val_accuracy: 0.6266\n",
      "Epoch 2828/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3971 - accuracy: 0.8711 - val_loss: 1.2795 - val_accuracy: 0.6201\n",
      "Epoch 2829/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4895 - accuracy: 0.8398 - val_loss: 1.2914 - val_accuracy: 0.6201\n",
      "Epoch 2830/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4145 - accuracy: 0.8691 - val_loss: 1.3133 - val_accuracy: 0.6201\n",
      "Epoch 2831/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4389 - accuracy: 0.8520 - val_loss: 1.3260 - val_accuracy: 0.6234\n",
      "Epoch 2832/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4545 - accuracy: 0.8564 - val_loss: 1.3415 - val_accuracy: 0.6104\n",
      "Epoch 2833/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4109 - accuracy: 0.8799 - val_loss: 1.3612 - val_accuracy: 0.6104\n",
      "Epoch 2834/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4049 - accuracy: 0.8603 - val_loss: 1.3879 - val_accuracy: 0.6104\n",
      "Epoch 2835/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4331 - accuracy: 0.8478 - val_loss: 1.4179 - val_accuracy: 0.5974\n",
      "Epoch 2836/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4658 - accuracy: 0.8547 - val_loss: 1.4219 - val_accuracy: 0.6071\n",
      "Epoch 2837/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4292 - accuracy: 0.8682 - val_loss: 1.4149 - val_accuracy: 0.6039\n",
      "Epoch 2838/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4484 - accuracy: 0.8534 - val_loss: 1.4174 - val_accuracy: 0.6071\n",
      "Epoch 2839/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3932 - accuracy: 0.8564 - val_loss: 1.4245 - val_accuracy: 0.6169\n",
      "Epoch 2840/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4612 - accuracy: 0.8575 - val_loss: 1.4249 - val_accuracy: 0.6104\n",
      "Epoch 2841/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4266 - accuracy: 0.8534 - val_loss: 1.4196 - val_accuracy: 0.6136\n",
      "Epoch 2842/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4049 - accuracy: 0.8574 - val_loss: 1.4160 - val_accuracy: 0.6104\n",
      "Epoch 2843/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4229 - accuracy: 0.8672 - val_loss: 1.3779 - val_accuracy: 0.6169\n",
      "Epoch 2844/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4637 - accuracy: 0.8520 - val_loss: 1.3278 - val_accuracy: 0.6299\n",
      "Epoch 2845/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4610 - accuracy: 0.8506 - val_loss: 1.2829 - val_accuracy: 0.6429\n",
      "Epoch 2846/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4204 - accuracy: 0.8534 - val_loss: 1.2668 - val_accuracy: 0.6461\n",
      "Epoch 2847/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4339 - accuracy: 0.8564 - val_loss: 1.2506 - val_accuracy: 0.6461\n",
      "Epoch 2848/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4199 - accuracy: 0.8673 - val_loss: 1.2553 - val_accuracy: 0.6429\n",
      "Epoch 2849/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3874 - accuracy: 0.8715 - val_loss: 1.2900 - val_accuracy: 0.6201\n",
      "Epoch 2850/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3983 - accuracy: 0.8721 - val_loss: 1.3386 - val_accuracy: 0.6006\n",
      "Epoch 2851/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4543 - accuracy: 0.8545 - val_loss: 1.3732 - val_accuracy: 0.5942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2852/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4229 - accuracy: 0.8555 - val_loss: 1.3804 - val_accuracy: 0.5877\n",
      "Epoch 2853/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4040 - accuracy: 0.8740 - val_loss: 1.3517 - val_accuracy: 0.5909\n",
      "Epoch 2854/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4845 - accuracy: 0.8506 - val_loss: 1.3132 - val_accuracy: 0.6234\n",
      "Epoch 2855/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4399 - accuracy: 0.8506 - val_loss: 1.2710 - val_accuracy: 0.6364\n",
      "Epoch 2856/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3589 - accuracy: 0.8771 - val_loss: 1.2379 - val_accuracy: 0.6461\n",
      "Epoch 2857/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4189 - accuracy: 0.8575 - val_loss: 1.2350 - val_accuracy: 0.6461\n",
      "Epoch 2858/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4014 - accuracy: 0.8589 - val_loss: 1.2566 - val_accuracy: 0.6429\n",
      "Epoch 2859/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4456 - accuracy: 0.8594 - val_loss: 1.2995 - val_accuracy: 0.6331\n",
      "Epoch 2860/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4360 - accuracy: 0.8603 - val_loss: 1.3511 - val_accuracy: 0.6104\n",
      "Epoch 2861/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4439 - accuracy: 0.8545 - val_loss: 1.4010 - val_accuracy: 0.6039\n",
      "Epoch 2862/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4833 - accuracy: 0.8496 - val_loss: 1.4557 - val_accuracy: 0.5942\n",
      "Epoch 2863/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4084 - accuracy: 0.8589 - val_loss: 1.5060 - val_accuracy: 0.5877\n",
      "Epoch 2864/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4234 - accuracy: 0.8623 - val_loss: 1.5711 - val_accuracy: 0.5812\n",
      "Epoch 2865/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4207 - accuracy: 0.8662 - val_loss: 1.6725 - val_accuracy: 0.5552\n",
      "Epoch 2866/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4076 - accuracy: 0.8575 - val_loss: 1.7522 - val_accuracy: 0.5390\n",
      "Epoch 2867/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4178 - accuracy: 0.8575 - val_loss: 1.7925 - val_accuracy: 0.5325\n",
      "Epoch 2868/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4500 - accuracy: 0.8555 - val_loss: 1.7820 - val_accuracy: 0.5195\n",
      "Epoch 2869/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4683 - accuracy: 0.8506 - val_loss: 1.7472 - val_accuracy: 0.5390\n",
      "Epoch 2870/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3844 - accuracy: 0.8799 - val_loss: 1.6875 - val_accuracy: 0.5292\n",
      "Epoch 2871/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4297 - accuracy: 0.8673 - val_loss: 1.6174 - val_accuracy: 0.5422\n",
      "Epoch 2872/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4437 - accuracy: 0.8545 - val_loss: 1.5677 - val_accuracy: 0.5617\n",
      "Epoch 2873/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3900 - accuracy: 0.8779 - val_loss: 1.5191 - val_accuracy: 0.5714\n",
      "Epoch 2874/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3946 - accuracy: 0.8721 - val_loss: 1.4777 - val_accuracy: 0.5747\n",
      "Epoch 2875/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4019 - accuracy: 0.8740 - val_loss: 1.4692 - val_accuracy: 0.5747\n",
      "Epoch 2876/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4549 - accuracy: 0.8574 - val_loss: 1.4986 - val_accuracy: 0.5844\n",
      "Epoch 2877/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4559 - accuracy: 0.8594 - val_loss: 1.5370 - val_accuracy: 0.5909\n",
      "Epoch 2878/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4415 - accuracy: 0.8645 - val_loss: 1.5520 - val_accuracy: 0.5844\n",
      "Epoch 2879/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4260 - accuracy: 0.8545 - val_loss: 1.5291 - val_accuracy: 0.5844\n",
      "Epoch 2880/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3996 - accuracy: 0.8682 - val_loss: 1.4947 - val_accuracy: 0.5877\n",
      "Epoch 2881/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4279 - accuracy: 0.8617 - val_loss: 1.4502 - val_accuracy: 0.5909\n",
      "Epoch 2882/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4161 - accuracy: 0.8673 - val_loss: 1.3887 - val_accuracy: 0.6136\n",
      "Epoch 2883/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4109 - accuracy: 0.8701 - val_loss: 1.3311 - val_accuracy: 0.6299\n",
      "Epoch 2884/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4460 - accuracy: 0.8547 - val_loss: 1.2859 - val_accuracy: 0.6364\n",
      "Epoch 2885/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3576 - accuracy: 0.8809 - val_loss: 1.2665 - val_accuracy: 0.6299\n",
      "Epoch 2886/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4449 - accuracy: 0.8478 - val_loss: 1.2632 - val_accuracy: 0.6494\n",
      "Epoch 2887/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3974 - accuracy: 0.8701 - val_loss: 1.2657 - val_accuracy: 0.6526\n",
      "Epoch 2888/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3904 - accuracy: 0.8715 - val_loss: 1.2658 - val_accuracy: 0.6558\n",
      "Epoch 2889/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4062 - accuracy: 0.8701 - val_loss: 1.2790 - val_accuracy: 0.6721\n",
      "Epoch 2890/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4430 - accuracy: 0.8547 - val_loss: 1.3059 - val_accuracy: 0.6526\n",
      "Epoch 2891/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3865 - accuracy: 0.8659 - val_loss: 1.3174 - val_accuracy: 0.6429\n",
      "Epoch 2892/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3775 - accuracy: 0.8809 - val_loss: 1.3200 - val_accuracy: 0.6494\n",
      "Epoch 2893/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4129 - accuracy: 0.8687 - val_loss: 1.3140 - val_accuracy: 0.6396\n",
      "Epoch 2894/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3767 - accuracy: 0.8750 - val_loss: 1.2997 - val_accuracy: 0.6299\n",
      "Epoch 2895/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3911 - accuracy: 0.8662 - val_loss: 1.2907 - val_accuracy: 0.6494\n",
      "Epoch 2896/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4118 - accuracy: 0.8662 - val_loss: 1.2794 - val_accuracy: 0.6461\n",
      "Epoch 2897/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3866 - accuracy: 0.8652 - val_loss: 1.2755 - val_accuracy: 0.6396\n",
      "Epoch 2898/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4226 - accuracy: 0.8617 - val_loss: 1.2811 - val_accuracy: 0.6429\n",
      "Epoch 2899/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4293 - accuracy: 0.8478 - val_loss: 1.2796 - val_accuracy: 0.6461\n",
      "Epoch 2900/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4270 - accuracy: 0.8561 - val_loss: 1.2823 - val_accuracy: 0.6461\n",
      "Epoch 2901/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4152 - accuracy: 0.8771 - val_loss: 1.2760 - val_accuracy: 0.6494\n",
      "Epoch 2902/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4205 - accuracy: 0.8687 - val_loss: 1.2884 - val_accuracy: 0.6526\n",
      "Epoch 2903/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4077 - accuracy: 0.8623 - val_loss: 1.3027 - val_accuracy: 0.6494\n",
      "Epoch 2904/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4026 - accuracy: 0.8672 - val_loss: 1.3086 - val_accuracy: 0.6429\n",
      "Epoch 2905/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3860 - accuracy: 0.8730 - val_loss: 1.3096 - val_accuracy: 0.6331\n",
      "Epoch 2906/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3741 - accuracy: 0.8682 - val_loss: 1.3166 - val_accuracy: 0.6299\n",
      "Epoch 2907/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4206 - accuracy: 0.8711 - val_loss: 1.3387 - val_accuracy: 0.6396\n",
      "Epoch 2908/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3886 - accuracy: 0.8603 - val_loss: 1.3597 - val_accuracy: 0.6234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2909/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4280 - accuracy: 0.8672 - val_loss: 1.3869 - val_accuracy: 0.6234\n",
      "Epoch 2910/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3724 - accuracy: 0.8953 - val_loss: 1.4244 - val_accuracy: 0.6136\n",
      "Epoch 2911/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3650 - accuracy: 0.8848 - val_loss: 1.4462 - val_accuracy: 0.6071\n",
      "Epoch 2912/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3955 - accuracy: 0.8687 - val_loss: 1.4702 - val_accuracy: 0.6006\n",
      "Epoch 2913/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4176 - accuracy: 0.8547 - val_loss: 1.4939 - val_accuracy: 0.5974\n",
      "Epoch 2914/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4232 - accuracy: 0.8760 - val_loss: 1.5037 - val_accuracy: 0.5974\n",
      "Epoch 2915/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3857 - accuracy: 0.8743 - val_loss: 1.5005 - val_accuracy: 0.5844\n",
      "Epoch 2916/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4259 - accuracy: 0.8564 - val_loss: 1.4525 - val_accuracy: 0.5844\n",
      "Epoch 2917/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4143 - accuracy: 0.8659 - val_loss: 1.3930 - val_accuracy: 0.6071\n",
      "Epoch 2918/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3884 - accuracy: 0.8757 - val_loss: 1.3374 - val_accuracy: 0.6104\n",
      "Epoch 2919/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3828 - accuracy: 0.8838 - val_loss: 1.2989 - val_accuracy: 0.6299\n",
      "Epoch 2920/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4473 - accuracy: 0.8672 - val_loss: 1.2671 - val_accuracy: 0.6396\n",
      "Epoch 2921/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4156 - accuracy: 0.8594 - val_loss: 1.2588 - val_accuracy: 0.6396\n",
      "Epoch 2922/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3954 - accuracy: 0.8574 - val_loss: 1.2556 - val_accuracy: 0.6364\n",
      "Epoch 2923/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4093 - accuracy: 0.8701 - val_loss: 1.2731 - val_accuracy: 0.6364\n",
      "Epoch 2924/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3994 - accuracy: 0.8711 - val_loss: 1.2734 - val_accuracy: 0.6396\n",
      "Epoch 2925/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4023 - accuracy: 0.8711 - val_loss: 1.2729 - val_accuracy: 0.6461\n",
      "Epoch 2926/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3820 - accuracy: 0.8770 - val_loss: 1.2686 - val_accuracy: 0.6526\n",
      "Epoch 2927/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4266 - accuracy: 0.8652 - val_loss: 1.2661 - val_accuracy: 0.6526\n",
      "Epoch 2928/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4433 - accuracy: 0.8617 - val_loss: 1.2788 - val_accuracy: 0.6526\n",
      "Epoch 2929/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4454 - accuracy: 0.8659 - val_loss: 1.3002 - val_accuracy: 0.6331\n",
      "Epoch 2930/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4653 - accuracy: 0.8477 - val_loss: 1.3437 - val_accuracy: 0.6234\n",
      "Epoch 2931/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3946 - accuracy: 0.8715 - val_loss: 1.3426 - val_accuracy: 0.6266\n",
      "Epoch 2932/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4327 - accuracy: 0.8631 - val_loss: 1.3210 - val_accuracy: 0.6331\n",
      "Epoch 2933/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4220 - accuracy: 0.8589 - val_loss: 1.2914 - val_accuracy: 0.6364\n",
      "Epoch 2934/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4020 - accuracy: 0.8757 - val_loss: 1.2588 - val_accuracy: 0.6494\n",
      "Epoch 2935/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4610 - accuracy: 0.8492 - val_loss: 1.2374 - val_accuracy: 0.6623\n",
      "Epoch 2936/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3835 - accuracy: 0.8883 - val_loss: 1.2259 - val_accuracy: 0.6623\n",
      "Epoch 2937/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3713 - accuracy: 0.8828 - val_loss: 1.2225 - val_accuracy: 0.6688\n",
      "Epoch 2938/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3706 - accuracy: 0.8789 - val_loss: 1.2157 - val_accuracy: 0.6786\n",
      "Epoch 2939/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4226 - accuracy: 0.8687 - val_loss: 1.2211 - val_accuracy: 0.6753\n",
      "Epoch 2940/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4271 - accuracy: 0.8645 - val_loss: 1.2280 - val_accuracy: 0.6753\n",
      "Epoch 2941/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4316 - accuracy: 0.8617 - val_loss: 1.2388 - val_accuracy: 0.6721\n",
      "Epoch 2942/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3902 - accuracy: 0.8730 - val_loss: 1.2464 - val_accuracy: 0.6656\n",
      "Epoch 2943/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4009 - accuracy: 0.8750 - val_loss: 1.2589 - val_accuracy: 0.6558\n",
      "Epoch 2944/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3830 - accuracy: 0.8682 - val_loss: 1.2773 - val_accuracy: 0.6558\n",
      "Epoch 2945/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3768 - accuracy: 0.8785 - val_loss: 1.2916 - val_accuracy: 0.6461\n",
      "Epoch 2946/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4086 - accuracy: 0.8729 - val_loss: 1.3047 - val_accuracy: 0.6396\n",
      "Epoch 2947/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4110 - accuracy: 0.8673 - val_loss: 1.3037 - val_accuracy: 0.6364\n",
      "Epoch 2948/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4480 - accuracy: 0.8506 - val_loss: 1.3046 - val_accuracy: 0.6396\n",
      "Epoch 2949/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4223 - accuracy: 0.8589 - val_loss: 1.3254 - val_accuracy: 0.6429\n",
      "Epoch 2950/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3826 - accuracy: 0.8673 - val_loss: 1.3252 - val_accuracy: 0.6429\n",
      "Epoch 2951/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3689 - accuracy: 0.8740 - val_loss: 1.3330 - val_accuracy: 0.6461\n",
      "Epoch 2952/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3998 - accuracy: 0.8771 - val_loss: 1.3261 - val_accuracy: 0.6396\n",
      "Epoch 2953/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4044 - accuracy: 0.8617 - val_loss: 1.3070 - val_accuracy: 0.6396\n",
      "Epoch 2954/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3997 - accuracy: 0.8729 - val_loss: 1.2889 - val_accuracy: 0.6526\n",
      "Epoch 2955/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4150 - accuracy: 0.8575 - val_loss: 1.2761 - val_accuracy: 0.6461\n",
      "Epoch 2956/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3929 - accuracy: 0.8617 - val_loss: 1.2728 - val_accuracy: 0.6591\n",
      "Epoch 2957/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4349 - accuracy: 0.8574 - val_loss: 1.2705 - val_accuracy: 0.6558\n",
      "Epoch 2958/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4342 - accuracy: 0.8715 - val_loss: 1.2734 - val_accuracy: 0.6558\n",
      "Epoch 2959/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3517 - accuracy: 0.8730 - val_loss: 1.2817 - val_accuracy: 0.6558\n",
      "Epoch 2960/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3832 - accuracy: 0.8711 - val_loss: 1.3060 - val_accuracy: 0.6461\n",
      "Epoch 2961/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4475 - accuracy: 0.8645 - val_loss: 1.3158 - val_accuracy: 0.6461\n",
      "Epoch 2962/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3601 - accuracy: 0.8896 - val_loss: 1.3269 - val_accuracy: 0.6526\n",
      "Epoch 2963/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3885 - accuracy: 0.8652 - val_loss: 1.3391 - val_accuracy: 0.6429\n",
      "Epoch 2964/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4113 - accuracy: 0.8633 - val_loss: 1.3455 - val_accuracy: 0.6429\n",
      "Epoch 2965/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4636 - accuracy: 0.8450 - val_loss: 1.3453 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2966/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4110 - accuracy: 0.8623 - val_loss: 1.3279 - val_accuracy: 0.6266\n",
      "Epoch 2967/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3519 - accuracy: 0.8827 - val_loss: 1.3105 - val_accuracy: 0.6331\n",
      "Epoch 2968/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3516 - accuracy: 0.8841 - val_loss: 1.3018 - val_accuracy: 0.6429\n",
      "Epoch 2969/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4041 - accuracy: 0.8743 - val_loss: 1.2862 - val_accuracy: 0.6591\n",
      "Epoch 2970/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4416 - accuracy: 0.8589 - val_loss: 1.2760 - val_accuracy: 0.6494\n",
      "Epoch 2971/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3694 - accuracy: 0.8701 - val_loss: 1.2634 - val_accuracy: 0.6656\n",
      "Epoch 2972/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4091 - accuracy: 0.8631 - val_loss: 1.2644 - val_accuracy: 0.6656\n",
      "Epoch 2973/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3955 - accuracy: 0.8623 - val_loss: 1.2739 - val_accuracy: 0.6656\n",
      "Epoch 2974/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4491 - accuracy: 0.8687 - val_loss: 1.2877 - val_accuracy: 0.6526\n",
      "Epoch 2975/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4014 - accuracy: 0.8682 - val_loss: 1.3155 - val_accuracy: 0.6591\n",
      "Epoch 2976/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3928 - accuracy: 0.8673 - val_loss: 1.3501 - val_accuracy: 0.6396\n",
      "Epoch 2977/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3723 - accuracy: 0.8828 - val_loss: 1.3870 - val_accuracy: 0.6364\n",
      "Epoch 2978/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4011 - accuracy: 0.8643 - val_loss: 1.4150 - val_accuracy: 0.6299\n",
      "Epoch 2979/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3825 - accuracy: 0.8779 - val_loss: 1.4320 - val_accuracy: 0.6396\n",
      "Epoch 2980/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4337 - accuracy: 0.8525 - val_loss: 1.4405 - val_accuracy: 0.6331\n",
      "Epoch 2981/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4330 - accuracy: 0.8574 - val_loss: 1.4386 - val_accuracy: 0.6169\n",
      "Epoch 2982/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3800 - accuracy: 0.8740 - val_loss: 1.4083 - val_accuracy: 0.6104\n",
      "Epoch 2983/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3999 - accuracy: 0.8729 - val_loss: 1.3698 - val_accuracy: 0.6071\n",
      "Epoch 2984/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4230 - accuracy: 0.8603 - val_loss: 1.3383 - val_accuracy: 0.6201\n",
      "Epoch 2985/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3824 - accuracy: 0.8855 - val_loss: 1.3115 - val_accuracy: 0.6266\n",
      "Epoch 2986/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3641 - accuracy: 0.8813 - val_loss: 1.2961 - val_accuracy: 0.6396\n",
      "Epoch 2987/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3512 - accuracy: 0.8828 - val_loss: 1.2890 - val_accuracy: 0.6558\n",
      "Epoch 2988/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3772 - accuracy: 0.8715 - val_loss: 1.2931 - val_accuracy: 0.6558\n",
      "Epoch 2989/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3804 - accuracy: 0.8584 - val_loss: 1.3040 - val_accuracy: 0.6429\n",
      "Epoch 2990/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3900 - accuracy: 0.8687 - val_loss: 1.3181 - val_accuracy: 0.6461\n",
      "Epoch 2991/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4626 - accuracy: 0.8506 - val_loss: 1.3105 - val_accuracy: 0.6364\n",
      "Epoch 2992/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4086 - accuracy: 0.8623 - val_loss: 1.3048 - val_accuracy: 0.6364\n",
      "Epoch 2993/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4171 - accuracy: 0.8691 - val_loss: 1.3159 - val_accuracy: 0.6266\n",
      "Epoch 2994/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3853 - accuracy: 0.8633 - val_loss: 1.3116 - val_accuracy: 0.6364\n",
      "Epoch 2995/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4059 - accuracy: 0.8547 - val_loss: 1.2946 - val_accuracy: 0.6623\n",
      "Epoch 2996/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3576 - accuracy: 0.8809 - val_loss: 1.2779 - val_accuracy: 0.6623\n",
      "Epoch 2997/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4187 - accuracy: 0.8561 - val_loss: 1.2677 - val_accuracy: 0.6786\n",
      "Epoch 2998/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3775 - accuracy: 0.8980 - val_loss: 1.2671 - val_accuracy: 0.6786\n",
      "Epoch 2999/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3802 - accuracy: 0.8789 - val_loss: 1.2722 - val_accuracy: 0.6623\n",
      "Epoch 3000/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3850 - accuracy: 0.8643 - val_loss: 1.2994 - val_accuracy: 0.6429\n",
      "Epoch 3001/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3419 - accuracy: 0.8857 - val_loss: 1.3464 - val_accuracy: 0.6461\n",
      "Epoch 3002/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3917 - accuracy: 0.8757 - val_loss: 1.3990 - val_accuracy: 0.6364\n",
      "Epoch 3003/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3466 - accuracy: 0.8799 - val_loss: 1.4336 - val_accuracy: 0.6201\n",
      "Epoch 3004/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4114 - accuracy: 0.8743 - val_loss: 1.4544 - val_accuracy: 0.6104\n",
      "Epoch 3005/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3629 - accuracy: 0.8916 - val_loss: 1.4653 - val_accuracy: 0.6071\n",
      "Epoch 3006/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4212 - accuracy: 0.8643 - val_loss: 1.4482 - val_accuracy: 0.6006\n",
      "Epoch 3007/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3524 - accuracy: 0.8877 - val_loss: 1.4132 - val_accuracy: 0.6136\n",
      "Epoch 3008/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3171 - accuracy: 0.8939 - val_loss: 1.3706 - val_accuracy: 0.6169\n",
      "Epoch 3009/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4320 - accuracy: 0.8687 - val_loss: 1.3281 - val_accuracy: 0.6299\n",
      "Epoch 3010/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4262 - accuracy: 0.8682 - val_loss: 1.3133 - val_accuracy: 0.6591\n",
      "Epoch 3011/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3548 - accuracy: 0.8841 - val_loss: 1.3071 - val_accuracy: 0.6656\n",
      "Epoch 3012/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4037 - accuracy: 0.8645 - val_loss: 1.3036 - val_accuracy: 0.6494\n",
      "Epoch 3013/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3305 - accuracy: 0.8925 - val_loss: 1.3003 - val_accuracy: 0.6526\n",
      "Epoch 3014/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3551 - accuracy: 0.8779 - val_loss: 1.2941 - val_accuracy: 0.6753\n",
      "Epoch 3015/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4106 - accuracy: 0.8662 - val_loss: 1.2932 - val_accuracy: 0.6656\n",
      "Epoch 3016/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3924 - accuracy: 0.8750 - val_loss: 1.2893 - val_accuracy: 0.6721\n",
      "Epoch 3017/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3635 - accuracy: 0.8687 - val_loss: 1.2947 - val_accuracy: 0.6591\n",
      "Epoch 3018/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4068 - accuracy: 0.8687 - val_loss: 1.3214 - val_accuracy: 0.6591\n",
      "Epoch 3019/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3685 - accuracy: 0.8721 - val_loss: 1.3520 - val_accuracy: 0.6494\n",
      "Epoch 3020/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4139 - accuracy: 0.8659 - val_loss: 1.3762 - val_accuracy: 0.6201\n",
      "Epoch 3021/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3765 - accuracy: 0.8673 - val_loss: 1.4243 - val_accuracy: 0.6169\n",
      "Epoch 3022/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4191 - accuracy: 0.8506 - val_loss: 1.4736 - val_accuracy: 0.5909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3023/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4645 - accuracy: 0.8477 - val_loss: 1.5167 - val_accuracy: 0.5877\n",
      "Epoch 3024/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3779 - accuracy: 0.8730 - val_loss: 1.5251 - val_accuracy: 0.5779\n",
      "Epoch 3025/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3795 - accuracy: 0.8631 - val_loss: 1.5139 - val_accuracy: 0.5747\n",
      "Epoch 3026/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4142 - accuracy: 0.8643 - val_loss: 1.4867 - val_accuracy: 0.5812\n",
      "Epoch 3027/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4829 - accuracy: 0.8506 - val_loss: 1.4425 - val_accuracy: 0.5877\n",
      "Epoch 3028/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4304 - accuracy: 0.8631 - val_loss: 1.4085 - val_accuracy: 0.5974\n",
      "Epoch 3029/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3466 - accuracy: 0.8869 - val_loss: 1.3721 - val_accuracy: 0.6169\n",
      "Epoch 3030/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3868 - accuracy: 0.8760 - val_loss: 1.3571 - val_accuracy: 0.6201\n",
      "Epoch 3031/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4114 - accuracy: 0.8687 - val_loss: 1.3582 - val_accuracy: 0.6136\n",
      "Epoch 3032/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3496 - accuracy: 0.8809 - val_loss: 1.3923 - val_accuracy: 0.5974\n",
      "Epoch 3033/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3588 - accuracy: 0.8838 - val_loss: 1.4239 - val_accuracy: 0.5909\n",
      "Epoch 3034/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4419 - accuracy: 0.8574 - val_loss: 1.4626 - val_accuracy: 0.5877\n",
      "Epoch 3035/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3549 - accuracy: 0.8867 - val_loss: 1.5141 - val_accuracy: 0.5779\n",
      "Epoch 3036/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4025 - accuracy: 0.8687 - val_loss: 1.5719 - val_accuracy: 0.5649\n",
      "Epoch 3037/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3937 - accuracy: 0.8659 - val_loss: 1.5934 - val_accuracy: 0.5584\n",
      "Epoch 3038/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3674 - accuracy: 0.8771 - val_loss: 1.6017 - val_accuracy: 0.5487\n",
      "Epoch 3039/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3840 - accuracy: 0.8779 - val_loss: 1.5521 - val_accuracy: 0.5682\n",
      "Epoch 3040/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3439 - accuracy: 0.8896 - val_loss: 1.4813 - val_accuracy: 0.5909\n",
      "Epoch 3041/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3503 - accuracy: 0.8911 - val_loss: 1.4105 - val_accuracy: 0.6104\n",
      "Epoch 3042/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3657 - accuracy: 0.8867 - val_loss: 1.3328 - val_accuracy: 0.6396\n",
      "Epoch 3043/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3652 - accuracy: 0.8869 - val_loss: 1.2804 - val_accuracy: 0.6558\n",
      "Epoch 3044/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4067 - accuracy: 0.8643 - val_loss: 1.2381 - val_accuracy: 0.6688\n",
      "Epoch 3045/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3950 - accuracy: 0.8760 - val_loss: 1.2207 - val_accuracy: 0.6656\n",
      "Epoch 3046/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4868 - accuracy: 0.8506 - val_loss: 1.2155 - val_accuracy: 0.6623\n",
      "Epoch 3047/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3466 - accuracy: 0.8687 - val_loss: 1.2154 - val_accuracy: 0.6721\n",
      "Epoch 3048/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3733 - accuracy: 0.8701 - val_loss: 1.2144 - val_accuracy: 0.6688\n",
      "Epoch 3049/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3682 - accuracy: 0.8813 - val_loss: 1.2259 - val_accuracy: 0.6623\n",
      "Epoch 3050/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3584 - accuracy: 0.8869 - val_loss: 1.2422 - val_accuracy: 0.6558\n",
      "Epoch 3051/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4055 - accuracy: 0.8604 - val_loss: 1.2572 - val_accuracy: 0.6396\n",
      "Epoch 3052/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4064 - accuracy: 0.8799 - val_loss: 1.2747 - val_accuracy: 0.6429\n",
      "Epoch 3053/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3962 - accuracy: 0.8760 - val_loss: 1.3164 - val_accuracy: 0.6396\n",
      "Epoch 3054/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3701 - accuracy: 0.8682 - val_loss: 1.3491 - val_accuracy: 0.6234\n",
      "Epoch 3055/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4202 - accuracy: 0.8617 - val_loss: 1.3497 - val_accuracy: 0.6136\n",
      "Epoch 3056/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4088 - accuracy: 0.8652 - val_loss: 1.3502 - val_accuracy: 0.6201\n",
      "Epoch 3057/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3863 - accuracy: 0.8771 - val_loss: 1.3393 - val_accuracy: 0.6169\n",
      "Epoch 3058/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3507 - accuracy: 0.8813 - val_loss: 1.3331 - val_accuracy: 0.6234\n",
      "Epoch 3059/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3448 - accuracy: 0.8841 - val_loss: 1.3295 - val_accuracy: 0.6299\n",
      "Epoch 3060/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3838 - accuracy: 0.8813 - val_loss: 1.3205 - val_accuracy: 0.6364\n",
      "Epoch 3061/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3993 - accuracy: 0.8813 - val_loss: 1.3327 - val_accuracy: 0.6364\n",
      "Epoch 3062/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4079 - accuracy: 0.8757 - val_loss: 1.3821 - val_accuracy: 0.6234\n",
      "Epoch 3063/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3804 - accuracy: 0.8887 - val_loss: 1.4438 - val_accuracy: 0.6071\n",
      "Epoch 3064/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3619 - accuracy: 0.8809 - val_loss: 1.5164 - val_accuracy: 0.5942\n",
      "Epoch 3065/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4216 - accuracy: 0.8589 - val_loss: 1.6022 - val_accuracy: 0.5844\n",
      "Epoch 3066/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3769 - accuracy: 0.8818 - val_loss: 1.6926 - val_accuracy: 0.5682\n",
      "Epoch 3067/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3966 - accuracy: 0.8721 - val_loss: 1.7337 - val_accuracy: 0.5714\n",
      "Epoch 3068/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3846 - accuracy: 0.8740 - val_loss: 1.7359 - val_accuracy: 0.5747\n",
      "Epoch 3069/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3896 - accuracy: 0.8743 - val_loss: 1.6865 - val_accuracy: 0.5812\n",
      "Epoch 3070/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4045 - accuracy: 0.8534 - val_loss: 1.5789 - val_accuracy: 0.5974\n",
      "Epoch 3071/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3780 - accuracy: 0.8779 - val_loss: 1.4904 - val_accuracy: 0.6006\n",
      "Epoch 3072/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3721 - accuracy: 0.8715 - val_loss: 1.4252 - val_accuracy: 0.6104\n",
      "Epoch 3073/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4152 - accuracy: 0.8672 - val_loss: 1.3850 - val_accuracy: 0.6039\n",
      "Epoch 3074/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3990 - accuracy: 0.8743 - val_loss: 1.3704 - val_accuracy: 0.6071\n",
      "Epoch 3075/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3958 - accuracy: 0.8672 - val_loss: 1.3570 - val_accuracy: 0.6266\n",
      "Epoch 3076/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3899 - accuracy: 0.8750 - val_loss: 1.3531 - val_accuracy: 0.6364\n",
      "Epoch 3077/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3941 - accuracy: 0.8789 - val_loss: 1.3660 - val_accuracy: 0.6364\n",
      "Epoch 3078/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3557 - accuracy: 0.8838 - val_loss: 1.3774 - val_accuracy: 0.6396\n",
      "Epoch 3079/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3878 - accuracy: 0.8711 - val_loss: 1.4037 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3080/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3447 - accuracy: 0.8877 - val_loss: 1.4214 - val_accuracy: 0.6331\n",
      "Epoch 3081/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4036 - accuracy: 0.8631 - val_loss: 1.4438 - val_accuracy: 0.6201\n",
      "Epoch 3082/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3864 - accuracy: 0.8771 - val_loss: 1.4694 - val_accuracy: 0.6039\n",
      "Epoch 3083/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3994 - accuracy: 0.8659 - val_loss: 1.4803 - val_accuracy: 0.5974\n",
      "Epoch 3084/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3989 - accuracy: 0.8729 - val_loss: 1.4888 - val_accuracy: 0.6039\n",
      "Epoch 3085/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4013 - accuracy: 0.8633 - val_loss: 1.4807 - val_accuracy: 0.6039\n",
      "Epoch 3086/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4238 - accuracy: 0.8701 - val_loss: 1.4588 - val_accuracy: 0.5974\n",
      "Epoch 3087/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4632 - accuracy: 0.8436 - val_loss: 1.4497 - val_accuracy: 0.6104\n",
      "Epoch 3088/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3976 - accuracy: 0.8740 - val_loss: 1.4416 - val_accuracy: 0.6234\n",
      "Epoch 3089/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4026 - accuracy: 0.8673 - val_loss: 1.4164 - val_accuracy: 0.6396\n",
      "Epoch 3090/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4030 - accuracy: 0.8771 - val_loss: 1.3884 - val_accuracy: 0.6526\n",
      "Epoch 3091/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3613 - accuracy: 0.8841 - val_loss: 1.3653 - val_accuracy: 0.6558\n",
      "Epoch 3092/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3829 - accuracy: 0.8701 - val_loss: 1.3373 - val_accuracy: 0.6526\n",
      "Epoch 3093/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4091 - accuracy: 0.8631 - val_loss: 1.3149 - val_accuracy: 0.6688\n",
      "Epoch 3094/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4441 - accuracy: 0.8631 - val_loss: 1.3041 - val_accuracy: 0.6656\n",
      "Epoch 3095/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3826 - accuracy: 0.8672 - val_loss: 1.2908 - val_accuracy: 0.6656\n",
      "Epoch 3096/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3307 - accuracy: 0.8869 - val_loss: 1.2965 - val_accuracy: 0.6688\n",
      "Epoch 3097/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3654 - accuracy: 0.8779 - val_loss: 1.2997 - val_accuracy: 0.6721\n",
      "Epoch 3098/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3888 - accuracy: 0.8730 - val_loss: 1.3007 - val_accuracy: 0.6688\n",
      "Epoch 3099/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3817 - accuracy: 0.8701 - val_loss: 1.2981 - val_accuracy: 0.6591\n",
      "Epoch 3100/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3551 - accuracy: 0.8869 - val_loss: 1.2981 - val_accuracy: 0.6526\n",
      "Epoch 3101/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3854 - accuracy: 0.8701 - val_loss: 1.2793 - val_accuracy: 0.6461\n",
      "Epoch 3102/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3056 - accuracy: 0.8925 - val_loss: 1.2654 - val_accuracy: 0.6558\n",
      "Epoch 3103/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3191 - accuracy: 0.8925 - val_loss: 1.2618 - val_accuracy: 0.6558\n",
      "Epoch 3104/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3334 - accuracy: 0.8925 - val_loss: 1.2648 - val_accuracy: 0.6656\n",
      "Epoch 3105/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4216 - accuracy: 0.8729 - val_loss: 1.2662 - val_accuracy: 0.6558\n",
      "Epoch 3106/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3879 - accuracy: 0.8673 - val_loss: 1.2714 - val_accuracy: 0.6591\n",
      "Epoch 3107/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4161 - accuracy: 0.8617 - val_loss: 1.2822 - val_accuracy: 0.6623\n",
      "Epoch 3108/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3572 - accuracy: 0.8848 - val_loss: 1.2977 - val_accuracy: 0.6656\n",
      "Epoch 3109/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3055 - accuracy: 0.8994 - val_loss: 1.3033 - val_accuracy: 0.6623\n",
      "Epoch 3110/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3562 - accuracy: 0.8841 - val_loss: 1.3081 - val_accuracy: 0.6623\n",
      "Epoch 3111/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3915 - accuracy: 0.8779 - val_loss: 1.3104 - val_accuracy: 0.6721\n",
      "Epoch 3112/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3507 - accuracy: 0.8965 - val_loss: 1.3098 - val_accuracy: 0.6688\n",
      "Epoch 3113/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3980 - accuracy: 0.8701 - val_loss: 1.3160 - val_accuracy: 0.6591\n",
      "Epoch 3114/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3566 - accuracy: 0.8785 - val_loss: 1.3326 - val_accuracy: 0.6526\n",
      "Epoch 3115/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3626 - accuracy: 0.8779 - val_loss: 1.3500 - val_accuracy: 0.6461\n",
      "Epoch 3116/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4270 - accuracy: 0.8603 - val_loss: 1.3437 - val_accuracy: 0.6494\n",
      "Epoch 3117/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3909 - accuracy: 0.8520 - val_loss: 1.3362 - val_accuracy: 0.6396\n",
      "Epoch 3118/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3217 - accuracy: 0.8916 - val_loss: 1.3304 - val_accuracy: 0.6429\n",
      "Epoch 3119/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3639 - accuracy: 0.8818 - val_loss: 1.3227 - val_accuracy: 0.6461\n",
      "Epoch 3120/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4323 - accuracy: 0.8589 - val_loss: 1.3159 - val_accuracy: 0.6429\n",
      "Epoch 3121/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4179 - accuracy: 0.8617 - val_loss: 1.3175 - val_accuracy: 0.6591\n",
      "Epoch 3122/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3259 - accuracy: 0.8916 - val_loss: 1.3214 - val_accuracy: 0.6558\n",
      "Epoch 3123/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3400 - accuracy: 0.8841 - val_loss: 1.3280 - val_accuracy: 0.6558\n",
      "Epoch 3124/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3938 - accuracy: 0.8659 - val_loss: 1.3289 - val_accuracy: 0.6591\n",
      "Epoch 3125/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4044 - accuracy: 0.8701 - val_loss: 1.3233 - val_accuracy: 0.6591\n",
      "Epoch 3126/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4146 - accuracy: 0.8813 - val_loss: 1.3206 - val_accuracy: 0.6623\n",
      "Epoch 3127/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3495 - accuracy: 0.8883 - val_loss: 1.3189 - val_accuracy: 0.6623\n",
      "Epoch 3128/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3856 - accuracy: 0.8813 - val_loss: 1.3235 - val_accuracy: 0.6526\n",
      "Epoch 3129/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3782 - accuracy: 0.8715 - val_loss: 1.3307 - val_accuracy: 0.6461\n",
      "Epoch 3130/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3331 - accuracy: 0.8955 - val_loss: 1.3729 - val_accuracy: 0.6396\n",
      "Epoch 3131/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4004 - accuracy: 0.8785 - val_loss: 1.4216 - val_accuracy: 0.6104\n",
      "Epoch 3132/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3786 - accuracy: 0.8770 - val_loss: 1.4629 - val_accuracy: 0.6039\n",
      "Epoch 3133/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4080 - accuracy: 0.8673 - val_loss: 1.5047 - val_accuracy: 0.5877\n",
      "Epoch 3134/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4055 - accuracy: 0.8691 - val_loss: 1.5124 - val_accuracy: 0.5812\n",
      "Epoch 3135/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3829 - accuracy: 0.8813 - val_loss: 1.4910 - val_accuracy: 0.5877\n",
      "Epoch 3136/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4083 - accuracy: 0.8701 - val_loss: 1.4573 - val_accuracy: 0.5877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3137/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4130 - accuracy: 0.8730 - val_loss: 1.3968 - val_accuracy: 0.6039\n",
      "Epoch 3138/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4101 - accuracy: 0.8645 - val_loss: 1.3443 - val_accuracy: 0.6331\n",
      "Epoch 3139/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3759 - accuracy: 0.8841 - val_loss: 1.3137 - val_accuracy: 0.6494\n",
      "Epoch 3140/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3953 - accuracy: 0.8730 - val_loss: 1.3006 - val_accuracy: 0.6494\n",
      "Epoch 3141/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4191 - accuracy: 0.8659 - val_loss: 1.3008 - val_accuracy: 0.6591\n",
      "Epoch 3142/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3900 - accuracy: 0.8691 - val_loss: 1.2969 - val_accuracy: 0.6656\n",
      "Epoch 3143/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3651 - accuracy: 0.8906 - val_loss: 1.2839 - val_accuracy: 0.6656\n",
      "Epoch 3144/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3543 - accuracy: 0.8757 - val_loss: 1.2690 - val_accuracy: 0.6591\n",
      "Epoch 3145/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4051 - accuracy: 0.8613 - val_loss: 1.2590 - val_accuracy: 0.6494\n",
      "Epoch 3146/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4062 - accuracy: 0.8617 - val_loss: 1.2545 - val_accuracy: 0.6688\n",
      "Epoch 3147/4000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3589 - accuracy: 0.8838 - val_loss: 1.2526 - val_accuracy: 0.6721\n",
      "Epoch 3148/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3632 - accuracy: 0.8617 - val_loss: 1.2588 - val_accuracy: 0.6721\n",
      "Epoch 3149/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3474 - accuracy: 0.8945 - val_loss: 1.2671 - val_accuracy: 0.6688\n",
      "Epoch 3150/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3965 - accuracy: 0.8771 - val_loss: 1.2586 - val_accuracy: 0.6623\n",
      "Epoch 3151/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3653 - accuracy: 0.8730 - val_loss: 1.2570 - val_accuracy: 0.6656\n",
      "Epoch 3152/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4169 - accuracy: 0.8662 - val_loss: 1.2590 - val_accuracy: 0.6558\n",
      "Epoch 3153/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3662 - accuracy: 0.8867 - val_loss: 1.2558 - val_accuracy: 0.6558\n",
      "Epoch 3154/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3255 - accuracy: 0.8953 - val_loss: 1.2486 - val_accuracy: 0.6494\n",
      "Epoch 3155/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3735 - accuracy: 0.8757 - val_loss: 1.2504 - val_accuracy: 0.6526\n",
      "Epoch 3156/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3994 - accuracy: 0.8662 - val_loss: 1.2521 - val_accuracy: 0.6591\n",
      "Epoch 3157/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3657 - accuracy: 0.8857 - val_loss: 1.2589 - val_accuracy: 0.6558\n",
      "Epoch 3158/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3694 - accuracy: 0.8672 - val_loss: 1.2703 - val_accuracy: 0.6558\n",
      "Epoch 3159/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4053 - accuracy: 0.8789 - val_loss: 1.2858 - val_accuracy: 0.6461\n",
      "Epoch 3160/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3589 - accuracy: 0.8799 - val_loss: 1.3050 - val_accuracy: 0.6526\n",
      "Epoch 3161/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3832 - accuracy: 0.8721 - val_loss: 1.3195 - val_accuracy: 0.6461\n",
      "Epoch 3162/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3655 - accuracy: 0.8785 - val_loss: 1.3210 - val_accuracy: 0.6623\n",
      "Epoch 3163/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3801 - accuracy: 0.8701 - val_loss: 1.3246 - val_accuracy: 0.6526\n",
      "Epoch 3164/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4168 - accuracy: 0.8687 - val_loss: 1.3315 - val_accuracy: 0.6429\n",
      "Epoch 3165/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3701 - accuracy: 0.8827 - val_loss: 1.3339 - val_accuracy: 0.6331\n",
      "Epoch 3166/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3801 - accuracy: 0.8750 - val_loss: 1.3422 - val_accuracy: 0.6364\n",
      "Epoch 3167/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3925 - accuracy: 0.8715 - val_loss: 1.3538 - val_accuracy: 0.6299\n",
      "Epoch 3168/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3642 - accuracy: 0.8789 - val_loss: 1.3553 - val_accuracy: 0.6201\n",
      "Epoch 3169/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4339 - accuracy: 0.8574 - val_loss: 1.3524 - val_accuracy: 0.6006\n",
      "Epoch 3170/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4253 - accuracy: 0.8574 - val_loss: 1.3503 - val_accuracy: 0.6104\n",
      "Epoch 3171/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3875 - accuracy: 0.8729 - val_loss: 1.3410 - val_accuracy: 0.6266\n",
      "Epoch 3172/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3790 - accuracy: 0.8743 - val_loss: 1.3312 - val_accuracy: 0.6234\n",
      "Epoch 3173/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3843 - accuracy: 0.8757 - val_loss: 1.3159 - val_accuracy: 0.6266\n",
      "Epoch 3174/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3519 - accuracy: 0.8857 - val_loss: 1.2951 - val_accuracy: 0.6364\n",
      "Epoch 3175/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3806 - accuracy: 0.8785 - val_loss: 1.2879 - val_accuracy: 0.6266\n",
      "Epoch 3176/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3806 - accuracy: 0.8809 - val_loss: 1.2942 - val_accuracy: 0.6396\n",
      "Epoch 3177/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3494 - accuracy: 0.8785 - val_loss: 1.3080 - val_accuracy: 0.6396\n",
      "Epoch 3178/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3888 - accuracy: 0.8645 - val_loss: 1.3166 - val_accuracy: 0.6461\n",
      "Epoch 3179/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3803 - accuracy: 0.8673 - val_loss: 1.3220 - val_accuracy: 0.6299\n",
      "Epoch 3180/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4267 - accuracy: 0.8673 - val_loss: 1.3314 - val_accuracy: 0.6331\n",
      "Epoch 3181/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3626 - accuracy: 0.8813 - val_loss: 1.3395 - val_accuracy: 0.6331\n",
      "Epoch 3182/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2939 - accuracy: 0.9050 - val_loss: 1.3462 - val_accuracy: 0.6396\n",
      "Epoch 3183/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4042 - accuracy: 0.8682 - val_loss: 1.3353 - val_accuracy: 0.6429\n",
      "Epoch 3184/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3857 - accuracy: 0.8730 - val_loss: 1.3096 - val_accuracy: 0.6461\n",
      "Epoch 3185/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3651 - accuracy: 0.8779 - val_loss: 1.2824 - val_accuracy: 0.6526\n",
      "Epoch 3186/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4119 - accuracy: 0.8760 - val_loss: 1.2652 - val_accuracy: 0.6591\n",
      "Epoch 3187/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3943 - accuracy: 0.8506 - val_loss: 1.2477 - val_accuracy: 0.6656\n",
      "Epoch 3188/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3418 - accuracy: 0.8855 - val_loss: 1.2438 - val_accuracy: 0.6721\n",
      "Epoch 3189/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4199 - accuracy: 0.8603 - val_loss: 1.2574 - val_accuracy: 0.6753\n",
      "Epoch 3190/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4399 - accuracy: 0.8645 - val_loss: 1.2556 - val_accuracy: 0.6753\n",
      "Epoch 3191/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3818 - accuracy: 0.8897 - val_loss: 1.2486 - val_accuracy: 0.6753\n",
      "Epoch 3192/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4048 - accuracy: 0.8561 - val_loss: 1.2381 - val_accuracy: 0.6818\n",
      "Epoch 3193/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3902 - accuracy: 0.8771 - val_loss: 1.2338 - val_accuracy: 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3194/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3880 - accuracy: 0.8687 - val_loss: 1.2385 - val_accuracy: 0.6656\n",
      "Epoch 3195/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3722 - accuracy: 0.8857 - val_loss: 1.2492 - val_accuracy: 0.6656\n",
      "Epoch 3196/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3688 - accuracy: 0.8771 - val_loss: 1.2575 - val_accuracy: 0.6688\n",
      "Epoch 3197/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3867 - accuracy: 0.8757 - val_loss: 1.2396 - val_accuracy: 0.6753\n",
      "Epoch 3198/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3212 - accuracy: 0.9022 - val_loss: 1.2214 - val_accuracy: 0.6786\n",
      "Epoch 3199/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3929 - accuracy: 0.8721 - val_loss: 1.2139 - val_accuracy: 0.6721\n",
      "Epoch 3200/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3487 - accuracy: 0.8896 - val_loss: 1.2130 - val_accuracy: 0.6688\n",
      "Epoch 3201/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3477 - accuracy: 0.8828 - val_loss: 1.2165 - val_accuracy: 0.6721\n",
      "Epoch 3202/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3985 - accuracy: 0.8701 - val_loss: 1.2199 - val_accuracy: 0.6688\n",
      "Epoch 3203/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3244 - accuracy: 0.8966 - val_loss: 1.2228 - val_accuracy: 0.6688\n",
      "Epoch 3204/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3791 - accuracy: 0.8687 - val_loss: 1.2242 - val_accuracy: 0.6656\n",
      "Epoch 3205/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4342 - accuracy: 0.8673 - val_loss: 1.2256 - val_accuracy: 0.6591\n",
      "Epoch 3206/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3992 - accuracy: 0.8757 - val_loss: 1.2187 - val_accuracy: 0.6558\n",
      "Epoch 3207/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3684 - accuracy: 0.8818 - val_loss: 1.2133 - val_accuracy: 0.6558\n",
      "Epoch 3208/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3900 - accuracy: 0.8789 - val_loss: 1.2128 - val_accuracy: 0.6558\n",
      "Epoch 3209/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3448 - accuracy: 0.8883 - val_loss: 1.2201 - val_accuracy: 0.6526\n",
      "Epoch 3210/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3726 - accuracy: 0.8799 - val_loss: 1.2252 - val_accuracy: 0.6494\n",
      "Epoch 3211/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3786 - accuracy: 0.8682 - val_loss: 1.2306 - val_accuracy: 0.6558\n",
      "Epoch 3212/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3624 - accuracy: 0.8730 - val_loss: 1.2412 - val_accuracy: 0.6623\n",
      "Epoch 3213/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3416 - accuracy: 0.8955 - val_loss: 1.2543 - val_accuracy: 0.6558\n",
      "Epoch 3214/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3518 - accuracy: 0.8828 - val_loss: 1.2581 - val_accuracy: 0.6429\n",
      "Epoch 3215/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3391 - accuracy: 0.8841 - val_loss: 1.2584 - val_accuracy: 0.6558\n",
      "Epoch 3216/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3751 - accuracy: 0.8730 - val_loss: 1.2674 - val_accuracy: 0.6558\n",
      "Epoch 3217/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3188 - accuracy: 0.8855 - val_loss: 1.2739 - val_accuracy: 0.6591\n",
      "Epoch 3218/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3964 - accuracy: 0.8740 - val_loss: 1.2818 - val_accuracy: 0.6558\n",
      "Epoch 3219/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3635 - accuracy: 0.8770 - val_loss: 1.2884 - val_accuracy: 0.6558\n",
      "Epoch 3220/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4151 - accuracy: 0.8740 - val_loss: 1.2899 - val_accuracy: 0.6591\n",
      "Epoch 3221/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4144 - accuracy: 0.8584 - val_loss: 1.2932 - val_accuracy: 0.6688\n",
      "Epoch 3222/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4222 - accuracy: 0.8643 - val_loss: 1.2916 - val_accuracy: 0.6656\n",
      "Epoch 3223/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3480 - accuracy: 0.9050 - val_loss: 1.3003 - val_accuracy: 0.6558\n",
      "Epoch 3224/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4226 - accuracy: 0.8682 - val_loss: 1.3099 - val_accuracy: 0.6494\n",
      "Epoch 3225/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3813 - accuracy: 0.8828 - val_loss: 1.3193 - val_accuracy: 0.6494\n",
      "Epoch 3226/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3436 - accuracy: 0.8813 - val_loss: 1.3291 - val_accuracy: 0.6494\n",
      "Epoch 3227/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4018 - accuracy: 0.8631 - val_loss: 1.3398 - val_accuracy: 0.6623\n",
      "Epoch 3228/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3468 - accuracy: 0.8936 - val_loss: 1.3453 - val_accuracy: 0.6494\n",
      "Epoch 3229/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3757 - accuracy: 0.8770 - val_loss: 1.3515 - val_accuracy: 0.6558\n",
      "Epoch 3230/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4255 - accuracy: 0.8652 - val_loss: 1.3576 - val_accuracy: 0.6558\n",
      "Epoch 3231/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3892 - accuracy: 0.8740 - val_loss: 1.3683 - val_accuracy: 0.6461\n",
      "Epoch 3232/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3314 - accuracy: 0.8789 - val_loss: 1.3739 - val_accuracy: 0.6461\n",
      "Epoch 3233/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3209 - accuracy: 0.8945 - val_loss: 1.3806 - val_accuracy: 0.6429\n",
      "Epoch 3234/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3713 - accuracy: 0.8701 - val_loss: 1.3836 - val_accuracy: 0.6396\n",
      "Epoch 3235/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3206 - accuracy: 0.8877 - val_loss: 1.3902 - val_accuracy: 0.6396\n",
      "Epoch 3236/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3179 - accuracy: 0.8896 - val_loss: 1.3997 - val_accuracy: 0.6331\n",
      "Epoch 3237/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3465 - accuracy: 0.8911 - val_loss: 1.4065 - val_accuracy: 0.6299\n",
      "Epoch 3238/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3331 - accuracy: 0.8906 - val_loss: 1.4094 - val_accuracy: 0.6169\n",
      "Epoch 3239/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3848 - accuracy: 0.8750 - val_loss: 1.4087 - val_accuracy: 0.6104\n",
      "Epoch 3240/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3275 - accuracy: 0.8743 - val_loss: 1.3968 - val_accuracy: 0.6169\n",
      "Epoch 3241/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3831 - accuracy: 0.8827 - val_loss: 1.3855 - val_accuracy: 0.6136\n",
      "Epoch 3242/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3559 - accuracy: 0.8945 - val_loss: 1.3775 - val_accuracy: 0.6266\n",
      "Epoch 3243/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4081 - accuracy: 0.8760 - val_loss: 1.3740 - val_accuracy: 0.6364\n",
      "Epoch 3244/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4028 - accuracy: 0.8779 - val_loss: 1.3718 - val_accuracy: 0.6364\n",
      "Epoch 3245/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3396 - accuracy: 0.9008 - val_loss: 1.3750 - val_accuracy: 0.6331\n",
      "Epoch 3246/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3547 - accuracy: 0.8867 - val_loss: 1.3736 - val_accuracy: 0.6364\n",
      "Epoch 3247/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3404 - accuracy: 0.8857 - val_loss: 1.3538 - val_accuracy: 0.6429\n",
      "Epoch 3248/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3627 - accuracy: 0.8729 - val_loss: 1.3297 - val_accuracy: 0.6526\n",
      "Epoch 3249/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3672 - accuracy: 0.8770 - val_loss: 1.3145 - val_accuracy: 0.6461\n",
      "Epoch 3250/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4184 - accuracy: 0.8645 - val_loss: 1.2977 - val_accuracy: 0.6558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3251/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3023 - accuracy: 0.8955 - val_loss: 1.2896 - val_accuracy: 0.6656\n",
      "Epoch 3252/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3396 - accuracy: 0.8945 - val_loss: 1.2794 - val_accuracy: 0.6753\n",
      "Epoch 3253/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2475 - accuracy: 0.9162 - val_loss: 1.2735 - val_accuracy: 0.6818\n",
      "Epoch 3254/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3586 - accuracy: 0.8841 - val_loss: 1.2826 - val_accuracy: 0.6656\n",
      "Epoch 3255/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4156 - accuracy: 0.8645 - val_loss: 1.2955 - val_accuracy: 0.6494\n",
      "Epoch 3256/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3562 - accuracy: 0.8848 - val_loss: 1.3287 - val_accuracy: 0.6331\n",
      "Epoch 3257/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4006 - accuracy: 0.8750 - val_loss: 1.3619 - val_accuracy: 0.6136\n",
      "Epoch 3258/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3551 - accuracy: 0.8799 - val_loss: 1.3838 - val_accuracy: 0.6136\n",
      "Epoch 3259/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3447 - accuracy: 0.8936 - val_loss: 1.3985 - val_accuracy: 0.6071\n",
      "Epoch 3260/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3701 - accuracy: 0.8813 - val_loss: 1.4017 - val_accuracy: 0.6104\n",
      "Epoch 3261/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3962 - accuracy: 0.8869 - val_loss: 1.3965 - val_accuracy: 0.6104\n",
      "Epoch 3262/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3734 - accuracy: 0.8813 - val_loss: 1.3630 - val_accuracy: 0.6201\n",
      "Epoch 3263/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3379 - accuracy: 0.8770 - val_loss: 1.3327 - val_accuracy: 0.6039\n",
      "Epoch 3264/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3495 - accuracy: 0.8877 - val_loss: 1.3215 - val_accuracy: 0.6104\n",
      "Epoch 3265/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3881 - accuracy: 0.8673 - val_loss: 1.3190 - val_accuracy: 0.6169\n",
      "Epoch 3266/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3816 - accuracy: 0.8743 - val_loss: 1.3249 - val_accuracy: 0.6136\n",
      "Epoch 3267/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3734 - accuracy: 0.8743 - val_loss: 1.3369 - val_accuracy: 0.6104\n",
      "Epoch 3268/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3294 - accuracy: 0.8883 - val_loss: 1.3720 - val_accuracy: 0.6071\n",
      "Epoch 3269/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4105 - accuracy: 0.8770 - val_loss: 1.4287 - val_accuracy: 0.6039\n",
      "Epoch 3270/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3673 - accuracy: 0.8682 - val_loss: 1.4812 - val_accuracy: 0.5909\n",
      "Epoch 3271/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3420 - accuracy: 0.8906 - val_loss: 1.5179 - val_accuracy: 0.5877\n",
      "Epoch 3272/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3576 - accuracy: 0.8911 - val_loss: 1.5244 - val_accuracy: 0.5844\n",
      "Epoch 3273/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4256 - accuracy: 0.8631 - val_loss: 1.5249 - val_accuracy: 0.5747\n",
      "Epoch 3274/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3581 - accuracy: 0.8906 - val_loss: 1.4964 - val_accuracy: 0.6006\n",
      "Epoch 3275/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3675 - accuracy: 0.8799 - val_loss: 1.4719 - val_accuracy: 0.6039\n",
      "Epoch 3276/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4095 - accuracy: 0.8534 - val_loss: 1.4782 - val_accuracy: 0.5942\n",
      "Epoch 3277/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3075 - accuracy: 0.8877 - val_loss: 1.4748 - val_accuracy: 0.5844\n",
      "Epoch 3278/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3735 - accuracy: 0.8877 - val_loss: 1.4640 - val_accuracy: 0.5909\n",
      "Epoch 3279/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3848 - accuracy: 0.8799 - val_loss: 1.4565 - val_accuracy: 0.6104\n",
      "Epoch 3280/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3055 - accuracy: 0.9148 - val_loss: 1.4772 - val_accuracy: 0.6039\n",
      "Epoch 3281/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3506 - accuracy: 0.8925 - val_loss: 1.4838 - val_accuracy: 0.6104\n",
      "Epoch 3282/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3562 - accuracy: 0.8848 - val_loss: 1.4979 - val_accuracy: 0.6039\n",
      "Epoch 3283/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3442 - accuracy: 0.8838 - val_loss: 1.5118 - val_accuracy: 0.6071\n",
      "Epoch 3284/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3828 - accuracy: 0.8729 - val_loss: 1.5260 - val_accuracy: 0.6071\n",
      "Epoch 3285/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3700 - accuracy: 0.8691 - val_loss: 1.5400 - val_accuracy: 0.6006\n",
      "Epoch 3286/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3847 - accuracy: 0.8799 - val_loss: 1.5692 - val_accuracy: 0.5942\n",
      "Epoch 3287/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3434 - accuracy: 0.8827 - val_loss: 1.5943 - val_accuracy: 0.5844\n",
      "Epoch 3288/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3508 - accuracy: 0.8715 - val_loss: 1.6092 - val_accuracy: 0.5649\n",
      "Epoch 3289/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3316 - accuracy: 0.8771 - val_loss: 1.6186 - val_accuracy: 0.5617\n",
      "Epoch 3290/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3125 - accuracy: 0.8911 - val_loss: 1.5951 - val_accuracy: 0.5649\n",
      "Epoch 3291/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3338 - accuracy: 0.8953 - val_loss: 1.5559 - val_accuracy: 0.5714\n",
      "Epoch 3292/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3361 - accuracy: 0.9064 - val_loss: 1.5201 - val_accuracy: 0.5877\n",
      "Epoch 3293/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3387 - accuracy: 0.8809 - val_loss: 1.4984 - val_accuracy: 0.5942\n",
      "Epoch 3294/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3460 - accuracy: 0.8911 - val_loss: 1.5008 - val_accuracy: 0.5942\n",
      "Epoch 3295/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3319 - accuracy: 0.9033 - val_loss: 1.5163 - val_accuracy: 0.5909\n",
      "Epoch 3296/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3559 - accuracy: 0.8841 - val_loss: 1.5237 - val_accuracy: 0.5942\n",
      "Epoch 3297/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3580 - accuracy: 0.8867 - val_loss: 1.5196 - val_accuracy: 0.5942\n",
      "Epoch 3298/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3932 - accuracy: 0.8701 - val_loss: 1.5123 - val_accuracy: 0.6039\n",
      "Epoch 3299/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3442 - accuracy: 0.8799 - val_loss: 1.4981 - val_accuracy: 0.6071\n",
      "Epoch 3300/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3021 - accuracy: 0.8965 - val_loss: 1.4775 - val_accuracy: 0.6201\n",
      "Epoch 3301/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3426 - accuracy: 0.8799 - val_loss: 1.4533 - val_accuracy: 0.6201\n",
      "Epoch 3302/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3306 - accuracy: 0.8966 - val_loss: 1.4506 - val_accuracy: 0.6234\n",
      "Epoch 3303/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3204 - accuracy: 0.8936 - val_loss: 1.4534 - val_accuracy: 0.6299\n",
      "Epoch 3304/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3199 - accuracy: 0.9043 - val_loss: 1.4538 - val_accuracy: 0.6201\n",
      "Epoch 3305/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3682 - accuracy: 0.8818 - val_loss: 1.4526 - val_accuracy: 0.6201\n",
      "Epoch 3306/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3528 - accuracy: 0.8869 - val_loss: 1.4568 - val_accuracy: 0.6104\n",
      "Epoch 3307/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3708 - accuracy: 0.8721 - val_loss: 1.4774 - val_accuracy: 0.6039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3308/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3115 - accuracy: 0.8841 - val_loss: 1.4935 - val_accuracy: 0.6039\n",
      "Epoch 3309/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3402 - accuracy: 0.8869 - val_loss: 1.5001 - val_accuracy: 0.5974\n",
      "Epoch 3310/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3352 - accuracy: 0.8799 - val_loss: 1.4909 - val_accuracy: 0.5942\n",
      "Epoch 3311/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3906 - accuracy: 0.8757 - val_loss: 1.4666 - val_accuracy: 0.6039\n",
      "Epoch 3312/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3545 - accuracy: 0.8841 - val_loss: 1.4229 - val_accuracy: 0.6299\n",
      "Epoch 3313/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3687 - accuracy: 0.8813 - val_loss: 1.4062 - val_accuracy: 0.6429\n",
      "Epoch 3314/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3562 - accuracy: 0.8857 - val_loss: 1.4008 - val_accuracy: 0.6364\n",
      "Epoch 3315/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3484 - accuracy: 0.8838 - val_loss: 1.4074 - val_accuracy: 0.6364\n",
      "Epoch 3316/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4069 - accuracy: 0.8799 - val_loss: 1.4078 - val_accuracy: 0.6526\n",
      "Epoch 3317/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3694 - accuracy: 0.8750 - val_loss: 1.4116 - val_accuracy: 0.6429\n",
      "Epoch 3318/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3013 - accuracy: 0.8936 - val_loss: 1.4123 - val_accuracy: 0.6364\n",
      "Epoch 3319/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3510 - accuracy: 0.8897 - val_loss: 1.4151 - val_accuracy: 0.6396\n",
      "Epoch 3320/4000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3436 - accuracy: 0.8828 - val_loss: 1.4105 - val_accuracy: 0.6429\n",
      "Epoch 3321/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3151 - accuracy: 0.8945 - val_loss: 1.4050 - val_accuracy: 0.6429\n",
      "Epoch 3322/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4240 - accuracy: 0.8643 - val_loss: 1.3887 - val_accuracy: 0.6526\n",
      "Epoch 3323/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3457 - accuracy: 0.8953 - val_loss: 1.3708 - val_accuracy: 0.6494\n",
      "Epoch 3324/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4139 - accuracy: 0.8740 - val_loss: 1.3515 - val_accuracy: 0.6494\n",
      "Epoch 3325/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3321 - accuracy: 0.8687 - val_loss: 1.3349 - val_accuracy: 0.6526\n",
      "Epoch 3326/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3907 - accuracy: 0.8673 - val_loss: 1.3267 - val_accuracy: 0.6494\n",
      "Epoch 3327/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3485 - accuracy: 0.8906 - val_loss: 1.3169 - val_accuracy: 0.6461\n",
      "Epoch 3328/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3319 - accuracy: 0.8916 - val_loss: 1.3136 - val_accuracy: 0.6396\n",
      "Epoch 3329/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3143 - accuracy: 0.8896 - val_loss: 1.3135 - val_accuracy: 0.6461\n",
      "Epoch 3330/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3600 - accuracy: 0.8827 - val_loss: 1.3196 - val_accuracy: 0.6494\n",
      "Epoch 3331/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3689 - accuracy: 0.8799 - val_loss: 1.3214 - val_accuracy: 0.6558\n",
      "Epoch 3332/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4428 - accuracy: 0.8687 - val_loss: 1.3365 - val_accuracy: 0.6623\n",
      "Epoch 3333/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2992 - accuracy: 0.8911 - val_loss: 1.3705 - val_accuracy: 0.6623\n",
      "Epoch 3334/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3443 - accuracy: 0.8869 - val_loss: 1.3934 - val_accuracy: 0.6721\n",
      "Epoch 3335/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3351 - accuracy: 0.8887 - val_loss: 1.4084 - val_accuracy: 0.6753\n",
      "Epoch 3336/4000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3720 - accuracy: 0.8701 - val_loss: 1.4091 - val_accuracy: 0.6688\n",
      "Epoch 3337/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3640 - accuracy: 0.8809 - val_loss: 1.4051 - val_accuracy: 0.6656\n",
      "Epoch 3338/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3579 - accuracy: 0.8911 - val_loss: 1.3963 - val_accuracy: 0.6429\n",
      "Epoch 3339/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3540 - accuracy: 0.8818 - val_loss: 1.3964 - val_accuracy: 0.6494\n",
      "Epoch 3340/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3444 - accuracy: 0.8939 - val_loss: 1.4050 - val_accuracy: 0.6494\n",
      "Epoch 3341/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3389 - accuracy: 0.8994 - val_loss: 1.4196 - val_accuracy: 0.6591\n",
      "Epoch 3342/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3443 - accuracy: 0.8887 - val_loss: 1.4439 - val_accuracy: 0.6558\n",
      "Epoch 3343/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3620 - accuracy: 0.8848 - val_loss: 1.4980 - val_accuracy: 0.6266\n",
      "Epoch 3344/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3083 - accuracy: 0.8877 - val_loss: 1.5577 - val_accuracy: 0.6006\n",
      "Epoch 3345/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3640 - accuracy: 0.8691 - val_loss: 1.6231 - val_accuracy: 0.5909\n",
      "Epoch 3346/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3792 - accuracy: 0.8813 - val_loss: 1.6493 - val_accuracy: 0.5779\n",
      "Epoch 3347/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3270 - accuracy: 0.8867 - val_loss: 1.6309 - val_accuracy: 0.5844\n",
      "Epoch 3348/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3206 - accuracy: 0.9023 - val_loss: 1.5876 - val_accuracy: 0.6006\n",
      "Epoch 3349/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3393 - accuracy: 0.8916 - val_loss: 1.5558 - val_accuracy: 0.6136\n",
      "Epoch 3350/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3801 - accuracy: 0.8743 - val_loss: 1.5292 - val_accuracy: 0.6201\n",
      "Epoch 3351/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3462 - accuracy: 0.8867 - val_loss: 1.5242 - val_accuracy: 0.6266\n",
      "Epoch 3352/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3265 - accuracy: 0.8965 - val_loss: 1.5275 - val_accuracy: 0.6201\n",
      "Epoch 3353/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3081 - accuracy: 0.9008 - val_loss: 1.5332 - val_accuracy: 0.6201\n",
      "Epoch 3354/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3312 - accuracy: 0.8953 - val_loss: 1.5367 - val_accuracy: 0.6104\n",
      "Epoch 3355/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3817 - accuracy: 0.8757 - val_loss: 1.5213 - val_accuracy: 0.6136\n",
      "Epoch 3356/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3239 - accuracy: 0.9062 - val_loss: 1.5128 - val_accuracy: 0.6071\n",
      "Epoch 3357/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3723 - accuracy: 0.8848 - val_loss: 1.5082 - val_accuracy: 0.6104\n",
      "Epoch 3358/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3350 - accuracy: 0.8980 - val_loss: 1.5179 - val_accuracy: 0.6234\n",
      "Epoch 3359/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3229 - accuracy: 0.8883 - val_loss: 1.5171 - val_accuracy: 0.6201\n",
      "Epoch 3360/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3437 - accuracy: 0.8729 - val_loss: 1.5166 - val_accuracy: 0.6169\n",
      "Epoch 3361/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3262 - accuracy: 0.8980 - val_loss: 1.5086 - val_accuracy: 0.6169\n",
      "Epoch 3362/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4185 - accuracy: 0.8715 - val_loss: 1.5294 - val_accuracy: 0.6104\n",
      "Epoch 3363/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3732 - accuracy: 0.8785 - val_loss: 1.5487 - val_accuracy: 0.6039\n",
      "Epoch 3364/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3554 - accuracy: 0.8877 - val_loss: 1.5704 - val_accuracy: 0.5877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3365/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3855 - accuracy: 0.8757 - val_loss: 1.6028 - val_accuracy: 0.5909\n",
      "Epoch 3366/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3364 - accuracy: 0.8813 - val_loss: 1.6377 - val_accuracy: 0.5812\n",
      "Epoch 3367/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3679 - accuracy: 0.8799 - val_loss: 1.6663 - val_accuracy: 0.5844\n",
      "Epoch 3368/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3745 - accuracy: 0.8906 - val_loss: 1.6905 - val_accuracy: 0.5779\n",
      "Epoch 3369/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3704 - accuracy: 0.8897 - val_loss: 1.7260 - val_accuracy: 0.5714\n",
      "Epoch 3370/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2913 - accuracy: 0.9072 - val_loss: 1.7637 - val_accuracy: 0.5584\n",
      "Epoch 3371/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3195 - accuracy: 0.8936 - val_loss: 1.7769 - val_accuracy: 0.5682\n",
      "Epoch 3372/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3350 - accuracy: 0.8906 - val_loss: 1.7921 - val_accuracy: 0.5487\n",
      "Epoch 3373/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3462 - accuracy: 0.8939 - val_loss: 1.7769 - val_accuracy: 0.5617\n",
      "Epoch 3374/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3611 - accuracy: 0.8916 - val_loss: 1.7321 - val_accuracy: 0.5844\n",
      "Epoch 3375/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3424 - accuracy: 0.9064 - val_loss: 1.6745 - val_accuracy: 0.5942\n",
      "Epoch 3376/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3510 - accuracy: 0.8883 - val_loss: 1.5667 - val_accuracy: 0.6136\n",
      "Epoch 3377/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3163 - accuracy: 0.8906 - val_loss: 1.5103 - val_accuracy: 0.6331\n",
      "Epoch 3378/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3346 - accuracy: 0.8883 - val_loss: 1.4714 - val_accuracy: 0.6461\n",
      "Epoch 3379/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2953 - accuracy: 0.8939 - val_loss: 1.4613 - val_accuracy: 0.6526\n",
      "Epoch 3380/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3744 - accuracy: 0.8809 - val_loss: 1.4667 - val_accuracy: 0.6558\n",
      "Epoch 3381/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3584 - accuracy: 0.8857 - val_loss: 1.4635 - val_accuracy: 0.6494\n",
      "Epoch 3382/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2958 - accuracy: 0.9082 - val_loss: 1.4595 - val_accuracy: 0.6461\n",
      "Epoch 3383/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3401 - accuracy: 0.8906 - val_loss: 1.4480 - val_accuracy: 0.6396\n",
      "Epoch 3384/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3267 - accuracy: 0.9036 - val_loss: 1.4357 - val_accuracy: 0.6364\n",
      "Epoch 3385/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3511 - accuracy: 0.8887 - val_loss: 1.4315 - val_accuracy: 0.6364\n",
      "Epoch 3386/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3549 - accuracy: 0.8789 - val_loss: 1.4312 - val_accuracy: 0.6364\n",
      "Epoch 3387/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3554 - accuracy: 0.8799 - val_loss: 1.4341 - val_accuracy: 0.6331\n",
      "Epoch 3388/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3496 - accuracy: 0.8785 - val_loss: 1.4535 - val_accuracy: 0.6266\n",
      "Epoch 3389/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3614 - accuracy: 0.8855 - val_loss: 1.4755 - val_accuracy: 0.6201\n",
      "Epoch 3390/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3255 - accuracy: 0.8867 - val_loss: 1.4802 - val_accuracy: 0.6169\n",
      "Epoch 3391/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3728 - accuracy: 0.8770 - val_loss: 1.4705 - val_accuracy: 0.6169\n",
      "Epoch 3392/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3784 - accuracy: 0.8785 - val_loss: 1.4436 - val_accuracy: 0.6234\n",
      "Epoch 3393/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3349 - accuracy: 0.8896 - val_loss: 1.4027 - val_accuracy: 0.6429\n",
      "Epoch 3394/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3406 - accuracy: 0.8827 - val_loss: 1.3766 - val_accuracy: 0.6429\n",
      "Epoch 3395/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3288 - accuracy: 0.8980 - val_loss: 1.3623 - val_accuracy: 0.6331\n",
      "Epoch 3396/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3119 - accuracy: 0.9004 - val_loss: 1.3577 - val_accuracy: 0.6299\n",
      "Epoch 3397/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3959 - accuracy: 0.8659 - val_loss: 1.3522 - val_accuracy: 0.6331\n",
      "Epoch 3398/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3713 - accuracy: 0.8743 - val_loss: 1.3438 - val_accuracy: 0.6396\n",
      "Epoch 3399/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3375 - accuracy: 0.8682 - val_loss: 1.3361 - val_accuracy: 0.6494\n",
      "Epoch 3400/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3097 - accuracy: 0.8925 - val_loss: 1.3371 - val_accuracy: 0.6526\n",
      "Epoch 3401/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2950 - accuracy: 0.8911 - val_loss: 1.3451 - val_accuracy: 0.6591\n",
      "Epoch 3402/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3803 - accuracy: 0.8799 - val_loss: 1.3680 - val_accuracy: 0.6526\n",
      "Epoch 3403/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3429 - accuracy: 0.8939 - val_loss: 1.3867 - val_accuracy: 0.6331\n",
      "Epoch 3404/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3336 - accuracy: 0.8925 - val_loss: 1.4079 - val_accuracy: 0.6299\n",
      "Epoch 3405/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3742 - accuracy: 0.8848 - val_loss: 1.4292 - val_accuracy: 0.6396\n",
      "Epoch 3406/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4136 - accuracy: 0.8729 - val_loss: 1.4541 - val_accuracy: 0.6331\n",
      "Epoch 3407/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3270 - accuracy: 0.8936 - val_loss: 1.4792 - val_accuracy: 0.6266\n",
      "Epoch 3408/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4008 - accuracy: 0.8662 - val_loss: 1.5142 - val_accuracy: 0.6266\n",
      "Epoch 3409/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3060 - accuracy: 0.8994 - val_loss: 1.5544 - val_accuracy: 0.6234\n",
      "Epoch 3410/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3260 - accuracy: 0.8911 - val_loss: 1.6107 - val_accuracy: 0.5909\n",
      "Epoch 3411/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3367 - accuracy: 0.8729 - val_loss: 1.6822 - val_accuracy: 0.5779\n",
      "Epoch 3412/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4086 - accuracy: 0.8813 - val_loss: 1.7352 - val_accuracy: 0.5779\n",
      "Epoch 3413/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3471 - accuracy: 0.8809 - val_loss: 1.7512 - val_accuracy: 0.5519\n",
      "Epoch 3414/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3810 - accuracy: 0.8770 - val_loss: 1.7685 - val_accuracy: 0.5617\n",
      "Epoch 3415/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3123 - accuracy: 0.9078 - val_loss: 1.7764 - val_accuracy: 0.5649\n",
      "Epoch 3416/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3197 - accuracy: 0.8869 - val_loss: 1.7683 - val_accuracy: 0.5519\n",
      "Epoch 3417/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2795 - accuracy: 0.9064 - val_loss: 1.7322 - val_accuracy: 0.5649\n",
      "Epoch 3418/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3444 - accuracy: 0.8966 - val_loss: 1.7113 - val_accuracy: 0.5747\n",
      "Epoch 3419/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3117 - accuracy: 0.8867 - val_loss: 1.6752 - val_accuracy: 0.5844\n",
      "Epoch 3420/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3670 - accuracy: 0.8980 - val_loss: 1.6213 - val_accuracy: 0.5877\n",
      "Epoch 3421/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3834 - accuracy: 0.8770 - val_loss: 1.5768 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3422/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3691 - accuracy: 0.8828 - val_loss: 1.5660 - val_accuracy: 0.6104\n",
      "Epoch 3423/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3565 - accuracy: 0.8857 - val_loss: 1.5627 - val_accuracy: 0.6104\n",
      "Epoch 3424/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3330 - accuracy: 0.8966 - val_loss: 1.5472 - val_accuracy: 0.6201\n",
      "Epoch 3425/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3269 - accuracy: 0.9033 - val_loss: 1.5432 - val_accuracy: 0.6136\n",
      "Epoch 3426/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3339 - accuracy: 0.8925 - val_loss: 1.5350 - val_accuracy: 0.6071\n",
      "Epoch 3427/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3335 - accuracy: 0.8916 - val_loss: 1.5400 - val_accuracy: 0.5974\n",
      "Epoch 3428/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3345 - accuracy: 0.8966 - val_loss: 1.5286 - val_accuracy: 0.5974\n",
      "Epoch 3429/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3650 - accuracy: 0.8848 - val_loss: 1.5195 - val_accuracy: 0.5844\n",
      "Epoch 3430/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3223 - accuracy: 0.8925 - val_loss: 1.5421 - val_accuracy: 0.5812\n",
      "Epoch 3431/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3556 - accuracy: 0.8779 - val_loss: 1.5797 - val_accuracy: 0.5909\n",
      "Epoch 3432/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3213 - accuracy: 0.9036 - val_loss: 1.6185 - val_accuracy: 0.5779\n",
      "Epoch 3433/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3111 - accuracy: 0.9022 - val_loss: 1.6407 - val_accuracy: 0.5844\n",
      "Epoch 3434/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4220 - accuracy: 0.8743 - val_loss: 1.6271 - val_accuracy: 0.5844\n",
      "Epoch 3435/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3486 - accuracy: 0.8897 - val_loss: 1.6004 - val_accuracy: 0.5877\n",
      "Epoch 3436/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3953 - accuracy: 0.8750 - val_loss: 1.5563 - val_accuracy: 0.6169\n",
      "Epoch 3437/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3536 - accuracy: 0.8897 - val_loss: 1.5207 - val_accuracy: 0.6364\n",
      "Epoch 3438/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3344 - accuracy: 0.8994 - val_loss: 1.4920 - val_accuracy: 0.6396\n",
      "Epoch 3439/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2895 - accuracy: 0.9064 - val_loss: 1.4643 - val_accuracy: 0.6364\n",
      "Epoch 3440/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3426 - accuracy: 0.8883 - val_loss: 1.4307 - val_accuracy: 0.6494\n",
      "Epoch 3441/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3716 - accuracy: 0.8673 - val_loss: 1.4193 - val_accuracy: 0.6429\n",
      "Epoch 3442/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3609 - accuracy: 0.8883 - val_loss: 1.4193 - val_accuracy: 0.6558\n",
      "Epoch 3443/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3441 - accuracy: 0.8887 - val_loss: 1.4211 - val_accuracy: 0.6591\n",
      "Epoch 3444/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3620 - accuracy: 0.8721 - val_loss: 1.4381 - val_accuracy: 0.6623\n",
      "Epoch 3445/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3553 - accuracy: 0.8813 - val_loss: 1.4641 - val_accuracy: 0.6526\n",
      "Epoch 3446/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3859 - accuracy: 0.8757 - val_loss: 1.4824 - val_accuracy: 0.6299\n",
      "Epoch 3447/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3073 - accuracy: 0.8936 - val_loss: 1.5031 - val_accuracy: 0.6299\n",
      "Epoch 3448/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3610 - accuracy: 0.8939 - val_loss: 1.5039 - val_accuracy: 0.6169\n",
      "Epoch 3449/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3201 - accuracy: 0.9004 - val_loss: 1.4981 - val_accuracy: 0.6071\n",
      "Epoch 3450/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3160 - accuracy: 0.8911 - val_loss: 1.4980 - val_accuracy: 0.6104\n",
      "Epoch 3451/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3435 - accuracy: 0.8897 - val_loss: 1.5410 - val_accuracy: 0.5812\n",
      "Epoch 3452/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3381 - accuracy: 0.8848 - val_loss: 1.5705 - val_accuracy: 0.5812\n",
      "Epoch 3453/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3618 - accuracy: 0.8855 - val_loss: 1.5915 - val_accuracy: 0.5779\n",
      "Epoch 3454/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3595 - accuracy: 0.8897 - val_loss: 1.5903 - val_accuracy: 0.5779\n",
      "Epoch 3455/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3135 - accuracy: 0.8994 - val_loss: 1.6342 - val_accuracy: 0.5682\n",
      "Epoch 3456/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3416 - accuracy: 0.8855 - val_loss: 1.6752 - val_accuracy: 0.5617\n",
      "Epoch 3457/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3411 - accuracy: 0.8916 - val_loss: 1.6922 - val_accuracy: 0.5552\n",
      "Epoch 3458/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3401 - accuracy: 0.8841 - val_loss: 1.7004 - val_accuracy: 0.5552\n",
      "Epoch 3459/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3101 - accuracy: 0.9078 - val_loss: 1.6672 - val_accuracy: 0.5747\n",
      "Epoch 3460/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3813 - accuracy: 0.8771 - val_loss: 1.6440 - val_accuracy: 0.5812\n",
      "Epoch 3461/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3325 - accuracy: 0.8926 - val_loss: 1.6178 - val_accuracy: 0.5812\n",
      "Epoch 3462/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3379 - accuracy: 0.9023 - val_loss: 1.5906 - val_accuracy: 0.5779\n",
      "Epoch 3463/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3018 - accuracy: 0.8966 - val_loss: 1.5723 - val_accuracy: 0.5812\n",
      "Epoch 3464/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3558 - accuracy: 0.8916 - val_loss: 1.5355 - val_accuracy: 0.5877\n",
      "Epoch 3465/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3253 - accuracy: 0.8867 - val_loss: 1.4949 - val_accuracy: 0.6006\n",
      "Epoch 3466/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3111 - accuracy: 0.9008 - val_loss: 1.4847 - val_accuracy: 0.5942\n",
      "Epoch 3467/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3717 - accuracy: 0.8721 - val_loss: 1.4608 - val_accuracy: 0.6006\n",
      "Epoch 3468/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2933 - accuracy: 0.9062 - val_loss: 1.4485 - val_accuracy: 0.6136\n",
      "Epoch 3469/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3311 - accuracy: 0.8897 - val_loss: 1.4333 - val_accuracy: 0.6136\n",
      "Epoch 3470/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3094 - accuracy: 0.8925 - val_loss: 1.4109 - val_accuracy: 0.6234\n",
      "Epoch 3471/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3076 - accuracy: 0.9008 - val_loss: 1.3886 - val_accuracy: 0.6266\n",
      "Epoch 3472/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2991 - accuracy: 0.8955 - val_loss: 1.3684 - val_accuracy: 0.6266\n",
      "Epoch 3473/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3739 - accuracy: 0.8672 - val_loss: 1.3493 - val_accuracy: 0.6396\n",
      "Epoch 3474/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3673 - accuracy: 0.8828 - val_loss: 1.3416 - val_accuracy: 0.6461\n",
      "Epoch 3475/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3265 - accuracy: 0.8869 - val_loss: 1.3315 - val_accuracy: 0.6526\n",
      "Epoch 3476/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2793 - accuracy: 0.9189 - val_loss: 1.3275 - val_accuracy: 0.6558\n",
      "Epoch 3477/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3383 - accuracy: 0.8877 - val_loss: 1.3229 - val_accuracy: 0.6526\n",
      "Epoch 3478/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2928 - accuracy: 0.8966 - val_loss: 1.3250 - val_accuracy: 0.6526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3479/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3267 - accuracy: 0.8936 - val_loss: 1.3348 - val_accuracy: 0.6429\n",
      "Epoch 3480/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3459 - accuracy: 0.8779 - val_loss: 1.3609 - val_accuracy: 0.6396\n",
      "Epoch 3481/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3418 - accuracy: 0.8906 - val_loss: 1.3891 - val_accuracy: 0.6299\n",
      "Epoch 3482/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3428 - accuracy: 0.8916 - val_loss: 1.4194 - val_accuracy: 0.6266\n",
      "Epoch 3483/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3922 - accuracy: 0.8687 - val_loss: 1.4488 - val_accuracy: 0.6266\n",
      "Epoch 3484/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3407 - accuracy: 0.8867 - val_loss: 1.4849 - val_accuracy: 0.6169\n",
      "Epoch 3485/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3162 - accuracy: 0.8911 - val_loss: 1.5150 - val_accuracy: 0.6104\n",
      "Epoch 3486/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3097 - accuracy: 0.9008 - val_loss: 1.5253 - val_accuracy: 0.6071\n",
      "Epoch 3487/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3503 - accuracy: 0.8771 - val_loss: 1.4947 - val_accuracy: 0.6071\n",
      "Epoch 3488/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2901 - accuracy: 0.9148 - val_loss: 1.4681 - val_accuracy: 0.6234\n",
      "Epoch 3489/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3297 - accuracy: 0.8926 - val_loss: 1.4550 - val_accuracy: 0.6104\n",
      "Epoch 3490/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3718 - accuracy: 0.8828 - val_loss: 1.4531 - val_accuracy: 0.6104\n",
      "Epoch 3491/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3208 - accuracy: 0.8877 - val_loss: 1.4569 - val_accuracy: 0.6104\n",
      "Epoch 3492/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3263 - accuracy: 0.8906 - val_loss: 1.4531 - val_accuracy: 0.6136\n",
      "Epoch 3493/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3579 - accuracy: 0.8828 - val_loss: 1.4361 - val_accuracy: 0.6136\n",
      "Epoch 3494/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2910 - accuracy: 0.9008 - val_loss: 1.4161 - val_accuracy: 0.6201\n",
      "Epoch 3495/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3372 - accuracy: 0.8994 - val_loss: 1.4075 - val_accuracy: 0.6331\n",
      "Epoch 3496/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3523 - accuracy: 0.8897 - val_loss: 1.4082 - val_accuracy: 0.6299\n",
      "Epoch 3497/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3528 - accuracy: 0.8818 - val_loss: 1.4059 - val_accuracy: 0.6331\n",
      "Epoch 3498/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3263 - accuracy: 0.8953 - val_loss: 1.3995 - val_accuracy: 0.6299\n",
      "Epoch 3499/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3099 - accuracy: 0.8896 - val_loss: 1.4027 - val_accuracy: 0.6299\n",
      "Epoch 3500/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3525 - accuracy: 0.8799 - val_loss: 1.4176 - val_accuracy: 0.6266\n",
      "Epoch 3501/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3224 - accuracy: 0.8869 - val_loss: 1.4401 - val_accuracy: 0.6299\n",
      "Epoch 3502/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2984 - accuracy: 0.9050 - val_loss: 1.4742 - val_accuracy: 0.6169\n",
      "Epoch 3503/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3323 - accuracy: 0.8926 - val_loss: 1.4917 - val_accuracy: 0.5974\n",
      "Epoch 3504/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3268 - accuracy: 0.8945 - val_loss: 1.5049 - val_accuracy: 0.5974\n",
      "Epoch 3505/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3094 - accuracy: 0.8813 - val_loss: 1.5097 - val_accuracy: 0.5909\n",
      "Epoch 3506/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2889 - accuracy: 0.8939 - val_loss: 1.5387 - val_accuracy: 0.5942\n",
      "Epoch 3507/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3524 - accuracy: 0.8887 - val_loss: 1.5374 - val_accuracy: 0.5974\n",
      "Epoch 3508/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3421 - accuracy: 0.8925 - val_loss: 1.5754 - val_accuracy: 0.5779\n",
      "Epoch 3509/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3860 - accuracy: 0.8779 - val_loss: 1.6057 - val_accuracy: 0.5682\n",
      "Epoch 3510/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3570 - accuracy: 0.8809 - val_loss: 1.6308 - val_accuracy: 0.5779\n",
      "Epoch 3511/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3439 - accuracy: 0.8887 - val_loss: 1.6360 - val_accuracy: 0.5844\n",
      "Epoch 3512/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3356 - accuracy: 0.8994 - val_loss: 1.6604 - val_accuracy: 0.5779\n",
      "Epoch 3513/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2984 - accuracy: 0.9050 - val_loss: 1.6746 - val_accuracy: 0.5779\n",
      "Epoch 3514/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3406 - accuracy: 0.8883 - val_loss: 1.6540 - val_accuracy: 0.5909\n",
      "Epoch 3515/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3915 - accuracy: 0.8701 - val_loss: 1.6169 - val_accuracy: 0.6006\n",
      "Epoch 3516/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3138 - accuracy: 0.8911 - val_loss: 1.5823 - val_accuracy: 0.6039\n",
      "Epoch 3517/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2825 - accuracy: 0.9050 - val_loss: 1.5330 - val_accuracy: 0.6104\n",
      "Epoch 3518/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3062 - accuracy: 0.9023 - val_loss: 1.4800 - val_accuracy: 0.6396\n",
      "Epoch 3519/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3369 - accuracy: 0.8945 - val_loss: 1.4493 - val_accuracy: 0.6396\n",
      "Epoch 3520/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3626 - accuracy: 0.8896 - val_loss: 1.4183 - val_accuracy: 0.6461\n",
      "Epoch 3521/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3305 - accuracy: 0.8925 - val_loss: 1.3889 - val_accuracy: 0.6461\n",
      "Epoch 3522/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3033 - accuracy: 0.9022 - val_loss: 1.3747 - val_accuracy: 0.6494\n",
      "Epoch 3523/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3122 - accuracy: 0.8966 - val_loss: 1.3676 - val_accuracy: 0.6591\n",
      "Epoch 3524/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3170 - accuracy: 0.8953 - val_loss: 1.3748 - val_accuracy: 0.6558\n",
      "Epoch 3525/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3303 - accuracy: 0.8945 - val_loss: 1.4013 - val_accuracy: 0.6429\n",
      "Epoch 3526/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3279 - accuracy: 0.8953 - val_loss: 1.4364 - val_accuracy: 0.6396\n",
      "Epoch 3527/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3178 - accuracy: 0.8887 - val_loss: 1.4499 - val_accuracy: 0.6364\n",
      "Epoch 3528/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3331 - accuracy: 0.8953 - val_loss: 1.4718 - val_accuracy: 0.6396\n",
      "Epoch 3529/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3349 - accuracy: 0.8818 - val_loss: 1.4695 - val_accuracy: 0.6494\n",
      "Epoch 3530/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3146 - accuracy: 0.8818 - val_loss: 1.4666 - val_accuracy: 0.6364\n",
      "Epoch 3531/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3009 - accuracy: 0.9092 - val_loss: 1.4586 - val_accuracy: 0.6331\n",
      "Epoch 3532/4000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3107 - accuracy: 0.8883 - val_loss: 1.4590 - val_accuracy: 0.6331\n",
      "Epoch 3533/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3494 - accuracy: 0.8911 - val_loss: 1.4613 - val_accuracy: 0.6396\n",
      "Epoch 3534/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3715 - accuracy: 0.8869 - val_loss: 1.4661 - val_accuracy: 0.6331\n",
      "Epoch 3535/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3184 - accuracy: 0.8887 - val_loss: 1.4629 - val_accuracy: 0.6331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3536/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3390 - accuracy: 0.8906 - val_loss: 1.4586 - val_accuracy: 0.6299\n",
      "Epoch 3537/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2816 - accuracy: 0.9072 - val_loss: 1.4419 - val_accuracy: 0.6396\n",
      "Epoch 3538/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3169 - accuracy: 0.8906 - val_loss: 1.4334 - val_accuracy: 0.6364\n",
      "Epoch 3539/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3382 - accuracy: 0.8848 - val_loss: 1.4197 - val_accuracy: 0.6429\n",
      "Epoch 3540/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3168 - accuracy: 0.9014 - val_loss: 1.4154 - val_accuracy: 0.6429\n",
      "Epoch 3541/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3379 - accuracy: 0.8939 - val_loss: 1.3926 - val_accuracy: 0.6494\n",
      "Epoch 3542/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3647 - accuracy: 0.8818 - val_loss: 1.3957 - val_accuracy: 0.6429\n",
      "Epoch 3543/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3336 - accuracy: 0.8760 - val_loss: 1.3953 - val_accuracy: 0.6461\n",
      "Epoch 3544/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3061 - accuracy: 0.8945 - val_loss: 1.4023 - val_accuracy: 0.6429\n",
      "Epoch 3545/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3592 - accuracy: 0.8779 - val_loss: 1.4108 - val_accuracy: 0.6429\n",
      "Epoch 3546/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3626 - accuracy: 0.8916 - val_loss: 1.4173 - val_accuracy: 0.6331\n",
      "Epoch 3547/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2872 - accuracy: 0.9162 - val_loss: 1.4296 - val_accuracy: 0.6429\n",
      "Epoch 3548/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3339 - accuracy: 0.8926 - val_loss: 1.4339 - val_accuracy: 0.6396\n",
      "Epoch 3549/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3665 - accuracy: 0.8911 - val_loss: 1.4314 - val_accuracy: 0.6461\n",
      "Epoch 3550/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3400 - accuracy: 0.8857 - val_loss: 1.4386 - val_accuracy: 0.6494\n",
      "Epoch 3551/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3241 - accuracy: 0.8841 - val_loss: 1.4431 - val_accuracy: 0.6656\n",
      "Epoch 3552/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3215 - accuracy: 0.8953 - val_loss: 1.4561 - val_accuracy: 0.6591\n",
      "Epoch 3553/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3414 - accuracy: 0.8867 - val_loss: 1.4642 - val_accuracy: 0.6558\n",
      "Epoch 3554/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2655 - accuracy: 0.9150 - val_loss: 1.4683 - val_accuracy: 0.6558\n",
      "Epoch 3555/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2963 - accuracy: 0.9064 - val_loss: 1.4661 - val_accuracy: 0.6656\n",
      "Epoch 3556/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3277 - accuracy: 0.8975 - val_loss: 1.4561 - val_accuracy: 0.6656\n",
      "Epoch 3557/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3509 - accuracy: 0.8838 - val_loss: 1.4433 - val_accuracy: 0.6721\n",
      "Epoch 3558/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2795 - accuracy: 0.9036 - val_loss: 1.4199 - val_accuracy: 0.6721\n",
      "Epoch 3559/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3394 - accuracy: 0.8828 - val_loss: 1.4109 - val_accuracy: 0.6753\n",
      "Epoch 3560/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3284 - accuracy: 0.8975 - val_loss: 1.4037 - val_accuracy: 0.6753\n",
      "Epoch 3561/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3232 - accuracy: 0.9036 - val_loss: 1.4032 - val_accuracy: 0.6786\n",
      "Epoch 3562/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3029 - accuracy: 0.8994 - val_loss: 1.4142 - val_accuracy: 0.6656\n",
      "Epoch 3563/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3002 - accuracy: 0.8945 - val_loss: 1.4215 - val_accuracy: 0.6753\n",
      "Epoch 3564/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3112 - accuracy: 0.8925 - val_loss: 1.4241 - val_accuracy: 0.6656\n",
      "Epoch 3565/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3334 - accuracy: 0.8966 - val_loss: 1.4214 - val_accuracy: 0.6656\n",
      "Epoch 3566/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2802 - accuracy: 0.8984 - val_loss: 1.4290 - val_accuracy: 0.6591\n",
      "Epoch 3567/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3042 - accuracy: 0.9082 - val_loss: 1.4226 - val_accuracy: 0.6526\n",
      "Epoch 3568/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3161 - accuracy: 0.8936 - val_loss: 1.4341 - val_accuracy: 0.6526\n",
      "Epoch 3569/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3235 - accuracy: 0.8906 - val_loss: 1.4306 - val_accuracy: 0.6461\n",
      "Epoch 3570/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2844 - accuracy: 0.8953 - val_loss: 1.4366 - val_accuracy: 0.6558\n",
      "Epoch 3571/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3133 - accuracy: 0.9036 - val_loss: 1.4390 - val_accuracy: 0.6526\n",
      "Epoch 3572/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3287 - accuracy: 0.8994 - val_loss: 1.4481 - val_accuracy: 0.6526\n",
      "Epoch 3573/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3332 - accuracy: 0.8818 - val_loss: 1.4754 - val_accuracy: 0.6429\n",
      "Epoch 3574/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3637 - accuracy: 0.8799 - val_loss: 1.4984 - val_accuracy: 0.6429\n",
      "Epoch 3575/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2931 - accuracy: 0.9033 - val_loss: 1.5235 - val_accuracy: 0.6396\n",
      "Epoch 3576/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3015 - accuracy: 0.8984 - val_loss: 1.5387 - val_accuracy: 0.6494\n",
      "Epoch 3577/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3840 - accuracy: 0.8760 - val_loss: 1.5588 - val_accuracy: 0.6429\n",
      "Epoch 3578/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3443 - accuracy: 0.8897 - val_loss: 1.5773 - val_accuracy: 0.6169\n",
      "Epoch 3579/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3360 - accuracy: 0.8887 - val_loss: 1.5941 - val_accuracy: 0.6006\n",
      "Epoch 3580/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3382 - accuracy: 0.8887 - val_loss: 1.5942 - val_accuracy: 0.6104\n",
      "Epoch 3581/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3280 - accuracy: 0.8916 - val_loss: 1.5679 - val_accuracy: 0.6136\n",
      "Epoch 3582/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3302 - accuracy: 0.8926 - val_loss: 1.5412 - val_accuracy: 0.6169\n",
      "Epoch 3583/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3391 - accuracy: 0.8897 - val_loss: 1.5189 - val_accuracy: 0.6234\n",
      "Epoch 3584/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2992 - accuracy: 0.9092 - val_loss: 1.4965 - val_accuracy: 0.6429\n",
      "Epoch 3585/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2696 - accuracy: 0.9023 - val_loss: 1.4751 - val_accuracy: 0.6429\n",
      "Epoch 3586/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3058 - accuracy: 0.9033 - val_loss: 1.4637 - val_accuracy: 0.6461\n",
      "Epoch 3587/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3072 - accuracy: 0.9023 - val_loss: 1.4585 - val_accuracy: 0.6494\n",
      "Epoch 3588/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2970 - accuracy: 0.9008 - val_loss: 1.4619 - val_accuracy: 0.6494\n",
      "Epoch 3589/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2934 - accuracy: 0.8906 - val_loss: 1.4797 - val_accuracy: 0.6429\n",
      "Epoch 3590/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3528 - accuracy: 0.8813 - val_loss: 1.4945 - val_accuracy: 0.6331\n",
      "Epoch 3591/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2866 - accuracy: 0.9131 - val_loss: 1.5109 - val_accuracy: 0.6266\n",
      "Epoch 3592/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2975 - accuracy: 0.8939 - val_loss: 1.5334 - val_accuracy: 0.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3593/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3327 - accuracy: 0.8936 - val_loss: 1.5527 - val_accuracy: 0.6331\n",
      "Epoch 3594/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3352 - accuracy: 0.9008 - val_loss: 1.5803 - val_accuracy: 0.6169\n",
      "Epoch 3595/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3346 - accuracy: 0.8980 - val_loss: 1.5980 - val_accuracy: 0.6201\n",
      "Epoch 3596/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3490 - accuracy: 0.8789 - val_loss: 1.6323 - val_accuracy: 0.5909\n",
      "Epoch 3597/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3341 - accuracy: 0.8883 - val_loss: 1.6789 - val_accuracy: 0.5877\n",
      "Epoch 3598/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2777 - accuracy: 0.8966 - val_loss: 1.7347 - val_accuracy: 0.5812\n",
      "Epoch 3599/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3171 - accuracy: 0.8984 - val_loss: 1.7703 - val_accuracy: 0.5812\n",
      "Epoch 3600/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3579 - accuracy: 0.8848 - val_loss: 1.7885 - val_accuracy: 0.5617\n",
      "Epoch 3601/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2980 - accuracy: 0.9008 - val_loss: 1.8007 - val_accuracy: 0.5714\n",
      "Epoch 3602/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3540 - accuracy: 0.8841 - val_loss: 1.7841 - val_accuracy: 0.5649\n",
      "Epoch 3603/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2991 - accuracy: 0.9064 - val_loss: 1.7466 - val_accuracy: 0.5682\n",
      "Epoch 3604/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3292 - accuracy: 0.8841 - val_loss: 1.7058 - val_accuracy: 0.5747\n",
      "Epoch 3605/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3295 - accuracy: 0.8911 - val_loss: 1.6886 - val_accuracy: 0.5779\n",
      "Epoch 3606/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3870 - accuracy: 0.8855 - val_loss: 1.6743 - val_accuracy: 0.5877\n",
      "Epoch 3607/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3510 - accuracy: 0.8729 - val_loss: 1.6634 - val_accuracy: 0.5844\n",
      "Epoch 3608/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2933 - accuracy: 0.9120 - val_loss: 1.6531 - val_accuracy: 0.5942\n",
      "Epoch 3609/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3324 - accuracy: 0.8883 - val_loss: 1.6451 - val_accuracy: 0.5909\n",
      "Epoch 3610/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3465 - accuracy: 0.8887 - val_loss: 1.6317 - val_accuracy: 0.6006\n",
      "Epoch 3611/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3160 - accuracy: 0.8799 - val_loss: 1.5967 - val_accuracy: 0.6039\n",
      "Epoch 3612/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2948 - accuracy: 0.9014 - val_loss: 1.5664 - val_accuracy: 0.6104\n",
      "Epoch 3613/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3125 - accuracy: 0.8813 - val_loss: 1.5455 - val_accuracy: 0.6169\n",
      "Epoch 3614/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2675 - accuracy: 0.9078 - val_loss: 1.5519 - val_accuracy: 0.6104\n",
      "Epoch 3615/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3570 - accuracy: 0.8818 - val_loss: 1.5698 - val_accuracy: 0.6039\n",
      "Epoch 3616/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2726 - accuracy: 0.9120 - val_loss: 1.5699 - val_accuracy: 0.6006\n",
      "Epoch 3617/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2939 - accuracy: 0.9022 - val_loss: 1.5993 - val_accuracy: 0.5877\n",
      "Epoch 3618/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3463 - accuracy: 0.8953 - val_loss: 1.6139 - val_accuracy: 0.5942\n",
      "Epoch 3619/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2966 - accuracy: 0.9064 - val_loss: 1.6130 - val_accuracy: 0.5942\n",
      "Epoch 3620/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3444 - accuracy: 0.8896 - val_loss: 1.6059 - val_accuracy: 0.6006\n",
      "Epoch 3621/4000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3278 - accuracy: 0.8897 - val_loss: 1.5910 - val_accuracy: 0.6039\n",
      "Epoch 3622/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2605 - accuracy: 0.9246 - val_loss: 1.5772 - val_accuracy: 0.6039\n",
      "Epoch 3623/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3564 - accuracy: 0.8828 - val_loss: 1.5615 - val_accuracy: 0.6136\n",
      "Epoch 3624/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2851 - accuracy: 0.9078 - val_loss: 1.5528 - val_accuracy: 0.6169\n",
      "Epoch 3625/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3185 - accuracy: 0.8953 - val_loss: 1.5501 - val_accuracy: 0.6234\n",
      "Epoch 3626/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3373 - accuracy: 0.8926 - val_loss: 1.5508 - val_accuracy: 0.6299\n",
      "Epoch 3627/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3023 - accuracy: 0.8966 - val_loss: 1.5778 - val_accuracy: 0.6266\n",
      "Epoch 3628/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3399 - accuracy: 0.8906 - val_loss: 1.6094 - val_accuracy: 0.6006\n",
      "Epoch 3629/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3421 - accuracy: 0.8838 - val_loss: 1.6339 - val_accuracy: 0.5909\n",
      "Epoch 3630/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3546 - accuracy: 0.8848 - val_loss: 1.6779 - val_accuracy: 0.5844\n",
      "Epoch 3631/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3222 - accuracy: 0.9072 - val_loss: 1.7333 - val_accuracy: 0.5812\n",
      "Epoch 3632/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3092 - accuracy: 0.9050 - val_loss: 1.7952 - val_accuracy: 0.5649\n",
      "Epoch 3633/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3122 - accuracy: 0.8906 - val_loss: 1.8412 - val_accuracy: 0.5649\n",
      "Epoch 3634/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2993 - accuracy: 0.9082 - val_loss: 1.8702 - val_accuracy: 0.5519\n",
      "Epoch 3635/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3036 - accuracy: 0.9014 - val_loss: 1.8943 - val_accuracy: 0.5390\n",
      "Epoch 3636/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2568 - accuracy: 0.9120 - val_loss: 1.8924 - val_accuracy: 0.5455\n",
      "Epoch 3637/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3558 - accuracy: 0.8867 - val_loss: 1.8576 - val_accuracy: 0.5584\n",
      "Epoch 3638/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3620 - accuracy: 0.8827 - val_loss: 1.8183 - val_accuracy: 0.5617\n",
      "Epoch 3639/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3093 - accuracy: 0.9008 - val_loss: 1.7651 - val_accuracy: 0.5747\n",
      "Epoch 3640/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3411 - accuracy: 0.8887 - val_loss: 1.7066 - val_accuracy: 0.5877\n",
      "Epoch 3641/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3465 - accuracy: 0.8955 - val_loss: 1.6954 - val_accuracy: 0.5974\n",
      "Epoch 3642/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3248 - accuracy: 0.8911 - val_loss: 1.6845 - val_accuracy: 0.5974\n",
      "Epoch 3643/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2751 - accuracy: 0.9106 - val_loss: 1.6589 - val_accuracy: 0.6071\n",
      "Epoch 3644/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3024 - accuracy: 0.9120 - val_loss: 1.6477 - val_accuracy: 0.5942\n",
      "Epoch 3645/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3241 - accuracy: 0.8965 - val_loss: 1.6289 - val_accuracy: 0.6006\n",
      "Epoch 3646/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3312 - accuracy: 0.9004 - val_loss: 1.6106 - val_accuracy: 0.6071\n",
      "Epoch 3647/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3405 - accuracy: 0.8975 - val_loss: 1.6130 - val_accuracy: 0.6104\n",
      "Epoch 3648/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2971 - accuracy: 0.8925 - val_loss: 1.6107 - val_accuracy: 0.6071\n",
      "Epoch 3649/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3208 - accuracy: 0.9036 - val_loss: 1.6396 - val_accuracy: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3650/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3662 - accuracy: 0.8740 - val_loss: 1.6838 - val_accuracy: 0.5844\n",
      "Epoch 3651/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3461 - accuracy: 0.8906 - val_loss: 1.7256 - val_accuracy: 0.5747\n",
      "Epoch 3652/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3273 - accuracy: 0.8965 - val_loss: 1.7552 - val_accuracy: 0.5617\n",
      "Epoch 3653/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3054 - accuracy: 0.8925 - val_loss: 1.7665 - val_accuracy: 0.5682\n",
      "Epoch 3654/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3082 - accuracy: 0.9008 - val_loss: 1.7403 - val_accuracy: 0.5747\n",
      "Epoch 3655/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2814 - accuracy: 0.9082 - val_loss: 1.6927 - val_accuracy: 0.5974\n",
      "Epoch 3656/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3135 - accuracy: 0.8955 - val_loss: 1.6219 - val_accuracy: 0.6071\n",
      "Epoch 3657/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3634 - accuracy: 0.8855 - val_loss: 1.5823 - val_accuracy: 0.6136\n",
      "Epoch 3658/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2737 - accuracy: 0.9111 - val_loss: 1.5522 - val_accuracy: 0.6234\n",
      "Epoch 3659/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3542 - accuracy: 0.8897 - val_loss: 1.5449 - val_accuracy: 0.6396\n",
      "Epoch 3660/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3467 - accuracy: 0.8848 - val_loss: 1.5516 - val_accuracy: 0.6331\n",
      "Epoch 3661/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3009 - accuracy: 0.9036 - val_loss: 1.5684 - val_accuracy: 0.6331\n",
      "Epoch 3662/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3112 - accuracy: 0.9008 - val_loss: 1.5737 - val_accuracy: 0.6396\n",
      "Epoch 3663/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3117 - accuracy: 0.9062 - val_loss: 1.5841 - val_accuracy: 0.6396\n",
      "Epoch 3664/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3087 - accuracy: 0.8994 - val_loss: 1.5786 - val_accuracy: 0.6364\n",
      "Epoch 3665/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3061 - accuracy: 0.8994 - val_loss: 1.5503 - val_accuracy: 0.6429\n",
      "Epoch 3666/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3366 - accuracy: 0.8869 - val_loss: 1.5357 - val_accuracy: 0.6266\n",
      "Epoch 3667/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2998 - accuracy: 0.9023 - val_loss: 1.5205 - val_accuracy: 0.6266\n",
      "Epoch 3668/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3431 - accuracy: 0.8770 - val_loss: 1.4996 - val_accuracy: 0.6201\n",
      "Epoch 3669/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3217 - accuracy: 0.8897 - val_loss: 1.4749 - val_accuracy: 0.6266\n",
      "Epoch 3670/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3278 - accuracy: 0.9014 - val_loss: 1.4575 - val_accuracy: 0.6461\n",
      "Epoch 3671/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2847 - accuracy: 0.9141 - val_loss: 1.4602 - val_accuracy: 0.6558\n",
      "Epoch 3672/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3372 - accuracy: 0.8955 - val_loss: 1.4675 - val_accuracy: 0.6494\n",
      "Epoch 3673/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3009 - accuracy: 0.9004 - val_loss: 1.4898 - val_accuracy: 0.6429\n",
      "Epoch 3674/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3148 - accuracy: 0.8906 - val_loss: 1.5105 - val_accuracy: 0.6266\n",
      "Epoch 3675/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3810 - accuracy: 0.8827 - val_loss: 1.5722 - val_accuracy: 0.6234\n",
      "Epoch 3676/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3034 - accuracy: 0.9062 - val_loss: 1.6004 - val_accuracy: 0.6169\n",
      "Epoch 3677/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2916 - accuracy: 0.8984 - val_loss: 1.6376 - val_accuracy: 0.5974\n",
      "Epoch 3678/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2912 - accuracy: 0.9023 - val_loss: 1.6557 - val_accuracy: 0.5909\n",
      "Epoch 3679/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3167 - accuracy: 0.9036 - val_loss: 1.6638 - val_accuracy: 0.5779\n",
      "Epoch 3680/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3265 - accuracy: 0.8994 - val_loss: 1.6844 - val_accuracy: 0.5747\n",
      "Epoch 3681/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3581 - accuracy: 0.8789 - val_loss: 1.6740 - val_accuracy: 0.5812\n",
      "Epoch 3682/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2894 - accuracy: 0.9131 - val_loss: 1.6314 - val_accuracy: 0.5942\n",
      "Epoch 3683/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3444 - accuracy: 0.8818 - val_loss: 1.5567 - val_accuracy: 0.6169\n",
      "Epoch 3684/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3158 - accuracy: 0.8984 - val_loss: 1.5144 - val_accuracy: 0.6136\n",
      "Epoch 3685/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2889 - accuracy: 0.8994 - val_loss: 1.4903 - val_accuracy: 0.6234\n",
      "Epoch 3686/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3211 - accuracy: 0.9078 - val_loss: 1.4782 - val_accuracy: 0.6331\n",
      "Epoch 3687/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3146 - accuracy: 0.8955 - val_loss: 1.4777 - val_accuracy: 0.6331\n",
      "Epoch 3688/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2995 - accuracy: 0.9050 - val_loss: 1.4666 - val_accuracy: 0.6494\n",
      "Epoch 3689/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3050 - accuracy: 0.9022 - val_loss: 1.4656 - val_accuracy: 0.6558\n",
      "Epoch 3690/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3317 - accuracy: 0.8945 - val_loss: 1.4739 - val_accuracy: 0.6526\n",
      "Epoch 3691/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3522 - accuracy: 0.8857 - val_loss: 1.4994 - val_accuracy: 0.6429\n",
      "Epoch 3692/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2644 - accuracy: 0.9092 - val_loss: 1.5301 - val_accuracy: 0.6331\n",
      "Epoch 3693/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2991 - accuracy: 0.9121 - val_loss: 1.5388 - val_accuracy: 0.6201\n",
      "Epoch 3694/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2660 - accuracy: 0.9092 - val_loss: 1.5431 - val_accuracy: 0.6201\n",
      "Epoch 3695/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2777 - accuracy: 0.9150 - val_loss: 1.5499 - val_accuracy: 0.6201\n",
      "Epoch 3696/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3340 - accuracy: 0.8867 - val_loss: 1.5494 - val_accuracy: 0.6071\n",
      "Epoch 3697/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3482 - accuracy: 0.9022 - val_loss: 1.5260 - val_accuracy: 0.6169\n",
      "Epoch 3698/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2652 - accuracy: 0.9148 - val_loss: 1.5031 - val_accuracy: 0.6136\n",
      "Epoch 3699/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3127 - accuracy: 0.8965 - val_loss: 1.5130 - val_accuracy: 0.6266\n",
      "Epoch 3700/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3812 - accuracy: 0.8757 - val_loss: 1.5180 - val_accuracy: 0.6169\n",
      "Epoch 3701/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2901 - accuracy: 0.9078 - val_loss: 1.5139 - val_accuracy: 0.6234\n",
      "Epoch 3702/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3721 - accuracy: 0.8855 - val_loss: 1.5279 - val_accuracy: 0.6299\n",
      "Epoch 3703/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3153 - accuracy: 0.8994 - val_loss: 1.5518 - val_accuracy: 0.6169\n",
      "Epoch 3704/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3102 - accuracy: 0.9064 - val_loss: 1.5910 - val_accuracy: 0.5974\n",
      "Epoch 3705/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3243 - accuracy: 0.8906 - val_loss: 1.6392 - val_accuracy: 0.5877\n",
      "Epoch 3706/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3158 - accuracy: 0.8911 - val_loss: 1.6995 - val_accuracy: 0.5747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3707/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3371 - accuracy: 0.8936 - val_loss: 1.7426 - val_accuracy: 0.5682\n",
      "Epoch 3708/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3534 - accuracy: 0.8799 - val_loss: 1.7594 - val_accuracy: 0.5747\n",
      "Epoch 3709/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2720 - accuracy: 0.9180 - val_loss: 1.7353 - val_accuracy: 0.5779\n",
      "Epoch 3710/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3410 - accuracy: 0.9036 - val_loss: 1.6834 - val_accuracy: 0.5877\n",
      "Epoch 3711/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2432 - accuracy: 0.9189 - val_loss: 1.6406 - val_accuracy: 0.5877\n",
      "Epoch 3712/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3269 - accuracy: 0.9053 - val_loss: 1.6154 - val_accuracy: 0.5877\n",
      "Epoch 3713/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3531 - accuracy: 0.8827 - val_loss: 1.6001 - val_accuracy: 0.5942\n",
      "Epoch 3714/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3074 - accuracy: 0.9014 - val_loss: 1.5794 - val_accuracy: 0.5974\n",
      "Epoch 3715/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3740 - accuracy: 0.8740 - val_loss: 1.5717 - val_accuracy: 0.6039\n",
      "Epoch 3716/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3172 - accuracy: 0.8945 - val_loss: 1.5636 - val_accuracy: 0.6104\n",
      "Epoch 3717/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3402 - accuracy: 0.8848 - val_loss: 1.5769 - val_accuracy: 0.6234\n",
      "Epoch 3718/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2559 - accuracy: 0.9162 - val_loss: 1.5994 - val_accuracy: 0.6039\n",
      "Epoch 3719/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3179 - accuracy: 0.8925 - val_loss: 1.6022 - val_accuracy: 0.6006\n",
      "Epoch 3720/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3787 - accuracy: 0.8799 - val_loss: 1.5821 - val_accuracy: 0.6104\n",
      "Epoch 3721/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3079 - accuracy: 0.9050 - val_loss: 1.5611 - val_accuracy: 0.6234\n",
      "Epoch 3722/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3253 - accuracy: 0.8953 - val_loss: 1.5481 - val_accuracy: 0.6299\n",
      "Epoch 3723/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3394 - accuracy: 0.8936 - val_loss: 1.5289 - val_accuracy: 0.6331\n",
      "Epoch 3724/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2854 - accuracy: 0.9008 - val_loss: 1.5148 - val_accuracy: 0.6266\n",
      "Epoch 3725/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3009 - accuracy: 0.9050 - val_loss: 1.4979 - val_accuracy: 0.6234\n",
      "Epoch 3726/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3340 - accuracy: 0.8945 - val_loss: 1.4964 - val_accuracy: 0.6169\n",
      "Epoch 3727/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3244 - accuracy: 0.8994 - val_loss: 1.5088 - val_accuracy: 0.6201\n",
      "Epoch 3728/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3132 - accuracy: 0.9022 - val_loss: 1.5173 - val_accuracy: 0.6039\n",
      "Epoch 3729/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2591 - accuracy: 0.9160 - val_loss: 1.5412 - val_accuracy: 0.6071\n",
      "Epoch 3730/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3322 - accuracy: 0.8838 - val_loss: 1.5675 - val_accuracy: 0.6071\n",
      "Epoch 3731/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3140 - accuracy: 0.8994 - val_loss: 1.5822 - val_accuracy: 0.6006\n",
      "Epoch 3732/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3310 - accuracy: 0.8965 - val_loss: 1.5844 - val_accuracy: 0.6006\n",
      "Epoch 3733/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3212 - accuracy: 0.8994 - val_loss: 1.5843 - val_accuracy: 0.6136\n",
      "Epoch 3734/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2940 - accuracy: 0.9078 - val_loss: 1.5793 - val_accuracy: 0.6201\n",
      "Epoch 3735/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2915 - accuracy: 0.9043 - val_loss: 1.5628 - val_accuracy: 0.6169\n",
      "Epoch 3736/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3168 - accuracy: 0.8936 - val_loss: 1.5453 - val_accuracy: 0.6006\n",
      "Epoch 3737/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3549 - accuracy: 0.8841 - val_loss: 1.5306 - val_accuracy: 0.6071\n",
      "Epoch 3738/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3134 - accuracy: 0.8966 - val_loss: 1.5180 - val_accuracy: 0.6136\n",
      "Epoch 3739/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2505 - accuracy: 0.9092 - val_loss: 1.5029 - val_accuracy: 0.6136\n",
      "Epoch 3740/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3697 - accuracy: 0.8828 - val_loss: 1.4859 - val_accuracy: 0.6234\n",
      "Epoch 3741/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3074 - accuracy: 0.9008 - val_loss: 1.4809 - val_accuracy: 0.6234\n",
      "Epoch 3742/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3028 - accuracy: 0.9036 - val_loss: 1.4733 - val_accuracy: 0.6364\n",
      "Epoch 3743/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3931 - accuracy: 0.8743 - val_loss: 1.4724 - val_accuracy: 0.6396\n",
      "Epoch 3744/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3414 - accuracy: 0.9022 - val_loss: 1.4720 - val_accuracy: 0.6396\n",
      "Epoch 3745/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2873 - accuracy: 0.9092 - val_loss: 1.4640 - val_accuracy: 0.6494\n",
      "Epoch 3746/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2568 - accuracy: 0.9121 - val_loss: 1.4587 - val_accuracy: 0.6429\n",
      "Epoch 3747/4000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2757 - accuracy: 0.9033 - val_loss: 1.4519 - val_accuracy: 0.6494\n",
      "Epoch 3748/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2974 - accuracy: 0.9121 - val_loss: 1.4498 - val_accuracy: 0.6429\n",
      "Epoch 3749/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3011 - accuracy: 0.9064 - val_loss: 1.4425 - val_accuracy: 0.6429\n",
      "Epoch 3750/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2963 - accuracy: 0.9199 - val_loss: 1.4387 - val_accuracy: 0.6396\n",
      "Epoch 3751/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3065 - accuracy: 0.8965 - val_loss: 1.4526 - val_accuracy: 0.6396\n",
      "Epoch 3752/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3357 - accuracy: 0.8911 - val_loss: 1.4448 - val_accuracy: 0.6364\n",
      "Epoch 3753/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2775 - accuracy: 0.8966 - val_loss: 1.4365 - val_accuracy: 0.6364\n",
      "Epoch 3754/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2988 - accuracy: 0.8926 - val_loss: 1.4365 - val_accuracy: 0.6494\n",
      "Epoch 3755/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2482 - accuracy: 0.9078 - val_loss: 1.4374 - val_accuracy: 0.6526\n",
      "Epoch 3756/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3208 - accuracy: 0.8926 - val_loss: 1.4475 - val_accuracy: 0.6526\n",
      "Epoch 3757/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2715 - accuracy: 0.9062 - val_loss: 1.4659 - val_accuracy: 0.6591\n",
      "Epoch 3758/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3374 - accuracy: 0.8848 - val_loss: 1.4906 - val_accuracy: 0.6558\n",
      "Epoch 3759/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2498 - accuracy: 0.9160 - val_loss: 1.5187 - val_accuracy: 0.6494\n",
      "Epoch 3760/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2970 - accuracy: 0.8911 - val_loss: 1.5464 - val_accuracy: 0.6494\n",
      "Epoch 3761/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2608 - accuracy: 0.9078 - val_loss: 1.5805 - val_accuracy: 0.6429\n",
      "Epoch 3762/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3416 - accuracy: 0.8897 - val_loss: 1.6101 - val_accuracy: 0.6331\n",
      "Epoch 3763/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3147 - accuracy: 0.9036 - val_loss: 1.6325 - val_accuracy: 0.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3764/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3244 - accuracy: 0.8925 - val_loss: 1.6518 - val_accuracy: 0.6169\n",
      "Epoch 3765/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3124 - accuracy: 0.9043 - val_loss: 1.6625 - val_accuracy: 0.6136\n",
      "Epoch 3766/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3054 - accuracy: 0.9023 - val_loss: 1.6709 - val_accuracy: 0.6136\n",
      "Epoch 3767/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2934 - accuracy: 0.9050 - val_loss: 1.6593 - val_accuracy: 0.6006\n",
      "Epoch 3768/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3210 - accuracy: 0.8869 - val_loss: 1.6452 - val_accuracy: 0.5974\n",
      "Epoch 3769/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3077 - accuracy: 0.9023 - val_loss: 1.6347 - val_accuracy: 0.5974\n",
      "Epoch 3770/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3429 - accuracy: 0.8897 - val_loss: 1.6462 - val_accuracy: 0.5877\n",
      "Epoch 3771/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2751 - accuracy: 0.9232 - val_loss: 1.6347 - val_accuracy: 0.5942\n",
      "Epoch 3772/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2870 - accuracy: 0.9141 - val_loss: 1.6267 - val_accuracy: 0.5812\n",
      "Epoch 3773/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2979 - accuracy: 0.8980 - val_loss: 1.6188 - val_accuracy: 0.5812\n",
      "Epoch 3774/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3207 - accuracy: 0.9050 - val_loss: 1.6219 - val_accuracy: 0.5877\n",
      "Epoch 3775/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3219 - accuracy: 0.8926 - val_loss: 1.6408 - val_accuracy: 0.5942\n",
      "Epoch 3776/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3049 - accuracy: 0.9072 - val_loss: 1.6580 - val_accuracy: 0.5909\n",
      "Epoch 3777/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3145 - accuracy: 0.8945 - val_loss: 1.6785 - val_accuracy: 0.5877\n",
      "Epoch 3778/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3179 - accuracy: 0.9008 - val_loss: 1.6756 - val_accuracy: 0.6006\n",
      "Epoch 3779/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2736 - accuracy: 0.9036 - val_loss: 1.6794 - val_accuracy: 0.6071\n",
      "Epoch 3780/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2985 - accuracy: 0.9106 - val_loss: 1.6768 - val_accuracy: 0.6039\n",
      "Epoch 3781/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2768 - accuracy: 0.9102 - val_loss: 1.6476 - val_accuracy: 0.6071\n",
      "Epoch 3782/4000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3190 - accuracy: 0.9148 - val_loss: 1.6024 - val_accuracy: 0.6169\n",
      "Epoch 3783/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2879 - accuracy: 0.9043 - val_loss: 1.5601 - val_accuracy: 0.6234\n",
      "Epoch 3784/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2952 - accuracy: 0.9043 - val_loss: 1.5298 - val_accuracy: 0.6266\n",
      "Epoch 3785/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2842 - accuracy: 0.9082 - val_loss: 1.5076 - val_accuracy: 0.6299\n",
      "Epoch 3786/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3322 - accuracy: 0.8953 - val_loss: 1.4950 - val_accuracy: 0.6299\n",
      "Epoch 3787/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3589 - accuracy: 0.8877 - val_loss: 1.4851 - val_accuracy: 0.6201\n",
      "Epoch 3788/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3079 - accuracy: 0.8953 - val_loss: 1.4703 - val_accuracy: 0.6234\n",
      "Epoch 3789/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2596 - accuracy: 0.9162 - val_loss: 1.4671 - val_accuracy: 0.6266\n",
      "Epoch 3790/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3144 - accuracy: 0.9004 - val_loss: 1.4690 - val_accuracy: 0.6201\n",
      "Epoch 3791/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2702 - accuracy: 0.9092 - val_loss: 1.4691 - val_accuracy: 0.6299\n",
      "Epoch 3792/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3056 - accuracy: 0.8994 - val_loss: 1.4661 - val_accuracy: 0.6266\n",
      "Epoch 3793/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2918 - accuracy: 0.8939 - val_loss: 1.4720 - val_accuracy: 0.6331\n",
      "Epoch 3794/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2848 - accuracy: 0.8994 - val_loss: 1.4727 - val_accuracy: 0.6331\n",
      "Epoch 3795/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3076 - accuracy: 0.8975 - val_loss: 1.4708 - val_accuracy: 0.6169\n",
      "Epoch 3796/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3170 - accuracy: 0.8980 - val_loss: 1.4676 - val_accuracy: 0.6169\n",
      "Epoch 3797/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3323 - accuracy: 0.8906 - val_loss: 1.4572 - val_accuracy: 0.6331\n",
      "Epoch 3798/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2596 - accuracy: 0.9274 - val_loss: 1.4474 - val_accuracy: 0.6396\n",
      "Epoch 3799/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3038 - accuracy: 0.8994 - val_loss: 1.4358 - val_accuracy: 0.6494\n",
      "Epoch 3800/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2975 - accuracy: 0.9033 - val_loss: 1.4319 - val_accuracy: 0.6494\n",
      "Epoch 3801/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3162 - accuracy: 0.9008 - val_loss: 1.4295 - val_accuracy: 0.6494\n",
      "Epoch 3802/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2813 - accuracy: 0.9106 - val_loss: 1.4306 - val_accuracy: 0.6494\n",
      "Epoch 3803/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2899 - accuracy: 0.9176 - val_loss: 1.4310 - val_accuracy: 0.6429\n",
      "Epoch 3804/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3425 - accuracy: 0.8855 - val_loss: 1.4380 - val_accuracy: 0.6429\n",
      "Epoch 3805/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2804 - accuracy: 0.9150 - val_loss: 1.4551 - val_accuracy: 0.6494\n",
      "Epoch 3806/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2874 - accuracy: 0.9180 - val_loss: 1.4920 - val_accuracy: 0.6461\n",
      "Epoch 3807/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2901 - accuracy: 0.9111 - val_loss: 1.5490 - val_accuracy: 0.6461\n",
      "Epoch 3808/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3066 - accuracy: 0.9053 - val_loss: 1.5936 - val_accuracy: 0.6364\n",
      "Epoch 3809/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2948 - accuracy: 0.9106 - val_loss: 1.6084 - val_accuracy: 0.6299\n",
      "Epoch 3810/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3366 - accuracy: 0.8869 - val_loss: 1.5957 - val_accuracy: 0.6299\n",
      "Epoch 3811/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3239 - accuracy: 0.8966 - val_loss: 1.5633 - val_accuracy: 0.6364\n",
      "Epoch 3812/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2539 - accuracy: 0.9180 - val_loss: 1.5540 - val_accuracy: 0.6299\n",
      "Epoch 3813/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2797 - accuracy: 0.9106 - val_loss: 1.5593 - val_accuracy: 0.6429\n",
      "Epoch 3814/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2969 - accuracy: 0.8994 - val_loss: 1.5642 - val_accuracy: 0.6396\n",
      "Epoch 3815/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2733 - accuracy: 0.9218 - val_loss: 1.5592 - val_accuracy: 0.6364\n",
      "Epoch 3816/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2548 - accuracy: 0.9111 - val_loss: 1.5583 - val_accuracy: 0.6299\n",
      "Epoch 3817/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3025 - accuracy: 0.8980 - val_loss: 1.5661 - val_accuracy: 0.6364\n",
      "Epoch 3818/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3000 - accuracy: 0.8975 - val_loss: 1.5811 - val_accuracy: 0.6331\n",
      "Epoch 3819/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3198 - accuracy: 0.8926 - val_loss: 1.5763 - val_accuracy: 0.6396\n",
      "Epoch 3820/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2544 - accuracy: 0.9176 - val_loss: 1.5656 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3821/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3121 - accuracy: 0.8965 - val_loss: 1.5521 - val_accuracy: 0.6364\n",
      "Epoch 3822/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2791 - accuracy: 0.9092 - val_loss: 1.5406 - val_accuracy: 0.6396\n",
      "Epoch 3823/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2903 - accuracy: 0.9092 - val_loss: 1.5432 - val_accuracy: 0.6429\n",
      "Epoch 3824/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2944 - accuracy: 0.9148 - val_loss: 1.5430 - val_accuracy: 0.6396\n",
      "Epoch 3825/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2721 - accuracy: 0.9150 - val_loss: 1.5455 - val_accuracy: 0.6364\n",
      "Epoch 3826/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3202 - accuracy: 0.8953 - val_loss: 1.5407 - val_accuracy: 0.6396\n",
      "Epoch 3827/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3433 - accuracy: 0.9064 - val_loss: 1.5405 - val_accuracy: 0.6234\n",
      "Epoch 3828/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2645 - accuracy: 0.9134 - val_loss: 1.5314 - val_accuracy: 0.6234\n",
      "Epoch 3829/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2461 - accuracy: 0.9148 - val_loss: 1.5225 - val_accuracy: 0.6266\n",
      "Epoch 3830/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3101 - accuracy: 0.9004 - val_loss: 1.5217 - val_accuracy: 0.6266\n",
      "Epoch 3831/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3200 - accuracy: 0.8925 - val_loss: 1.5393 - val_accuracy: 0.6331\n",
      "Epoch 3832/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2962 - accuracy: 0.8994 - val_loss: 1.5802 - val_accuracy: 0.6396\n",
      "Epoch 3833/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3197 - accuracy: 0.8906 - val_loss: 1.6357 - val_accuracy: 0.6201\n",
      "Epoch 3834/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3342 - accuracy: 0.8916 - val_loss: 1.6836 - val_accuracy: 0.6136\n",
      "Epoch 3835/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2638 - accuracy: 0.9190 - val_loss: 1.7355 - val_accuracy: 0.6039\n",
      "Epoch 3836/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2741 - accuracy: 0.9082 - val_loss: 1.7705 - val_accuracy: 0.6006\n",
      "Epoch 3837/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2938 - accuracy: 0.9082 - val_loss: 1.8018 - val_accuracy: 0.5942\n",
      "Epoch 3838/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3267 - accuracy: 0.8994 - val_loss: 1.8125 - val_accuracy: 0.6006\n",
      "Epoch 3839/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3659 - accuracy: 0.8789 - val_loss: 1.7826 - val_accuracy: 0.6039\n",
      "Epoch 3840/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2874 - accuracy: 0.9078 - val_loss: 1.7416 - val_accuracy: 0.5942\n",
      "Epoch 3841/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2779 - accuracy: 0.9014 - val_loss: 1.7040 - val_accuracy: 0.5942\n",
      "Epoch 3842/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2932 - accuracy: 0.9053 - val_loss: 1.6691 - val_accuracy: 0.6169\n",
      "Epoch 3843/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2642 - accuracy: 0.9148 - val_loss: 1.6466 - val_accuracy: 0.6201\n",
      "Epoch 3844/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2799 - accuracy: 0.9053 - val_loss: 1.6318 - val_accuracy: 0.6331\n",
      "Epoch 3845/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3106 - accuracy: 0.8965 - val_loss: 1.6253 - val_accuracy: 0.6299\n",
      "Epoch 3846/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3209 - accuracy: 0.9033 - val_loss: 1.6188 - val_accuracy: 0.6266\n",
      "Epoch 3847/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2629 - accuracy: 0.9078 - val_loss: 1.6256 - val_accuracy: 0.6201\n",
      "Epoch 3848/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2652 - accuracy: 0.9082 - val_loss: 1.6381 - val_accuracy: 0.6201\n",
      "Epoch 3849/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2909 - accuracy: 0.9022 - val_loss: 1.6623 - val_accuracy: 0.6201\n",
      "Epoch 3850/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2837 - accuracy: 0.9062 - val_loss: 1.6901 - val_accuracy: 0.6006\n",
      "Epoch 3851/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3021 - accuracy: 0.8939 - val_loss: 1.7222 - val_accuracy: 0.5942\n",
      "Epoch 3852/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2634 - accuracy: 0.9120 - val_loss: 1.7647 - val_accuracy: 0.5974\n",
      "Epoch 3853/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2419 - accuracy: 0.9162 - val_loss: 1.7998 - val_accuracy: 0.5812\n",
      "Epoch 3854/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3017 - accuracy: 0.9082 - val_loss: 1.8101 - val_accuracy: 0.5779\n",
      "Epoch 3855/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2806 - accuracy: 0.9106 - val_loss: 1.7931 - val_accuracy: 0.5812\n",
      "Epoch 3856/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3024 - accuracy: 0.8980 - val_loss: 1.7537 - val_accuracy: 0.5877\n",
      "Epoch 3857/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2594 - accuracy: 0.9131 - val_loss: 1.6828 - val_accuracy: 0.6006\n",
      "Epoch 3858/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2856 - accuracy: 0.9004 - val_loss: 1.6037 - val_accuracy: 0.6136\n",
      "Epoch 3859/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2763 - accuracy: 0.9160 - val_loss: 1.5406 - val_accuracy: 0.6201\n",
      "Epoch 3860/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2684 - accuracy: 0.9170 - val_loss: 1.5055 - val_accuracy: 0.6331\n",
      "Epoch 3861/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2684 - accuracy: 0.9260 - val_loss: 1.4807 - val_accuracy: 0.6429\n",
      "Epoch 3862/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2683 - accuracy: 0.9131 - val_loss: 1.4602 - val_accuracy: 0.6494\n",
      "Epoch 3863/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3457 - accuracy: 0.8936 - val_loss: 1.4540 - val_accuracy: 0.6688\n",
      "Epoch 3864/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2921 - accuracy: 0.8966 - val_loss: 1.4521 - val_accuracy: 0.6721\n",
      "Epoch 3865/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2981 - accuracy: 0.9008 - val_loss: 1.4569 - val_accuracy: 0.6688\n",
      "Epoch 3866/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2945 - accuracy: 0.9036 - val_loss: 1.4651 - val_accuracy: 0.6591\n",
      "Epoch 3867/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2957 - accuracy: 0.8994 - val_loss: 1.4566 - val_accuracy: 0.6429\n",
      "Epoch 3868/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3285 - accuracy: 0.8896 - val_loss: 1.4457 - val_accuracy: 0.6558\n",
      "Epoch 3869/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2937 - accuracy: 0.9082 - val_loss: 1.4427 - val_accuracy: 0.6526\n",
      "Epoch 3870/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3364 - accuracy: 0.8953 - val_loss: 1.4577 - val_accuracy: 0.6526\n",
      "Epoch 3871/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2757 - accuracy: 0.9050 - val_loss: 1.4583 - val_accuracy: 0.6558\n",
      "Epoch 3872/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2838 - accuracy: 0.9062 - val_loss: 1.4612 - val_accuracy: 0.6526\n",
      "Epoch 3873/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2689 - accuracy: 0.9134 - val_loss: 1.4778 - val_accuracy: 0.6526\n",
      "Epoch 3874/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2613 - accuracy: 0.9170 - val_loss: 1.4895 - val_accuracy: 0.6461\n",
      "Epoch 3875/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3080 - accuracy: 0.8939 - val_loss: 1.5141 - val_accuracy: 0.6299\n",
      "Epoch 3876/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2799 - accuracy: 0.9004 - val_loss: 1.5442 - val_accuracy: 0.6396\n",
      "Epoch 3877/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2910 - accuracy: 0.9043 - val_loss: 1.5724 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3878/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2757 - accuracy: 0.9232 - val_loss: 1.6070 - val_accuracy: 0.6136\n",
      "Epoch 3879/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2391 - accuracy: 0.9344 - val_loss: 1.6208 - val_accuracy: 0.6104\n",
      "Epoch 3880/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3007 - accuracy: 0.9072 - val_loss: 1.6203 - val_accuracy: 0.6136\n",
      "Epoch 3881/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2739 - accuracy: 0.9111 - val_loss: 1.5833 - val_accuracy: 0.6201\n",
      "Epoch 3882/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2572 - accuracy: 0.9176 - val_loss: 1.5560 - val_accuracy: 0.6201\n",
      "Epoch 3883/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3092 - accuracy: 0.8877 - val_loss: 1.5217 - val_accuracy: 0.6169\n",
      "Epoch 3884/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2977 - accuracy: 0.9022 - val_loss: 1.4708 - val_accuracy: 0.6396\n",
      "Epoch 3885/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3180 - accuracy: 0.8906 - val_loss: 1.4248 - val_accuracy: 0.6558\n",
      "Epoch 3886/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2604 - accuracy: 0.9141 - val_loss: 1.4213 - val_accuracy: 0.6591\n",
      "Epoch 3887/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2611 - accuracy: 0.9148 - val_loss: 1.4151 - val_accuracy: 0.6656\n",
      "Epoch 3888/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4002 - accuracy: 0.8955 - val_loss: 1.4089 - val_accuracy: 0.6721\n",
      "Epoch 3889/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2882 - accuracy: 0.9111 - val_loss: 1.4315 - val_accuracy: 0.6656\n",
      "Epoch 3890/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3144 - accuracy: 0.9008 - val_loss: 1.4573 - val_accuracy: 0.6656\n",
      "Epoch 3891/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3051 - accuracy: 0.8994 - val_loss: 1.4977 - val_accuracy: 0.6526\n",
      "Epoch 3892/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2819 - accuracy: 0.9053 - val_loss: 1.5334 - val_accuracy: 0.6494\n",
      "Epoch 3893/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2658 - accuracy: 0.9219 - val_loss: 1.5625 - val_accuracy: 0.6429\n",
      "Epoch 3894/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3059 - accuracy: 0.8975 - val_loss: 1.5885 - val_accuracy: 0.6396\n",
      "Epoch 3895/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3106 - accuracy: 0.9004 - val_loss: 1.6057 - val_accuracy: 0.6364\n",
      "Epoch 3896/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3077 - accuracy: 0.9120 - val_loss: 1.6258 - val_accuracy: 0.6201\n",
      "Epoch 3897/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2856 - accuracy: 0.9078 - val_loss: 1.6275 - val_accuracy: 0.6039\n",
      "Epoch 3898/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2932 - accuracy: 0.9014 - val_loss: 1.6321 - val_accuracy: 0.6039\n",
      "Epoch 3899/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3000 - accuracy: 0.9092 - val_loss: 1.6375 - val_accuracy: 0.6169\n",
      "Epoch 3900/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2819 - accuracy: 0.9023 - val_loss: 1.6719 - val_accuracy: 0.6136\n",
      "Epoch 3901/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2801 - accuracy: 0.9064 - val_loss: 1.7098 - val_accuracy: 0.6039\n",
      "Epoch 3902/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2904 - accuracy: 0.9053 - val_loss: 1.7266 - val_accuracy: 0.6006\n",
      "Epoch 3903/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2900 - accuracy: 0.9078 - val_loss: 1.7443 - val_accuracy: 0.6104\n",
      "Epoch 3904/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3012 - accuracy: 0.9141 - val_loss: 1.7554 - val_accuracy: 0.6071\n",
      "Epoch 3905/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2728 - accuracy: 0.9148 - val_loss: 1.7630 - val_accuracy: 0.6039\n",
      "Epoch 3906/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2571 - accuracy: 0.9131 - val_loss: 1.7497 - val_accuracy: 0.6071\n",
      "Epoch 3907/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3237 - accuracy: 0.9064 - val_loss: 1.7002 - val_accuracy: 0.5974\n",
      "Epoch 3908/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3115 - accuracy: 0.8965 - val_loss: 1.6803 - val_accuracy: 0.6006\n",
      "Epoch 3909/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2999 - accuracy: 0.9004 - val_loss: 1.6459 - val_accuracy: 0.6136\n",
      "Epoch 3910/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2997 - accuracy: 0.9111 - val_loss: 1.6092 - val_accuracy: 0.6234\n",
      "Epoch 3911/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2765 - accuracy: 0.9092 - val_loss: 1.5959 - val_accuracy: 0.6266\n",
      "Epoch 3912/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2873 - accuracy: 0.9033 - val_loss: 1.5847 - val_accuracy: 0.6234\n",
      "Epoch 3913/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3136 - accuracy: 0.9008 - val_loss: 1.5696 - val_accuracy: 0.6234\n",
      "Epoch 3914/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3084 - accuracy: 0.9064 - val_loss: 1.5569 - val_accuracy: 0.6331\n",
      "Epoch 3915/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2884 - accuracy: 0.9148 - val_loss: 1.5393 - val_accuracy: 0.6299\n",
      "Epoch 3916/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3004 - accuracy: 0.9053 - val_loss: 1.5300 - val_accuracy: 0.6396\n",
      "Epoch 3917/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2716 - accuracy: 0.9092 - val_loss: 1.5286 - val_accuracy: 0.6364\n",
      "Epoch 3918/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3149 - accuracy: 0.9043 - val_loss: 1.5331 - val_accuracy: 0.6396\n",
      "Epoch 3919/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2837 - accuracy: 0.9150 - val_loss: 1.5368 - val_accuracy: 0.6396\n",
      "Epoch 3920/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2799 - accuracy: 0.9053 - val_loss: 1.5447 - val_accuracy: 0.6429\n",
      "Epoch 3921/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2710 - accuracy: 0.8994 - val_loss: 1.5453 - val_accuracy: 0.6429\n",
      "Epoch 3922/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3024 - accuracy: 0.9008 - val_loss: 1.5340 - val_accuracy: 0.6494\n",
      "Epoch 3923/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2930 - accuracy: 0.9062 - val_loss: 1.5247 - val_accuracy: 0.6364\n",
      "Epoch 3924/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2636 - accuracy: 0.9134 - val_loss: 1.5253 - val_accuracy: 0.6364\n",
      "Epoch 3925/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2687 - accuracy: 0.9131 - val_loss: 1.5359 - val_accuracy: 0.6364\n",
      "Epoch 3926/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2534 - accuracy: 0.9232 - val_loss: 1.5401 - val_accuracy: 0.6396\n",
      "Epoch 3927/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2812 - accuracy: 0.9064 - val_loss: 1.5336 - val_accuracy: 0.6461\n",
      "Epoch 3928/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2881 - accuracy: 0.9141 - val_loss: 1.5277 - val_accuracy: 0.6429\n",
      "Epoch 3929/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3074 - accuracy: 0.9062 - val_loss: 1.5248 - val_accuracy: 0.6429\n",
      "Epoch 3930/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3051 - accuracy: 0.8939 - val_loss: 1.5210 - val_accuracy: 0.6526\n",
      "Epoch 3931/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2716 - accuracy: 0.9176 - val_loss: 1.5231 - val_accuracy: 0.6526\n",
      "Epoch 3932/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2360 - accuracy: 0.9232 - val_loss: 1.5284 - val_accuracy: 0.6494\n",
      "Epoch 3933/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3783 - accuracy: 0.8841 - val_loss: 1.5213 - val_accuracy: 0.6429\n",
      "Epoch 3934/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3144 - accuracy: 0.8848 - val_loss: 1.5188 - val_accuracy: 0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3935/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2906 - accuracy: 0.9064 - val_loss: 1.5131 - val_accuracy: 0.6234\n",
      "Epoch 3936/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2726 - accuracy: 0.9102 - val_loss: 1.5055 - val_accuracy: 0.6169\n",
      "Epoch 3937/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2850 - accuracy: 0.9053 - val_loss: 1.4993 - val_accuracy: 0.6234\n",
      "Epoch 3938/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3350 - accuracy: 0.8896 - val_loss: 1.4905 - val_accuracy: 0.6234\n",
      "Epoch 3939/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2695 - accuracy: 0.9043 - val_loss: 1.4837 - val_accuracy: 0.6299\n",
      "Epoch 3940/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2886 - accuracy: 0.9033 - val_loss: 1.4828 - val_accuracy: 0.6364\n",
      "Epoch 3941/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3073 - accuracy: 0.9036 - val_loss: 1.4953 - val_accuracy: 0.6266\n",
      "Epoch 3942/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2696 - accuracy: 0.9134 - val_loss: 1.5196 - val_accuracy: 0.6299\n",
      "Epoch 3943/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2760 - accuracy: 0.9082 - val_loss: 1.5473 - val_accuracy: 0.6234\n",
      "Epoch 3944/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3256 - accuracy: 0.8897 - val_loss: 1.5748 - val_accuracy: 0.6299\n",
      "Epoch 3945/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2804 - accuracy: 0.9120 - val_loss: 1.5920 - val_accuracy: 0.6201\n",
      "Epoch 3946/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2425 - accuracy: 0.9268 - val_loss: 1.6058 - val_accuracy: 0.6136\n",
      "Epoch 3947/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2954 - accuracy: 0.9120 - val_loss: 1.5904 - val_accuracy: 0.6136\n",
      "Epoch 3948/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2937 - accuracy: 0.9092 - val_loss: 1.5540 - val_accuracy: 0.6071\n",
      "Epoch 3949/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2899 - accuracy: 0.9064 - val_loss: 1.4987 - val_accuracy: 0.6071\n",
      "Epoch 3950/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2622 - accuracy: 0.9141 - val_loss: 1.4554 - val_accuracy: 0.6136\n",
      "Epoch 3951/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2960 - accuracy: 0.8984 - val_loss: 1.4143 - val_accuracy: 0.6494\n",
      "Epoch 3952/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2897 - accuracy: 0.9148 - val_loss: 1.3876 - val_accuracy: 0.6591\n",
      "Epoch 3953/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3229 - accuracy: 0.8994 - val_loss: 1.3769 - val_accuracy: 0.6591\n",
      "Epoch 3954/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3430 - accuracy: 0.9023 - val_loss: 1.3792 - val_accuracy: 0.6623\n",
      "Epoch 3955/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2830 - accuracy: 0.9082 - val_loss: 1.3935 - val_accuracy: 0.6721\n",
      "Epoch 3956/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3180 - accuracy: 0.9053 - val_loss: 1.4060 - val_accuracy: 0.6558\n",
      "Epoch 3957/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3088 - accuracy: 0.9082 - val_loss: 1.4277 - val_accuracy: 0.6526\n",
      "Epoch 3958/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2469 - accuracy: 0.9176 - val_loss: 1.4578 - val_accuracy: 0.6461\n",
      "Epoch 3959/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2936 - accuracy: 0.9092 - val_loss: 1.4967 - val_accuracy: 0.6364\n",
      "Epoch 3960/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3159 - accuracy: 0.8966 - val_loss: 1.5348 - val_accuracy: 0.6364\n",
      "Epoch 3961/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2682 - accuracy: 0.9043 - val_loss: 1.5408 - val_accuracy: 0.6299\n",
      "Epoch 3962/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3000 - accuracy: 0.9022 - val_loss: 1.5088 - val_accuracy: 0.6429\n",
      "Epoch 3963/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2833 - accuracy: 0.9190 - val_loss: 1.4796 - val_accuracy: 0.6396\n",
      "Epoch 3964/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3324 - accuracy: 0.9023 - val_loss: 1.4538 - val_accuracy: 0.6461\n",
      "Epoch 3965/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2823 - accuracy: 0.8984 - val_loss: 1.4254 - val_accuracy: 0.6591\n",
      "Epoch 3966/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3568 - accuracy: 0.8939 - val_loss: 1.4041 - val_accuracy: 0.6688\n",
      "Epoch 3967/4000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3118 - accuracy: 0.9022 - val_loss: 1.3909 - val_accuracy: 0.6558\n",
      "Epoch 3968/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2297 - accuracy: 0.9204 - val_loss: 1.3966 - val_accuracy: 0.6494\n",
      "Epoch 3969/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2923 - accuracy: 0.9120 - val_loss: 1.3985 - val_accuracy: 0.6494\n",
      "Epoch 3970/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2442 - accuracy: 0.9072 - val_loss: 1.4040 - val_accuracy: 0.6623\n",
      "Epoch 3971/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2876 - accuracy: 0.9092 - val_loss: 1.4157 - val_accuracy: 0.6526\n",
      "Epoch 3972/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2761 - accuracy: 0.9199 - val_loss: 1.4322 - val_accuracy: 0.6526\n",
      "Epoch 3973/4000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3295 - accuracy: 0.8939 - val_loss: 1.4724 - val_accuracy: 0.6364\n",
      "Epoch 3974/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2679 - accuracy: 0.9199 - val_loss: 1.5312 - val_accuracy: 0.6266\n",
      "Epoch 3975/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2817 - accuracy: 0.9078 - val_loss: 1.5949 - val_accuracy: 0.6201\n",
      "Epoch 3976/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2829 - accuracy: 0.8984 - val_loss: 1.6126 - val_accuracy: 0.6136\n",
      "Epoch 3977/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3392 - accuracy: 0.8925 - val_loss: 1.5675 - val_accuracy: 0.6169\n",
      "Epoch 3978/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3241 - accuracy: 0.8939 - val_loss: 1.5063 - val_accuracy: 0.6299\n",
      "Epoch 3979/4000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3297 - accuracy: 0.8953 - val_loss: 1.4734 - val_accuracy: 0.6331\n",
      "Epoch 3980/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3077 - accuracy: 0.8945 - val_loss: 1.4473 - val_accuracy: 0.6299\n",
      "Epoch 3981/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3349 - accuracy: 0.8867 - val_loss: 1.4392 - val_accuracy: 0.6234\n",
      "Epoch 3982/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3042 - accuracy: 0.8955 - val_loss: 1.4419 - val_accuracy: 0.6364\n",
      "Epoch 3983/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2948 - accuracy: 0.9014 - val_loss: 1.4430 - val_accuracy: 0.6396\n",
      "Epoch 3984/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2881 - accuracy: 0.9064 - val_loss: 1.4547 - val_accuracy: 0.6299\n",
      "Epoch 3985/4000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3025 - accuracy: 0.9092 - val_loss: 1.4668 - val_accuracy: 0.6234\n",
      "Epoch 3986/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2792 - accuracy: 0.9092 - val_loss: 1.4728 - val_accuracy: 0.6396\n",
      "Epoch 3987/4000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2669 - accuracy: 0.9120 - val_loss: 1.4875 - val_accuracy: 0.6364\n",
      "Epoch 3988/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2657 - accuracy: 0.9111 - val_loss: 1.5096 - val_accuracy: 0.6299\n",
      "Epoch 3989/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3062 - accuracy: 0.9004 - val_loss: 1.5220 - val_accuracy: 0.6234\n",
      "Epoch 3990/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2755 - accuracy: 0.9106 - val_loss: 1.5149 - val_accuracy: 0.6331\n",
      "Epoch 3991/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2722 - accuracy: 0.9199 - val_loss: 1.5279 - val_accuracy: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3992/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2761 - accuracy: 0.9033 - val_loss: 1.5566 - val_accuracy: 0.6169\n",
      "Epoch 3993/4000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2464 - accuracy: 0.9036 - val_loss: 1.5567 - val_accuracy: 0.6169\n",
      "Epoch 3994/4000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3355 - accuracy: 0.8925 - val_loss: 1.5282 - val_accuracy: 0.6136\n",
      "Epoch 3995/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2507 - accuracy: 0.9218 - val_loss: 1.5136 - val_accuracy: 0.6201\n",
      "Epoch 3996/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3037 - accuracy: 0.8994 - val_loss: 1.5035 - val_accuracy: 0.6234\n",
      "Epoch 3997/4000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2772 - accuracy: 0.9218 - val_loss: 1.4810 - val_accuracy: 0.6299\n",
      "Epoch 3998/4000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2962 - accuracy: 0.9014 - val_loss: 1.4771 - val_accuracy: 0.6461\n",
      "Epoch 3999/4000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2784 - accuracy: 0.8994 - val_loss: 1.4792 - val_accuracy: 0.6429\n",
      "Epoch 4000/4000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2982 - accuracy: 0.9078 - val_loss: 1.4857 - val_accuracy: 0.6461\n",
      "CNN: Epochs=4000, Train accuracy=0.93436, Validation accuracy=0.69805\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "batch_size = 128\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AN-n4oXHFhB"
   },
   "outputs": [],
   "source": [
    "#k-fold로 훈련시키기\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "epochs = 800\n",
    "batch_size = 512\n",
    "\n",
    "for k_train_index, k_valid_index in kf.split(X, y):\n",
    "    history = model.fit(\n",
    "    datagen.flow(X[k_train_index,:], y[k_train_index,:], batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=X[k_train_index,:].shape[0]//batch_size,\n",
    "    validation_data=(X[k_valid_index,:], y[k_valid_index,:]),\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2603262,
     "status": "ok",
     "timestamp": 1598167802346,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "MaRzqpQmHFhD",
    "outputId": "9bcd067b-5514-491c-8c63-db77d4fc6967"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####relu 대신 leaky relu 써보자########\n",
    "#####Adam보단 RMSprop이 좋은 듯도?######\n",
    "#####후에 early stopping도 추가 ########\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHMuMFz1DsU2"
   },
   "outputs": [],
   "source": [
    "#model_10\n",
    "from tensorflow import keras\n",
    "#model_9-3 9-2에서 optimizer만 RMSprop로 바꿔봄\n",
    "from tensorflow import keras\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add,\n",
    "    Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), Adagrad(lr=0.01, epsilon=None, decay=0.0), adadelta, adam\n",
    "    model.compile(optimizer=RMSprop(lr=0.001, rho=0.95, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1598177058258,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "Lmn384nZDysV",
    "outputId": "5f3b3b04-604f-410c-ac92-0ec2f300de42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1201 (Conv2D)         (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1157 (Ba (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_630 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1202 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1158 (Ba (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_631 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1203 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1159 (Ba (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_632 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1204 (Conv2D)         (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1160 (Ba (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_633 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1205 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1161 (Ba (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_634 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1206 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1162 (Ba (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_635 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1207 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1163 (Ba (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_636 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1208 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1164 (Ba (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_637 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1209 (Conv2D)         (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1165 (Ba (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_638 (LeakyReLU)  (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_31  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_639 (LeakyReLU)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 125,392\n",
      "Trainable params: 124,720\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVsg_v1KD4rr"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.975 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 858204,
     "status": "ok",
     "timestamp": 1598177916752,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "_YuoyhnFD7qj",
    "outputId": "9a9e2baa-b85e-405f-d605-310f7ff15302",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 2.4998 - accuracy: 0.1276 - val_loss: 2.2552 - val_accuracy: 0.1526\n",
      "Epoch 2/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.2659 - accuracy: 0.1593 - val_loss: 2.1527 - val_accuracy: 0.2273\n",
      "Epoch 3/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.1901 - accuracy: 0.1868 - val_loss: 2.3029 - val_accuracy: 0.1201\n",
      "Epoch 4/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.1149 - accuracy: 0.2330 - val_loss: 2.4806 - val_accuracy: 0.1039\n",
      "Epoch 5/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.0548 - accuracy: 0.2617 - val_loss: 3.0083 - val_accuracy: 0.1039\n",
      "Epoch 6/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.9871 - accuracy: 0.2875 - val_loss: 2.8759 - val_accuracy: 0.1039\n",
      "Epoch 7/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.8967 - accuracy: 0.3226 - val_loss: 2.7598 - val_accuracy: 0.1169\n",
      "Epoch 8/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.8031 - accuracy: 0.3618 - val_loss: 3.1314 - val_accuracy: 0.1234\n",
      "Epoch 9/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.7294 - accuracy: 0.3852 - val_loss: 1.8271 - val_accuracy: 0.4221\n",
      "Epoch 10/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.6769 - accuracy: 0.3958 - val_loss: 1.2876 - val_accuracy: 0.6234\n",
      "Epoch 11/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.5821 - accuracy: 0.4420 - val_loss: 1.3205 - val_accuracy: 0.5877\n",
      "Epoch 12/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.5320 - accuracy: 0.4693 - val_loss: 1.2170 - val_accuracy: 0.6136\n",
      "Epoch 13/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.4765 - accuracy: 0.4795 - val_loss: 1.2912 - val_accuracy: 0.5877\n",
      "Epoch 14/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.4124 - accuracy: 0.5146 - val_loss: 1.2951 - val_accuracy: 0.5714\n",
      "Epoch 15/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 1.3823 - accuracy: 0.5187 - val_loss: 1.4694 - val_accuracy: 0.5065\n",
      "Epoch 16/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.3816 - accuracy: 0.5018 - val_loss: 1.0159 - val_accuracy: 0.6688\n",
      "Epoch 17/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.2975 - accuracy: 0.5527 - val_loss: 1.0708 - val_accuracy: 0.6429\n",
      "Epoch 18/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.2263 - accuracy: 0.5796 - val_loss: 0.9438 - val_accuracy: 0.6818\n",
      "Epoch 19/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.2246 - accuracy: 0.5790 - val_loss: 1.0757 - val_accuracy: 0.6429\n",
      "Epoch 20/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.1714 - accuracy: 0.6060 - val_loss: 0.8871 - val_accuracy: 0.6883\n",
      "Epoch 21/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.1384 - accuracy: 0.6189 - val_loss: 0.8942 - val_accuracy: 0.6883\n",
      "Epoch 22/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.1424 - accuracy: 0.6171 - val_loss: 0.8996 - val_accuracy: 0.6851\n",
      "Epoch 23/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.0789 - accuracy: 0.6352 - val_loss: 0.7822 - val_accuracy: 0.7338\n",
      "Epoch 24/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.0897 - accuracy: 0.6306 - val_loss: 0.7925 - val_accuracy: 0.7338\n",
      "Epoch 25/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 1.0528 - accuracy: 0.6411 - val_loss: 0.7672 - val_accuracy: 0.7338\n",
      "Epoch 26/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9782 - accuracy: 0.6569 - val_loss: 0.6813 - val_accuracy: 0.7727\n",
      "Epoch 27/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9853 - accuracy: 0.6692 - val_loss: 0.7866 - val_accuracy: 0.7370\n",
      "Epoch 28/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9913 - accuracy: 0.6628 - val_loss: 0.8792 - val_accuracy: 0.7013\n",
      "Epoch 29/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9389 - accuracy: 0.6797 - val_loss: 0.7541 - val_accuracy: 0.7403\n",
      "Epoch 30/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9157 - accuracy: 0.6821 - val_loss: 0.9700 - val_accuracy: 0.6688\n",
      "Epoch 31/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9173 - accuracy: 0.6944 - val_loss: 0.6722 - val_accuracy: 0.7695\n",
      "Epoch 32/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.9178 - accuracy: 0.6909 - val_loss: 0.7221 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8738 - accuracy: 0.6915 - val_loss: 0.7235 - val_accuracy: 0.7597\n",
      "Epoch 34/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8717 - accuracy: 0.7067 - val_loss: 0.6963 - val_accuracy: 0.7727\n",
      "Epoch 35/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8594 - accuracy: 0.7190 - val_loss: 0.8186 - val_accuracy: 0.7175\n",
      "Epoch 36/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8376 - accuracy: 0.7149 - val_loss: 0.6815 - val_accuracy: 0.7825\n",
      "Epoch 37/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8354 - accuracy: 0.7084 - val_loss: 0.8090 - val_accuracy: 0.7305\n",
      "Epoch 38/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8459 - accuracy: 0.7137 - val_loss: 0.6092 - val_accuracy: 0.7955\n",
      "Epoch 39/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8059 - accuracy: 0.7336 - val_loss: 0.7836 - val_accuracy: 0.7338\n",
      "Epoch 40/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8178 - accuracy: 0.7219 - val_loss: 0.6750 - val_accuracy: 0.7597\n",
      "Epoch 41/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7811 - accuracy: 0.7254 - val_loss: 0.6522 - val_accuracy: 0.7630\n",
      "Epoch 42/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7963 - accuracy: 0.7365 - val_loss: 0.7445 - val_accuracy: 0.7435\n",
      "Epoch 43/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8059 - accuracy: 0.7196 - val_loss: 0.6496 - val_accuracy: 0.7857\n",
      "Epoch 44/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.8114 - accuracy: 0.7149 - val_loss: 0.7443 - val_accuracy: 0.7305\n",
      "Epoch 45/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7662 - accuracy: 0.7500 - val_loss: 0.6249 - val_accuracy: 0.7792\n",
      "Epoch 46/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7500 - accuracy: 0.7383 - val_loss: 0.6272 - val_accuracy: 0.7890\n",
      "Epoch 47/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7456 - accuracy: 0.7447 - val_loss: 0.7600 - val_accuracy: 0.7468\n",
      "Epoch 48/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7262 - accuracy: 0.7488 - val_loss: 0.5925 - val_accuracy: 0.7987\n",
      "Epoch 49/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7260 - accuracy: 0.7412 - val_loss: 0.6221 - val_accuracy: 0.8019\n",
      "Epoch 50/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7505 - accuracy: 0.7559 - val_loss: 0.7101 - val_accuracy: 0.7435\n",
      "Epoch 51/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7277 - accuracy: 0.7535 - val_loss: 0.6287 - val_accuracy: 0.7857\n",
      "Epoch 52/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7258 - accuracy: 0.7465 - val_loss: 0.5989 - val_accuracy: 0.8052\n",
      "Epoch 53/150\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.6988 - accuracy: 0.7652 - val_loss: 0.6240 - val_accuracy: 0.7825\n",
      "Epoch 54/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7062 - accuracy: 0.7541 - val_loss: 0.6481 - val_accuracy: 0.8019\n",
      "Epoch 55/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6977 - accuracy: 0.7711 - val_loss: 0.6163 - val_accuracy: 0.7987\n",
      "Epoch 56/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6929 - accuracy: 0.7570 - val_loss: 0.6802 - val_accuracy: 0.7792\n",
      "Epoch 57/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.7194 - accuracy: 0.7529 - val_loss: 0.6242 - val_accuracy: 0.7890\n",
      "Epoch 58/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6953 - accuracy: 0.7605 - val_loss: 0.6067 - val_accuracy: 0.8019\n",
      "Epoch 59/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6613 - accuracy: 0.7758 - val_loss: 0.6572 - val_accuracy: 0.7760\n",
      "Epoch 60/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6696 - accuracy: 0.7681 - val_loss: 0.8487 - val_accuracy: 0.7273\n",
      "Epoch 61/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6757 - accuracy: 0.7646 - val_loss: 0.7014 - val_accuracy: 0.7662\n",
      "Epoch 62/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6608 - accuracy: 0.7670 - val_loss: 0.6366 - val_accuracy: 0.7857\n",
      "Epoch 63/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6320 - accuracy: 0.7881 - val_loss: 0.7097 - val_accuracy: 0.7695\n",
      "Epoch 64/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6651 - accuracy: 0.7693 - val_loss: 0.6045 - val_accuracy: 0.7987\n",
      "Epoch 65/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6655 - accuracy: 0.7641 - val_loss: 0.6040 - val_accuracy: 0.7987\n",
      "Epoch 66/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6524 - accuracy: 0.7664 - val_loss: 0.6303 - val_accuracy: 0.8052\n",
      "Epoch 67/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6729 - accuracy: 0.7810 - val_loss: 0.6506 - val_accuracy: 0.7890\n",
      "Epoch 68/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6340 - accuracy: 0.7951 - val_loss: 0.6675 - val_accuracy: 0.7565\n",
      "Epoch 69/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6644 - accuracy: 0.7752 - val_loss: 0.5886 - val_accuracy: 0.8182\n",
      "Epoch 70/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6400 - accuracy: 0.7804 - val_loss: 0.5669 - val_accuracy: 0.7955\n",
      "Epoch 71/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6376 - accuracy: 0.7822 - val_loss: 0.5742 - val_accuracy: 0.8117\n",
      "Epoch 72/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6627 - accuracy: 0.7863 - val_loss: 0.6134 - val_accuracy: 0.8182\n",
      "Epoch 73/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6027 - accuracy: 0.7986 - val_loss: 0.6403 - val_accuracy: 0.7987\n",
      "Epoch 74/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6432 - accuracy: 0.7910 - val_loss: 0.6138 - val_accuracy: 0.7922\n",
      "Epoch 75/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6152 - accuracy: 0.7957 - val_loss: 0.5987 - val_accuracy: 0.8084\n",
      "Epoch 76/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6078 - accuracy: 0.7904 - val_loss: 0.6446 - val_accuracy: 0.7857\n",
      "Epoch 77/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6203 - accuracy: 0.7810 - val_loss: 0.6096 - val_accuracy: 0.7922\n",
      "Epoch 78/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6308 - accuracy: 0.7828 - val_loss: 0.6246 - val_accuracy: 0.7987\n",
      "Epoch 79/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6240 - accuracy: 0.7822 - val_loss: 0.6460 - val_accuracy: 0.7857\n",
      "Epoch 80/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6232 - accuracy: 0.7851 - val_loss: 0.6637 - val_accuracy: 0.7825\n",
      "Epoch 81/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6052 - accuracy: 0.7945 - val_loss: 0.7033 - val_accuracy: 0.7630\n",
      "Epoch 82/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6134 - accuracy: 0.7881 - val_loss: 0.5900 - val_accuracy: 0.7792\n",
      "Epoch 83/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6014 - accuracy: 0.7910 - val_loss: 0.6836 - val_accuracy: 0.7760\n",
      "Epoch 84/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5992 - accuracy: 0.7986 - val_loss: 0.6291 - val_accuracy: 0.7955\n",
      "Epoch 85/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5965 - accuracy: 0.8015 - val_loss: 0.6344 - val_accuracy: 0.7922\n",
      "Epoch 86/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6191 - accuracy: 0.7886 - val_loss: 0.6093 - val_accuracy: 0.7890\n",
      "Epoch 87/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6049 - accuracy: 0.7933 - val_loss: 0.6477 - val_accuracy: 0.7825\n",
      "Epoch 88/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5972 - accuracy: 0.7951 - val_loss: 0.5780 - val_accuracy: 0.8182\n",
      "Epoch 89/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6217 - accuracy: 0.7904 - val_loss: 0.5783 - val_accuracy: 0.8117\n",
      "Epoch 90/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.6283 - accuracy: 0.7886 - val_loss: 0.6178 - val_accuracy: 0.8019\n",
      "Epoch 91/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5556 - accuracy: 0.8085 - val_loss: 0.5905 - val_accuracy: 0.8084\n",
      "Epoch 92/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5792 - accuracy: 0.8085 - val_loss: 0.6331 - val_accuracy: 0.8019\n",
      "Epoch 93/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5812 - accuracy: 0.7904 - val_loss: 0.6477 - val_accuracy: 0.7825\n",
      "Epoch 94/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5970 - accuracy: 0.7945 - val_loss: 0.6084 - val_accuracy: 0.8019\n",
      "Epoch 95/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5827 - accuracy: 0.7998 - val_loss: 0.6296 - val_accuracy: 0.7760\n",
      "Epoch 96/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5704 - accuracy: 0.8103 - val_loss: 0.5769 - val_accuracy: 0.8052\n",
      "Epoch 97/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5970 - accuracy: 0.7904 - val_loss: 0.6054 - val_accuracy: 0.7955\n",
      "Epoch 98/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5966 - accuracy: 0.7998 - val_loss: 0.5896 - val_accuracy: 0.8019\n",
      "Epoch 99/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5565 - accuracy: 0.8050 - val_loss: 0.6189 - val_accuracy: 0.7922\n",
      "Epoch 100/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5815 - accuracy: 0.8142 - val_loss: 0.6427 - val_accuracy: 0.7890\n",
      "Epoch 101/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5558 - accuracy: 0.8091 - val_loss: 0.6597 - val_accuracy: 0.7695\n",
      "Epoch 102/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5649 - accuracy: 0.8208 - val_loss: 0.6526 - val_accuracy: 0.7760\n",
      "Epoch 103/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5582 - accuracy: 0.8080 - val_loss: 0.6199 - val_accuracy: 0.7792\n",
      "Epoch 104/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5485 - accuracy: 0.8004 - val_loss: 0.6102 - val_accuracy: 0.8052\n",
      "Epoch 105/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5762 - accuracy: 0.7992 - val_loss: 0.6148 - val_accuracy: 0.8019\n",
      "Epoch 106/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5449 - accuracy: 0.8109 - val_loss: 0.5861 - val_accuracy: 0.7987\n",
      "Epoch 107/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5728 - accuracy: 0.8068 - val_loss: 0.5534 - val_accuracy: 0.8084\n",
      "Epoch 108/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5739 - accuracy: 0.8039 - val_loss: 0.6319 - val_accuracy: 0.7825\n",
      "Epoch 109/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5926 - accuracy: 0.7968 - val_loss: 0.6230 - val_accuracy: 0.7825\n",
      "Epoch 110/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5398 - accuracy: 0.8156 - val_loss: 0.6177 - val_accuracy: 0.7922\n",
      "Epoch 111/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5507 - accuracy: 0.8121 - val_loss: 0.5872 - val_accuracy: 0.7987\n",
      "Epoch 112/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5678 - accuracy: 0.8074 - val_loss: 0.5963 - val_accuracy: 0.7955\n",
      "Epoch 113/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5877 - accuracy: 0.7869 - val_loss: 0.5938 - val_accuracy: 0.7987\n",
      "Epoch 114/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5390 - accuracy: 0.8144 - val_loss: 0.6080 - val_accuracy: 0.7922\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5488 - accuracy: 0.8021 - val_loss: 0.5931 - val_accuracy: 0.7890\n",
      "Epoch 116/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5346 - accuracy: 0.8197 - val_loss: 0.6279 - val_accuracy: 0.7955\n",
      "Epoch 117/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5494 - accuracy: 0.8138 - val_loss: 0.6057 - val_accuracy: 0.7922\n",
      "Epoch 118/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5358 - accuracy: 0.8208 - val_loss: 0.6448 - val_accuracy: 0.7857\n",
      "Epoch 119/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5234 - accuracy: 0.8185 - val_loss: 0.6424 - val_accuracy: 0.7792\n",
      "Epoch 120/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8197 - val_loss: 0.6297 - val_accuracy: 0.7825\n",
      "Epoch 121/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5419 - accuracy: 0.8050 - val_loss: 0.6185 - val_accuracy: 0.7890\n",
      "Epoch 122/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5313 - accuracy: 0.8132 - val_loss: 0.6142 - val_accuracy: 0.7922\n",
      "Epoch 123/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5291 - accuracy: 0.8074 - val_loss: 0.6259 - val_accuracy: 0.7857\n",
      "Epoch 124/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5717 - accuracy: 0.8109 - val_loss: 0.6011 - val_accuracy: 0.7955\n",
      "Epoch 125/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5470 - accuracy: 0.8068 - val_loss: 0.5836 - val_accuracy: 0.8084\n",
      "Epoch 126/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8056 - val_loss: 0.6075 - val_accuracy: 0.8019\n",
      "Epoch 127/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5169 - accuracy: 0.8279 - val_loss: 0.6067 - val_accuracy: 0.7890\n",
      "Epoch 128/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5248 - accuracy: 0.8290 - val_loss: 0.6456 - val_accuracy: 0.7825\n",
      "Epoch 129/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5331 - accuracy: 0.8214 - val_loss: 0.5859 - val_accuracy: 0.8019\n",
      "Epoch 130/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5741 - accuracy: 0.8091 - val_loss: 0.5804 - val_accuracy: 0.8214\n",
      "Epoch 131/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5071 - accuracy: 0.8349 - val_loss: 0.6237 - val_accuracy: 0.7857\n",
      "Epoch 132/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5542 - accuracy: 0.8050 - val_loss: 0.5969 - val_accuracy: 0.8052\n",
      "Epoch 133/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5382 - accuracy: 0.8138 - val_loss: 0.6054 - val_accuracy: 0.8019\n",
      "Epoch 134/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8121 - val_loss: 0.6200 - val_accuracy: 0.7922\n",
      "Epoch 135/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5653 - accuracy: 0.8103 - val_loss: 0.5936 - val_accuracy: 0.7987\n",
      "Epoch 136/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5032 - accuracy: 0.8167 - val_loss: 0.6319 - val_accuracy: 0.7857\n",
      "Epoch 137/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5513 - accuracy: 0.8115 - val_loss: 0.6192 - val_accuracy: 0.7922\n",
      "Epoch 138/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5346 - accuracy: 0.8097 - val_loss: 0.6215 - val_accuracy: 0.7955\n",
      "Epoch 139/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5496 - accuracy: 0.8144 - val_loss: 0.6068 - val_accuracy: 0.7922\n",
      "Epoch 140/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.4722 - accuracy: 0.8367 - val_loss: 0.6097 - val_accuracy: 0.7890\n",
      "Epoch 141/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5471 - accuracy: 0.8138 - val_loss: 0.6330 - val_accuracy: 0.7760\n",
      "Epoch 142/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5260 - accuracy: 0.8273 - val_loss: 0.6185 - val_accuracy: 0.7825\n",
      "Epoch 143/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5475 - accuracy: 0.8068 - val_loss: 0.6198 - val_accuracy: 0.7987\n",
      "Epoch 144/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.4780 - accuracy: 0.8367 - val_loss: 0.6033 - val_accuracy: 0.7987\n",
      "Epoch 145/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5080 - accuracy: 0.8208 - val_loss: 0.6197 - val_accuracy: 0.7890\n",
      "Epoch 146/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5259 - accuracy: 0.8132 - val_loss: 0.6196 - val_accuracy: 0.7922\n",
      "Epoch 147/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5112 - accuracy: 0.8343 - val_loss: 0.5957 - val_accuracy: 0.7987\n",
      "Epoch 148/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5390 - accuracy: 0.8285 - val_loss: 0.6055 - val_accuracy: 0.7987\n",
      "Epoch 149/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5543 - accuracy: 0.8156 - val_loss: 0.6071 - val_accuracy: 0.7922\n",
      "Epoch 150/150\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.5114 - accuracy: 0.8249 - val_loss: 0.6284 - val_accuracy: 0.7825\n",
      "CNN: Epochs=150, Train accuracy=0.83665, Validation accuracy=0.82143\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ztjVtlqWD_Nb"
   },
   "outputs": [],
   "source": [
    "#9까지는 콘볼루션 층 9개에 맥스풀링과 FC 첨가해서 필터 수나 러닝 레이트만 조절해봄\n",
    "#이번 model_10은 LeNet 참고하여 비슷한 구조로 얕게 층 쌓음 - 훈련 모델에 대한 오버피팅 심함\n",
    "\n",
    "#conv 층과 maxpooling 층에 strides=2 추가해서 해봄\n",
    "\n",
    "#randomsearch로 learning rate 등 하이퍼 파라미터 조절해보기\n",
    "#차라리 learning rate 줄이고 많이 시도? 진동하는 경향이 좀 보임 epoch 75부터 계~~~~속 0.7대 유지 - epoch 161 아직도 탈출 못함\n",
    "#0.003으로 했을 때 진동하는 듯 해서 0.001로 다시 돌아옴 - 근데 학습률이 낮아도 마찬가지로 local 최적에 빠지지 않을까? - global 최적 찾을 방법은??\n",
    "#이것도 진동에 빠진다면 0.002로 시도해보기\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PD-P4Jt4MoI7"
   },
   "outputs": [],
   "source": [
    "#model_11 - 모델 10에서 Leaky ReLU나 PReLU나 Maxout 시도해보기\n",
    "#아무튼 적당한 활성화 함수 찾은 후 RandomSearch로 하이퍼파라미터 최적화\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from keras import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dropout,\n",
    "    Flatten, Dense, Input, Concatenate, LeakyReLU, PReLU, \n",
    "    Add, Activation, BatchNormalization, MaxPooling2D\n",
    ")\n",
    "\n",
    "#데이터 증강\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.1, #10퍼센트 확대\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1)\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal', input_shape = train_X.shape[1:]))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(16, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1597999558839,
     "user": {
      "displayName": "피자치즈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ4P6BaNTGcVVotmUSqhc7XW3XdSFyT9bNAKBTCg=s64",
      "userId": "09924732654346687849"
     },
     "user_tz": -540
    },
    "id": "RkVofda0MsDp",
    "outputId": "303bc178-314a-4b69-a342-b6fb04ffc8c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1174 (Conv2D)         (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_600 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1175 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_601 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1176 (Conv2D)         (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_602 (LeakyReLU)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1177 (Conv2D)         (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_603 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1178 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_604 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1179 (Conv2D)         (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_605 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1180 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_606 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1181 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_607 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1182 (Conv2D)         (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_608 (LeakyReLU)  (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_28  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_609 (LeakyReLU)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 124,048\n",
      "Trainable params: 124,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_fn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UJzxDuhMvcE"
   },
   "outputs": [],
   "source": [
    "#각 epoch마다 learning rate 낮춰줌\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.975 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ByQCa6DAMyRv",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 230\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_y, batch_size=batch_size),\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=train_X.shape[0]//batch_size,\n",
    "    validation_data=(valid_X,valid_y),\n",
    "    verbose=1,\n",
    "    callbacks=[annealer]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"CNN: Epochs={epochs:d}, \" +\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8AWxmI1RF-1"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(valid_X, valid_y, verbose=2)\n",
    "print('테스트 손실함수:', test_loss, '\\n테스트 정확도:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vr35rvIqPNUu"
   },
   "source": [
    "시도해볼 것: maxout은 dropout과 함께 쓰면 효과가 좋은 활성화함수라고 함\n",
    "    - maxout 적용 예제 / 코드 찾아서 직접 사용해보기\n",
    "    - maxout의 단점은 파라미터의 수가 두배가 된다는 점\n",
    "             maxpooling만 쓰지 말고 각 방법의 장단점 파악 후 새롭게 적용해보기\n",
    "\n",
    "Summary\n",
    "Stanford의 CS231n 강의에서는 다음과 같은 순서로 Activation function을 시도해볼 것을 권한다.\n",
    "\n",
    "(1) ReLU를 사용하자.\n",
    "\n",
    "(2) 성능이 만족스럽지 않다면, LeakyReLU, Maxout, ELU를 사용하라.\n",
    "\n",
    "(3) 그래도 만족스럽지 않다면, tanh를 사용하라. 하지만 많은 기대는 하지말자.\n",
    "\n",
    "(4) 그러나 Sigmoid는 사용하지 말라.\n",
    "\n",
    "실무적으로는 ReLU를 가장 많이 사용하며, LeakyReLU/Maxout/ELU도 좋은 선택지가 될 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XskrI2jTrcn"
   },
   "source": [
    "learning rate 점점 감소 시켰을 때: 0.7941\n",
    "\n",
    "그냥 없이 했을 때: 0.8284\n",
    "\n",
    "model_5: train - 0.87, valid - 0.82\n",
    "\n",
    "model_6: Train accuracy=0.89975, Validation accuracy=0.82195\n",
    "\n",
    "강아지 품종 분류 cnn, 데이터 부풀리기 비교 예제\n",
    "\n",
    "# https://lsjsj92.tistory.com/387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_GEq195_R9L"
   },
   "source": [
    "cnn\n",
    "# https://m.blog.naver.com/laonple/221212462034\n",
    "\n",
    "https://m.blog.naver.com/laonple/220808903260\n",
    "\n",
    "# https://buomsoo-kim.github.io/keras/2018/05/05/Easy-deep-learning-with-Keras-11.md/\n",
    "\n",
    "https://machine-geon.tistory.com/46\n",
    "\n",
    "https://excelsior-cjh.tistory.com/152\n",
    "\n",
    "cnn 정확도 높이기\n",
    "\n",
    "https://manofconcrete.blogspot.com/2019/12/mnist-hands-on-3.html\n",
    "\n",
    "randpm search vs grid search\n",
    "\n",
    "https://shwksl101.github.io/ml/dl/2019/01/30/Hyper_parameter_optimization.html\n",
    "\n",
    "케라스 튜너\n",
    "# https://github.com/keras-team/keras-tuner\n",
    "https://tykimos.github.io/2019/05/10/KerasTuner/\n",
    "\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Md1ua95yr-J"
   },
   "outputs": [],
   "source": [
    "'''def model_fn():\n",
    "    LR = Choice('learning_rate', [0.001, 0.0005, 0.0001], group='optimizer')\n",
    "    DROPOUT_RATE = Linear('dropout_rate', 0.0, 0.5, 5, group='dense')\n",
    "    NUM_DIMS = Range('num_dims', 8, 32, 8, group='dense')\n",
    "    NUM_LAYERS = Range('num_layers', 1, 3, group='dense')\n",
    "    L2_NUM_FILTERS = Range('l2_num_filters', 8, 64, 8, group='cnn')\n",
    "    L1_NUM_FILTERS = Range('l1_num_filters', 8, 64, 8, group='cnn')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(L1_NUM_FILTERS, kernel_size=(3, 3), activation='relu'), input_shape = train_X.shape[1:])\n",
    "    model.add(Conv2D(L2_NUM_FILTERS, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    for _ in range(NUM_LAYERS):\n",
    "        model.add(Dense(NUM_DIMS, activation='relu'))\n",
    "        model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(LR), metrics=['accuracy'])\n",
    "\n",
    "    return model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6uEnvE_8RF-3"
   },
   "outputs": [],
   "source": [
    "'''def create_cnn_model(train_x):\n",
    "    inputs = tf.keras.layers.Input(train_x.shape[1:])\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    conv = tf.keras.layers.Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu')(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2,2))(conv)\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(pool)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    pool = tf.keras.layers.MaxPooling2D((2,2))(conv)\n",
    "    \n",
    "    flatten = tf.keras.layers.Flatten()(pool)\n",
    "    \n",
    "    bn = tf.keras.layers.BatchNormalization()(flatten)\n",
    "    dense = tf.keras.layers.Dense(1000, activation='relu')(bn)\n",
    "\n",
    "    bn = tf.keras.layers.BatchNormalization()(dense)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(bn)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvsh_fosRF-5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''model = create_cnn_model(train_X)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=20)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cEvNqqJeRF-8"
   },
   "outputs": [],
   "source": [
    "'''test_loss, test_acc = model.evaluate(valid_X, valid_y, verbose=2)\n",
    "print('테스트 손실함수:', test_loss, '\\n테스트 정확도:', test_acc)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcIjWCcoRF-_"
   },
   "source": [
    "https://excelsior-cjh.tistory.com/152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8lDYw1oRF-_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "train = pd.read_csv('./data/cvision/train.csv')\n",
    "train_x = train.iloc[:,3:].values.reshape(-1,28,28)\n",
    "data = train_x[0]\n",
    "data.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZiVdnh4RF_C"
   },
   "outputs": [],
   "source": [
    "'''#상하좌우 이동\n",
    "samples = np.expand_dims(data, 0)\n",
    "\n",
    "#Generator 생성\n",
    "#range를 설정해 얼마나 움직일지 정해줌\n",
    "gen = ImageDataGenerator(width_shift_range=[-10,10])\n",
    "\n",
    "#figure 생성\n",
    "fig = plt.figure(figsize=(28,28))\n",
    "\n",
    "#it\n",
    "it = gen.flow(samples, batch_size=1)\n",
    "\n",
    "#9개 이미지 생성\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    \n",
    "    batch = it.next()\n",
    "    img = batch[0].astype('uint8')\n",
    "    \n",
    "    #plot raw pixel data\n",
    "    plt.imshow(img)\n",
    "    \n",
    "#show the figure\n",
    "plt.title('moving')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P75WrD3Zkzfb"
   },
   "outputs": [],
   "source": [
    "#ResNet - Residual Block\n",
    "\n",
    "'''\n",
    "from keras import layers\n",
    "\n",
    "def residual_block(x, filters_in, filters_out, k_size):\n",
    "    shortcut = x\n",
    "    x = layers.Conv2D(filters_in, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters_in, kernel_size=(k_size, k_size), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)    \n",
    "    \n",
    "    x = layers.Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    shortcut_channel = x.shape.as_list()[-1]\n",
    "    \n",
    "    if shortcut_channel != filters_out:\n",
    "        shortcut = layers.Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(shortcut)\n",
    "        \n",
    "    x = layers.Add()([x, shortcut])\n",
    "    return layers.LeakyReLU()(x)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Co_cvision_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
