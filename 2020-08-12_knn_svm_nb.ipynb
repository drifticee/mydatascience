{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "#모든 특성을 고르게 반영하기 위해 정규화 필요\n",
    "#k가 너무 작으면 오버피팅 / 반대도 발생 가능\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "standardizer = StandardScaler()\n",
    "features_standardized = standardizer.fit_transform(features)\n",
    "\n",
    "#k=2\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors=2).fit(features_standardized)\n",
    "new_observation = [1,1,1,1]\n",
    "\n",
    "distances, indices = nearest_neighbors.kneighbors([new_observation])\n",
    "print('최근접 이웃 확인:', features_standardized[indices])\n",
    "\n",
    "nearestneighbors_euclidean = NearestNeighbors(n_neighbors=2, metric='euclidean').fit(features_standardized)\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k=3\n",
    "nearestneighbors_euclidean = NearestNeighbors(n_neighbors=3, metric=\"euclidean\").fit(features_standardized) \n",
    "\n",
    "nearest_neighbors_with_self = nearestneighbors_euclidean.kneighbors_graph(features_standardized).toarray()\n",
    "for i, x in enumerate(nearest_neighbors_with_self):\n",
    "    x[i] = 0\n",
    "    \n",
    "nearest_neighbors_with_self[0]\n",
    "\n",
    "# 첫 번째 샘플에 대한 두 개의 최근접 이웃을 확인합니다.\n",
    "print(nearest_neighbors_with_self[0])\n",
    "\n",
    "# 이 샘플과 가장 가까운 이웃의 다섯개의 인덱스를 찾습니다.\n",
    "indices = nearest_neighbors.kneighbors([new_observation], n_neighbors=5, return_distance=False)\n",
    "features_standardized[indices] # 최근접 이웃을 확인\n",
    "\n",
    "# 반경 0.5 안에 있는 모든 샘플의 인덱스를 찾습니다.\n",
    "indices = nearest_neighbors.radius_neighbors([new_observation], radius=0.5, return_distance=False)\n",
    "features_standardized[indices[0]] # 반경 내의 이웃을 확인\n",
    "\n",
    "# 반경 내의 이웃을 나타내는 리스트의 리스트\n",
    "nearest_neighbors_with_self = nearest_neighbors.radius_neighbors_graph( [new_observation], radius=0.5).toarray()\n",
    "nearest_neighbors_with_self[0] # 첫 번째 샘플에 대한 반경 내의 이웃을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "standardizer = StandardScaler() # 표준화 객체\n",
    "X_std = standardizer.fit_transform(X) # 특성을 표준화\n",
    "\n",
    "# 5개의 이웃을 사용한 KNN 분류기를 훈련합니다.\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1).fit(X_std, y)\n",
    "new_observations = [[0.75, 0.75, 0.75, 0.75],\n",
    "                    [1, 1, 1, 1]] # 두 개의 샘플을 만듭니다.\n",
    "\n",
    "print(knn.predict(new_observations)) # 두 샘플의 클래스를 예측\n",
    "print(knn.predict_proba(new_observations)) # 각 샘플이 세 클래스에 속할 확률을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston() # 데이터 로드\n",
    "features = boston.data[:,0:2] #두 개의 특성만 선택\n",
    "target = boston.target\n",
    "\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=10) # 최근접 회귀 모델 객체 생성\n",
    "model = knn_regressor.fit(features, target) # 모델 훈련\n",
    "\n",
    "# 첫 번째 샘플의 타깃 값을 예측하고 1000을 곱합니다.\n",
    "print(model.predict(features[0:1])[0]*1000)\n",
    "\n",
    "import numpy as np\n",
    "indices = model.kneighbors(features[0:1], return_distance=False) #첫 예측값의 neighbors의 index인 indices\n",
    "np.mean(target[indices]) * 1000 #단위가 천 달러이므로 곱하기 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV로 KNN의 k값 결정\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "standardizer = StandardScaler() # 표준화 객체 생성\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1) # KNN 분류기 객체 생성\n",
    "pipe = Pipeline([(\"standardizer\", standardizer),\n",
    "                 (\"knn\", knn)]) # 파이프라인 생성\n",
    "\n",
    "# 탐색 영역의 후보를 만듭니다.\n",
    "search_space = [{\"knn__n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "classifier = GridSearchCV(pipe, search_space, cv=5, verbose=0).fit(features, target)\n",
    "\n",
    "# 최선의 이웃 개수 (k)\n",
    "classifier.best_estimator_.get_params()[\"knn__n_neighbors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris() #데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "standardizer = StandardScaler() #표준화 객체 생성\n",
    "features_standardized = standardizer.fit_transform(features) #특성을 표준화\n",
    "\n",
    "#반지름 이웃 분류기를 훈련합니다.\n",
    "rnn = RadiusNeighborsClassifier(radius=.5, n_jobs=-1).fit(features_standardized, target)\n",
    "new_observations = [[1, 1, 1, 1]] #두 개의 샘플을 만듭니다.\n",
    "rnn.predict(new_observations) #두 샘플의 클래스를 예측\n",
    "\n",
    "#반지름 이웃 분류기를 훈련합니다.\n",
    "rnn = RadiusNeighborsClassifier(radius=.5, outlier_label=-1, n_jobs=-1).fit(features_standardized, target)\n",
    "rnn.predict([[100, 100, 100, 100]]) #값이 너무 커서 outlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data[:100,:2] #두 개의 클래스와 두 개의 특성만 선택\n",
    "target = iris.target[:100]\n",
    "\n",
    "scaler = StandardScaler() # 특성 표준화\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "svc = LinearSVC(C=1.0) # 서포트 벡터 분류기 생성\n",
    "model = svc.fit(features_standardized, target) # 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# 클래스를 색으로 구분한 산점도를 그립니다.\n",
    "color = [\"black\" if c == 0 else \"lightgrey\" for c in target]\n",
    "plt.scatter(features_standardized[:,0], features_standardized[:,1], c=color)\n",
    "w = svc.coef_[0] # 초평면을 만듭니다.\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(-2.5, 2.5)\n",
    "yy = a * xx - (svc.intercept_[0]) / w[1]\n",
    "plt.plot(xx, yy) # 초평면을 그립니다.\n",
    "plt.axis(\"off\"), plt.show();\n",
    "new_observation = [[ -2, 3]] # 새로운 샘플을 만듭니다.\n",
    "svc.predict(new_observation) # 새로운 샘플의 클래스를 예측\n",
    "svc.decision_function(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "np.random.seed(0) # 랜덤 시드를 지정\n",
    "features = np.random.randn(200, 2) # 두 개의 특성을 만듭니다.\n",
    "# XOR 연산(이것이 무엇인지 알 필요는 없습니다)을 사용하여\n",
    "# 선형적으로 구분할 수 없는 클래스를 만듭니다.\n",
    "target_xor = np.logical_xor(features[:, 0] > 0, features[:, 1] > 0)\n",
    "target = np.where(target_xor, 0, 1)\n",
    "# 방사 기저 함수 커널을 사용한 서포트 벡터 머신을 만듭니다.\n",
    "svc = SVC(kernel=\"rbf\", random_state=0, gamma=1, C=1)\n",
    "model = svc.fit(features, target) # 분류기 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플과 결정 경계를 그립니다.\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_decision_regions(X, y, classifier):\n",
    "cmap = ListedColormap((\"red\", \"blue\"))\n",
    "xx1, xx2 = np.meshgrid(np.arange(-3, 3, 0.02), np.arange(-3, 3, 0.02))\n",
    "Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "Z = Z.reshape(xx1.shape)\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.1, cmap=cmap)\n",
    "for idx, cl in enumerate(np.unique(y)):\n",
    "plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "alpha=0.8, c=cmap.colors[idx],\n",
    "marker=\"+\", label=cl)\n",
    "# 선형 커널을 사용한 서포트 벡터 분류기를 만듭니다.\n",
    "svc_linear = SVC(kernel=\"linear\", random_state=0, C=1)\n",
    "svc_linear.fit(features, target) # 모델 훈련\n",
    "plot_decision_regions(features, target, classifier=svc_linear) # 샘플과 초평면을 그립니다.\n",
    "plt.axis(\"off\"), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "scaler = StandardScaler() # 특성 표준화\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "# 서포트 벡터 분류기 객체 생성\n",
    "svc = SVC(kernel=\"linear\", probability=True, random_state=0)\n",
    "model = svc.fit(features_standardized, target) # 분류기 훈련\n",
    "new_observation = [[.4, .4, .4, .4]] #New Sample Data\n",
    "model.predict_proba(new_observation) # 예측 확률 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "iris = datasets.load_iris() #데이터 로드\n",
    "features = iris.data[:100,:] #두 개의 클래스만 선택\n",
    "target = iris.target[:100]\n",
    "scaler = StandardScaler() # 특성을 표준화\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "svc = SVC(kernel=\"linear\", random_state=0) # 서포트 벡터 분류기 객체 생성\n",
    "model = svc.fit(features_standardized, target) # 분류기 훈련\n",
    "model.support_vectors_ # 서포트 벡터를 확인\n",
    "model.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "iris = datasets.load_iris() #데이터 로드\n",
    "features = iris.data[:100,:] #두 개의 클래스만 선택\n",
    "target = iris.target[:100]\n",
    "features = features[40:,:] # 처음 40개 샘플을 제거\n",
    "target = target[40:] #불균형한 클래스를 만듭니다.\n",
    "# 타깃 벡터에서 0이 아닌 클래스는 모두 1로 만듭니다.\n",
    "target = np.where((target == 0), 0, 1)\n",
    "scaler = StandardScaler() # 특성을 표준화\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "svc = SVC(kernel=\"linear\", class_weight=\"balanced\", C=1.0, random_state=0)\n",
    "model = svc.fit(features_standardized, target) # 분류기 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "classifer = GaussianNB() # 가우시안 나이브 베이지 객체 생성\n",
    "model = classifer.fit(features, target) # 모델 훈련\n",
    "new_observation = [[ 4, 4, 4, 0.4]] #New Sample Data\n",
    "model.predict(new_observation) # 클래스 예측\n",
    "# 각 클래스별 사전 확률을 지정한 가우시안 나이브 베이즈 객체 생성\n",
    "clf = GaussianNB(priors=[0.25, 0.25, 0.5])\n",
    "model = classifer.fit(features, target) # 모델 훈련\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이산적인 카운트 특성으로 분류기 훈련\n",
    "#텍스트 분류 예측\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                      'Brazil is best',\n",
    "                      'Germany beats both'])\n",
    "count = CountVectorizer() #bag of words 객체 생성\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "features = bag_of_words.toarray()\n",
    "target = np.array([0,0,1])\n",
    "\n",
    "#MultinomialNB를 사용해 두 클래스(brazil과 germany)에 대한 사전 확률을 지정하여 모델을 훈련\n",
    "#각 클래스별 사전확률을 지정한 다항 나이브 베이즈 객체 생성\n",
    "clf = MultinomialNB(class_prior=[0.25,0.5])\n",
    "model = clf.fit(features, target)\n",
    "new_observation = ([[0,0,0,1,0,1,0],\n",
    "                   [1,1,0,1,0,0,0]])\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이진 특성으로 나이브 베이지 분류기 훈련(베르누이)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#세 개의 이진 특성을 만듭니다\n",
    "features = np.random.randint(2, size=(100,3))\n",
    "\n",
    "#이진 타깃 벡터를 만듭니다.\n",
    "target = np.random.randint(2, size=(100,1)).ravel()\n",
    "\n",
    "#각 클래스별 사전 확률을 지정하여 베르누이 나이브 베이즈 객체 생성\n",
    "clf = BernoulliNB(class_prior=[0.25,0.5])\n",
    "model = clf.fit(features,target)\n",
    "\n",
    "#10개의 observations에 대한 예측\n",
    "model.predict(np.random.randint(2, size=(10,3)))\n",
    "\n",
    "#clf = BernoulliNB(class_prior=None, fit_prior=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#나이브 베이즈에서는 타깃 클래스에 대한 예측 확률의 순위는 유효하지만\n",
    "#예측 확률이 0 또는 1에 극단적으로 가까워지는 경향이 있음\n",
    "#이를 CalibratedClassifierCV 를 이용해 보정하여 의미 있는 예측 확률을 얻을 수 있음\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "#가우시안 나이브 객체를 생성\n",
    "clf = GaussianNB()\n",
    "\n",
    "#시그모이드 보정을 사용해 보정 교차 검증을 만듭니다.\n",
    "clf_sigmoid = CalibratedClassifierCV(clf, cv=2, method='sigmoid')\n",
    "clf_sigmoid.fit(features, target)\n",
    "\n",
    "new_observation = [[2.6,2.6,2.6,0.4]]\n",
    "\n",
    "print('원본 확률값:', clf.fit(features, target).predict_proba(new_observation)) #원본 분류기의 확률값들\n",
    "print('보정된 값:', clf_sigmoid.predict_proba(new_observation)) #보정한 확률값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit([\"첫번째 문서 테스트\", \"두번째 문서 테스트\"])\n",
    "\n",
    "#['두번째', '문서', '첫번째', '테스트'] - 단어 오름차순?\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "counts = vectorizer.transform(['직접 첫번째 테스트 두번째 테스트'])\n",
    "counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "#clf.fit(counts, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering - 비지도 학습, 샘플의 그룹 식별\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "\n",
    "scaler = StandardScaler() # 특성 표준화\n",
    "features_std = scaler.fit_transform(features)\n",
    "\n",
    "cluster = KMeans(n_clusters=3, random_state=0, n_jobs=-1) # k-평균 객체 생성\n",
    "model = cluster.fit(features_std) # 모델 훈련\n",
    "\n",
    "print('예측', model.labels_) # 예측 클래스 확인\n",
    "print('실제', iris.target) # 진짜 클래스 확인\n",
    "\n",
    "new_observation = [[0.8, 0.8, 0.8, 0.8]] #New Sample Data\n",
    "print('예측:', model.predict(new_observation)) # 샘플의 클러스터를 예측\n",
    "model.cluster_centers_ #중심점에 가장 가까운 샘플들(세 개) 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.inertia_\n",
    "model.score(features_std)\n",
    "model.transform(new_observation)\n",
    "\n",
    "inertia = []\n",
    "for n in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=n, random_state=0, n_jobs=-1)\n",
    "    inertia.append(kmeans.fit(features_std).inertia_)\n",
    "\n",
    "#시각화\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, 10), inertia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#미니배치 k-평균은 랜덤 샘플에 대해서만 수행 - 성능을 조금 희생하고 학습 시간 대폭 줄임\n",
    "#매개변수 batch_size는 각 배치에 선택할 샘플의 수\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)\n",
    "\n",
    "cluster = MiniBatchKMeans(n_clusters=3,\n",
    "                          random_state=0,\n",
    "                          batch_size=100)\n",
    "model = cluster.fit(features_std)\n",
    "model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_kmeans = MiniBatchKMeans()\n",
    "for i in range(3):\n",
    "    mb_kmeans.partial_fit(features_std[i*50:(i+1)*50])\n",
    "    #훈련 세트가 너무 클 때 하나의 넘파이 배열로 전달하기 어려움\n",
    "    #데이터를 조금씩 전달하며 훈련하는 partial_fit() 사용\n",
    "\n",
    "mb_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균이동을 사용한 군집 - 거리 중심이 아닌 밀도 중심?\n",
    "#클러스터 수와 모양을 가정하지 않음\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)\n",
    "\n",
    "cluster = MeanShift(n_jobs=-1)\n",
    "model = cluster.fit(features_std)\n",
    "\n",
    "print(model.labels_)\n",
    "print(model.cluster_centers_) #중심점에 가장 가까운 샘플 둘 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris_df = pd.DataFrame(data=iris.data,\n",
    "                       columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++',\n",
    "               max_iter=300, random_state=0)\n",
    "kmeans.fit(iris_df)\n",
    "\n",
    "print(kmeans.labels_)\n",
    "\n",
    "iris_df['target'] = iris.target\n",
    "iris_df['cluster'] = kmeans.labels_\n",
    "iris_result = iris_df.groupby(['target', 'cluster'])['sepal_width'].count()\n",
    "#target과 cluster로 묶어서 count로 출력(count할 index는 상관 x 세기만 하면 됨)\n",
    "print(iris_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전통적인 K-Means는 아래와 같은 원리로 진행된다.\n",
    "\n",
    "일단 K개의 임의의 중심점(centroid)을 배치하고 각 데이터들을 가장 가까운 중심점으로 할당한다. (일종의 군집을 형성한다.) 군집으로 지정된 데이터들을 기반으로 해당 군집의 중심점을 업데이트한다. 2번, 3번 단계를 그래서 수렴이 될 때까지, 즉 더이상 중심점이 업데이트 되지 않을 때까지 반복한다. 그러나 K-Means++는 좀 다르다. K-Means에서 가장 첫번째 단계, 즉 중심점을 배치하는 걸 그냥 임의로 하는 대신 좀 더 신중하게(?) 하는 거다.\n",
    "\n",
    "(일단 아무 공간에나 중심점을 k개 찍고 시작하는 게 아니라) 가지고 있는 데이터 포인트 중에서 무작위로 1개를 선택하여 그 녀석을 첫번째 중심점으로 지정한다. 나머지 데이터 포인트들에 대해 그 첫번째 중심점까지의 거리를 계산한다. 두번째 중심점은 각 점들로부터 거리비례 확률에 따라 선택한다. (뭔 소리야?) 즉, 이미 지정된 중심점으로부터 최대한 먼 곳에 배치된 데이터포인트를 그 다음 중심점으로 지정한다는 뜻이다. 중심점이 k개가 될 때까지 2, 3번을 반복한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2) (200,)\n",
      "[0 1 2] [67 67 66]\n"
     ]
    }
   ],
   "source": [
    "#클러스터 알고리즘 테스트\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X, y = make_blobs(n_samples=200, n_features=2,\n",
    "                  centers=3, cluster_std=0.8,\n",
    "                  random_state=0)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "unique, counts = np.unique(y, return_counts = True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ftr1</th>\n",
       "      <th>ftr2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.692427</td>\n",
       "      <td>3.622025</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.697940</td>\n",
       "      <td>4.428867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.100228</td>\n",
       "      <td>4.606317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.448724</td>\n",
       "      <td>3.384245</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.214861</td>\n",
       "      <td>5.364896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.908302</td>\n",
       "      <td>1.970778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.472119</td>\n",
       "      <td>0.437033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.656842</td>\n",
       "      <td>2.441289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.077800</td>\n",
       "      <td>4.625379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.679427</td>\n",
       "      <td>2.602003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ftr1      ftr2  target\n",
       "0 -1.692427  3.622025       2\n",
       "1  0.697940  4.428867       0\n",
       "2  1.100228  4.606317       0\n",
       "3 -1.448724  3.384245       2\n",
       "4  1.214861  5.364896       0\n",
       "5 -0.908302  1.970778       2\n",
       "6  2.472119  0.437033       1\n",
       "7  1.656842  2.441289       1\n",
       "8  1.077800  4.625379       0\n",
       "9 -1.679427  2.602003       2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_df = pd.DataFrame(data=X, columns=['ftr1', 'ftr2'])\n",
    "cluster_df['target'] = y\n",
    "cluster_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KMeans 객체를 이용하여 X 데이터를 K-Means 클러스터링 수행\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++',\n",
    "                max_iter=200, random_state=0)\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "cluster_df['kmeans_label'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_centers_는 개별 클러스터의 중심 위치 좌표 시각화를 위해 추출\n",
    "centers = kmeans.cluster_centers_\n",
    "unique_labels = np.unique(cluster_labels)\n",
    "markers = ['o', 's', 'p', 'P', 'D', 'H', 'x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#군집된 label 유형별로 iteration 하면서 marker별로 scatter plot 시각화\n",
    "#먼저 샘플들 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_cluster = cluster_df[cluster_df['kmeans_label'] == label]\n",
    "    center_x_y = centers[label]\n",
    "    plt.scatter(x=label_cluster['ftr1'],\n",
    "                y=label_cluster['ftr2'],\n",
    "                edgecolor='k',\n",
    "                marker=markers[label]) #마커 모양\n",
    "    \n",
    "    #군집별 중심 위치 좌표 시각화\n",
    "    #하얀 중심원\n",
    "    plt.scatter(x=center_x_y[0], y=center_x_y[1],\n",
    "               s=350, color='white', alpha=0.9,\n",
    "               edgecolor='k', marker=markers[label]) #샘플의 마커 모양 따라서\n",
    "    #그 안에 군집 숫자\n",
    "    plt.scatter(x=center_x_y[0], y=center_x_y[1],\n",
    "               s=70, color='k', edgecolor='k',\n",
    "                marker='$%d$' % label) #중심 좌표에 라벨 숫자 표시    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_df.groupby('target')['kmeans_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "feature_names = ['sepal_length', 'sepal_width',\n",
    "                 'petal_length', 'petal_width']\n",
    "iris_df = pd.DataFrame(data=iris.data,\n",
    "                       columns=feature_names)\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++',\n",
    "               max_iter=300, random_state=0).fit(iris_df)\n",
    "iris_df['cluster'] = kmeans.labels_ #예측 군집을 df에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "#iris의 모든 개별 데이터에 실루엣 계수값을 구함\n",
    "#실루엣 계수: -1~1, 1에 가까울수록 군집화가 잘 된 것\n",
    "score_samples = silhouette_samples(iris.data, iris_df['cluster'])\n",
    "print('silhouette_samples() return 값의 shape', score_samples.shape)\n",
    "\n",
    "#iris_df에 실루엣 계수 컬럼 추가\n",
    "iris_df['silhouette_coeff'] = score_samples\n",
    "\n",
    "#모든 데이터의 평균 실루엣 계수값을 구함\n",
    "average_score = np.mean(score_samples)\n",
    "print('total average silhouette score', average_score)\n",
    "iris_df.groupby('cluster')['silhouette_coeff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Density-based Spatial Clustering of Applications with Noise, DBSCAN\n",
    "#각각의 데이터들에 대해 이웃한 데이터와의 밀도를 계산하며 불특정한 모양의 클러스터를 생성\n",
    "#pdf. 14, page. 13\n",
    "\n",
    "#매개변수 eps: 다른 샘플을 이웃으로 고려하기 위한 최대 거리\n",
    "#min_samples: 핵심 샘플이 되기 위한 eps 내 필요 최소 샘플 수\n",
    "#metric: eps에서 사용할 거리 측정 방식\n",
    "#찾은 핵심 샘플의 인덱스는 core_sample_indices_ 속성에 저장됨\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)\n",
    "\n",
    "cluster = DBSCAN(n_jobs=-1)\n",
    "model = cluster.fit(features_std)\n",
    "model.labels_\n",
    "model.core_sample_indices_\n",
    "cluster.fit_predict(features_std)\n",
    "#-1, 0 1 세 개의 군집으로 나뉘는 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#계층적 병합을 사용한 군집\n",
    "#모든 샘플이 각자 하나의 클러스터로 시작 - 조건에 부합하는 클러스터끼리 병합\n",
    "#종료 조건 도달까지 계속 클러스터가 커짐\n",
    "#ex) 매개변수 linkage에 따라 조건 달라짐\n",
    "#- ward 분산, average 샘플 간 평균 거리, complete 샘플 간 최대 거리 최소화하는 병합 전략\n",
    "#single 두 클러스터 샘플 간의 최소 거리를 최소화하는 병합 전략\n",
    "\n",
    "#affinity: linkage에서 사용할 거리 측정 방식 (minkowski, euclidean 등)\n",
    "#n_clusters: 찾을 클러스터 수 (종료 조건?)\n",
    "#labels_ 속성을 사용해 각 샘플이 속한 클러스터 확인 가능\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering as AggClustering\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)\n",
    "\n",
    "cluster = AggClustering(n_clusters=3)\n",
    "model = cluster.fit(features_std)\n",
    "model.labels_ #클러스터 소속 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.fit_predict(features_std) #그냥 predict는 없고 fit_predict 써야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이차원 시각화 위한 함수\n",
    "def visualize_cluster_plot(clusterobj, dataframe, label_name, iscenter=True):\n",
    "    if iscenter :\n",
    "        centers = clusterobj.cluster_centers_\n",
    "        \n",
    "    unique_labels = np.unique(dataframe[label_name].values)\n",
    "    markers=['o', 's', '^', 'x', '*']\n",
    "    isNoise=False\n",
    "\n",
    "    for label in unique_labels:\n",
    "        label_cluster = dataframe[dataframe[label_name]==label]\n",
    "        if label == -1:\n",
    "            cluster_legend = 'Noise'\n",
    "            isNoise=True\n",
    "        else :\n",
    "            cluster_legend = 'Cluster '+str(label)\n",
    "        \n",
    "        plt.scatter(x=label_cluster['ftr1'], y=label_cluster['ftr2'], s=70,\\\n",
    "                    edgecolor='k', marker=markers[label], label=cluster_legend)\n",
    "        \n",
    "        if iscenter:\n",
    "            center_x_y = centers[label]\n",
    "            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=250, color='white',\n",
    "                        alpha=0.9, edgecolor='k', marker=markers[label])\n",
    "            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=70, color='k',\\\n",
    "                        edgecolor='k', marker='$%d$' % label)\n",
    "    if isNoise:\n",
    "        legend_loc='upper center'\n",
    "    else: legend_loc='upper right'\n",
    "    \n",
    "    plt.legend(loc=legend_loc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris() #데이터 로드\n",
    "\n",
    "feature_names = ['sepal_length', 'sepal_width',\n",
    "                 'petal_length', 'petal_width']\n",
    "iris_df = pd.DataFrame(data=iris.data,\n",
    "                       columns=feature_names) #데이터 df화\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=8,\n",
    "               metric='euclidean')\n",
    "dbscan_labels = dbscan.fit_predict(iris.data)\n",
    "\n",
    "iris_df['dbscan_cluster'] = dbscan_labels #dbscan으로 예측한 라벨\n",
    "iris_df['target'] = iris.target #실제 라벨\n",
    "\n",
    "iris_result = iris_df.groupby(['target'])['dbscan_cluster'].value_counts()\n",
    "iris_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2차원으로 시각화하기 위해 PCA 이용하여 2차원으로 내림\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "pca_transformed = pca.fit_transform(iris.data)\n",
    "\n",
    "#visualize_cluster_plot() 함수는 df 안의 ftr1과 ftr2 열을 이용해 시각화하므로\n",
    "#PCA 변환값을 df의 ftr1, ftr2로 삽입\n",
    "iris_df['ftr1'] = pca_transformed[:,0]\n",
    "iris_df['ftr2'] = pca_transformed[:,1]\n",
    "\n",
    "visualize_cluster_plot(dbscan, iris_df,\n",
    "                       'dbscan_cluster',\n",
    "                       iscenter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Density-based Spatial Clustering of Applications with Noise, DBSCAN\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris() #데이터 로드\n",
    "\n",
    "feature_names = ['sepal_length', 'sepal_width',\n",
    "                 'petal_length', 'petal_width']\n",
    "iris_df = pd.DataFrame(data=iris.data,\n",
    "                       columns=feature_names) #데이터 df화\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "#eps=0.8인 경우\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=8,\n",
    "               metric='euclidean')\n",
    "dbscan_labels = dbscan.fit_predict(iris.data)\n",
    "\n",
    "iris_df['dbscan_cluster'] = dbscan_labels #dbscan으로 예측한 라벨\n",
    "iris_df['target'] = iris.target #실제 라벨\n",
    "\n",
    "iris_result = iris_df.groupby(['target'])['dbscan_cluster'].value_counts()\n",
    "iris_result\n",
    "#훨씬 잘 분류함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=0)\n",
    "pca_transformed = pca.fit_transform(iris.data)\n",
    "\n",
    "#visualize_cluster_plot() 함수는 df 안의 ftr1과 ftr2 열을 이용해 시각화하므로\n",
    "#PCA 변환값을 df의 ftr1, ftr2로 삽입\n",
    "iris_df['ftr1'] = pca_transformed[:,0]\n",
    "iris_df['ftr2'] = pca_transformed[:,1]\n",
    "\n",
    "visualize_cluster_plot(dbscan, iris_df,\n",
    "                       'dbscan_cluster',\n",
    "                       iscenter=False)\n",
    "#핵심 샘플에 더 많이 포함됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
